{"title": "Investigating the impact of generative AI integration on ...", "content": "[Skip to main content](https://www.sciencedirect.com/www.sciencedirect.com#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/www.sciencedirect.com#screen-reader-main-title)\n\n- [View **PDF**](https://www.sciencedirect.com/science/article/pii/S2666920X25001006/pdfft?md5=23a6378fb1531a9e24ae23bdec94d6d2&pid=1-s2.0-S2666920X25001006-main.pdf)\n- Download full issue\n\nSearch ScienceDirect\n\n## Outline\n\n01. [Highlights](https://www.sciencedirect.com/www.sciencedirect.com#abs0015)\n02. [Abstract](https://www.sciencedirect.com/www.sciencedirect.com#abs0010)\n03. [Keywords](https://www.sciencedirect.com/www.sciencedirect.com#kwrds0010)\n04. [1\\. Introduction](https://www.sciencedirect.com/www.sciencedirect.com#sec1)\n05. [2\\. Literature review](https://www.sciencedirect.com/www.sciencedirect.com#sec2)\n06. [3\\. Methods](https://www.sciencedirect.com/www.sciencedirect.com#sec3)\n07. [4\\. Findings](https://www.sciencedirect.com/www.sciencedirect.com#sec4)\n08. [5\\. Discussion and implications](https://www.sciencedirect.com/www.sciencedirect.com#sec5)\n09. [6\\. Conclusion](https://www.sciencedirect.com/www.sciencedirect.com#sec6)\n10. [CRediT authorship contribution statement](https://www.sciencedirect.com/www.sciencedirect.com#sec8)\n11. [Availability of data and material](https://www.sciencedirect.com/www.sciencedirect.com#sec9)\n12. [Ethics approval statement](https://www.sciencedirect.com/www.sciencedirect.com#sec10)\n13. [Funding](https://www.sciencedirect.com/www.sciencedirect.com#sec11)\n14. [Declaration of competing interest](https://www.sciencedirect.com/www.sciencedirect.com#coi0010)\n15. [Acknowledgements](https://www.sciencedirect.com/www.sciencedirect.com#ack0010)\n16. [Appendix 1.](https://www.sciencedirect.com/www.sciencedirect.com#appsec1)\n17. [Appendix 2.](https://www.sciencedirect.com/www.sciencedirect.com#appsec2)\n18. [Appendix 3.](https://www.sciencedirect.com/www.sciencedirect.com#appsec3)\n19. [References](https://www.sciencedirect.com/www.sciencedirect.com#cebib0010)\n\nShow full outline\n\n## Figures (4)\n\n## Tables (14)\n\n1. [Table 1](https://www.sciencedirect.com/www.sciencedirect.com#tbl1)\n2. [Table 2](https://www.sciencedirect.com/www.sciencedirect.com#tbl2)\n3. [Table 3](https://www.sciencedirect.com/www.sciencedirect.com#tbl3)\n4. [Table 4](https://www.sciencedirect.com/www.sciencedirect.com#tbl4)\n5. [Table 5](https://www.sciencedirect.com/www.sciencedirect.com#tbl5)\n6. [Table 6](https://www.sciencedirect.com/www.sciencedirect.com#tbl6)\n\nShow all tables\n\n## [Computers and Education: Artificial Intelligence](https://www.sciencedirect.com/journal/computers-and-education-artificial-intelligence)\n\n[Volume 9](https://www.sciencedirect.com/journal/computers-and-education-artificial-intelligence/vol/9/suppl/C), December 2025, 100460\n\n# Investigating the impact of generative AI integration on the sustenance of higher-order thinking skills and understanding of programming logic\n\nAuthor links open overlay panelJemimahNathanielab, Solomon SundayOyelerecd, JarkkoSuhonena, MattiTedrea\n\nShow more\n\nOutline\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.1016/j.caeai.2025.100460](https://doi.org/10.1016/j.caeai.2025.100460) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S2666920X25001006&orderBeanReset=true)\n\nUnder a Creative Commons [license](http://creativecommons.org/licenses/by/4.0/)\n\nOpen access\n\n## Highlights\n\n- •\nIntegrated GenAI with scaffolding to sustain programming logic and HOTS.\n\n- •\nScaffolding + prompt engineering boosts programming logic and HOTS.\n\n- •\nNovel GenAI-Ped framework prevents overreliance while enhancing programming logic and HOTS.\n\n- •\nMixed-methods reveal students' prompt quality directly impacts learning gains.\n\n- •\nScaffolding prevents overreliance while enhancing creativity in coding tasks.\n\n\n## Abstract\n\nThis study investigates how integrating generative AI (GenAI) with instructional scaffolding and prompt engineering supports higher-order thinking skills (HOTS) and programming logic. A mixed-methods design was used, combining quantitative and qualitative data. The intervention followed a one-group pretest-post-test structure over seven weeks with 25 computer science students with no prior C++ experience. The GenAI-Ped framework guided the design. It combines Bloom's taxonomy, Seelf-Regulated Learning, Universal Design for Learning, and Vygotsky's Zone of Proximal Development. Students received scaffolded support across six instructional phases, including prompt training and guided GenAI use. Quantitative results showed significant gains in problem-solving (applying constructs: _t_ = 2.38, _p_ = 0.013, _d_ = 0.475), critical thinking (conditional reasoning: _t_ = 2.53, _p_ = 0.018, _d_ = 0.506), creativity (applying new ideas: _t_ = 2.28, _p_ = 0.032, _d_ = 0.456), and programming logic (loops: _t_ = 2.78, _p_ = 0.010, _d_ = 0.555). However, smaller gains were observed in code optimization ( _t_ = 1.693, _p_ = 0.103, _d_ = 0.339) and evaluating solutions ( _t_ = 1.732, _p_ = 0.096). Qualitative data, including feedback and GenAI chat logs, showed that prompt specificity and scaffolded feedback improved engagement, HOTS, and programming logic. The novelty of the study lies in its demonstration that the integration of GenAI into programming education using GenAI-Ped framework can sustain HOTS and programming logic while mitigating overreliance. These findings offer a practical model for integrating GenAI into programming education.\n\n- [Previous article in issue](https://www.sciencedirect.com/science/article/pii/S2666920X25001018)\n- [Next article in issue](https://www.sciencedirect.com/science/article/pii/S2666920X25001031)\n\n## Keywords\n\nGenerative AI\n\nProgramming education\n\nHigher-order thinking skills\n\nProblem-solving\n\nCritical thinking\n\nCreativity\n\nProgramming logic\n\n## 1\\. Introduction\n\nProgramming is a complex skill that involves logic, creativity, critical thinking, problem-solving, and attention to detail. As [Lewis (2022)](https://www.sciencedirect.com/www.sciencedirect.com#bib66) notes, programming extends beyond writing code to developing life skills such as resilience and analytical thinking. Due to the complexity involved in programming, traditional classrooms have embraced various technologies, tools, and innovations to enrich the teaching and learning of programming. However, educators still struggle to personalize learning despite available resources, which can make programming instruction overwhelming for educators and students ( [Oyelere, Suhonen, & Laine, 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib116)). Among the latest technologies, generative AI (GenAI) is conspicuous for its ability to transform programming education (Bermejo et al., 2024). These tools offer instant support for tasks such as coding, debugging, algorithm design, and even content generation, making programming more accessible than was previously the case ( [MacNeil et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib70); [Yilmaz & Yilmaz, 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib109)). GenAI has been widely used in generating code ( [Finnie-Ansley et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib37); [Koutcheme et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib61); [Wermelinger, 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib104)), automatically generating programming exercises ( [Zavala & Mendoza, 2018](https://www.sciencedirect.com/www.sciencedirect.com#bib110)), improving error messages ( [Leinonen et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib65)), creating debugging quizzes ( [Logacheva et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib68)), and automating grading ( [González-Calatayud et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bib39); [Ho et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib45)). It also enables code auto-completion (Phung et al., 2023; Savelka et al., 2023a) and serves as programming assistance (Savelka et al., 2023b).\n\nThese GenAI tools are reshaping how students engage with programming concepts and how instructors facilitate learning. The practical relevance of these use cases is evident in a range of studies. For example, [Papadakis (2020)](https://www.sciencedirect.com/www.sciencedirect.com#bib80) found that integrating a game-development approach enhanced novice motivation and basic programming skills. Spasić et al. (2024) highlighted how teachers with no programming backgrounds can leverage GenAI prompts (for instance, “Create a memory game using JavaScript and HTML5”) to generate meaningful instructional content, making GenAI a tool for expanding access to programming education. [Hou et al.’s (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib47) CodeTailor used GenAI to convert buggy student code into Parsons puzzles, helping students debug through structured exploration, thereby increasing engagement. [Chen, Xiao, and Chen (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib18) introduced CoRemix, which supports conceptual understanding by using GenAI-generated visual aids to help novices remix Scratch code. Finally, [Lee et al. (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib64) demonstrated that GenAI's subgoal-oriented guidance enabled learners to complete tasks more quickly than without using GenAI and with increased confidence, underscoring its value in supporting task efficiency and self-efficacy.\n\nHowever, despite the benefits of GenAI tools, uncritical use risks fostering overreliance, potentially weakening understanding of programming logic and higher-order thinking skills (HOTS) such as problem-solving, critical thinking, and creativity ( [Dickey, Bejarano, & Chirayu, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib19); [Kazemitabaar et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib56); Zastudil et al., 2023). Nonetheless, limited empirical research has been conducted that examines the impact of GenAI tools on sustaining HOTS and programming logic. To address this gap, the current study applies the GenAI-Ped framework ( [Nathaniel et al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib77)), which represents a novel approach combining GenAI tools with scaffolding strategies and prompt engineering. The GenAI-Ped framework guided the structure and implementation of the intervention. It integrates Bloom's taxonomy, Universal Design for Learning (UDL), and Vygotsky's Zone of Proximal Development (ZPD) to scaffold students' use of GenAI tools. This ensured that students were gradually supported across six instructional phases, from needs analysis to independent coding and reflection. [Naeem et al. (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib76) and [Dickey, Bejarano, & Chirayu, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib19), have highlighted the importance of guided tasks that promote reflective thinking. [Liao et al. (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib67) showed that a scaffolded ChatGPT system improved computational thinking. Prather et al. (2024) cautioned that AI-generated tasks, while helpful for debugging, may widen metacognitive gaps without proper scaffolding. These studies emphasize the importance of combining GenAI tools with instructional strategies that maintain learners' skills ( [Obaido et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib113))\n\nThe overarching aim of this study is to examine how structured GenAI integration can support and sustain HOTS and programming logic in programming education. The specific objective is to evaluate the extent to which GenAI integration, supported by scaffolding and prompt engineering, enhances the development and sustenance of HOTS and programming logic in programming education. The research is guided by two research questions: (1) To what extent does GenAI integration, with scaffolding and prompt engineering, enhance the development and sustenance of HOTS in programming education? (2) How effectively does GenAI integration, with scaffolding and prompt engineering, sustain and enhance students’ foundational programming logic?\n\nThis study helps educators use GenAI to enhance learning without promoting shallow engagement or overreliance on GenAI. Beyond the classroom, the intervention supports students in building essential skills for the digital workforce, aligning with broader goals like innovation, digital equity, and lifelong learning.\n\n## 2\\. Literature review\n\n### 2.1. Higher-order thinking, programming, and generative AI\n\nHOTS include critical thinking, problem-solving, creativity, communication, and collaboration. HOTS are essential for independent learning and innovation and are globally recognized by the World Economic Forum as key competencies for the digital age ( [Aibin et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib2); [Gendenjamts, 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib38); [Luna, 2015](https://www.sciencedirect.com/www.sciencedirect.com#bib69)). These skills are essential for helping learners develop cognitive flexibility and adaptability in today's world ( [Astuti et al., 2019](https://www.sciencedirect.com/www.sciencedirect.com#bib5); [Maryani et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bib73)). HOTS form the foundation of high-quality human capital ( [Misrom et al., 2020](https://www.sciencedirect.com/www.sciencedirect.com#bib75)) and are often categorized into three domains: transfer (applying knowledge in varied contexts), critical thinking (analyzing and evaluating information), and problem-solving (developing practical solutions; [Brookhart, 2010](https://www.sciencedirect.com/www.sciencedirect.com#bib12)). The significance of HOTS has grown, particularly within global educational frameworks such as those highlighted by [Zhou et al. (2023)](https://www.sciencedirect.com/www.sciencedirect.com#bib111), in which competencies such as analysis, evaluation, and creativity are emphasized as crucial for navigating complex problems ( [Chen, Xiao, & Chen, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib18)). According to [Egbert et al. (2021)](https://www.sciencedirect.com/www.sciencedirect.com#bib29), programming effectively fosters HOTS, particularly among K–12 learners. It encourages students to design solutions, plan logically, and think analytically. The iterative and flexible structure of programming allows students to test strategies and integrate interdisciplinary concepts ( [Fanchamps et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bib34)). It also generates innovative solutions, making it a fertile ground for cultivating both cognitive and creative thinking. These activities support the development of computational thinking ( [Falloon, 2016](https://www.sciencedirect.com/www.sciencedirect.com#bib33); [Sun et al., 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib100)), which is a process that mirrors HOTS through abstraction, decomposition, and algorithmic reasoning.\n\nWith the advancement of educational technology, GenAI has introduced new tools for teaching and learning programming ( [Ahme et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib1)), and ways to support HOTS in programming. Studies show that GenAI tools such as ChatGPT can enhance learning in introductory programming courses by offering explanations of programming concepts, handling complex topics, generating code, and supporting error correction ( [MacNeil et al., 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib71); [Deriba et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib24); [Santos et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib88); [Hartley et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib43); [Ho et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib45)). These tools also improve feedback quality and promote self-paced learning, leading to increased learner confidence and performance ( [Kazemitabaar et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib56); Gardella et al., 2024). However, although GenAI can support critical thinking ( [Yatigammana et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib108)), overdependence on AI-generated solutions may hinder reflective thinking and deep engagement. This is especially true when learners rely on GenAI without understanding the underlying programming principles ( [Kurtz et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib63); [Xue et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib105)). Furthermore, since hands-on practice remains key to developing programming skills, the integration of GenAI must be guided to ensure that it supplements, rather than substitutes for, active learning ( [Logacheva et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib68)). Hence, guidance is required in the integration of GenAI to sustain these skills ( [Dickey, Bejarano, & Chirayu, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib19)).\n\n### 2.2. Impact of GenAI on programming logic understanding\n\nProgramming logic is the foundation of effective coding. It includes core concepts such as loops, conditionals, functions, and control flow. This logic enables learners to translate real-world problems into algorithmic solutions, which is essential for building efficient and maintainable software. These concepts also enable learners to design solutions that are logical, efficient, and adaptable ( [Ibarra-Torres et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib51)). According to Liu (2018), students who understand programming logic can better navigate both procedural and object-oriented paradigms, as they are able to think abstractly and apply concepts across different programming contexts. However, many beginners find programming logic difficult due to its abstract nature and the precision it requires ( [Jonsson & Tholander, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib54)). These challenges can lead to frustration and disengagement. This is where GenAI tools offer unique support. GenAI has the ability to simplify syntax, generate illustrative examples, and streamline development processes ( [Hamadeh, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib42); [Spinellis, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib96)). Unlike traditional environments bound by strict syntax and limited feedback, GenAI can dynamically assist students by providing contextual suggestions and debugging support ( [Jonsson & Tholander, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib54)). This adaptability can help learners overcome common hurdles such as syntax errors and vague semantics ( [Huang et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib50)).\n\nHowever, without guidance, students may become dependent on GenAI, copying and pasting code without understanding how it works. This may result in superficial learning in which students submit correct solutions without understanding the underlying logic ( [Rahe & Maalej, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib84)). [Fernandez and Cornell (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib36) refer to this as the “black-box effect,” in which the code works, but the student cannot explain how or why. This problem is more pronounced when students do not receive guidance on how to interpret or critique GenAI responses.\n\n### 2.3. Mapping students' programming learning with Bloom's taxonomy and pedagogical considerations\n\nBloom's taxonomy provides a structured framework for classifying educational objectives and cognitive processes. This makes it a valuable tool for designing programming instruction ( [Krathwohl, 2002](https://www.sciencedirect.com/www.sciencedirect.com#bib62); [Omer, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib79)). The taxonomy categorizes learning into six hierarchical levels: remembering, understanding, applying, analyzing, evaluating, and creating ( [Rozita et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bib87)). The six levels of the taxonomy offer a framework that allows educators to evaluate the students' knowledge and abilities as they move from simple to complex programming concepts ( [Rozita et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bib87)). The taxonomy also helps educators track HOTS development and adjust instruction to address learning gaps. This is particularly useful in programming in which abstract concepts often confuse beginners ( [Sobral, 2021](https://www.sciencedirect.com/www.sciencedirect.com#bib94)). To maximize the benefits of Bloom's taxonomy, it is necessary to map programming tasks to the taxonomy. This enhances teaching effectiveness by aligning course objectives, instructional strategies, and assessments with specific cognitive levels ( [Cabo, 2015](https://www.sciencedirect.com/www.sciencedirect.com#bib13)). Mapping Bloom taxonomy allows educators to identify gaps in students' understanding of concepts and their ability to successfully apply programming concepts ( [Ullah et al., 2020](https://www.sciencedirect.com/www.sciencedirect.com#bib101)). Mapping has also been effective in addressing the diverse cognitive types defined within the taxonomy ( [Malik, 2019](https://www.sciencedirect.com/www.sciencedirect.com#bib72)).\n\nPedagogical considerations are also vital for ensuring effective learning. These refer to the teaching methods, strategies, and conditions that influence student engagement and comprehension. According to [Strawhacker et al. (2018)](https://www.sciencedirect.com/www.sciencedirect.com#bib98), flexibility in lesson delivery, timely feedback, and active learning strategies all contribute to improved learning outcomes. Their study further suggests that adjusting teaching based on students’ needs enhances learning in early programming education. Research by [Bjursten et al. (2023)](https://www.sciencedirect.com/www.sciencedirect.com#bib10) and ( [Sunday et al., 2020](https://www.sciencedirect.com/www.sciencedirect.com#bib114)) suggests that motivation increases when students are engaged in authentic tasks. For instance, constructivist approaches encourage students to build their own understanding through exploration and reflection ( [Kiesler, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib57); [Sullivan, 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib99)). Project-based learning (PBL) allows learners to apply skills in meaningful contexts ( [Grant, 2011](https://www.sciencedirect.com/www.sciencedirect.com#bib40)). These models promote student autonomy and collaboration, and they are key factors in building problem-solving and creative thinking abilities. However, finding the right teaching method remains challenging, particularly in resource-constrained environments. [Eteng et al. (2022)](https://www.sciencedirect.com/www.sciencedirect.com#bib32) identified that many developing countries lack access to effective programming instruction due to limited infrastructure and trained educators. In this regard, GenAI tools offer new possibilities for supporting diverse pedagogical needs. GenAI offers numerous conventional pedagogical approaches that can improve learning experiences ( [Hazzan & Erez, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib44)), especially in the teaching of introductory programming ( [Stone, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib97)). However, meaningful integration requires a shift in perception, from seeing GenAI as a mere tool to embracing it as a collaborative partner in the learning process ( [Yan, Nakajima, & Sawada, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib107)).\n\n### 2.4. Theoretical aspects, scaffolding, and prompt engineering for GenAI integration in programming education\n\nIn this study, integrating GenAI into programming education is rooted in constructivist learning theories and Vygotsky's ZPD. Constructivism emphasizes that learners build knowledge through experience and interaction ( [Sullivan, 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib99), p. 22), hence, this approach is suitable for programming education. Vygotsky's ZPD also emphasizes scaffolding, which are supportive strategies that help learners move beyond their current abilities with guidance ( [Erdei et al., 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib30)). Scaffolding describes instructional practices that help students extend their knowledge and abilities ( [Belland, 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib8)) and requires due attention to various aspects to maximize learning ( [Devolder et al., 2012](https://www.sciencedirect.com/www.sciencedirect.com#bib25)). Scaffolding can be applied through interactive feedback, guided exercises, and collaborative learning environments, enabling learners to internalize concepts and progressively achieve independence ( [Sentance,Waite, & Kallia, 2019](https://www.sciencedirect.com/www.sciencedirect.com#bib55))\n\nIntegrating scaffolding techniques into GenAI chatbots provides students with a guided experience that accommodates varying levels of learner competence ( [Jin et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib53)), playing an effective role in improving students' comprehension skills ( [Yan, Nakajima, & Sawada, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib107)). For instance, integrating GenAI into high school students' education through scaffolding in a practical learning workshop has positively impacted students’ understanding of GenAI concepts ( [Estevez et al., 2019](https://www.sciencedirect.com/www.sciencedirect.com#bib31)). GenAI tools such as MindScratch showcase that adaptive scaffolding can achieve more effective learning outcomes by facilitating cognitive and creative thinking skills ( [Chen et al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib18)). This suggest that the constructionist prompting model for working with large language models promotes problem-solving ability through natural language programming and prompt engineering ( [Hsu, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib49)) and advocates pedagogical practices that integrate collective project-based and active learning ( [Grant, 2011](https://www.sciencedirect.com/www.sciencedirect.com#bib40)).\n\nPrompt engineering is a new skill emerging from GenAI usage. It involves crafting precise prompts to receive accurate outputs ( [Viswanathan, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib102)). The “Prompt Problems” approach encourages students to create natural language prompts that retrieve correct code from large language models. This fosters computational thinking and helps learners build the key skill of prompt design, an increasingly valuable competency in GenAI-assisted programming ( [Denny et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib23)). According to [Walter (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib103), students' abilities to create effective prompts have the capacity to strongly shape how they interact with GenAI tools. Particularly in programming languages such as C++, prompt engineering plays a vital role in improving the effectiveness of GenAI tools ( [Ramona & Aleksandar, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib85)). Due to the intricacies of C++ programming, such as memory management and its complicated syntax, well-structured prompts are necessary to effectively guide GenAI responses. Hence, to effectively enrich learning experiences for students, guidelines are needed (Mac, 2024). To improve the students' learning process, it is also necessary to design efficient prompts and motivate learners to identify and rectify GenAI's errors while mitigating the risks of overdependence on these tools ( [Dickey, Bejarano, & Chirayu, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib19)).\n\n### 2.5. Mapping HOTS and programming logic to Bloom's taxonomy\n\nThis study applied the GenAI-Ped framework to operationalize these mappings (Nathaniel, et.al., 2025).The framework integrates Bloom's taxonomy into both instructional design and assessment rubrics. Bloom's taxonomy comprises of six levels provides a structured way to assess and support the development of both foundational and advanced programming skills. This ensures that students' use of GenAI supports not only code generation but also HOTS development. For example, problem-solving spans understanding, applying, analyzing, and evaluating stages, as students identify problems, plan and implement solutions, and assess their effectiveness. Critical thinking is essential for debugging and decision-making. It aligns with the evaluating stage of Bloom's taxonomy, in which students justify their choices and refine code. Creativity, which involves developing original and effective solutions, maps to the creating level, encouraging students to integrate novel approaches. These criteria were selected for their relevance to programming education. They also appear in validated tools such as the Computational Thinking Scale ( [Gupta & Mehrotra, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib41); [Korkmaz et al., 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib59)), which this study adapted.\n\n## 3\\. Methods\n\n### 3.1. Research model and participants\n\nThe study employed a one-group pretest-posttest design. It aimed to evaluate the impact of integrating GenAI tools, such as ChatGPT and GitHub Copilot, into programming education. The one-group pretest-posttest design was selected for both practical and ethical reasons. Ethically, it allowed all students to benefit from the intervention, avoiding an unfair control group (Campbell, Stanley, & Gage, 1963). However, because only 30 second-year computer science students volunteered to participate, with five students withdrawing due to personal reasons, the small sample size of 25 made it difficult to divide participants into groups without losing statistical power. To improve reliability, a pre-pretest was conducted before the main pretest to establish an extra baseline performance. The mixed-methods approach ensured methodological triangulation, improving the validity of findings through the convergence of quantitative and qualitative data ( [Creswell, 2014](https://www.sciencedirect.com/www.sciencedirect.com#bib21)).\n\nA non-probabilistic, convenience sampling method was used for the participant selection ( [Novosel, 2023](https://www.sciencedirect.com/www.sciencedirect.com#bib77)). Participants were selected based on availability and willingness. While this method limits the generalizability of the findings, it enabled efficient access to participants within the available institutional and logistical constraints. It also allowed an in-depth exploration of the intervention within a specific educational context.\n\n#### 3.1.1. Reliability and validity\n\nTo ensure reliability, a pre-pretest was conducted to serve as an extra baseline before the main pretest. This step helped confirm that any changes observed in the posttest were due to the intervention rather than natural variability or repeated exposure to the test. This approach aligns with the recommendations of [Campbell and Stanley (1963)](https://www.sciencedirect.com/www.sciencedirect.com#bib15), who emphasize the importance of controlling for testing threats to internal validity in quasi-experimental designs. Additionally, [Dimitrov and Rumrill (2003)](https://www.sciencedirect.com/www.sciencedirect.com#bib27) advocate the use of repeated baseline assessments to strengthen confidence that post-intervention changes are attributable to the treatment, rather than to prior exposure. The pre-pretest thus served as a control measure, enhancing the reliability and internal validity of the study's outcomes. It was adapted from the CTS ( [Korkmaz et al., 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib59)) and Bloom's taxonomy ( [Krathwohl, 2002](https://www.sciencedirect.com/www.sciencedirect.com#bib62)) to create a tailored HOTS scale. The new HOTS scale evaluates four key domains: problem-solving, critical thinking, creativity, and programming logic. For content validity, five experts were consulted to validate the new HOTS scale and programming exercises. Three lecturers and two industry professionals who were familiar with C++ and Bloom's taxonomy performed the grading.\n\n### 3.2. Data collection tools\n\n#### 3.2.1. Quantitative data collection\n\nPretest and posttest programming exercises ( [Appendix 2](https://www.sciencedirect.com/www.sciencedirect.com#appsec2)) were used to measure students' skills before and after the intervention. These exercises were developed from the new HOTS scale, shown in [Appendix 1](https://www.sciencedirect.com/www.sciencedirect.com#appsec1). The rubric used for grading the pretest and posttest tasks was adapted from the multi-dimensional rubrics for analyzing free-choice Scratch programming projects ( [Basu, 2019](https://www.sciencedirect.com/www.sciencedirect.com#bib6)) and the corresponding level of Bloom's taxonomy ( [Gupta & Mehrotra, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib41)) to suit this research.\n\n##### 3.2.1.1. Rubrics\n\nCustom rubrics were categorized into four main areas: problem-solving, critical thinking, creativity, and understanding programming logic. Each category contains specific criteria mapped to Bloom's taxonomy levels and is evaluated on a scale that ranges from Lacking Proficiency (0) to Exceeding Proficiency (4). The code produced by each student was reviewed using the rubric, and a score was assigned based on how well it met the criteria. The rubrics consist of four factors and 28 criteria, as shown in [Appendix 3](https://www.sciencedirect.com/www.sciencedirect.com#appsec3). For example, under “Problem Identification” in the Problem-Solving Rubric, it was necessary to check whether the student correctly identified the problem requirements, and then to determine which part of the rubric each code snippet addressed. For example, a program that sums two numbers relates to “Problem Identification” and “Applying Constructs.” Student 1 wrote “sum = num1 from 2; ”, which was invalid. The correct response should be “sum = num1 + num2; ”. This error indicates incorrect use of operators, so in Understanding Programming Logic - > Use of Operators & Expressions, the score was Lacking (0) because it was incorrect.\n\nAs shown above, the Problem-Solving Rubric ( [Table 1](https://www.sciencedirect.com/www.sciencedirect.com#tbl1), [Appendix 3](https://www.sciencedirect.com/www.sciencedirect.com#appsec3)) evaluates a student's ability to address programming challenges by examining seven key areas. It begins with how effectively they identify and break down a problem, followed by their capacity to clearly define solution requirements. It then assesses their skill in planning a logical approach, applying programming constructs such as loops and conditionals, handling and correcting errors, implementing a functional solution, and, finally, testing that solution thoroughly. The Critical Thinking Rubric measures a student's ability to reason through coding challenges and refine their work. It covers error identification, in which the focus is on spotting both syntactical and logical mistakes. It then looks at debugging strategies recognizing that a student at a Developing level (2) might use basic techniques, while a student at the level of Exceeding Proficiency (4) employs more advanced methods and explains their approach, as shown in [Table 2](https://www.sciencedirect.com/www.sciencedirect.com#tbl2) in [Appendix 3](https://www.sciencedirect.com/www.sciencedirect.com#appsec3). [Table 3](https://www.sciencedirect.com/www.sciencedirect.com#tbl3) in [Appendix 3](https://www.sciencedirect.com/www.sciencedirect.com#appsec3) shows the Creativity Rubric used to assess how students introduce original ideas and innovative solutions into their programming projects. The rubric checks their ability to deliberate on different solution options, extend the problem by adding new dimensions, and integrate fresh ideas into their work. Finally, the Understanding Programming Logic Rubric in [Table 4](https://www.sciencedirect.com/www.sciencedirect.com#tbl4) in [Appendix 3](https://www.sciencedirect.com/www.sciencedirect.com#appsec3) examines a student's command of fundamental coding principles. It evaluates the effective use of variables and further assesses their skill in creating and reusing procedures and functions, using operators and expressions, properly initializing and terminating programs, organizing code clearly, and designing components that can be reused.\n\nTable 1. Kolmogorov-Smirnov (K-S) test result.\n\n| Category | Criterion | K-S Statistic (D) | p value |\n| --- | --- | --- | --- |\n| Problem-solving | Problem Identification | 0.12 | 0.07 |\n| Defining Requirements | 0.11 | 0.09 |\n| Solution Planning | 0.1 | 0.12 |\n| Applying Constructs | 0.13 | 0.05 |\n| Handling Errors | 0.11 | 0.08 |\n| Implementing the Solution | 0.12 | 0.06 |\n| Testing the Solution | 0.1 | 0.11 |\n| Critical Thinking | Error Identification | 0.11 | 0.08 |\n| Debugging Strategies | 0.12 | 0.07 |\n| Optimizing Code | 0.1 | 0.1 |\n| Evaluating Solutions | 0.11 | 0.09 |\n| Use of Logical Constructs | 0.13 | 0.05 |\n| Conditional Thinking | 0.12 | 0.06 |\n| Application of Patterns | 0.1 | 0.11 |\n| Creativity | Originality of Approach | 0.11 | 0.08 |\n| Creative Application of Constructs | 0.12 | 0.07 |\n| Exploring Alternatives | 0.1 | 0.1 |\n| Extending Problem Scope | 0.11 | 0.09 |\n| Application of New Ideas | 0.13 | 0.05 |\n| Experimentation | 0.12 | 0.06 |\n| Innovative Problem Approach | 0.1 | 0.11 |\n| Understanding Programming Logic | Use of Variables | 0.11 | 0.08 |\n| Use of Loops | 0.12 | 0.07 |\n| Use of Conditionals | 0.1 | 0.1 |\n| Use of Operators & Expressions | 0.11 | 0.09 |\n| Program Initialization | 0.13 | 0.05 |\n| Program Termination | 0.12 | 0.06 |\n| Code Organization and Clarity | 0.1 | 0.11 |\n\nTable 2. Comparison of pre-pretest and pretest scores.\n\n| Category | Criterion | Pre-Pretest Mean (SD) | Pretest Mean (SD) | p value |\n| --- | --- | --- | --- | --- |\n| Problem-Solving | Problem Identification | 1.82 (0.61) | 1.84 (0.62) | 0.876 |\n| Defining Requirements | 1.35 (0.75) | 1.36 (0.76) | 0.912 |\n| Solution Planning | 1.67 (0.69) | 1.68 (0.69) | 0.943 |\n| Critical Thinking | Error Identification | 1.31 (0.56) | 1.32 (0.56) | 0.901 |\n| Debugging Strategies | 1.11 (0.44) | 1.12 (0.44) | 0.889 |\n| Conditional Thinking | 1.67 (0.85) | 1.68 (0.85) | 0.935 |\n| Creativity | Originality of Approach | 1.19 (0.50) | 1.20 (0.50) | 0.908 |\n| Application of New Ideas | 1.03 (0.20) | 1.04 (0.20) | 0.920 |\n| Programming Logic | Use of Variables | 1.67 (0.94) | 1.68 (0.95) | 0.942 |\n| Use of Loops | 1.55 (1.04) | 1.56 (1.04) | 0.927 |\n| Program Initialization | 1.75 (0.97) | 1.76 (0.97) | 0.918 |\n\nTable 3. Descriptive statistics for problem-solving skills.\n\n| Criteria | Assessment | Mean | SD |\n| --- | --- | --- | --- |\n| Problem Identification | pretest | 1.840 | 0.624 |\n| posttest | 2.160 | 0.554 |\n| Defining Requirements | pretest | 1.360 | 0.757 |\n| posttest | 1.600 | 0.816 |\n| Solution Planning | pretest | 1.680 | 0.690 |\n| posttest | 2.000 | 0.707 |\n| Applying Constructs | pretest | 1.520 | 0.653 |\n| posttest | 1.880 | 0.666 |\n| Handling Errors | pretest | 1.200 | 0.500 |\n| posttest | 1.480 | 0.586 |\n| Implementing the Solution | pretest | 1.400 | 0.645 |\n| posttest | 1.760 | 0.723 |\n| Testing the Solution | pretest | 1.000 | 0.289 |\n| posttest | 1.200 | 0.500 |\n\nTable 4. Paired samples _t_-test for problem-solving criteria.\n\n| Measure | t value | p value | Cohen's d |\n| --- | --- | --- | --- |\n| Problem Identification | 2.551 | 0.009 | 0.510 |\n| Defining Requirements | 1.809 | 0.041 | 0.362 |\n| Solution Planning | 2.317 | 0.015 | 0.463 |\n| Applying Constructs | 2.377 | 0.013 | 0.475 |\n| Handling Errors | 1.899 | 0.035 | 0.380 |\n| Implementing the Solution | 2.092 | 0.024 | 0.418 |\n| Testing the Solution | 1.732 | 0.048 | 0.346 |\n\nEach criterion is reflected in the study's adapted assessment rubric and was measured through a combination of pre-pretest, pretest, and posttest exercises. By clearly linking these constructs to Bloom's taxonomy and explicitly defining the criteria used, the study ensured theoretical coherence and practical applicability in evaluating the impact of GenAI on student learning outcomes. Each dataset collected in this study was mapped directly to specific HOTS criteria, as outlined in the assessment rubrics shown in [Appendix 3](https://www.sciencedirect.com/www.sciencedirect.com#appsec3).\n\n##### 3.2.1.2. Pre-pretest, pretest, and posttest\n\nTo the best of our knowledge, no standardized tool exists for measuring HOTS. Hence, this study adapted a hybrid version of the CTS by [Korkmaz et al. (2017)](https://www.sciencedirect.com/www.sciencedirect.com#bib59). The scales consist of a Likert-type rating structure with items and subfactors, and the Bloom taxonomy ( [Krathwohl, 2002](https://www.sciencedirect.com/www.sciencedirect.com#bib62); [Chandio et al., 2016](https://www.sciencedirect.com/www.sciencedirect.com#bib16)). Computational thinking is recognized as a fundamental approach for developing problem-solving skills ( [Nathaniel, et.al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib77)). The customized HOTS scale for programming education was created by modifying the five subfactors in the CTS, creativity, algorithmic thinking, cooperativity, critical thinking, and problem-solving, to four subfactors consisting of creativity, understanding of programming logic, critical thinking, and problem-solving. The 29 items that were collected under five factors were also modified to 18 items, as shown in [Appendix 1](https://www.sciencedirect.com/www.sciencedirect.com#appsec1). E-forms were used to collect the data for the pre-pretest, and all items in the instrument were assessed using a 5-point Likert scale, ranging from 1 ( _strongly disagree_) to 5 ( _strongly agree_).\n\nPretest and posttest programming exercises were obtained by converting the items in the HOTS scale, as shown in [Appendix 1](https://www.sciencedirect.com/www.sciencedirect.com#appsec1), to programming tasks. For instance, “I can explain how loops (for, while, do-while) work in programming” was reworded to a programming question: “ _Write a program that prints all numbers from 1 to 10 using a for loop_,” as shown in [Appendix 2](https://www.sciencedirect.com/www.sciencedirect.com#appsec2). For the pretest, students completed baseline programming tasks before the commencement of the intervention, and their solutions were graded using the rubrics to establish initial skill levels. The posttest administered after the intervention was the same as the pretest. Posttest scores were compared to pretest results to measure progress.\n\n#### 3.2.2. Qualitative data collection\n\nQualitative data was obtained through student feedback, code submission, and GenAI chat logs submitted during the intervention. At the end of each phase, students completed structured feedback forms designed to capture their experiences and perceptions of working with GenAI. This feedback included open-ended questions that encouraged learners to express how they engaged with the tools, challenges encountered, and changes in understanding over time. In addition to feedback, students submitted the GenAI chat logs or screenshots of their interactions with the GenAI (ChatGPT). These logs included the prompts students used, the GenAI-generated responses, and any modifications students made to the AI outputs before integrating them into their codes. Code submissions were analyzed to observe how students used GenAI-generated code.This combination allowed for a richer understanding of learner behavior, particularly regarding prompt use, tool interpretation, and strategic adaptation throughout the intervention phases.\n\n### 3.3. Data analysis\n\n#### 3.3.1. Quantitative analysis\n\nThe quantitative data were analyzed using JASP version 0.19.1. Descriptive statistics, including means and standard deviations, were used to summarize overall trends in the students' performance. Inferential statistics, particularly paired samples t-tests and effect sizes (Cohen's d; [Cohen, 1992](https://www.sciencedirect.com/www.sciencedirect.com#bib20)), were employed to evaluate the effectiveness of the intervention. Standard deviation helped to understand the variability of the scores. Inferential statistics provides a broader view of learning trends beyond individual results. The comparison of pretest and posttest means helped determine changes in students' HOTS and understanding of programming logic following the intervention. The paired samples _t_-test was selected because it suits a one-group pretest-posttest quasi-experimental design. This method accounts for within-subject variability and isolates the effect of the intervention by directly comparing each student's performance before and after the learning activities. To ensure the appropriateness of the statistical tests, the normality of the data was assessed using the Kolmogorov-Smirnov (K-S) test. In addition, Cronbach's alpha was used to evaluate the internal consistency of the measurement instrument. However, while Cronbach's alpha provides insights into how well items measure a construct at a single time point, it does not address consistency across time. Therefore, test-retest reliability was used to assess the stability of the instrument and reinforce the validity of the findings.\n\n#### 3.3.2. Qualitative analysis\n\nA thematic approach was used to analyze the qualitative data gathered during the intervention. Qualitative data were drawn from three sources: students feedback, GenAI-generated chat Logs, code submission and prompt logs collected during Phases 2 to 5 of the intervention. It was submitted digitally after each session using structured online forms. Thematic analysis was conducted using [Braun and Clarke's (2006)](https://www.sciencedirect.com/www.sciencedirect.com#bib11), it was used to examine patterns in students' experiences with GenAI tools. Student reflections and GenAI chat logs were reviewed to identify emerging themes and patterns.\n\nStudent reflections and GenAI chat logs were analyzed using NVivo 14. NVivo enabled systematic identification and organization of key themes and patterns related to the integration of GenAI tools in programming education. Prominent and representative student statements were selected to illustrate each theme. This included prompt quality, code use behavior, tool challenges, perceptions of GenAI, and the impact of scaffolding and prompt engineering. The themes were used to structure the reporting in Section [4.5](https://www.sciencedirect.com/www.sciencedirect.com#sec4.5), where one or more illustrative quotes per theme were included to enhance the interpretation of the findings. This process provided insight into how students engaged with the tools and how their interactions influenced learning. This approach ensured efficient data management, coding consistency, and robust theme development throughout the analysis process.\n\n### 3.4. Research environment and procedure\n\nProgramming concepts were introduced using a smartboard. Students engaged in hands-on exercises using their preferred C++ Development Environment. The intervention was conducted over a period of seven weeks (twice a week), with each session lasting 2 h and 30 min. The study took place in a classroom setting and followed a structured instructional timeline. Six weeks of the study involved in-person instruction, while one week was dedicated to completing a programming project outside the classroom. PBL was integrated into the intervention to enhance learner autonomy, promote collaboration, and deepen engagement with programming concepts ( [Grant, 2011](https://www.sciencedirect.com/www.sciencedirect.com#bib40)). The overall structure and flow of the study are summarized in [Fig. 1](https://www.sciencedirect.com/www.sciencedirect.com#fig1). These visuals outline the research process used to integrate GenAI into programming education. This process is guided by the GenAI-Ped framework ( [Nathaniel, et.al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib77)),shown in [Fig. 2](https://www.sciencedirect.com/www.sciencedirect.com#fig2): PBL provided students with opportunities to apply theoretical knowledge in practical, real-world programming tasks, culminating in a capstone project (Formative and summative assessment). Formative and summative tasks were designed to encourage independent thinking, with students using GenAI tools such as ChatGPT for code generation and debugging. Educator guidance was gradually reduced in line with ZPD and PBL's emphasis on student-driven learning ( [Grant, 2011](https://www.sciencedirect.com/www.sciencedirect.com#bib40)). To address internet and electricity challenges, the educator provided additional internet access.\n\n1. [Download: Download high-res image (393KB)](https://ars.els-cdn.com/content/image/1-s2.0-S2666920X25001006-gr1_lrg.jpg)\n2. [Download: Download full-size image](https://ars.els-cdn.com/content/image/1-s2.0-S2666920X25001006-gr1.jpg)\n\nFig. 1. Research process of integrating GenAI into programming education.\n\n1. [Download: Download high-res image (352KB)](https://ars.els-cdn.com/content/image/1-s2.0-S2666920X25001006-gr2_lrg.jpg)\n2. [Download: Download full-size image](https://ars.els-cdn.com/content/image/1-s2.0-S2666920X25001006-gr2.jpg)\n\nFig. 2. The GenAI-Ped framework used in this study. It combines self-regulated learning, Bloom's taxonomy, and prompt engineering techniques to guide structured GenAI integration across six instructional phases ( [Nathaniel, et.al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib77)).\n\nThe study adopted an explanatory, sequential, mixed-methods design, consisting of two main phases ( [Creswell, 2014](https://www.sciencedirect.com/www.sciencedirect.com#bib21)). The first phase focused on quantitative data collection through pre-pretests, pretests, and posttests to assess students' HOTS and foundational programming logic. The second phase involved qualitative data collection through GenAI chat logs, student reflections, and code submissions. The qualitative data were collected for every session. This design enabled the researchers to interpret quantitative findings in greater depth and gain a comprehensive understanding of the intervention's impact.\n\n#### 3.4.1. GenAI-pedagogical framework\n\nGenAI-Ped framework in [Fig. 2](https://www.sciencedirect.com/www.sciencedirect.com#fig2) was built on established pedagogical theories and consisted of six phases. It was adapted from the self-regulated learning (SRL) model by [Prasad and Sane (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib83), which emphasizes learner autonomy through goal setting, monitoring, and reflection. The framework incorporates a needs analysis that tailors instruction to the students' prior knowledge and accessibility requirements ( [Fayzulloeva & Mustafoeva, 2020](https://www.sciencedirect.com/www.sciencedirect.com#bib35)) and prompt-engineering techniques from the AI-Lab framework ( [Dickey, Bejarano, & Chirayu, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib19); [Prasad & Sane, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib83)), which aid in transforming GenAI interactions into deliberate HOT exercises. Finally, Bloom's taxonomy ( [Krathwohl, 2002](https://www.sciencedirect.com/www.sciencedirect.com#bib62)) was incorporated to ensure that learning activities and assessments move beyond basic code writing to involve analysis, evaluation, and creation, along with Universal Design for Learning ( [Roth et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bib86)) principles that guarantee multiple means of engagement and expression.\n\nThe implementation process of GenAI-Ped framework shown in [Fig. 3](https://www.sciencedirect.com/www.sciencedirect.com#fig3), followed six structured phases designed to scaffold learning and support the development of HOTS and programming logic. Phase 1 focused on assessing students’ prior knowledge and identifying learning needs (covered in weeks 1 and 2). A pre-pretest was administered to establish a baseline before the formal pretest. This helped eliminate test familiarity as a confounding factor.\n\n1. [Download: Download high-res image (744KB)](https://ars.els-cdn.com/content/image/1-s2.0-S2666920X25001006-gr3_lrg.jpg)\n2. [Download: Download full-size image](https://ars.els-cdn.com/content/image/1-s2.0-S2666920X25001006-gr3.jpg)\n\nFig. 3. Implementation process of GenAI in programming education (GenAI-Ped) framework ( [Nathaniel, et.al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib77)).\n\nThis was followed by a formal pretest to assess students' actual starting points (students’ prior knowledge). The results of the pre-pretest and pretest were compared to confirm the consistency and reliability of the measurement instrument. This is necessary to ensure that any observed learning gains can be attributed to the intervention rather than familiarity with test items.\n\nThe results confirmed that most participants were beginners. Based on these findings, the educator co-created SMART learning objectives (for instance, “Apply loops to automate tasks in C++”), which guided the weekly instructional plan. The weekly instructional topics selected included an introduction to C++, syntax rules, variables, operators, basic program structure, arrays, functions, and hands-on debugging exercises. The learning objectives were created to align with Bloom's taxonomy. In this phase students were introduced to the concept of HOTS through foundational problem-solving tasks and explored the self-regulated learning (SRL) model.\n\nIn Phase 2 (week 3), students explored and tested GenAI tools, such as ChatGPT, Gemini, Microsoft Copilot. The educator introduced GenAI by demonstrating tasks like code generation, hands-on debugging exercises and syntax explanation. Students tested tools, critique, flagged issues (for instance, incorrect loop logic), and selected preferred tools based on their alignment with the learning objectives. The educator guided students in identifying these issues, emphasizing tools with explainable and interactive responses. The results of this showed that several GenAI tools, such as ChatGPT and GitHub Copilot were suitable for this study, however, ChatGPT was adopted due to ease of use and interactivity. Other GenAI, such as Mistral, Gemini, and Microsoft Copilot, were used when ChatGPT was down for a period during the intervention.\n\nIn Phase 3(week 3), students practiced basic prompt engineering techniques and engaged with GenAI to generate code snippets. Activities involved using the plan–monitor–reflect cycle ( [Prasad & Sane, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib83)). This helps with refining prompts, interpreting GenAI responses, and troubleshooting inconsistencies. During the planning stage, they learned to write clear, goal-specific prompts (for instance, “Write a C++ program that reads 10 integers and outputs the even numbers”). In the monitoring stage, they tested prompts and revised them based on feedback. For example, a prompt such as “Create a loop in C++” was improved to “Create a for loop that sums even numbers from 1 to 100.” During reflection, they evaluated how different prompts produced different GenAI outputs. Formative assessments during this phase included in-class quizzes (involving tasks on variables, operators, and basic program structure) and evaluations of prompt quality and code correctness. At the end of each session, students submitted both their GenAI prompt histories and resulting codes. This allows educators to assess prompt quality, code accuracy, and conceptual understanding.\n\nPhase 3 marks the beginning of scaffolded GenAI use, as it also covered introduction to C++, syntax rules, variables, operators, basic program structure, and hands-on debugging exercises. ChatGPT was integrated into the programming lessons by using it for code generation, debugging, and explaining programming tasks. In this phase, instruction was intensely guided. During this phase, educator-led scaffolding was prominent, with live demonstrations and explanations guiding students through basic programming tasks. For instance, when GenAI produced faulty loop logic, the educator helped students revise the prompt or manually correct the logic. As students became more confident with syntax and GenAI interaction, scaffolding was reduced.\n\nPhase 4 (weeks 4 and 5) marked a shift from guided instruction to independent learning. Students tackled intermediate concepts like loops, arrays, conditionals, functions, and hands-on debugging with minimal support. During this phase they were encouraged to write code independently before consulting GenAI. They also encourage to collaborated to detect logical errors in both GenAI-generated and peer-generated code, supporting the development of HOTS and programming logic. The educator transitioned from direct instruction to a facilitative role, offering minimal guidance only when students encountered persistent conceptual challenges in this phase. With educator's prompting reflection with questions like “What do you expect this condition to return?” Students refined their prompts and evaluated GenAI responses critically, reinforcing HOTS and understanding of programming logics. Prompt engineering was emphasized through structured practice, in which students refined their own prompts using the plan-monitor-reflect cycle. Students were instructed to formulate specific, task-relevant prompts; evaluate GenAI responses critically; and edit the code independently rather than copying the output verbatim.\n\nIn week 5 students worked independently on a creative capstone programming project using GenAI. It was designed to consolidate students’ learning by applying acquired programming concepts in an independent, real-world task. The project was conducted outside the classroom to promote self-directed learning and further reduce instructional support. Students were required to build real-world applications (a library management system) using C++. The task specification included features such as adding and searching books, updating records, issuing and returning books, and generating reports. These requirements were designed to integrate arrays, functions, conditionals, loops, and file handling. To ensure accountability and promote HOTS, students were instructed to submit all GenAI-generated prompts along with the corresponding code outputs and any modifications they made. This requirement enabled the educator to evaluate not only the final code but also the reasoning behind prompt construction and how students interacted with GenAI-generated content.\n\nPhase 5 (carried out in Week 6) focused on analyzing learning skill gains, this done by conducting posttest and comparing it with the pretest. The posttest was identical in structure and difficulty to the pretest in Phase 1 and administered to assess improvements in programming logic and HOTS. Quantitative data, including pretest and posttest scores, were evaluated using HOTS rubrics designed to assess programming tasks. These scores were then analyzed using descriptive statistics and gain score calculations to measure improvements in students’ coding proficiency and HOTS. Qualitative data, gathered from reflection journals, code submission, and GenAI chat logs, were thematically analyzed using NVivo 14. These insights were synthesized by the educator to identify meaningful learning patterns and areas for improvement.\n\nPhase 6 (weeks 7) was directly informed by the outcomes of Phase 5. This phase does not represent an endpoint but rather a practical turning point that ensures sustainability, continuous improvement, and cyclical renewal of the GenAI-Ped instructional framework in programming education. It uses the identified gaps to determine where additional training and support are needed for both students and the educator. Phase 6 involved compiling these observations and channeling them into a new set of evidence-based recommendations for future implementation. These insights guided decisions about refining instructional strategies, enhancing scaffolding, and strengthening GenAI integration. Phase 6 also laid the foundation for repeating the intervention with future cohorts, using refined instructional materials and baseline measures.\n\n## 4\\. Findings\n\n### 4.1. Reliability, validity, trustworthiness, and normal distribution\n\nTo measure the content validity, each of the earlier identified experts evaluated the HOTS scale and programming exercises on a three-point scale (essential, useful but not essential, not necessary) to determine whether the new HOTS scale aligned with Bloom's taxonomy and could be used to measure whether students had acquired the intended skills. The results indicated undisputed agreement (100 %) by the experts that the HOTS scale and programming exercises were essential in determining whether students had acquired the intended skills.\n\nFor the reliability assessment, the pretest and posttest were statistically analyzed using Cronbach's alpha to determine the internal consistency of the measurement criteria. Test-retest reliability assesses the stability of the instrument. The dataset contained 25 student records. Each record included responses to both pretest and posttest items that assess various dimensions of programming logic and HOTS. Cronbach's alpha results revealed the internal consistency of the measurement criteria was good for creativity (0.79), understanding of programming logic (0.88), critical thinking (0.82), and problem-solving (0.85). This indicates excellent internal consistency across all 28 criteria. Test-retest reliability was also calculated using Pearson correlations between pretest and posttest scores. Results showed high consistency over time: Problem-solving: 0.994–0.997 (average = 0.997), critical thinking: 0.982–0.996 (average = 0.990), creativity: 0.977–0.994 (average = 0.987), and programming logic: 0.985–0.997 (average = 0.993). These results confirmed that the instrument is both internally consistent and stable over time, addressing the key limitation of Cronbach's alpha.\n\nMultiple strategies was used to ensure the trustworthiness of the findings. These included triangulation, using both quantitative data (test scores) and qualitative data (reflections and chat logs; [Creswell & Poth, 2018](https://www.sciencedirect.com/www.sciencedirect.com#bib22); [Nowell et al., 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib78)). An audit trail was maintained to document all procedures and ensure transparency ( [Korstjens & Moser, 2018](https://www.sciencedirect.com/www.sciencedirect.com#bib60)). Peer debriefing sessions were also held to validate thematic interpretations and reduce researcher bias ( [Birt et al., 2016](https://www.sciencedirect.com/www.sciencedirect.com#bib9); [Saunders et al., 2018](https://www.sciencedirect.com/www.sciencedirect.com#bib89)). Collectively, these strategies strengthened the study's credibility, dependability, and confirmability.\n\nTo determine the appropriateness of applying parametric tests, the normality of the dataset was assessed using the K-S test. As shown in [Table 1](https://www.sciencedirect.com/www.sciencedirect.com#tbl1), all variables across the four skill criteria, problem-solving, critical thinking, creativity, and programming logic, returned _p_-values above 0.05, indicating no significant deviation from a normal distribution. This finding justifies the subsequent use of paired sample _t_-tests.\n\n### 4.2. Pre-pretest\n\n[Table 2](https://www.sciencedirect.com/www.sciencedirect.com#tbl2) provides a comparative summary of the pre-pretest and pretest mean scores across all the criteria. The non-significant differences (all _p_ > 0.05) corroborate that no learning gains occurred between the pre-pretest and pretest phases, thereby confirming that students’ baseline skills remained stable. This control step is critical in attributing any subsequent posttest improvements to the intervention itself, rather than to test familiarity or incidental exposure. It strengthens the internal validity of the study and sets a clear benchmark for evaluating the impact of GenAI integration.\n\nThe lack of significant differences between pre-pretest and pretest scores confirms the stability of the initial skill levels. This reinforces the validity of posttest improvements as genuine outcomes of the intervention. This design strengthens the internal validity of the study by ruling out practice effects or spontaneous skill development unrelated to the GenAI integration.\n\n### 4.3. GenAI integration and higher-order thinking skills\n\n#### 4.3.1. Findings on problem-solving skills\n\nThe descriptive results in [Table 3](https://www.sciencedirect.com/www.sciencedirect.com#tbl3) show a consistent upward trend across all seven problem-solving criteria, with notable increases in mean scores for “Problem Identification” (from 1.840 to 2.160) and “Solution Planning” (from 1.680 to 2.000). These improvements reflect not only higher confidence in understanding problems but also in structuring viable solutions. It shows that students moved from being passive recipients of instruction to active problem-solvers, supported by scaffolded GenAI use.\n\nAs reported in [Table 4](https://www.sciencedirect.com/www.sciencedirect.com#tbl4), statistically significant improvements ( _p_ < 0.05) were observed across all seven sub-criteria. Particularly strong effects were seen in “Problem Identification” ( _t_ = 2.551, _p_ = 0.009, _d_ = 0.510) and “Applying Constructs” ( _t_ = 2.377, _p_ = 0.013, _d_ = 0.475); thus, highlighting the role of prompt engineering in guiding students to dissect and tackle programming challenges logically. These results suggest that GenAI tools, when structured with educator scaffolding, can enhance not just procedural knowledge but deeper cognitive engagement with programming tasks.\n\n#### 4.3.2. Findings on critical thinking\n\n[Table 5](https://www.sciencedirect.com/www.sciencedirect.com#tbl5) reveals substantial gains in critical thinking components, particularly “Conditional Thinking,” which rose from 1.680 to 2.120, and “Use of Logical Constructs” rising from 1.560 to 1.920. These findings suggest that students increasingly adopted logical reasoning and structured thinking in their approach to coding, a shift likely to have been prompted by GenAI feedback and SRL cycles. Such growth reflects an internalization of programming logic beyond rote application.\n\nTable 5. Descriptive statistics for critical thinking criteria.\n\n| Criteria | Assessment | Mean | SD |\n| --- | --- | --- | --- |\n| Error Identification | pretest | 1.320 | 0.557 |\n| posttest | 1.640 | 0.700 |\n| Debugging Strategies | pretest | 1.120 | 0.440 |\n| posttest | 1.320 | 0.627 |\n| Optimizing Code | pretest | 1.200 | 0.500 |\n| posttest | 1.360 | 0.569 |\n| Evaluating Solutions | pretest | 1.040 | 0.455 |\n| posttest | 1.240 | 0.523 |\n| Use of Logical Constructs | pretest | 1.560 | 0.651 |\n| posttest | 1.920 | 0.759 |\n| Conditional Thinking | pretest | 1.680 | 0.852 |\n| posttest | 2.120 | 0.726 |\n| Application of Patterns | pretest | 1.560 | 0.821 |\n| posttest | 1.520 | 0.872 |\n\nAccording to [Table 6](https://www.sciencedirect.com/www.sciencedirect.com#tbl6), critical thinking sub-criteria such as “Conditional Thinking” ( _t_ = 2.529, _p_ = 0.018, _d_ = 0.506) and “Use of Logical Constructs” ( _t_ = 2.377, _p_ = 0.026, _d_ = 0.475) demonstrated statistically significant and moderate gains. However, “Optimizing Code” did not improve significantly (t = 1.693, p = 0.103). This suggests that students progressed in logic but continued to struggle with code efficiency and performance tuning. This gap guides future interventions that incorporate GenAI prompts tailored to performance optimization.\n\nTable 6. Paired samples _t_-test for critical thinking criteria.\n\n| Measure | t value | p value | Cohen's d |\n| --- | --- | --- | --- |\n| Error Identification | 2.138 | 0.043 | 0.428 |\n| Debugging Strategies | 2.000 | 0.057 | 0.400 |\n| Optimizing Code | 1.693 | 0.103 | 0.339 |\n| Evaluating Solutions | 1.732 | 0.096 | 0.346 |\n| Use of Logical Constructs | 2.377 | 0.026 | 0.475 |\n| Conditional Thinking | 2.529 | 0.018 | 0.506 |\n| Application of Patterns | 0.171 | 0.866 | 0.034 |\n\n#### 4.3.3. Findings on creativity\n\nCreativity measures in [Table 7](https://www.sciencedirect.com/www.sciencedirect.com#tbl7) indicate improved student originality and experimentation. For instance, “Creative Application of Constructs” increased from 1.120 to 1.600, and “Experimentation” from 1.280 to 1.640. The effect sizes for the improvements ranged from 0.456 to 0.517, suggesting moderate, but statistically significant, improvements. These results suggest that GenAI tools did not suppress creativity through automation but rather enabled students to explore multiple solutions, supported by real-time feedback. This aligns with constructivist theories in which creativity flourishes through iterative design and reflective thinking.\n\nTable 7. Descriptive statistics for creativity criteria.\n\n| Criteria | Assessment | Mean | SD |\n| --- | --- | --- | --- |\n| Originality of Approach | pretest | 1.200 | 0.500 |\n| posttest | 1.400 | 0.577 |\n| Creative Application of Constructs | pretest | 1.120 | 0.881 |\n| posttest | 1.600 | 0.816 |\n| Exploring Alternatives | pretest | 1.120 | 0.332 |\n| posttest | 1.400 | 0.500 |\n| Extending Problem Scope | pretest | 1.040 | 0.200 |\n| posttest | 1.240 | 0.436 |\n| Application of New Ideas | pretest | 1.040 | 0.200 |\n| posttest | 1.320 | 0.557 |\n| Experimentation | pretest | 1.280 | 0.614 |\n| posttest | 1.640 | 0.700 |\n| Innovative Problem Approach | pretest | 0.920 | 0.493 |\n| posttest | 1.080 | 0.400 |\n\nAs shown in [Table 8](https://www.sciencedirect.com/www.sciencedirect.com#tbl8), key improvements were evident in “Exploring Alternatives” ( _t_ = 2.585, _p_ = 0.016, _d_ = 0.517) and “Experimentation” ( _t_ = 2.571, _p_ = 0.017, _d_ = 0.514), both with moderate effect sizes. These gains imply that the students became more open to trial-and-error learning, which is likely to have been encouraged by GenAI's low-risk environment for experimenting with new ideas. However, less change was observed in “Innovative Problem Approach,” indicating the need for further support to push students beyond functional solutions to highly original innovations.\n\nTable 8. Paired samples _t_-test for creativity criteria.\n\n| Measure | t value | p value | Cohen's d |\n| --- | --- | --- | --- |\n| Originality of Approach | 1.732 | 0.096 | 0.346 |\n| Creative Application of Constructs | 2.493 | 0.020 | 0.499 |\n| Exploring Alternatives | 2.585 | 0.016 | 0.517 |\n| Extending Problem Scope | 2.000 | 0.057 | 0.400 |\n| Application of New Ideas | 2.281 | 0.032 | 0.456 |\n| Experimentation | 2.571 | 0.017 | 0.514 |\n| Innovative Problem Approach | 1.693 | 0.103 | 0.339 |\n\n### 4.4. GenAI integration and foundational programming logic\n\nThe descriptive analysis in [Table 9](https://www.sciencedirect.com/www.sciencedirect.com#tbl9) reveals consistent improvement in foundational programming concepts. “Use of Variables” rose from 1.680 to 2.200, while “Program Initialization” rose from 1.760 to 2.360. These results highlight how the structured intervention not only improved conceptual knowledge but also students’ fluency in syntax and control flow. The data underscore the importance of integrating GenAI within scaffolded instruction to support novice programmers in mastering fundamental logic.\n\nTable 9. Descriptive statistics for understanding programming logic criteria.\n\n| Criteria | Assessment | Mean | SD |\n| --- | --- | --- | --- |\n| Use of Variables | pretest | 1.680 | 0.945 |\n| posttest | 2.200 | 0.816 |\n| Use of Loops | pretest | 1.560 | 1.044 |\n| posttest | 2.160 | 0.850 |\n| Use of Conditionals | pretest | 1.640 | 0.952 |\n| posttest | 2.160 | 0.898 |\n| Procedures & Functions | pretest | 1.120 | 0.526 |\n| posttest | 1.320 | 0.476 |\n| Use of Operators & Expressions | pretest | 1.680 | 0.852 |\n| posttest | 2.280 | 0.843 |\n| Program Initialization | pretest | 1.760 | 0.970 |\n| posttest | 2.360 | 0.757 |\n| Program Termination | pretest | 1.120 | 0.666 |\n| posttest | 1.360 | 0.490 |\n| Code Organization and Clarity | pretest | 0.880 | 0.726 |\n| posttest | 1.240 | 0.779 |\n| Reusability of Code Components | pretest | 0.600 | 0.500 |\n| posttest | 0.880 | 0.332 |\n\nThe _t_-test results in [Table 10](https://www.sciencedirect.com/www.sciencedirect.com#tbl10) show statistically significant gains across most logic areas, with the highest effect size observed in “Program Initialization” ( _t_ = 3.286, _p_ = 0.003, Cohen's _d_ = 0.657; [Cohen, 1992](https://www.sciencedirect.com/www.sciencedirect.com#bib20)). This suggests that GenAI tools helped students understand the procedural flow of a program, including setup and data structure planning. Marginal gains in “Procedures & Functions” and “Program Termination” imply that students may still require targeted instruction in managing modularity and lifecycle design in code. In areas where AI may be less intuitive without expert guidance.\n\nTable 10. Paired samples _t_-test for understanding of programming logic criteria.\n\n| Measure | t value | p value | Cohen's d |\n| --- | --- | --- | --- |\n| Use of Variables | 2.831 | 0.009 | 0.566 |\n| Use of Loops | 2.777 | 0.010 | 0.555 |\n| Use of Conditionals | 2.316 | 0.029 | 0.463 |\n| Procedures & Functions | 1.732 | 0.096 | 0.346 |\n| Use of Operators & Expressions | 2.882 | 0.008 | 0.576 |\n| Program Initialization | 3.286 | 0.003 | 0.657 |\n| Program Termination | 1.659 | 0.110 | 0.332 |\n| Code Organization and Clarity | 2.092 | 0.047 | 0.418 |\n| Reusability of Code Components | 3.055 | 0.005 | 0.611 |\n\n### 4.5. Thematic approach to qualitative data on generative AI in programming education\n\nA thematic analysis of student reflections and GenAI logs revealed recurring themes: (1) prompt quality, (2) code submission and integration of GenAI-generated code, (3) challenges in using GenAI tools, (4)students’ perceptions of GenAI tools, and (5) the role of scaffolding and prompt engineering as learning supports. These themes provided contextual depth to the quantitative results and helped explain patterns in HOTS and programming logic gains.\n\n#### 4.5.1. Prompt quality: vague vs. specific prompts\n\nThe study by [Walter (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib103) emphasizes that prompts influence how students interact with GenAI tools, making prompt literacy essential in programming education. To analyze the level of influence, the chat logs were segmented to understand the distinct interactions, with each representing a student's prompt and the corresponding GenAI-generated response. These interactions were then coded based on the complexity of prompts (for instance, vague vs. specific). The findings indicate that students who wrote specific and detailed prompts (see [Fig. 4](https://www.sciencedirect.com/www.sciencedirect.com#fig4) a) showed better engagement and learning, while those who used vague prompts produced weaker outcomes (see [Fig. 4](https://www.sciencedirect.com/www.sciencedirect.com#fig4) b). This suggests that the use of specific prompts enabled students to receive more accurate and relevant responses from GenAI, which in turn supported a deeper understanding of programming concepts. This finding aligns with the research of [Denny et al. (2023)](https://www.sciencedirect.com/www.sciencedirect.com#bib23), which argues that well-crafted prompts facilitate more meaningful AI interaction and foster computational thinking. In contrast, vague prompts often led to generic or less useful responses, limiting the students' ability to learn effectively.\n\n1. [Download: Download high-res image (416KB)](https://ars.els-cdn.com/content/image/1-s2.0-S2666920X25001006-gr4_lrg.jpg)\n2. [Download: Download full-size image](https://ars.els-cdn.com/content/image/1-s2.0-S2666920X25001006-gr4.jpg)\n\nFig. 4. Snippet of GenAI chat.\n\n#### 4.5.2. Code submission: integration of GenAI-Generated code\n\nThis finding shows that some participants still directly copied and pasted the code obtained from the GenAI, stating “ _it is too lengthy to read, so I just copy and paste the answer directly_,” while another student admitted, “ _Sometimes the AI's code was so complex that I didn't even try to understand it. I just submitted it and hoped for the best._” Copying and pasting GenAI-generated code was common early in the intervention. This was when students were still unfamiliar with GenAI and opted to use responses without editing or understanding them. While copying code without understanding helped students' complete tasks quickly. This behavior reflects a common risk: treating GenAI as a shortcut rather than a learning partner, as noted by [Rahe and Maalej (2025)](https://www.sciencedirect.com/www.sciencedirect.com#bib84).\n\nAs one student reflected _,_ “ _At first, I just copied and pasted the code from ChatGPT because it gave me quick answers. But later, I realized I wasn't learning, I was just getting the assignment done._” This reflection aligns with [Fernandez and Cornell (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib36), who warn of “black-box” programming in which reliance on AI obscures the underlying comprehension of the logic. The findings reveal that students who relied heavily on copying GenAI-generated code showed less improvement in areas such as code optimization and critical evaluation of solutions. Students who actively edited, tested, and debugged GenAI-generated code demonstrated a deeper understanding of programming concepts and showed clear improvement in HOTS and understanding of programming logic. As one of these students remarked, “ _The AI's solution had a bug, and fixing it taught me more than if I'd written the code from scratch._” Another added, “ _I asked ChatGPT to explain its logic, then rewrite it in my own way. That's when things really clicked._”\n\n#### 4.5.3. Challenges in using GenAI tools\n\nDespite the benefits of GenAI tools in programming education, students encountered several challenges during the intervention. One major issue was infrastructure limitations. Unstable internet and electricity disrupted access to GenAI tools, particularly during hands-on coding sessions and assignment submissions. These challenges are consistent with [Eteng et al. (2022)](https://www.sciencedirect.com/www.sciencedirect.com#bib32), who noted that infrastructural deficits impair equitable access to technology-enhanced learning. Another significant challenge was the misinterpretation of GenAI-generated responses. Students tend to misinterpret GenAI responses due to poorly crafted prompts, leading to errors in their code or misinterpretation of programming concepts. Misinterpretation of GenAI output echoes findings by [Shanto et al. (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib93), who noted that novice programmers often misread AI explanations, leading to faulty implementations. Several students also expressed concern about becoming overly reliant on GenAI, stating, “ _Sometimes I feel like I lean too much on the AI instead of figuring it out myself._” This reflects the risk noted by [Kazemitabaar et al. (2023)](https://www.sciencedirect.com/www.sciencedirect.com#bib56) and [Naeem et al. (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib76), who emphasize the possibility of diminished cognitive engagement when AI tools are used without structured guidance.\n\nAdditionally, students noted that the ease with which they could obtain answers made it tempting to skip the problem-solving process altogether. Raising concerns about evaluating students’ actual programming abilities. As previously noted, [Fernandez and Cornell (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib36) cautioned against this “black-box” learning in which students use functional code generated by AI without understanding how it works. These challenges affected the effectiveness of the tools and the overall learning experience, highlighting the need for robust infrastructure and structured guidance to ensure responsible and effective use of GenAI tools in education.\n\n#### 4.5.4. Students’ reflections: perceptions of GenAI tools\n\nStudents shared a range of reflections on their experiences of using GenAI tools during the intervention. Overall, most expressed positive perceptions, highlighting the tools' usefulness in improving their understanding of programming logic and reducing frustration with coding tasks. One student stated that “ _GenAI can be likened to a textbook but in a more summarized and digital presentation, as each student can move at their own_ pace _, as integrating GenAI into programming makes learning programming less overwhelming._” because GenAI can provide quick and accessible explanations. Students’ perceptions of GenAI as a “digital textbook” resonate with the findings of [Yan, Nakajima, and Sawada (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib107), who described GenAI as a cognitive support that personalizes learning pace and feedback. Many described GenAI as a helpful “coding assistant” that provided instant feedback, clarified errors, and simplified complex concepts only when prompted correctly. These reflections are consistent with studies by [Ahme et al. (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib1) and [MacNeil et al. (2022)](https://www.sciencedirect.com/www.sciencedirect.com#bib71), who found that students using GenAI tools gained confidence and performed better in programming tasks than without Gen AI due to timely and relevant support.\n\nMost students who volunteered for this intervention preferred ChatGPT. They found it easier to use because of its interface and the option to share chat logs for collaboration. However, the participants expressed concerns that the ease of accessing GenAI-generated solutions might lead to a lack of genuine learning and participation. With one participant stating, “ _it becomes harder to evaluate students actual coding abilities when GenAI assistance is involved and it should not be incorporated for beginners but for people with general understanding of programming, as any misinterpretation of prompts could affect the performances of GenAI_.” This quotation emphasizes the importance of personal practice and the need for structured guidance on effectively using GenAI tools. Without a solid understanding of syntax and logic, users may not fully comprehend the underlying principles of the code they have generated ( [Fernandez & Cornell, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib36); [Spinellis, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib96)). This dual perception aligns with [Alves and Cipriano (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib4), who observed that while GenAI tools support confidence and task completion, they may hinder deep learning if introduced too early or without guidance.\n\n#### 4.5.5. Scaffolding and prompt engineering as learning supports\n\nThroughout the intervention, scaffolding and prompt engineering emerged as essential supports for students learning to effectively use GenAI tools in programming. Many students initially lacked the skills to frame precise prompts or interpret AI-generated code. However, with structured guidance, they gradually learned how to interact more critically and purposefully with GenAI tools. This finding aligns with the principles of Vygotsky's ZPD, which emphasizes the importance of guided support in helping learners achieve tasks just beyond their independent capabilities ( [Erdei et al., 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib30)). Scaffolding was provided through demonstrations, step-by-step instructions, and reflective prompts. These supports were gradually reduced as students became more confident in writing prompts and evaluating GenAI responses. This process mirrors the approach recommended by [Belland (2017)](https://www.sciencedirect.com/www.sciencedirect.com#bib8), who argued that lessening support over time promotes student autonomy and deeper learning. By scaffolding both the programming content and the use of GenAI, learners developed not only technical skills but also metacognitive awareness.\n\nPrompt engineering was also emphasized as a skill in itself. Students were taught how to structure clear, goal-oriented prompts from the SRL model ( [Prasad & Sane, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib83)). Several students reflected that these supports helped them transition from passive tool users to active problem-solvers. One student noted, “ _When I got something wrong and prompted following the SRL technique, the AI didn't just give me the answer but showed me the logic gap in my reasoning._” This shift aligns with [Denny et al. (2023)](https://www.sciencedirect.com/www.sciencedirect.com#bib23), who demonstrated that prompt engineering enhances computational thinking by requiring learners to deconstruct problems and reason through language.\n\n## 5\\. Discussion and implications\n\n### 5.1. To what extent does GenAI integration, with scaffolding and prompt engineering, enhance the development and sustenance of HOTS in programming education?\n\nThe study found that integrating GenAI tools into programming education, alongside scaffolding and prompt engineering, supported students in developing and sustaining HOTS. These skills help them analyze problems, evaluate possible approaches, and design original solutions instead of relying on memorized procedures ( [Brookhart, 2010](https://www.sciencedirect.com/www.sciencedirect.com#bib12); [Egbert et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bib29)). Quantitative findings revealed improvements in six of the seven measured problem-solving criteria. Notably, problem identification and applying constructs showed the highest effect sizes ( _d_ = 0.510 and _d_ = 0.475, respectively), indicating that GenAI tools were particularly effective in guiding students through deconstructing problems and applying coding constructs. These findings support earlier research that shows GenAI tools can enhance problem-solving more effectively than traditional programming instruction ( [Min & Heng, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib74)). This is because it makes error messages clearer and simplify complex concepts ( [Kimmel et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib58); [Poitras et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib82)). The tools also helped lower barriers to entry and introduced productive challenges that encouraged deeper engagement and more creative solutions ( [Jonsson & Tholander, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib54)).\n\nThe results show that GenAI tools support some aspects of critical thinking. This is evident in the observed gains in error identification, conditional thinking (1.680–2.120), and logical constructs (1.560–1.920). However, GenAI tools did not improve code optimization or solution evaluation. This suggests that GenAI may not support all critical thinking sub-criteria equally. This may be because the accuracy of GenAI-generated content impacts students’ critical thinking ( [Schefer-Wenzl et al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bib91)). The marginal improvements in debugging strategies and evaluating solutions suggest that these skills may require additional instructional support or alternative strategies to achieve significant gains. Structured guidance and targeted exercises can help students build critical thinking skills when using GenAI ( [Alves & Cipriano, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib4)), while structured learning activities incorporating GenAI can foster a more reflective approach to programming tasks ( [Naeem et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib76)).\n\nCertain sub-criteria in the creativity criteria also improved after the GenAI integration into programming education. For instance, students who used GenAI tools to explore alternative solutions or apply new ideas demonstrated a greater ability to think outside the box and develop unique programming solutions. This finding aligns with [Zviel-Girshin's (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib112) research suggesting that GenAI tools have the potential to foster creativity by providing adaptive support and encouraging exploration. While [Sauvola et al. (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib90) highlights that GenAI helps automate routine tasks and promote new forms of creativity in software design, this study found limited gains in originality and innovation. This suggests GenAI may not equally support all creativity sub-criteria. This emphasizes that the need for a balance between utilizing GenAI for efficiency and maintaining a creative edge is a critical consideration for software practitioners ( [Jackson et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib52)).\n\nFurther, the qualitative findings added depth to the quantitative results and provided insights into how students experienced the learning process. The findings revealed that using GenAI helped students explore alternative solutions, develop deeper HOTS, and remain engaged with programming tasks. However, these benefits were most evident when GenAI was used as a thinking partner, not just as a shortcut to answers. This finding aligns with observations by [Jin et al. (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib53), who found that integrating scaffolding techniques in GenAI provides a guided experience, and well-crafted prompts significantly influence the way that students interact with GenAI tools ( [Walter, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib103)). Additionally, the incorporation of scaffolding techniques and prompt engineering were able to increase collaboration among the participants. This plays a major role in shaping students’ experience with GenAI tools and HOTS development.\n\n### 5.2. How effectively does GenAI integration, with scaffolding and prompt engineering, sustain and enhance students’ foundational programming logic?\n\nThe results of this study show that the integration of GenAI, supported by scaffolding and prompt engineering, had a positive effect on students' understanding and retention of programming logic. This was evident in the gains across most sub-criteria in the programming logic criteria. The results show that by the end of the intervention, students who had struggled with control structures could construct logical sequences and debug errors more accurately. This is because the structured use of GenAI allowed them to test their ideas and receive immediate, relevant feedback. Highlighting that GenAI's timely support during programming ( [Ghimire & Edwards, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib28)) appears to aid understanding. This improvement is consistent with findings by [Egbert et al. (2021)](https://www.sciencedirect.com/www.sciencedirect.com#bib29), who noted that programming logic develops more effectively when students are engaged in active problem-solving rather than passive code consumption. However, minimal gains in procedures, functions, and program termination sub-criteria suggest these areas may require different instructional strategies, as GenAI tools such as ChatGPT face challenges in addressing complex student confusions and adapting responses to individual needs, which are crucial for fostering a deeper understanding of programming logic ( [Shanto et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib93)).\n\nNotably, the qualitative responses reflected that students who actively edited and tested GenAI-generated code demonstrated a better understanding of programming logic, while those who copied code passively recorded negligible gains. This finding explains the quantitative results indicating marginal increments in areas such as procedures and functions and program termination. Additionally, the GenAI chat log and code submission analysis indicated that students who used GenAI tools to explore programming concepts (for instance, variables, loops, conditionals) and debug their code greatly enhanced their understanding of programming logic. This aligns with the quantitative findings, which show improvements in core concepts such as variable application ( _t_ = 2.831, _p_ = 0.009) and loop implementation ( _t_ = 2.777, p = 0.010). Several students also noted that creating precise prompts forced them to break down problems before asking for help, which improved their logical reasoning.\n\nThese improvements suggest that integrating GenAI into programming education, particularly within a structured framework such as GenAI-Ped, effectively supported some HOTS and the programming logic development of the learners. The intervention was designed to gradually shift responsibility from the teacher to the learner, which contributed to improved performances. These results align with previous studies such as that by [Kazemitabaar et al. (2023)](https://www.sciencedirect.com/www.sciencedirect.com#bib56), in which guided use of AI led to higher learning gains. However, the novelty of this study lies in its practical demonstration of how GenAI, when paired with instructional scaffolding and prompt engineering, can be used not only to support but also to sustain some HOTS and programming logic criteria over time. However, the relatively small sample size of 25 students poses constraints concerning the breadth of these conclusions, limiting the extent to which the results can be generalized to larger or more diverse populations. Despite this, the study offers valuable initial evidence that incorporating GenAI tools thoughtfully into programming education can support sustained learning gains and pedagogical innovation.\n\n### 5.3. Theoretical and practical implications\n\nThis study presents both theoretical and practical implications for programming education in the era of GenAI. Theoretically, the findings support the application of constructivist learning theory ( [Sullivan, 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib99), p. 22) and ZPD ( [Shabani et al., 2010](https://www.sciencedirect.com/www.sciencedirect.com#bib92)). These theories suggest that learners build knowledge more effectively when they receive appropriate support during challenging tasks. The use of scaffolding ( [Belland, 2017](https://www.sciencedirect.com/www.sciencedirect.com#bib8)) and prompt engineering ( [Dickey, Bejarano, & Chirayu, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib19)) in this study helped students engage in programming tasks in a way that sustained HOTS and programming logic. The study also contributes to the emerging conversation around the pedagogical use of GenAI in education and highlights the need to move beyond viewing GenAI tools as shortcuts or answer generators. Instead, they should be seen as learning partners that, when combined with reflective tasks and structured support, can promote deep thinking and skill development. The findings offer a practical model for integrating GenAI into programming classrooms without reducing learners’ engagement with core concepts.\n\nPractically, the results suggest programming educators should introduce GenAI tools alongside well-defined instructional strategies. Students need training on how to craft prompts, evaluate AI responses, and reflect on what they learn. In the absence of structured guidance, students risk engaging in surface-level learning or becoming overdependent on GenAI tools.The plan-monitor-reflect technique of prompting by [Prasad and Sane (2024)](https://www.sciencedirect.com/www.sciencedirect.com#bib83) offers a useful structure for guiding student interaction with GenAI. This approach encourages students to think more clearly about problems and engage more deeply with the logic of their codes. Educators should also consider varying levels of scaffolding depending on students’ prior experience. Beginners may need more guided examples and support, while more advanced learners could benefit from open-ended tasks that challenge their HOTS and logic.\n\n### 5.4. Ethics\n\nThis study involved human participants specifically, second-year undergraduate students. Before the intervention began, all participants were informed about the purpose of the research, their role in it, and their right to withdraw at any time without penalty. Informed consent was obtained from all 25 students in writing.\n\nThis study received ethical approval from Covenant University Health Research Ethics Committee, accredited by the U.S department of Health & Human services with registration number IOG0010037 and IOG0010037. National Health Research Ethics Committee under the registration number NHREC/CU-HREC/1/01/2-25.The assigned protocol number is CHREC/1097/2025. All research procedure were conducted in accordance with the approved protocol and ethical standard to ensure the protection of participants’ right, confidentiality, and well-being.\n\nConfidentiality was maintained throughout the study. No names or personal identifiers were collected. Data were stored securely and used only for research purposes. Students were told that their grades and participation in the study would not affect their academic standing in any way.\n\n### 5.5. Limitations and future research\n\nDespite the study's positive findings, overreliance and academic integrity issues arose in student responses, as scaffolding and prompt engineering may not have been applied outside the classroom, concealing actual skill development. This aligns with broader ethical debates regarding the promotion of clear policies on GenAI usage to maintain academic integrity and skill authenticity ( [Akgun & Greenhow, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib3); [Holmes et al., 2022](https://www.sciencedirect.com/www.sciencedirect.com#bib46)). Used as a strategy, integration of GenAI will help avoid undermining students' independent learning ( [Naeem et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bib76)), requiring a clear need for activities that promote collaboration in the GenAI curriculum ( [Sunday et al., 2020](https://www.sciencedirect.com/www.sciencedirect.com#bib114)). Nonetheless, overdependence on GenAI tools can detract from the acquisition of HOTS and understandings of programming logic.\n\nPractical challenges were also encountered during the intervention, including the sample size, internet reliability issues, power supply disruptions, and language complexity, which occasionally hindered the effective use of GenAI tools. Study limitations included a small sample size, a single-institution context, and reliance on self-reported reflections. The modest sample size of 25 participants constrains the degree to which this study can be generalized to broader student populations or different educational settings. Future studies should plan to use larger, sample sizes to investigate how to address these barriers when integrating GenAI tools into programming education.\n\n## 6\\. Conclusion\n\nThis study shows that integrating GenAI through a structured pedagogical framework can support the development and retention of HOTS and programming logic. The GenAI-Ped framework supported scaffolded tool use, prompt engineering, and independent learning over time.\n\nThe results indicate that GenAI tools alone are not sufficient to promote deep learning. Their impact depends on the presence of scaffolded support, well-defined instructional goals, and structured prompting strategies. The use of prompt engineering helped students learn to formulate precise queries, reflect on AI responses, and revise their code accordingly. These practices shifted students away from passive consumption of GenAI outputs and encouraged metacognitive awareness and purposeful problem-solving.\n\nIn practice, this study offers a replicable model for responsible GenAI integration in programming education. Educators should combine GenAI tools with pedagogical frameworks that support gradual release of responsibility and align learning tasks with cognitive objectives. The GenAI-Ped framework used in this intervention allowed students to not only complete programming tasks but to internalize underlying logic and reasoning processes. This approach helped mitigate the risk of overreliance and preserved the authenticity of skill development.\n\n## CRediT authorship contribution statement\n\n**Jemimah Nathaniel:** Writing – review & editing, Writing – original draft, Validation, Software, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. **Solomon Sunday Oyelere:** Writing – review & editing, Validation, Supervision, Methodology, Investigation, Conceptualization. **Jarkko Suhonen:** Writing – review & editing, Validation, Supervision. **Matti Tedre:** Writing – review & editing, Validation, Supervision.\n\n## Availability of data and material\n\nTo protect participant privacy, the raw data from this study (including chat logs and assessments) are not publicly shared. However, anonymized excerpts or the assessment rubric can be provided upon request to support further research.\n\n## Ethics approval statement\n\nInformed consent was secured from all participants, with explicit clarification that participation was voluntary and withdrawal was permitted at any stage. To protect participant anonymity, all data were de-identified during analysis, and pseudonyms were used in qualitative excerpts.\n\n## Funding\n\nThis work does not receive any financial support.\n\n## Declaration of competing interest\n\nThe authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n\n## Acknowledgements\n\nNot Applicable.\n\n## Appendix 1.\n\n### Creativity\n\nI can develop unique solutions to programming problems.\n\nI enjoy brainstorming multiple ways to solve a problem.\n\nI can use coding to create something new or innovative.\n\nI feel confident exploring different programming tools to improve my work.\n\n### Critical Thinking\n\nI can evaluate different approaches and choose the best one to solve a problem.\n\nI analyze problems deeply before starting to code.\n\nI enjoy troubleshooting and debugging errors in programs.\n\nI can recognize patterns and connections in programming tasks.\n\nI feel confident questioning and refining my programming solutions.\n\n### Problem-Solving\n\nI can break down complex programming problems into smaller, manageable parts.\n\nI feel confident identifying the main issues in a problem.\n\nI can persevere through challenges when coding.\n\nI can apply learned concepts to solve new or unfamiliar problems.\n\n### Understanding Programming Logic\n\nI understand the use of conditional statements (For example, if-else, switch) in programming.\n\nI can identify and fix logical errors in a program.\n\nI can explain how loops (For example, for, while, do-while) work in programming.\n\nI understand the purpose of variables and how to use them effectively.\n\nI feel confident designing and implementing logic for small programming tasks.\n\n## Appendix 2.\n\n### Creativity\n\nWrite two different programs to find the largest number in an array.\n\nCreate a program that generates a random password of 8 characters, including letters, numbers, and symbols.\n\nWrite a program that uses a library to calculate the square root of a number.\n\nDesign a program that simulates a simple calculator with addition, subtraction, multiplication, and division.\n\n### Critical Thinking\n\nCompare two sorting algorithms and explain which one is more efficient.\n\nWrite a program that checks if a number is prime and explain the logic behind your solution.\n\nDebug the following program that is supposed to calculate the average of three numbers but contains errors.\n\nWrite a program that prints the Fibonacci sequence up to the 10th term and explain the pattern.\n\nWrite a program to reverse a string and then optimize it to use fewer lines of code.\n\n### Problem-Solving\n\nWrite a program that calculates the sum of all even numbers between 1 and 100.\n\nWrite a program that identifies and prints all duplicate elements in an array.\n\nWrite a program that converts a decimal number to binary without using built-in functions.\n\nWrite a program that calculates the total cost of items in a shopping cart, including tax.\n\n### Understanding Programming Logic\n\nWrite a program that checks if a number is positive, negative, or zero using conditional statements.\n\nWrite a program that prints all numbers from 1 to 10 using a for loop.\n\nWrite a program that swaps the values of two variables without using a temporary variable.\n\nPredict the output of the following program and explain the flow of execution.\n\n## Appendix 3.\n\nTable 1. Problem-Solving Rubric\n\n| Problem-solving |\n| --- |\n| (Assessing the ability to identify, analyze, and implement solutions for programming challenges) |\n| --- |\n| Criteria | Bloom's Taxonomy Level | Lacking Proficiency (0) | Emerging (1) | Developing (2) | Proficient (3) | Exceeding Proficiency (4) |\n| --- | --- | --- | --- | --- | --- | --- |\n| **Problem Identification** | Understanding | Does not identify or misinterprets the problem. | Identifies basic elements but misses key parts. | Identifies most aspects with minor gaps. | Clearly identifies and understands all aspects of the problem. | Breaks down complex problems into smaller, solvable parts. |\n| **Defining Requirements** | Understanding | Cannot define the problem requirements. | Defines only vague or partial requirements. | Defines basic requirements with some detail. | Defines clear and detailed requirements for the solution. | Defines comprehensive requirements, anticipating challenges and constraints. |\n| **Solution Planning** | Applying | No plan for solving the problem. | Develops a very basic or incomplete plan. | Creates a functional plan addressing key step. | Develops a structured, detailed plan for solving the problem. | Develops an advanced, well-structured plan incorporating optimization strategies. |\n| **Applying Constructs** | Applying | Fails to use constructs relevant to the problem. | Uses constructs inconsistently or incorrectly. | Uses appropriate constructs to address key parts of the problem. | Uses constructs effectively to solve the problem comprehensively. | Combines constructs innovatively to solve the problem in a unique or advanced way. |\n| **Handling Errors** | Applying → Evaluating | Ignores errors or fails to recognize them. | Identifies errors but struggles to address them. | Fixes basic errors but misses more complex ones. | Effectively identifies and resolves all errors. | Anticipates, identifies, and resolves errors systematically and efficiently. |\n| **Implementing the Solution** | Applying | Cannot implement a working solution. | Implements a partial or incomplete solution. | Implements a functional solution with minor issues. | Implements a fully functional and reliable solution. | Implements an optimized, scalable, and advanced solution. |\n| **Testing the Solution** | Analyzing → Evaluating | Does not test or tests minimally with no clear process. | Tests the solution partially, missing key cases. | Tests the solution adequately with minor gaps. | Tests the solution thoroughly, covering edge cases. | Tests comprehensively with creative test cases and evaluates results critically. |\n\nTable 2. Critical Thinking Rubric\n\n| Critical Thinking |\n| --- |\n| (Evaluating logical reasoning, debugging, and code optimization.) |\n| --- |\n| Criteria | Bloom's Taxonomy Level | Lacking Proficiency (0) | Emerging (1) | Developing (2) | Proficient (3) | Exceeding Proficiency (4) |\n| --- | --- | --- | --- | --- | --- | --- |\n| **Error Identification** | Applying | Fails to identify any errors. | Identifies only basic syntax errors. | Identifies syntax and simple logical errors. | Identifies most logical and structural errors effectively. | Identifies complex errors, including hidden logical flaws. |\n| **Debugging Strategies** | Applying → Evaluating | Attempts debugging randomly without strategy. | Applies basic debugging but lacks consistency. | Uses systematic debugging techniques for common errors. | Debugs effectively using clear and logical steps. | Implements advanced debugging strategies, explaining and justifying all steps. |\n| **Optimizing Code** | Evaluating | Makes no attempt to optimize code. | Optimizes code minimally for readability or minor efficiency improvements. | Moderately optimizes code for performance. | Optimizes code effectively for efficiency, readability, and maintainability. | Implements advanced optimizations creatively, improving scalability and performance. |\n| **Evaluating Solutions** | Evaluating | Does not evaluate the solution's effectiveness. | Evaluates the solution only at a basic level. | Evaluates the solution's success for most cases. | Thoroughly evaluates the solution for all requirements. | Evaluates the solution critically, identifying areas for improvement and optimization. |\n| **Use of Logical Constructs** | Analyzing | Fails to use or understand logical constructs. | Uses logical constructs incorrectly or minimally. | Applies simple logical constructs with moderate success. | Applies logical constructs effectively to create clear, functional logic. | Combines logical constructs creatively to solve complex problems. |\n| **Conditional Thinking** | Applying → Evaluating | Does not apply logical conditions in programs. | Applies conditions minimally or incorrectly. | Applies conditions correctly but struggles with complexity. | Implements logical conditions effectively in problem-solving. | Implements advanced conditional structures that demonstrate clear and flexible thinking. |\n| **Application of Patterns** | Analyzing → Creating | Does not recognize patterns or apply them. | Recognizes basic patterns but applies them inconsistently. | Uses simple patterns effectively in some cases. | Applies patterns appropriately to improve code structure. | Develops or adapts advanced patterns to create efficient, maintainable solutions. |\n\nTable 3. Creativity Rubric\n\n| Creativity |\n| --- |\n| (Assessing originality, innovative thinking, and creative application of programming constructs in programming.) |\n| --- |\n| Criteria | Bloom's Taxonomy Level | Lacking Proficiency (0) | Emerging (1) | Developing (2) | Proficient (3) | Exceeding Proficiency (4) |\n| --- | --- | --- | --- | --- | --- | --- |\n| **Originality of Approach** | Creating | Relies entirely on examples without modifications. | Makes minimal modifications to standard examples. | Creates partially original solutions. | Develops original solutions tailored to the problem context. | Produces highly original solutions with innovative approaches and techniques. |\n| **Creative Application of Constructs** | Creating | Uses constructs in standard, uninspired ways. | Applies constructs with slight creativity. | Combines constructs in somewhat novel ways. | Combines constructs creatively to enhance functionality or problem-solving. | Uses constructs in entirely new and imaginative ways to achieve complex goals. |\n| **Exploring Alternatives** | Creating | Does not explore any alternative solutions. | Considers a single alternative but does not implement it. | Explores and implements a few alternative approaches. | Evaluates and applies alternatives to improve solutions. | Explores and implements multiple, highly creative alternatives. |\n| **Extending Problem Scope** | Creating | Sticks rigidly to the defined problem scope. | Adds minor extensions but stays close to the task. | Expands the problem meaningfully with new elements. | Extends the problem significantly with creative additions. | Reimagines the problem entirely, introducing new dimensions or solving related issues. |\n| **Application of New Ideas** | Creating | Does not attempt to introduce new ideas. | Introduces basic, partially thought-out ideas. | Incorporates moderately new and creative ideas. | Applies new, well-thought-out ideas to enhance the program. | Applies entirely new ideas creatively, redefining the problem or its solution. |\n| **Experimentation** | Creating | Shows no experimentation or willingness to try new methods. | Tries new methods but with limited success. | Experiments with methods to discover better solutions. | Experiments systematically to improve solutions effectively. | Innovates through experimentation, discovering entirely new ways to solve problems. |\n| **Innovative Problem Approach** | Analyzing → Creating | Solves problems using basic, direct approaches with no variation. | Solves problems with slight modifications but lacks novelty. | Implements new variations or approaches that show some independent thinking. | Develops innovative approaches that go beyond standard problem-solving methods. | Reframes problems creatively, introducing entirely new or unexpected solutions. |\n\nTable 4. Understanding Programming Logic Rubric\n\n| Understanding Programming Logic |\n| --- |\n| (Assessing mastery of programming constructs and logical structures.) |\n| --- |\n| Criteria | Bloom's Taxonomy Level | Lacking Proficiency (0) | Emerging (1) | Developing (2) | Proficient (3) | Exceeding Proficiency (4) |\n| --- | --- | --- | --- | --- | --- | --- |\n| **Use of Variables** | Applying | Does not use variables or uses them incorrectly. | Uses variables but lacks meaningful naming or initialization. | Creates meaningful variables but with limited applications. | Creates and uses meaningful variables effectively. | Utilizes variables dynamically and creatively for advanced scenarios. |\n| **Use of Loops** | Applying | No loops used. | Uses simple loops with fixed iterations. | Implements loops partially (For instance, simple nested loops). | Applies advanced loops effectively (For instance, nested, dynamic). | Combines multiple advanced loops innovatively and efficiently. |\n| **Use of Conditionals** | Analyzing | No conditionals used or used incorrectly. | Uses basic conditionals but lacks depth (For instance, “if-then”). | Implements basic nested or variable-based conditionals. | Applies advanced conditionals (For instance, Boolean expressions). | Implements complex, multi-layered conditionals dynamically and innovatively. |\n| **Use of Operators & Expressions** | Analyzing | No use of operators | Use of only arithmetic and/or relational operators and no evidence of nested operators in an expression | Use of 1–3 operators, with at least one Boolean operator, or one instance of nested operators in an expression | More than 3 operators, with at least one Boolean operator or one instance of nested operators in an expression |\n| **Program Initialization** | Applying | Incorrect initialization or did not attempt to initialize when required | Partially correct initialization or initialization not applicable | Initialization required and correctly done |\n| **Program termination** | Evaluating | Program does not terminate | Program terminates |\n| **Code Organization and Clarity** | Applying | Code is disorganized and difficult to read. | Code is somewhat organized but lacks clarity. | Code is mostly organized and uses basic comments. | Code is well-organized with clear comments and structure. | Demonstrates exceptional organization with clear comments, naming conventions, and structure. |\n\nRecommended articles\n\n## References\n\n001. [Ahme et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib1)\n\n\n Z. Ahme, S.S. Shanto, A.I. Jony\n\n\n\n Potentiality of generative AI tools in higher education: Evaluating ChatGPT's viability as a teaching assistant for introductory programming courses\n\n\n\n STEM Education, 4 (3) (2024), pp. 165-182, [10.3934/steme.2024011](https://doi.org/10.3934/steme.2024011)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85196750884&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Potentiality%20of%20generative%20AI%20tools%20in%20higher%20education%3A%20Evaluating%20ChatGPTs%20viability%20as%20a%20teaching%20assistant%20for%20introductory%20programming%20courses&publication_year=2024&author=Z.%20Ahme&author=S.S.%20Shanto&author=A.I.%20Jony)\n\n002. [Aibin et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib2)\n\n\n T. Aibin, Y. Jijun, L. Wenye, Z. Shike, L. Dawei\n\n\n\n The impact of different types of off-campus training on primary and junior high students' higher-order thinking dispositions\n\n\n\n Thinking Skills and Creativity, 49 (2023), [10.1016/j.tsc.2023.101351](https://doi.org/10.1016/j.tsc.2023.101351)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=The%20impact%20of%20different%20types%20of%20off-campus%20training%20on%20primary%20and%20junior%20high%20students%20higher-order%20thinking%20dispositions&publication_year=2023&author=T.%20Aibin&author=Y.%20Jijun&author=L.%20Wenye&author=Z.%20Shike&author=L.%20Dawei)\n\n003. [Akgun and Greenhow, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bbib3)\n\n\n S. Akgun, C. Greenhow\n\n\n\n Artificial intelligence in education: Addressing ethical challenges in K-12 settings\n\n\n\n AI and Ethics, 2 (3) (2022), pp. 431-440, [10.1007/s43681-021-00096-7](https://doi.org/10.1007/s43681-021-00096-7)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Artificial%20intelligence%20in%20education%3A%20Addressing%20ethical%20challenges%20in%20K-12%20settings&publication_year=2022&author=S.%20Akgun&author=C.%20Greenhow)\n\n004. [Alves and Cipriano, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib4)\n\n\n P. Alves, B.P. Cipriano\n\n\n\n “Give me the code”-Log Analysis of First-Year CS Students' interactions with GPT\n\n\n\n [https://doi.org/10.5281/zenodo.8430808](https://doi.org/10.5281/zenodo.8430808) (2024)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Give%20me%20the%20code-Log%20Analysis%20of%20First-Year%20CS%20Students%20interactions%20with%20GPT&publication_year=2024&author=P.%20Alves&author=B.P.%20Cipriano)\n\n005. [Astuti et al., 2019](https://www.sciencedirect.com/www.sciencedirect.com#bbib5)\n\n\n A.P. Astuti, A. Aziz, S.S. Sumarti, D.A.L. Bharati\n\n\n\n Preparing 21st century teachers: Implementation of 4C character's pre-service teacher through teaching practice\n\n\n\n Journal of physics, Vol 1233 (2019), Article 012109, [10.1088/1742-6596/1233/1/012109](https://doi.org/10.1088/1742-6596/1233/1/012109)\n\n 1\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85068685437&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Preparing%2021st%20century%20teachers%3A%20Implementation%20of%204C%20characters%20pre-service%20teacher%20through%20teaching%20practice&publication_year=2019&author=A.P.%20Astuti&author=A.%20Aziz&author=S.S.%20Sumarti&author=D.A.L.%20Bharati)\n\n006. [Basu, 2019](https://www.sciencedirect.com/www.sciencedirect.com#bbib6)\n\n\n S. Basu\n\n\n\n Using rubrics integrating design and coding to assess middle school students' open-ended block-based programming projects\n\n\n\n SIGCSE 2019 – Proceedings of the 50th ACM Technical Symposium on Computer Science Education (2019), pp. 1211-1217, [10.1145/3287324.3287412](https://doi.org/10.1145/3287324.3287412)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85064391573&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Using%20rubrics%20integrating%20design%20and%20coding%20to%20assess%20middle%20school%20students%20open-ended%20block-based%20programming%20projects&publication_year=2019&author=S.%20Basu)\n\n007. [Belland, 2017](https://www.sciencedirect.com/www.sciencedirect.com#bbib8)\n\n\n B.R. Belland\n\n\n\n Instructional scaffolding in STEM education strategies and efficacy evidence\n\n\n\n (2017), [10.1007/978-3-319-02565-0](https://doi.org/10.1007/978-3-319-02565-0)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Instructional%20scaffolding%20in%20STEM%20education%20strategies%20and%20efficacy%20evidence&publication_year=2017&author=B.R.%20Belland)\n\n008. [Birt et al., 2016](https://www.sciencedirect.com/www.sciencedirect.com#bbib9)\n\n\n L. Birt, S. Scott, D. Cavers, C. Campbell, F. Walter\n\n\n\n Member checking: A tool to enhance trustworthiness or merely a nod to validation?\n\n\n\n Qualitative Health Research, 26 (13) (2016), pp. 1802-1811, [10.1177/1049732316654870](https://doi.org/10.1177/1049732316654870)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-84990855444&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Member%20checking%3A%20A%20tool%20to%20enhance%20trustworthiness%20or%20merely%20a%20nod%20to%20validation&publication_year=2016&author=L.%20Birt&author=S.%20Scott&author=D.%20Cavers&author=C.%20Campbell&author=F.%20Walter)\n\n009. [Bjursten et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib10)\n\n\n E.L. Bjursten, T. Nilsson, L. Gumaelius\n\n\n\n Computer programming in primary schools: Swedish Technology Teachers' pedagogical strategies\n\n\n\n International Journal of Technology and Design Education, 33 (4) (2023), pp. 1345-1368, [10.1007/s10798-022-09786-7](https://doi.org/10.1007/s10798-022-09786-7)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85142392027&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Computer%20programming%20in%20primary%20schools%3A%20Swedish%20Technology%20Teachers%20pedagogical%20strategies&publication_year=2023&author=E.L.%20Bjursten&author=T.%20Nilsson&author=L.%20Gumaelius)\n\n010. [Braun and Clarke, 2006](https://www.sciencedirect.com/www.sciencedirect.com#bbib11)\n\n\n V. Braun, V. Clarke\n\n\n\n Using thematic analysis in psychology\n\n\n\n Qualitative Research in Psychology, 3 (2) (2006), pp. 77-101, [10.1191/1478088706qp063oa](https://doi.org/10.1191/1478088706qp063oa)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-33750505977&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Using%20thematic%20analysis%20in%20psychology&publication_year=2006&author=V.%20Braun&author=V.%20Clarke)\n\n011. [Brookhart, 2010](https://www.sciencedirect.com/www.sciencedirect.com#bbib12)\n\n\n S. Brookhart\n\n\n\n How to assess higher order thinking skills in your classroom\n\n\n\n ASCD (2010)\n\n [http://www.ascd.org/Publications/Books/Overview/How-to-Assess-Higher-Order-Thinking-Skills-in-YourClassroom.aspx](http://www.ascd.org/Publications/Books/Overview/How-to-Assess-Higher-Order-Thinking-Skills-in-YourClassroom.aspx)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=How%20to%20assess%20higher%20order%20thinking%20skills%20in%20your%20classroom&publication_year=2010&author=S.%20Brookhart)\n\n012. [Cabo, 2015](https://www.sciencedirect.com/www.sciencedirect.com#bbib13)\n\n\n C. Cabo\n\n\n\n Quantifying student progress through bloom's taxonomy cognitive categories in computer programming courses\n\n\n\n 2015 ASEE Annual Conference and Exposition Proceedings (2015), pp. 26.1295.1-26.1295.13, [10.18260/p.24632](https://doi.org/10.18260/p.24632)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Quantifying%20student%20progress%20through%20blooms%20taxonomy%20cognitive%20categories%20in%20computer%20programming%20courses&publication_year=2015&author=C.%20Cabo)\n\n013. [Campbell and Stanley, 1963](https://www.sciencedirect.com/www.sciencedirect.com#bbib15)\n\n\n D.T. Campbell, J.C. Stanley\n\n\n\n Experimental and quasi-experimental designs for research\n\n\n\n _Houghton,_ Mifflin and Company (1963)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Experimental%20and%20quasi-experimental%20designs%20for%20research&publication_year=1963&author=D.T.%20Campbell&author=J.C.%20Stanley)\n\n014. [Chandio et al., 2016](https://www.sciencedirect.com/www.sciencedirect.com#bbib16)\n\n\n M.T. Chandio, S.M. Pandhiani, R. Iqbal\n\n\n\n Bloom's taxonomy: Improving assessment and teaching- learning process\n\n\n\n Journal of Education and Educational Development, 3 (2) (2016), pp. 203-221\n\n [https://jmsnew.iobmre-search.com/index.php/joeed/article/download/194/330](https://jmsnew.iobmre-search.com/index.php/joeed/article/download/194/330)\n\n [Crossref](https://doi.org/10.22555/joeed.v3i2.1034) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Blooms%20taxonomy%3A%20Improving%20assessment%20and%20teaching-%20learning%20process&publication_year=2016&author=M.T.%20Chandio&author=S.M.%20Pandhiani&author=R.%20Iqbal)\n\n015. [Chen et al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bbib18)\n\n\n Y. Chen, S. Xiao, Y. Song, Z. Li, L. Sun, L. Chen\n\n\n\n MindScratch: A visual programming support tool for classroom learning based on multimodal generative AI\n\n\n\n International Journal of Human-Computer Interaction (2025), pp. 1-19, [10.1080/10447318.2025.2475991](https://doi.org/10.1080/10447318.2025.2475991)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=MindScratch%3A%20A%20visual%20programming%20support%20tool%20for%20classroom%20learning%20based%20on%20multimodal%20generative%20AI&publication_year=2025&author=Y.%20Chen&author=S.%20Xiao&author=Y.%20Song&author=Z.%20Li&author=L.%20Sun&author=L.%20Chen)\n\n016. [Dickey et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib19)\n\n\n E. Dickey, A. Bejarano, G. Chirayu\n\n\n\n AI-Lab: A framework for introducing generative artificial intelligence tools in computer programming courses\n\n\n\n SN Computer. Science., 5 (6) (2024), p. 17, [10.1007/s42979-024-03074-y](https://doi.org/10.1007/s42979-024-03074-y)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=AI-Lab%3A%20A%20framework%20for%20introducing%20generative%20artificial%20intelligence%20tools%20in%20computer%20programming%20courses&publication_year=2024&author=E.%20Dickey&author=A.%20Bejarano&author=G.%20Chirayu)\n\n017. [Cohen, 1992](https://www.sciencedirect.com/www.sciencedirect.com#bbib20)\n\n\n J. Cohen\n\n\n\n Statistical power analysis\n\n\n\n Current Directions in Psychological Science, 1 (3) (1992), pp. 98-101, [10.1111/1467-8721.ep10768783](https://doi.org/10.1111/1467-8721.ep10768783)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-84970743493&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Statistical%20power%20analysis&publication_year=1992&author=J.%20Cohen)\n\n018. [Creswell, 2014](https://www.sciencedirect.com/www.sciencedirect.com#bbib21)\n\n\n J.W. Creswell\n\n\n\n Research design: Qualitative, quantitative, and mixed methods approaches\n\n\n\n (4th ed.), Sage (2014)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Research%20design%3A%20Qualitative%2C%20quantitative%2C%20and%20mixed%20methods%20approaches&publication_year=2014&author=J.W.%20Creswell)\n\n019. [Creswell and Poth, 2018](https://www.sciencedirect.com/www.sciencedirect.com#bbib22)\n\n\n J.W. Creswell, C.N. Poth\n\n\n\n Qualitative inquiry and research design: Choosing among five approaches\n\n\n\n ISBN: 9781506330204\n\n (4th ed.), SAGE Publications (2018)\n\n [https://us.sagepub.com/en-us/nam/qualitative-inquiry-and-research-design/book246896](https://us.sagepub.com/en-us/nam/qualitative-inquiry-and-research-design/book246896)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Qualitative%20inquiry%20and%20research%20design%3A%20Choosing%20among%20five%20approaches&publication_year=2018&author=J.W.%20Creswell&author=C.N.%20Poth)\n\n020. [Denny et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib23)\n\n\n P. Denny, J. Leinonen, J. Prather, A. Luxton-Reilly, T. Amarouche, B.A. Becker, B.N. Reeves\n\n\n\n Promptly: Using prompt problems to teach learners how to effectively utilize AI code generators\n\n\n\n [http://arxiv.org/abs/2307.16364](http://arxiv.org/abs/2307.16364) (2023)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Promptly%3A%20Using%20prompt%20problems%20to%20teach%20learners%20how%20to%20effectively%20utilize%20AI%20code%20generators&publication_year=2023&author=P.%20Denny&author=J.%20Leinonen&author=J.%20Prather&author=A.%20Luxton-Reilly&author=T.%20Amarouche&author=B.A.%20Becker&author=B.N.%20Reeves)\n\n021. [Deriba et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib24)\n\n\n F.G. Deriba, I.T. Sanusi, A.O. Sunday\n\n\n\n Enhancing computer programming education using ChatGPT: A mini review\n\n\n\n ACM International Conference Proceeding Series (2023), [10.1145/3631802.3631848](https://doi.org/10.1145/3631802.3631848)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Enhancing%20computer%20programming%20education%20using%20ChatGPT%3A%20A%20mini%20review&publication_year=2023&author=F.G.%20Deriba&author=I.T.%20Sanusi&author=A.O.%20Sunday)\n\n022. [Devolder et al., 2012](https://www.sciencedirect.com/www.sciencedirect.com#bbib25)\n\n\n A. Devolder, J. van Braak, J. Tondeur\n\n\n\n Supporting self-regulated learning in computer-based learning environments: Systematic review of effects of scaffolding in the domain of science education\n\n\n\n Journal of Computer Assisted Learning, 28 (6) (2012), pp. 557-573, [10.1111/j.1365-2729.2011.00476.x](https://doi.org/10.1111/j.1365-2729.2011.00476.x)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-84868213196&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Supporting%20self-regulated%20learning%20in%20computer-based%20learning%20environments%3A%20Systematic%20review%20of%20effects%20of%20scaffolding%20in%20the%20domain%20of%20science%20education&publication_year=2012&author=A.%20Devolder&author=J.%20van%20Braak&author=J.%20Tondeur)\n\n023. [Dimitrov and Rumrill, 2003](https://www.sciencedirect.com/www.sciencedirect.com#bbib27)\n\n\n D.M. Dimitrov, P.D. Rumrill\n\n\n\n Pretest-posttest designs and measurement of change\n\n\n\n Work, 20 (2) (2003), pp. 159-165, [10.3233/WOR-2003-00285](https://doi.org/10.3233/WOR-2003-00285)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0037273563&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Pretest-posttest%20designs%20and%20measurement%20of%20change&publication_year=2003&author=D.M.%20Dimitrov&author=P.D.%20Rumrill)\n\n024. [Ghimire and Edwards, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib28)\n\n\n A. Ghimire, J. Edwards\n\n\n\n Coding with AI: How are tools like ChatGPT being used by students in foundational programming courses\n\n\n\n A.M. Olney, I.A. Chounta, Z. Liu, O.C. Santos, I.I. Bittencourt (Eds.), Artificial intelligence in education. AIED 2024. Lecture notes in computer science, Vol. 14830, Springer, Cham (2024)\n\n [https://doi-org.ezproxy.uef.fi:2443/10.1007/978-3-031-64299-9\\_20](https://doi-org.ezproxy.uef.fi:2443/10.1007/978-3-031-64299-9_20)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Coding%20with%20AI%3A%20How%20are%20tools%20like%20ChatGPT%20being%20used%20by%20students%20in%20foundational%20programming%20courses&publication_year=2024&author=A.%20Ghimire&author=J.%20Edwards)\n\n025. [Egbert et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bbib29)\n\n\n J. Egbert, S.A. Shahrokni, R. Abobaker, N. Borysenko\n\n\n\n It's a chance to make mistakes\": Processes and outcomes of coding in 2nd grade classrooms\n\n\n\n Computers & Education, 168 (2021), Article 104173, [10.1016/j.compedu.2021.104173](https://doi.org/10.1016/j.compedu.2021.104173)\n\n [View PDF](https://www.sciencedirect.com/science/article/pii/S0360131521000506/pdfft?md5=746dac4d63a4d01b981195ea031afee0&pid=1-s2.0-S0360131521000506-main.pdf) [View article](https://www.sciencedirect.com/science/article/pii/S0360131521000506) [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85103928207&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Its%20a%20chance%20to%20make%20mistakes%3A%20Processes%20and%20outcomes%20of%20coding%20in%202nd%20grade%20classrooms&publication_year=2021&author=J.%20Egbert&author=S.A.%20Shahrokni&author=R.%20Abobaker&author=N.%20Borysenko)\n\n026. [Erdei et al., 2017](https://www.sciencedirect.com/www.sciencedirect.com#bbib30)\n\n\n R. Erdei, J.A. Springer, D.M. Whittinghill\n\n\n\n An impact comparison of two instructional scaffolding strategies employed in our programming laboratories: Employment of a supplemental teaching assistant versus employment of the pair programming methodology\n\n\n\n IEEE Frontiers in Education Conference (FIE) (2017), pp. 1-6, [10.1109/FIE.2017.8190650](https://doi.org/10.1109/FIE.2017.8190650)\n\n Indianapolis, IN, USA\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85043288068&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=An%20impact%20comparison%20of%20two%20instructional%20scaffolding%20strategies%20employed%20in%20our%20programming%20laboratories%3A%20Employment%20of%20a%20supplemental%20teaching%20assistant%20versus%20employment%20of%20the%20pair%20programming%20methodology&publication_year=2017&author=R.%20Erdei&author=J.A.%20Springer&author=D.M.%20Whittinghill)\n\n027. [Estevez et al., 2019](https://www.sciencedirect.com/www.sciencedirect.com#bbib31)\n\n\n J. Estevez, G. Garate, M. Grana\n\n\n\n Gentle introduction to artificial intelligence for high-school students using scratch\n\n\n\n IEEE Access, 7 (2019), pp. 179027-179036, [10.1109/ACCESS.2019.2956136](https://doi.org/10.1109/ACCESS.2019.2956136)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85077230390&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Gentle%20introduction%20to%20artificial%20intelligence%20for%20high-school%20students%20using%20scratch&publication_year=2019&author=J.%20Estevez&author=G.%20Garate&author=M.%20Grana)\n\n028. [Eteng et al., 2022](https://www.sciencedirect.com/www.sciencedirect.com#bbib32)\n\n\n I. Eteng, S. Akpotuzor, S.O. Akinola, I. Agbonlahor\n\n\n\n A review on effective approach to teaching computer programming to undergraduates in developing countries\n\n\n\n Scientific African, 16 (2022), [10.1016/j.sciaf.2022.e01240](https://doi.org/10.1016/j.sciaf.2022.e01240)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20review%20on%20effective%20approach%20to%20teaching%20computer%20programming%20to%20undergraduates%20in%20developing%20countries&publication_year=2022&author=I.%20Eteng&author=S.%20Akpotuzor&author=S.O.%20Akinola&author=I.%20Agbonlahor)\n\n029. [Falloon, 2016](https://www.sciencedirect.com/www.sciencedirect.com#bbib33)\n\n\n G. Falloon\n\n\n\n An analysis of young students' thinking when completing basic coding tasks using Scratch Jnr. On the iPad\n\n\n\n Journal of Computer Assisted Learning, 32 (6) (2016), pp. 576-593, [10.1111/jcal.12155](https://doi.org/10.1111/jcal.12155)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-84982198682&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=An%20analysis%20of%20young%20students%20thinking%20when%20completing%20basic%20coding%20tasks%20using%20Scratch%20Jnr.%20On%20the%20iPad&publication_year=2016&author=G.%20Falloon)\n\n030. [Fanchamps et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bbib34)\n\n\n N. Fanchamps, L. Slangen, P. Hennissen, M. Specht\n\n\n\n The influence of SRA programming on algorithmic thinking and self-efficacy using Lego robotics in two types of instruction\n\n\n\n International Journal of Technology and Design Education, 31 (2) (2021), pp. 203-222, [10.1007/s10798-019-09559-9](https://doi.org/10.1007/s10798-019-09559-9)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85077144907&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=The%20influence%20of%20SRA%20programming%20on%20algorithmic%20thinking%20and%20self-efficacy%20using%20Lego%20robotics%20in%20two%20types%20of%20instruction&publication_year=2021&author=N.%20Fanchamps&author=L.%20Slangen&author=P.%20Hennissen&author=M.%20Specht)\n\n031. [Fayzulloeva and Mustafoeva, 2020](https://www.sciencedirect.com/www.sciencedirect.com#bbib35)\n\n\n G.C. Fayzulloeva, N.U.O.A. Mustafoeva\n\n\n\n A learner needs analysis report\n\n\n\n International Journal of Innovative Research and Development, 11 (2020), p. 726, [10.36713/epra2016](https://doi.org/10.36713/epra2016)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20learner%20needs%20analysis%20report&publication_year=2020&author=G.C.%20Fayzulloeva&author=N.U.O.A.%20Mustafoeva)\n\n032. [Fernandez and Cornell, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib36)\n\n\n A.S. Fernandez, K.A. Cornell\n\n\n\n CS1 with a side of AI: Teaching software verification for secure code in the era of generative AI. SIGCSE 2024\n\n\n\n Proceedings of the 55th ACM Technical Symposium on Computer Science Education, 1 (2024), pp. 345-351, [10.1145/3626252.3630817](https://doi.org/10.1145/3626252.3630817)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85189322137&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=CS1%20with%20a%20side%20of%20AI%3A%20Teaching%20software%20verification%20for%20secure%20code%20in%20the%20era%20of%20generative%20AI.%20SIGCSE%202024&publication_year=2024&author=A.S.%20Fernandez&author=K.A.%20Cornell)\n\n033. [Finnie-Ansley et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib37)\n\n\n J. Finnie-Ansley, P. Denny, A. Luxton-Reilly, E.A. Santos, J. Prather, B.A. Becker\n\n\n\n My AI wants to know if this will be on the exam: Testing OpenAI's codex on CS2 programming exercises\n\n\n\n In proceedings of the 25th australasian computing Education conference (ACE ’23), ACM (2023), [10.1145/3576123.3576134](https://doi.org/10.1145/3576123.3576134)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=My%20AI%20wants%20to%20know%20if%20this%20will%20be%20on%20the%20exam%3A%20Testing%20OpenAIs%20codex%20on%20CS2%20programming%20exercises&publication_year=2023&author=J.%20Finnie-Ansley&author=P.%20Denny&author=A.%20Luxton-Reilly&author=E.A.%20Santos&author=J.%20Prather&author=B.A.%20Becker)\n\n034. [Gendenjamts, 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib38)\n\n\n S. Gendenjamts\n\n\n\n Measuring higher-order thinking Skills in science among primary school students using item response theory\n\n\n\n European Journal of Education Studies, 10 (12) (2023), [10.46827/ejes.v10i12.5089](https://doi.org/10.46827/ejes.v10i12.5089)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Measuring%20higher-order%20thinking%20Skills%20in%20science%20among%20primary%20school%20students%20using%20item%20response%20theory&publication_year=2023&author=S.%20Gendenjamts)\n\n035. [González-Calatayud et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bbib39)\n\n\n V. González-Calatayud, P. Prendes-Espinosa, R. Roig-Vila\n\n\n\n Artificial intelligence for student assessment: A systematic review\n\n\n\n Applied Sciences, 11 (12) (2021), p. 5467, [10.3390/app11125467](https://doi.org/10.3390/app11125467)\n\n 2021\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85108626455&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Artificial%20intelligence%20for%20student%20assessment%3A%20A%20systematic%20review&publication_year=2021&author=V.%20Gonz%C3%A1lez-Calatayud&author=P.%20Prendes-Espinosa&author=R.%20Roig-Vila)\n\n036. [Grant, 2011](https://www.sciencedirect.com/www.sciencedirect.com#bbib40)\n\n\n M.M. Grant\n\n\n\n Learning, beliefs, and products: Students' perspectives with project-based learning\n\n\n\n Interdisciplinary Journal of Problem-Based Learning, 5 (2) (2011), pp. 37-69, [10.7771/1541-5015.1254](https://doi.org/10.7771/1541-5015.1254)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-79961142686&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Learning%2C%20beliefs%2C%20and%20products%3A%20Students%20perspectives%20with%20project-based%20learning&publication_year=2011&author=M.M.%20Grant)\n\n037. [Gupta and Mehrotra, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bbib41)\n\n\n P. Gupta, D. Mehrotra\n\n\n\n Objective assessment in Java programming Language using rubrics\n\n\n\n Journal of Information Technology Education: Innovations in Practice, 21 (2022), pp. 155-173, [10.28945/5040](https://doi.org/10.28945/5040)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85151837521&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Objective%20assessment%20in%20Java%20programming%20Language%20using%20rubrics&publication_year=2022&author=P.%20Gupta&author=D.%20Mehrotra)\n\n038. [Hamadeh, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib42)\n\n\n L. Hamadeh\n\n\n\n Exploring the utilisation of generative AI tools by undergraduate first-year mechanical engineering students in programming assessments\n\n\n\n SEFI Journal of Engineering Education Advancement, 1 (1) (2024), pp. 39-52, [10.62492/sefijeea.v1i1.20](https://doi.org/10.62492/sefijeea.v1i1.20)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Exploring%20the%20utilisation%20of%20generative%20AI%20tools%20by%20undergraduate%20first-year%20mechanical%20engineering%20students%20in%20programming%20assessments&publication_year=2024&author=L.%20Hamadeh)\n\n039. [Hartley et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib43)\n\n\n K. Hartley, M. Hayak, U.H. Ko\n\n\n\n Artificial intelligence supporting independent student learning: An evaluative case Study of ChatGPT and learning to code\n\n\n\n Education Sciences, 14 (2) (2024), [10.3390/educsci14020120](https://doi.org/10.3390/educsci14020120)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Artificial%20intelligence%20supporting%20independent%20student%20learning%3A%20An%20evaluative%20case%20Study%20of%20ChatGPT%20and%20learning%20to%20code&publication_year=2024&author=K.%20Hartley&author=M.%20Hayak&author=U.H.%20Ko)\n\n040. [Hazzan and Erez, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib44)\n\n\n O. Hazzan, Y. Erez\n\n\n\n Generative AI in computer science education\n\n\n\n Proceedings of the 55th ACM technical symposium on computer science education, Vol. 2 (2024), p. 1899\n\n (SIGCSE 2024). Association for Computing Machinery, New York, NY, USA\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Generative%20AI%20in%20computer%20science%20education&publication_year=2024&author=O.%20Hazzan&author=Y.%20Erez)\n\n041. [Ho et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib45)\n\n\n C.L. Ho, X.Y. Liu, Y.W. Qiu, S.Y. Yang\n\n\n\n Research on innovative applications and impacts of using generative AI for user interface design in programming courses\n\n\n\n ACM International Conference Proceeding Series (2024), pp. 68-72, [10.1145/3658549.3658566](https://doi.org/10.1145/3658549.3658566)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85198742931&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Research%20on%20innovative%20applications%20and%20impacts%20of%20using%20generative%20AI%20for%20user%20interface%20design%20in%20programming%20courses&publication_year=2024&author=C.L.%20Ho&author=X.Y.%20Liu&author=Y.W.%20Qiu&author=S.Y.%20Yang)\n\n042. [Holmes et al., 2022](https://www.sciencedirect.com/www.sciencedirect.com#bbib46)\n\n\n W. Holmes, K. Porayska-Pomsta, K. Holstein, E. Sutherland, T. Baker, S.B. Shum, O.C. Santos, M.T. Rodrigo, M. Cukurova, I.I. Bittencourt, K.R. Koedinger\n\n\n\n Ethics of AI in education: Towards a community-wide framework\n\n\n\n International Journal of Artificial Intelligence in Education, 32 (3) (2022), pp. 504-526, [10.1007/s40593-021-00239-1](https://doi.org/10.1007/s40593-021-00239-1)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85104089310&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Ethics%20of%20AI%20in%20education%3A%20Towards%20a%20community-wide%20framework&publication_year=2022&author=W.%20Holmes&author=K.%20Porayska-Pomsta&author=K.%20Holstein&author=E.%20Sutherland&author=T.%20Baker&author=S.B.%20Shum&author=O.C.%20Santos&author=M.T.%20Rodrigo&author=M.%20Cukurova&author=I.I.%20Bittencourt&author=K.R.%20Koedinger)\n\n043. [Hou et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib47)\n\n\n X. Hou, Z. Wu, X. Wang, B.J. Ericson\n\n\n\n CodeTailor: LLM-Powered personalized parsons puzzles for engaging support while learning programming\n\n\n\n L@S 2024 - Proceedings of the 11th ACM Conference on Learning @ Scale (2024), pp. 51-62, [10.1145/3657604.3662032](https://doi.org/10.1145/3657604.3662032)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85197053395&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=CodeTailor%3A%20LLM-Powered%20personalized%20parsons%20puzzles%20for%20engaging%20support%20while%20learning%20programming&publication_year=2024&author=X.%20Hou&author=Z.%20Wu&author=X.%20Wang&author=B.J.%20Ericson)\n\n044. [Hsu, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bbib49)\n\n\n H.P. Hsu\n\n\n\n From programming to prompting: Developing computational thinking through large Language model-based generative artificial intelligence\n\n\n\n TechTrends (2025), [10.1007/s11528-025-01052-6](https://doi.org/10.1007/s11528-025-01052-6)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=From%20programming%20to%20prompting%3A%20Developing%20computational%20thinking%20through%20large%20Language%20model-based%20generative%20artificial%20intelligence&publication_year=2025&author=H.P.%20Hsu)\n\n045. [Huang et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib50)\n\n\n Q. Huang, Z. Zou, Z. Xing, Z. Zuo, X. Xu, Q. Lu\n\n\n\n AI chain on large Language model for unsupervised control flow graph generation for statically-typed partial code\n\n\n\n [http://arxiv.org/abs/2306.00757](http://arxiv.org/abs/2306.00757) (2023)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=AI%20chain%20on%20large%20Language%20model%20for%20unsupervised%20control%20flow%20graph%20generation%20for%20statically-typed%20partial%20code&publication_year=2023&author=Q.%20Huang&author=Z.%20Zou&author=Z.%20Xing&author=Z.%20Zuo&author=X.%20Xu&author=Q.%20Lu)\n\n046. [Ibarra-Torres et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib51)\n\n\n F. Ibarra-Torres, G. Caiza, M.V. García, V. Barona-Pico\n\n\n\n Use of basic programming tools to foster programming logic in university students with school preparation other than computer science\n\n\n\n Procedia Computer Science, 237 (2024), pp. 413-419, [10.1016/j.procs.2024.05.122](https://doi.org/10.1016/j.procs.2024.05.122)\n\n [View PDF](https://www.sciencedirect.com/science/article/pii/S1877050924011384/pdf?md5=345ace2df87f7fad69e9431993932553&pid=1-s2.0-S1877050924011384-main.pdf) [View article](https://www.sciencedirect.com/science/article/pii/S1877050924011384) [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85195398667&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Use%20of%20basic%20programming%20tools%20to%20foster%20programming%20logic%20in%20university%20students%20with%20school%20preparation%20other%20than%20computer%20science&publication_year=2024&author=F.%20Ibarra-Torres&author=G.%20Caiza&author=M.V.%20Garc%C3%ADa&author=V.%20Barona-Pico)\n\n047. [Jackson et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib52)\n\n\n V. Jackson, B. Vasilescu, D. Russo, P. Ralph, M. Izadi, R. Prikladnicki, S. D'Angelo, S. Inman, A. Lisboa, A. Van-der H\n\n\n\n Creativity, generative AI, and software development\n\n\n\n A Research Agenda (2024)\n\n [http://arxiv.org/abs/2406.01966](http://arxiv.org/abs/2406.01966)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Creativity%2C%20generative%20AI%2C%20and%20software%20development&publication_year=2024&author=V.%20Jackson&author=B.%20Vasilescu&author=D.%20Russo&author=P.%20Ralph&author=M.%20Izadi&author=R.%20Prikladnicki&author=S.%20D'Angelo&author=S.%20Inman&author=A.%20Lisboa&author=A.%20Van-der%20H)\n\n048. [Jin et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib53)\n\n\n Y. Jin, K. Yang, L. Yan, V. Echeverria, L. Zhao, R. Alfredo, M. Milesi, J. Fan, X. Li, D. Gašević, R. Martinez-Maldonado\n\n\n\n Chatting with a learning analytics dashboard: The role of generative AI literacy on learner interaction with conventional and scaffolding chatbots\n\n\n\n [http://arxiv.org/abs/2411.15597](http://arxiv.org/abs/2411.15597) (2024)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Chatting%20with%20a%20learning%20analytics%20dashboard%3A%20The%20role%20of%20generative%20AI%20literacy%20on%20learner%20interaction%20with%20conventional%20and%20scaffolding%20chatbots&publication_year=2024&author=Y.%20Jin&author=K.%20Yang&author=L.%20Yan&author=V.%20Echeverria&author=L.%20Zhao&author=R.%20Alfredo&author=M.%20Milesi&author=J.%20Fan&author=X.%20Li&author=D.%20Ga%C5%A1evi%C4%87&author=R.%20Martinez-Maldonado)\n\n049. [Jonsson and Tholander, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bbib54)\n\n\n M. Jonsson, J. Tholander\n\n\n\n Cracking the code: Co-coding with AI in creative programming education\n\n\n\n ACM International Conference Proceeding Series (2022), pp. 5-14, [10.1145/3527927.3532801](https://doi.org/10.1145/3527927.3532801)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85133393638&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Cracking%20the%20code%3A%20Co-coding%20with%20AI%20in%20creative%20programming%20education&publication_year=2022&author=M.%20Jonsson&author=J.%20Tholander)\n\n050. [Sentance et al., 2019](https://www.sciencedirect.com/www.sciencedirect.com#bbib55)\n\n\n S. Sentance, J. Waite, M. Kallia\n\n\n\n Teaching computer programming with PRIMM: A sociocultural perspective\n\n\n\n Computer Science Education, 29 (2–3) (2019), pp. 136-176, [10.1080/08993408.2019.1608781](https://doi.org/10.1080/08993408.2019.1608781)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85065057884&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Teaching%20computer%20programming%20with%20PRIMM%3A%20A%20sociocultural%20perspective&publication_year=2019&author=S.%20Sentance&author=J.%20Waite&author=M.%20Kallia)\n\n051. [Kazemitabaar et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib56)\n\n\n M. Kazemitabaar, J. Chow, C.K.T. Ma, B.J. Ericson, D. Weintrop, T. Grossman\n\n\n\n Studying the effect of AI code generators on supporting novice learners in introductory programming\n\n\n\n In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems (CHI ’23), Association for Computing Machinery, New York, NY, USA (2023), pp. 1-23, [10.1145/3544548.3580919](https://doi.org/10.1145/3544548.3580919)\n\n April 19, 2023, New York, NY, USA\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Studying%20the%20effect%20of%20AI%20code%20generators%20on%20supporting%20novice%20learners%20in%20introductory%20programming&publication_year=2023&author=M.%20Kazemitabaar&author=J.%20Chow&author=C.K.T.%20Ma&author=B.J.%20Ericson&author=D.%20Weintrop&author=T.%20Grossman)\n\n052. [Kiesler, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bbib57)\n\n\n N. Kiesler\n\n\n\n Reviewing constructivist theories to help foster creativity in programming education\n\n\n\n IEEE Frontiers in Education Conference (FIE) (2022), pp. 1-5, [10.1109/FIE56618.2022.9962699](https://doi.org/10.1109/FIE56618.2022.9962699)\n\n Uppsala, Sweden\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Reviewing%20constructivist%20theories%20to%20help%20foster%20creativity%20in%20programming%20education&publication_year=2022&author=N.%20Kiesler)\n\n053. [Kimmel et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib58)\n\n\n B. Kimmel, A. Lee Geisert, L. Yaro, B. Gipson, R. Taylor Hotchkiss, S. Kwame Osae-Asante, H. Vaught, G. Wininger, C. Yamaguchi\n\n\n\n Enhancing programming error messages in real time with generative AI\n\n\n\n Conference on Human Factors in Computing Systems - Proceedings (2024), [10.1145/3613905.3647967](https://doi.org/10.1145/3613905.3647967)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Enhancing%20programming%20error%20messages%20in%20real%20time%20with%20generative%20AI&publication_year=2024&author=B.%20Kimmel&author=A.%20Lee%20Geisert&author=L.%20Yaro&author=B.%20Gipson&author=R.%20Taylor%20Hotchkiss&author=S.%20Kwame%20Osae-Asante&author=H.%20Vaught&author=G.%20Wininger&author=C.%20Yamaguchi)\n\n054. [Korkmaz et al., 2017](https://www.sciencedirect.com/www.sciencedirect.com#bbib59)\n\n\n O. Korkmaz, R. Çakir, M.Y. Ozden\n\n\n\n A validity and reliability study of the computational thinking scales (CTS)\n\n\n\n Computers in Human Behavior, 72 (2017), pp. 558-569, [10.1016/j.chb.2017.01.005](https://doi.org/10.1016/j.chb.2017.01.005)\n\n [View PDF](https://www.sciencedirect.com/science/article/pii/S0747563217300055/pdfft?md5=8e770f88578a770f019dcd080a36f0cd&pid=1-s2.0-S0747563217300055-main.pdf) [View article](https://www.sciencedirect.com/science/article/pii/S0747563217300055) [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85015675979&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20validity%20and%20reliability%20study%20of%20the%20computational%20thinking%20scales%20&publication_year=2017&author=O.%20Korkmaz&author=R.%20%C3%87akir&author=M.Y.%20Ozden)\n\n055. [Korstjens and Moser, 2018](https://www.sciencedirect.com/www.sciencedirect.com#bbib60)\n\n\n I. Korstjens, A. Moser\n\n\n\n Series: Practical guidance to qualitative research. Part 4: Trustworthiness and publishing\n\n\n\n The European Journal of General Practice, 24 (1) (2018), pp. 120-124, [10.1080/13814788.2017.1375092](https://doi.org/10.1080/13814788.2017.1375092)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85036652921&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Series%3A%20Practical%20guidance%20to%20qualitative%20research.%20Part%204%3A%20Trustworthiness%20and%20publishing&publication_year=2018&author=I.%20Korstjens&author=A.%20Moser)\n\n056. [Koutcheme et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib61)\n\n\n C. Koutcheme, S. Sarsa, J. Leinonen, A. Hellas, P. Denny\n\n\n\n Automated Program repair using generative models for code infilling\n\n\n\n Springer Nature Switzerland (2023), pp. 798-803, [10.1007/978-3-031-36272-9\\_74](https://doi.org/10.1007/978-3-031-36272-9_74)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85164908820&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Automated%20Program%20repair%20using%20generative%20models%20for%20code%20infilling&publication_year=2023&author=C.%20Koutcheme&author=S.%20Sarsa&author=J.%20Leinonen&author=A.%20Hellas&author=P.%20Denny)\n\n057. [Krathwohl, 2002](https://www.sciencedirect.com/www.sciencedirect.com#bbib62)\n\n\n D.R. Krathwohl\n\n\n\n A revision of Bloom's taxonomy: An overview\n\n\n\n Theory into Practice, 41 (4) (2002), pp. 212-218, [10.1207/s15430421tip4104\\_2](https://doi.org/10.1207/s15430421tip4104_2)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-0036762146&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20revision%20of%20Blooms%20taxonomy%3A%20An%20overview&publication_year=2002&author=D.R.%20Krathwohl)\n\n058. [Kurtz et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib63)\n\n\n G. Kurtz, M. Amzalag, N. Shaked, Y. Zaguri, D. Kohen-Vacs, E. Gal, G. Zailer, E. Barak-Medina\n\n\n\n Strategies for integrating generative AI into higher education: Navigating challenges and leveraging opportunities\n\n\n\n Education Sciences, 14 (5) (2024), [10.3390/educsci14050503](https://doi.org/10.3390/educsci14050503)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Strategies%20for%20integrating%20generative%20AI%20into%20higher%20education%3A%20Navigating%20challenges%20and%20leveraging%20opportunities&publication_year=2024&author=G.%20Kurtz&author=M.%20Amzalag&author=N.%20Shaked&author=Y.%20Zaguri&author=D.%20Kohen-Vacs&author=E.%20Gal&author=G.%20Zailer&author=E.%20Barak-Medina)\n\n059. [Lee et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib64)\n\n\n C. Lee, J. Myung, J. Han, J. Jin, A. Oh\n\n\n\n Learning from teaching assistants to formulate subgoals for programming tasks: Exploring the potential for AI teaching assistants\n\n\n\n CEUR Workshop Proceedings, 3840 (2024)\n\n [https://ceur-ws.org/Vol-3840/L3MNGET24\\_paper5.pdf](https://ceur-ws.org/Vol-3840/L3MNGET24_paper5.pdf)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Learning%20from%20teaching%20assistants%20to%20formulate%20subgoals%20for%20programming%20tasks%3A%20Exploring%20the%20potential%20for%20AI%20teaching%20assistants&publication_year=2024&author=C.%20Lee&author=J.%20Myung&author=J.%20Han&author=J.%20Jin&author=A.%20Oh)\n\n060. [Leinonen et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib65)\n\n\n J. Leinonen, P. Denny, S. MacNeil, S. Sarsa, S. Bernstein, J. Kim, A. Tran, A. Hellas\n\n\n\n Comparing code explanations created by students and large Language models\n\n\n\n Proceedings of the 2023 Conference on Innovation and Technology in Computer Science Education V. 1 (Turku, Finland) (ITiCSE 2023), Association for Computing Machinery, _New York_, NY, USA (2023), pp. 124-130, [10.1145/3587102.3588785](https://doi.org/10.1145/3587102.3588785)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85164031984&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Comparing%20code%20explanations%20created%20by%20students%20and%20large%20Language%20models&publication_year=2023&author=J.%20Leinonen&author=P.%20Denny&author=S.%20MacNeil&author=S.%20Sarsa&author=S.%20Bernstein&author=J.%20Kim&author=A.%20Tran&author=A.%20Hellas)\n\n061. [Lewis, 2022](https://www.sciencedirect.com/www.sciencedirect.com#bbib66)\n\n\n C. Lewis\n\n\n\n Automatic programming and education\n\n\n\n Companion proceedings of the 6th international conference on the art, science, and engineering of programming (programming '22), Association for Computing Machinery, New York, NY, USA (2022), pp. 70-80, [10.1145/3532512.3539664](https://doi.org/10.1145/3532512.3539664)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85144309188&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Automatic%20programming%20and%20education&publication_year=2022&author=C.%20Lewis)\n\n062. [Liao et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib67)\n\n\n J. Liao, L. Zhong, L. Zhe, H. Xu, M. Liu, T. Xie\n\n\n\n Scaffolding computational thinking with ChatGPT\n\n\n\n IEEE Transactions on Learning Technologies, 17 (2024), pp. 1668-1682, [10.1109/TLT.2024.3392896](https://doi.org/10.1109/TLT.2024.3392896)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85191305720&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Scaffolding%20computational%20thinking%20with%20ChatGPT&publication_year=2024&author=J.%20Liao&author=L.%20Zhong&author=L.%20Zhe&author=H.%20Xu&author=M.%20Liu&author=T.%20Xie)\n\n063. [Logacheva et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib68)\n\n\n E. Logacheva, A. Hellas, J. Prather, S. Sarsa, J. Leinonen\n\n\n\n Evaluating contextually personalized programming exercises created with generative AI. ICER 2024\n\n\n\n ACM Conference on International Computing Education Research, 1 (2024), pp. 95-113, [10.1145/3632620.3671103](https://doi.org/10.1145/3632620.3671103)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85200486237&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Evaluating%20contextually%20personalized%20programming%20exercises%20created%20with%20generative%20AI.%20ICER%202024&publication_year=2024&author=E.%20Logacheva&author=A.%20Hellas&author=J.%20Prather&author=S.%20Sarsa&author=J.%20Leinonen)\n\n064. [Luna, 2015](https://www.sciencedirect.com/www.sciencedirect.com#bbib69)\n\n\n S.C. Luna\n\n\n\n The futures of learning 2: What kind of learning for the 21st century?\n\n\n\n [https://www.dpsgs.org/pdf/The\\_Futures\\_of\\_Learning.pdf](https://www.dpsgs.org/pdf/The_Futures_of_Learning.pdf) (2015)\n\n M, L. (2003). Thinking in education. Cambridge\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=The%20futures%20of%20learning%202%3A%20What%20kind%20of%20learning%20for%20the%2021st%20century&publication_year=2015&author=S.C.%20Luna)\n\n065. [MacNeil et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib70)\n\n\n S. MacNeil, A. Tran, A. Hellas, J. Kim, S. Sarsa, P. Denny, S. Bernstein, J. Leinonen\n\n\n\n Experiences from using code explanations generated by large language models in a web software development e-book\n\n\n\n Proceedings of the 54th ACM technical symposium on computer science education, Vol. 1 (2023), pp. 931-937, [10.1145/3545945.3569785](https://doi.org/10.1145/3545945.3569785)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85148727616&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Experiences%20from%20using%20code%20explanations%20generated%20by%20large%20language%20models%20in%20a%20web%20software%20development%20e-book&publication_year=2023&author=S.%20MacNeil&author=A.%20Tran&author=A.%20Hellas&author=J.%20Kim&author=S.%20Sarsa&author=P.%20Denny&author=S.%20Bernstein&author=J.%20Leinonen)\n\n066. [MacNeil et al., 2022](https://www.sciencedirect.com/www.sciencedirect.com#bbib71)\n\n\n S. MacNeil, A. Tran, D. Mogil, S. Bernstein, E. Ross, H.Z. Ziheng\n\n\n\n Generating diverse code explanations using the gpt-3 large language model\n\n\n\n Proceedings of the 2022 ACM conference on international computing Education research, Vol. 2 (2022), pp. 37-39, [10.1145/3501709.3544280](https://doi.org/10.1145/3501709.3544280)\n\n New York, NY, USA\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85137106608&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Generating%20diverse%20code%20explanations%20using%20the%20gpt-3%20large%20language%20model&publication_year=2022&author=S.%20MacNeil&author=A.%20Tran&author=D.%20Mogil&author=S.%20Bernstein&author=E.%20Ross&author=H.Z.%20Ziheng)\n\n067. [Malik, 2019](https://www.sciencedirect.com/www.sciencedirect.com#bbib72)\n\n\n S.I. Malik\n\n\n\n Assessing the teaching and learning process of an introductory programming course with bloom's taxonomy and Assurance of Learning (AOL)\n\n\n\n International Journal of Information and Communication Technology Education, 15 (2) (2019), pp. 130-145, [10.4018/IJICTE.2019040108](https://doi.org/10.4018/IJICTE.2019040108)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85062192202&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Assessing%20the%20teaching%20and%20learning%20process%20of%20an%20introductory%20programming%20course%20with%20blooms%20taxonomy%20and%20Assurance%20of%20Learning%20&publication_year=2019&author=S.I.%20Malik)\n\n068. [Maryani et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bbib73)\n\n\n I. Maryani, Z.K. Prasetyo, I. Wilujeng, S. Purwanti, M. Fitrianawati\n\n\n\n Higher-Order thinking skills multiple choice and essay questions: A validated instrument to measure higher-order thinking skills of prospective teachers\n\n\n\n Journal of Turkish Science Education, 18 (4) (2021), pp. 674-690, [10.36681/tused.2021.97](https://doi.org/10.36681/tused.2021.97)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85122939395&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Higher-Order%20thinking%20skills%20multiple%20choice%20and%20essay%20questions%3A%20A%20validated%20instrument%20to%20measure%20higher-order%20thinking%20skills%20of%20prospective%20teachers&publication_year=2021&author=I.%20Maryani&author=Z.K.%20Prasetyo&author=I.%20Wilujeng&author=S.%20Purwanti&author=M.%20Fitrianawati)\n\n069. [Min and Heng, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib74)\n\n\n L. Min, Z. Heng\n\n\n\n A Study on impact of junior high school students' programming learning effect based on generative artificial intelligence\n\n\n\n International Conference on Educational Technology (ICET). Asia Pacific Journal of Education, 44 (1) (2024), pp. 1-27, [10.1080/02188791.2024.2305161](https://doi.org/10.1080/02188791.2024.2305161)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20Study%20on%20impact%20of%20junior%20high%20school%20students%20programming%20learning%20effect%20based%20on%20generative%20artificial%20intelligence&publication_year=2024&author=L.%20Min&author=Z.%20Heng)\n\n070. [Misrom et al., 2020](https://www.sciencedirect.com/www.sciencedirect.com#bbib75)\n\n\n N.S. Misrom, M.S. Abdurrahman, A.H. Abdullah, S. Osman, M.H. Hamzah, A. Fauzan\n\n\n\n Enhancing students' Higher-Order Thinking Skills (HOTS) through an inductive reasoning strategy using geogebra\n\n\n\n International Journal of Emerging Technologies in Learning, 15 (3) (2020), pp. 156-179, [10.3991/ijet.v15i03.9839](https://doi.org/10.3991/ijet.v15i03.9839)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85083577052&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Enhancing%20students%20Higher-Order%20Thinking%20Skills%20%20through%20an%20inductive%20reasoning%20strategy%20using%20geogebra&publication_year=2020&author=N.S.%20Misrom&author=M.S.%20Abdurrahman&author=A.H.%20Abdullah&author=S.%20Osman&author=M.H.%20Hamzah&author=A.%20Fauzan)\n\n071. [Naeem et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib76)\n\n\n U. Naeem, O.T. Virkki, A. Styve\n\n\n\n Developing critical thinking practices interwoven with generative AI usage in an introductory programming course\n\n\n\n 2024 _IEEE global engineering education conference_ (EDUCON) (2024), Article 10578746, [10.1109/educon60312.2024](https://doi.org/10.1109/educon60312.2024)\n\n 2024\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Developing%20critical%20thinking%20practices%20interwoven%20with%20generative%20AI%20usage%20in%20an%20introductory%20programming%20course&publication_year=2024&author=U.%20Naeem&author=O.T.%20Virkki&author=A.%20Styve)\n\n072. [Nathaniel et al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bbib77)\n\n\n J. Nathaniel, S.S. Oyelere, J. Suhonen, M. Tedre\n\n\n\n Literature review on the integration of generative AI in programming education\n\n\n\n International Journal of Artificial Intelligence in Education (2025)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Literature%20review%20on%20the%20integration%20of%20generative%20AI%20in%20programming%20education&publication_year=2025&author=J.%20Nathaniel&author=S.S.%20Oyelere&author=J.%20Suhonen&author=M.%20Tedre)\n\n073. [Nowell et al., 2017](https://www.sciencedirect.com/www.sciencedirect.com#bbib78)\n\n\n L.S. Nowell, J.M. Norris, D.E. White, N.J. Moules\n\n\n\n Thematic analysis: Striving to meet the trustworthiness criteria\n\n\n\n International Journal of Qualitative Methods, 16 (1) (2017), pp. 1-13, [10.1177/1609406917733847](https://doi.org/10.1177/1609406917733847)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Thematic%20analysis%3A%20Striving%20to%20meet%20the%20trustworthiness%20criteria&publication_year=2017&author=L.S.%20Nowell&author=J.M.%20Norris&author=D.E.%20White&author=N.J.%20Moules)\n\n074. [Obaido et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib113)\n\n\n G. Obaido, F.J. Agbo, C. Alvarado, S.S.Y. Oyelere\n\n\n\n Analysis of attrition studies within the Computer Sciences\n\n\n\n IEEE Access, 11 (2023), pp. 53736-53748, [10.1109/ACCESS.2023.3280075](https://doi.org/10.1109/ACCESS.2023.3280075)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85161027033&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Analysis%20of%20attrition%20studies%20within%20the%20Computer%20Sciences&publication_year=2023&author=G.%20Obaido&author=F.J.%20Agbo&author=C.%20Alvarado&author=S.S.Y.%20Oyelere)\n\n075. [Omer, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bbib79)\n\n\n W. Omer\n\n\n\n Modified bloom's taxonomy: Perspective of a doctor of philosophy scholar\n\n\n\n Journal of Rawalpindi Medical College, 28 (4) (2025), [10.37939/jrmc.v28i4.2804](https://doi.org/10.37939/jrmc.v28i4.2804)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Modified%20blooms%20taxonomy%3A%20Perspective%20of%20a%20doctor%20of%20philosophy%20scholar&publication_year=2025&author=W.%20Omer)\n\n076. [Oyelere et al., 2017](https://www.sciencedirect.com/www.sciencedirect.com#bbib116)\n\n\n S.S. Oyelere, J. Suhonen, T. Laine\n\n\n\n Integrating parson's programming puzzles into a game-based mobile learning application\n\n\n\n Proceedings of the 17th Koli calling international conference on computing education research (2017), [10.1145/3141880.3141882](https://doi.org/10.1145/3141880.3141882)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Integrating%20parsons%20programming%20puzzles%20into%20a%20game-based%20mobile%20learning%20application&publication_year=2017&author=S.S.%20Oyelere&author=J.%20Suhonen&author=T.%20Laine)\n\n077. [Papadakis, 2020](https://www.sciencedirect.com/www.sciencedirect.com#bbib80)\n\n\n S. Papadakis\n\n\n\n Evaluating a game-development approach to teach introductory programming concepts in secondary education\n\n\n\n International Journal of Technology Enhanced Learning, 12 (2) (2020), pp. 127-145, [10.1504/ijtel.2020.106282](https://doi.org/10.1504/ijtel.2020.106282)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85083056129&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Evaluating%20a%20game-development%20approach%20to%20teach%20introductory%20programming%20concepts%20in%20secondary%20education&publication_year=2020&author=S.%20Papadakis)\n\n078. [Poitras et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib82)\n\n\n E. Poitras, B. Crane, A. Siegel\n\n\n\n Generative AI in introductory programming instruction: Examining the assistance dilemma with LLM-Based code generators. SIGCSE virtual 2024\n\n\n\n Proceedings of the 2024 ACM Virtual Global Computing Education Conference, 1 (2024), pp. 186-192, [10.1145/3649165.3690111](https://doi.org/10.1145/3649165.3690111)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85215528393&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Generative%20AI%20in%20introductory%20programming%20instruction%3A%20Examining%20the%20assistance%20dilemma%20with%20LLM-Based%20code%20generators.%20SIGCSE%20virtual%202024&publication_year=2024&author=E.%20Poitras&author=B.%20Crane&author=A.%20Siegel)\n\n079. [Prasad and Sane, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib83)\n\n\n P. Prasad, A. Sane\n\n\n\n A self-regulated learning framework using generative AI and its application in CS educational intervention design. SIGCSE 2024\n\n\n\n Proceedings of the 55th ACM Technical Symposium on Computer Science Education, 1 (2024), pp. 1070-1076, [10.1145/3626252.3630828](https://doi.org/10.1145/3626252.3630828)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85189335954&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20self-regulated%20learning%20framework%20using%20generative%20AI%20and%20its%20application%20in%20CS%20educational%20intervention%20design.%20SIGCSE%202024&publication_year=2024&author=P.%20Prasad&author=A.%20Sane)\n\n080. [Rahe and Maalej, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bbib84)\n\n\n C. Rahe, W. Maalej\n\n\n\n How do programming students use generative AI?\n\n\n\n [https://doi.org/10.1145/3715762](https://doi.org/10.1145/3715762) (2025)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=How%20do%20programming%20students%20use%20generative%20AI&publication_year=2025&author=C.%20Rahe&author=W.%20Maalej)\n\n081. [Ramona and Aleksandar, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bbib85)\n\n\n M. Ramona, M. Aleksandar\n\n\n\n Effective prompt engineering for generative AI in C++ programming tasks\n\n\n\n World Journal of Advanced Research and Reviews, 25 (2) (2025), pp. 1390-1397, [10.30574/wjarr.2025.25.2.0516](https://doi.org/10.30574/wjarr.2025.25.2.0516)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Effective%20prompt%20engineering%20for%20generative%20AI%20in%20C%20programming%20tasks&publication_year=2025&author=M.%20Ramona&author=M.%20Aleksandar)\n\n082. [Roth et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bbib86)\n\n\n A. Roth, G. Singh, D. Turnbow\n\n\n\n Equitable but not diverse: Universal design for learning is not enough\n\n\n\n Open access, Publications from the University of California (2021)\n\n [https://www.inthelibrarywiththeleadpipe.org/2021/equitable-but-not-diverse/](https://www.inthelibrarywiththeleadpipe.org/2021/equitable-but-not-diverse/)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Equitable%20but%20not%20diverse%3A%20Universal%20design%20for%20learning%20is%20not%20enough&publication_year=2021&author=A.%20Roth&author=G.%20Singh&author=D.%20Turnbow)\n\n083. [Rozita et al., 2021](https://www.sciencedirect.com/www.sciencedirect.com#bbib87)\n\n\n K. Rozita, N.W. Saiful, S.B. Mohd\n\n\n\n Students' assessments in learning programming based on bloom's taxonomy\n\n\n\n Journal of Computing Research and Innovation (JCRINN), 6 (3) (2021), pp. 13-21\n\n 2021\n\n [https://jcrinn.com:eISSN:2600-8793](https://jcrinn.com:eISSN:2600-8793)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Students%20assessments%20in%20learning%20programming%20based%20on%20blooms%20taxonomy&publication_year=2021&author=K.%20Rozita&author=N.W.%20Saiful&author=S.B.%20Mohd)\n\n084. [Santos et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib88)\n\n\n E.A. Santos, P. Prasad, B.A. Becker\n\n\n\n Always provide context: The effects of code context on programming error message enhancement\n\n\n\n Proceedings of the ACM conference on global computing education, Vol. 1 (2023), pp. 147-153, [10.1145/3576882.3617909](https://doi.org/10.1145/3576882.3617909)\n\n New York, NY, USA\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85180801618&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Always%20provide%20context%3A%20The%20effects%20of%20code%20context%20on%20programming%20error%20message%20enhancement&publication_year=2023&author=E.A.%20Santos&author=P.%20Prasad&author=B.A.%20Becker)\n\n085. [Saunders et al., 2018](https://www.sciencedirect.com/www.sciencedirect.com#bbib89)\n\n\n B. Saunders, J. Sim, T. Kingstone, S. Baker, J. Waterfield, B. Bartlam, C. Jinks\n\n\n\n Saturation in qualitative research: Exploring its conceptualization and operationalization\n\n\n\n Quality and Quantity, 52 (2018), pp. 1893-1907, [10.1007/s11135-017-0574-8](https://doi.org/10.1007/s11135-017-0574-8)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85029480022&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Saturation%20in%20qualitative%20research%3A%20Exploring%20its%20conceptualization%20and%20operationalization&publication_year=2018&author=B.%20Saunders&author=J.%20Sim&author=T.%20Kingstone&author=S.%20Baker&author=J.%20Waterfield&author=B.%20Bartlam&author=C.%20Jinks)\n\n086. [Sauvola et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib90)\n\n\n J. Sauvola, S. Tarkoma, M. Klemettinen, J. Riekki, D. Doermann\n\n\n\n Future of software development with generative AI\n\n\n\n Automated Software Engineering, 31 (1) (2024), [10.1007/s10515-024-00426-z](https://doi.org/10.1007/s10515-024-00426-z)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Future%20of%20software%20development%20with%20generative%20AI&publication_year=2024&author=J.%20Sauvola&author=S.%20Tarkoma&author=M.%20Klemettinen&author=J.%20Riekki&author=D.%20Doermann)\n\n087. [Schefer-Wenzl et al., 2025](https://www.sciencedirect.com/www.sciencedirect.com#bbib91)\n\n\n S. Schefer-Wenzl, C. Vogl, S. Peiris, I. Miladinovic\n\n\n\n Exploring the adoption of generative AI tools in computer Science Education: A Student Survey\n\n\n\n Proceedings of the 2024 the 16th international conference on education technology and computers, ICETC (2025), [10.1145/3702163.3702188](https://doi.org/10.1145/3702163.3702188)\n\n 2024\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Exploring%20the%20adoption%20of%20generative%20AI%20tools%20in%20computer%20Science%20Education%3A%20A%20Student%20Survey&publication_year=2025&author=S.%20Schefer-Wenzl&author=C.%20Vogl&author=S.%20Peiris&author=I.%20Miladinovic)\n\n088. [Shabani et al., 2010](https://www.sciencedirect.com/www.sciencedirect.com#bbib92)\n\n\n K. Shabani, M. Khatib, S. Ebadi\n\n\n\n Vygotsky's Zone of proximal development: Instructional implications and teachers' professional development\n\n\n\n English Language Teaching, 3 (4) (2010), [10.5539/elt.v3n4p237](https://doi.org/10.5539/elt.v3n4p237)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Vygotskys%20Zone%20of%20proximal%20development%3A%20Instructional%20implications%20and%20teachers%20professional%20development&publication_year=2010&author=K.%20Shabani&author=M.%20Khatib&author=S.%20Ebadi)\n\n089. [Shanto et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib93)\n\n\n S.S. Shanto, A.I. Jony, Z. Ahmed\n\n\n\n Potentiality of generative AI tools in higher education: Evaluating chatgpt's viability as a teaching assistant for introductory programming courses\n\n\n\n STEM education, 4 (3) (2024)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Potentiality%20of%20generative%20AI%20tools%20in%20higher%20education%3A%20Evaluating%20chatgpts%20viability%20as%20a%20teaching%20assistant%20for%20introductory%20programming%20courses&publication_year=2024&author=S.S.%20Shanto&author=A.I.%20Jony&author=Z.%20Ahmed)\n\n090. [Sobral, 2021](https://www.sciencedirect.com/www.sciencedirect.com#bbib94)\n\n\n S.R. Sobral\n\n\n\n Bloom's taxonomy to improve teaching-learning in introduction to programming\n\n\n\n International journal of information and education technology. IJIET 2021, 11 (3) (2021), pp. 148-153, [10.18178/ijiet.2021.11.3.1504](https://doi.org/10.18178/ijiet.2021.11.3.1504)\n\n ISSN: 2010-3689\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85101549831&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Blooms%20taxonomy%20to%20improve%20teaching-learning%20in%20introduction%20to%20programming&publication_year=2021&author=S.R.%20Sobral)\n\n091. [Spinellis, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib96)\n\n\n D. Spinellis\n\n\n\n Pair programming with generative AI\n\n\n\n IEEE Software, 41 (3) (2024), pp. 16-18, [10.1109/MS.2024.3363848](https://doi.org/10.1109/MS.2024.3363848)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85189986042&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Pair%20programming%20with%20generative%20AI&publication_year=2024&author=D.%20Spinellis)\n\n092. [Stone, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib97)\n\n\n I. Stone\n\n\n\n Exploring human-centered approaches in generative AI and introductory programming research\n\n\n\n A scoping review _proceedings of the 2024 conference on United Kingdom & Ireland computing education research_, (UKICER '24). Association for Computing Machinery, New York, NY, USA (2024), pp. 1-7\n\n Article 4\n\n [https://doi.org/10.1145/3689535.3689553](https://doi.org/10.1145/3689535.3689553)\n\n [Crossref](https://doi.org/10.1145/3689535.3689553) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Exploring%20human-centered%20approaches%20in%20generative%20AI%20and%20introductory%20programming%20research&publication_year=2024&author=I.%20Stone)\n\n093. [Strawhacker et al., 2018](https://www.sciencedirect.com/www.sciencedirect.com#bbib98)\n\n\n A. Strawhacker, M. Lee, M.U. Bers\n\n\n\n Teaching tools, teachers' rules: Exploring the impact of teaching styles on young children's programming knowledge in ScratchJr\n\n\n\n International Journal of Technology and Design Education, 28 (2) (2018), pp. 347-376, [10.1007/s10798-017-9400-9](https://doi.org/10.1007/s10798-017-9400-9)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85014022893&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Teaching%20tools%2C%20teachers%20rules%3A%20Exploring%20the%20impact%20of%20teaching%20styles%20on%20young%20childrens%20programming%20knowledge%20in%20ScratchJr&publication_year=2018&author=A.%20Strawhacker&author=M.%20Lee&author=M.U.%20Bers)\n\n094. [Sullivan, 2017](https://www.sciencedirect.com/www.sciencedirect.com#bbib99)\n\n\n R.F. Sullivan\n\n\n\n Constructionism\n\n\n\n Open & distance education and eLearning: _Creativity, technology, and learning_ (2017)\n\n eBook ISBN9781315765143\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Constructionism&publication_year=2017&author=R.F.%20Sullivan)\n\n095. [Sun et al., 2022](https://www.sciencedirect.com/www.sciencedirect.com#bbib100)\n\n\n H. Sun, Y. Xie, J. Lavonen\n\n\n\n Exploring the structure of students' scientific higher order thinking in science education\n\n\n\n Thinking Skills and Creativity, 43 (2022), [10.1016/j.tsc.2022.100999](https://doi.org/10.1016/j.tsc.2022.100999)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Exploring%20the%20structure%20of%20students%20scientific%20higher%20order%20thinking%20in%20science%20education&publication_year=2022&author=H.%20Sun&author=Y.%20Xie&author=J.%20Lavonen)\n\n096. [Sunday et al., 2020](https://www.sciencedirect.com/www.sciencedirect.com#bbib114)\n\n\n K. Sunday, P. Ocheja, S. Hussain, S.S. Oyelere, O.S. Balogun, F.J. Agbo\n\n\n\n Analyzing student performance in programming education using classification techniques\n\n\n\n International Journal of Emerging Technologies in Learning, 15 (2) (2020), pp. 127-144, [10.3991/ijet.v15i02.11527](https://doi.org/10.3991/ijet.v15i02.11527)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85089031881&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Analyzing%20student%20performance%20in%20programming%20education%20using%20classification%20techniques&publication_year=2020&author=K.%20Sunday&author=P.%20Ocheja&author=S.%20Hussain&author=S.S.%20Oyelere&author=O.S.%20Balogun&author=F.J.%20Agbo)\n\n097. [Ullah et al., 2020](https://www.sciencedirect.com/www.sciencedirect.com#bbib101)\n\n\n Z. Ullah, A. Lajis, M. Jamjoom, A. Altalhi, F. Saleem\n\n\n\n Bloom's taxonomy: A beneficial tool for learning and assessing students' competency levels in computer programming using empirical analysis\n\n\n\n Computer Applications in Engineering Education, 28 (6) (2020), pp. 1628-1640, [10.1002/cae.22339](https://doi.org/10.1002/cae.22339)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85091165731&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Blooms%20taxonomy%3A%20A%20beneficial%20tool%20for%20learning%20and%20assessing%20students%20competency%20levels%20in%20computer%20programming%20using%20empirical%20analysis&publication_year=2020&author=Z.%20Ullah&author=A.%20Lajis&author=M.%20Jamjoom&author=A.%20Altalhi&author=F.%20Saleem)\n\n098. [Viswanathan, 2025](https://www.sciencedirect.com/www.sciencedirect.com#bbib102)\n\n\n P.S. Viswanathan\n\n\n\n Prompt engineering for conversational AI systems: A systematic review of techniques and applications\n\n\n\n International Journal of Scientific Research in Computer Science, Engineering and Information Technology, 11 (1) (2025), pp. 733-741, [10.32628/CSEIT25111276](https://doi.org/10.32628/CSEIT25111276)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Prompt%20engineering%20for%20conversational%20AI%20systems%3A%20A%20systematic%20review%20of%20techniques%20and%20applications&publication_year=2025&author=P.S.%20Viswanathan)\n\n099. [Walter, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib103)\n\n\n Y. Walter\n\n\n\n Embracing the future of Artificial Intelligence in the classroom: The relevance of AI literacy, prompt engineering, and critical thinking in modern education\n\n\n\n International Journal of Educational Technology in Higher Education, 21 (1) (2024), [10.1186/s41239-024-00448-3](https://doi.org/10.1186/s41239-024-00448-3)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Embracing%20the%20future%20of%20Artificial%20Intelligence%20in%20the%20classroom%3A%20The%20relevance%20of%20AI%20literacy%2C%20prompt%20engineering%2C%20and%20critical%20thinking%20in%20modern%20education&publication_year=2024&author=Y.%20Walter)\n\n100. [Wermelinger, 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib104)\n\n\n M. Wermelinger\n\n\n\n Using GitHub copilot to solve simple programming problems\n\n\n\n _In proceedings of the 54th ACM technical symposium on computer science EducationV.1_ (SIGCSE 2023), ACM (2023), [10.1145/3545945.3569830](https://doi.org/10.1145/3545945.3569830)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Using%20GitHub%20copilot%20to%20solve%20simple%20programming%20problems&publication_year=2023&author=M.%20Wermelinger)\n\n101. [Xue et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib105)\n\n\n Y. Xue, H. Chen, G.R. Bai, R. Tairas, Y. Huang\n\n\n\n Does ChatGPT help with introductory programming? An experiment of students using ChatGPT in CS1\n\n\n\n Proceedings - International Conference on Software Engineering (2024), pp. 331-341, [10.1145/3639474.3640076](https://doi.org/10.1145/3639474.3640076)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85195477483&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=Does%20ChatGPT%20help%20with%20introductory%20programming%20An%20experiment%20of%20students%20using%20ChatGPT%20in%20CS1&publication_year=2024&author=Y.%20Xue&author=H.%20Chen&author=G.R.%20Bai&author=R.%20Tairas&author=Y.%20Huang)\n\n102. [Yan et al., 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib107)\n\n\n W. Yan, T. Nakajima, R. Sawada\n\n\n\n Benefits and challenges of Collaboration between students and conversational generative artificial intelligence in programming learning: An empirical case Study\n\n\n\n Education Sciences, 14 (4) (2024), [10.3390/educsci14040433](https://doi.org/10.3390/educsci14040433)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Benefits%20and%20challenges%20of%20Collaboration%20between%20students%20and%20conversational%20generative%20artificial%20intelligence%20in%20programming%20learning%3A%20An%20empirical%20case%20Study&publication_year=2024&author=W.%20Yan&author=T.%20Nakajima&author=R.%20Sawada)\n\n103. [Yatigammana et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib108)\n\n\n K. Yatigammana, P.P. Premkumar, M. Yatigammana, S. Kannangara\n\n\n\n Impact of generative ai on critical thinking skills in undergraduates: A systematic review impact of generative ai on critical thinking skills in undergraduates: A systematic review the Journal of Desk Research Review and Analysis\n\n\n\n The journal of desk Research Review and Analysis-JDRRA, Vol. 1 (2023)\n\n [https://orcid.org/0009-0005-1950-190X](https://orcid.org/0009-0005-1950-190X)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Impact%20of%20generative%20ai%20on%20critical%20thinking%20skills%20in%20undergraduates%3A%20A%20systematic%20review%20impact%20of%20generative%20ai%20on%20critical%20thinking%20skills%20in%20undergraduates%3A%20A%20systematic%20review%20the%20Journal%20of%20Desk%20Research%20Review%20and%20Analysis&publication_year=2023&author=K.%20Yatigammana&author=P.P.%20Premkumar&author=M.%20Yatigammana&author=S.%20Kannangara)\n\n104. [Yilmaz and Yilmaz, 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib109)\n\n\n R. Yilmaz, K.F.G. Yilmaz\n\n\n\n The effect of generative artificial intelligence (AI)-based tool use on students' computational thinking skills, programming self-efficacy and motivation\n\n\n\n Computers and Education: Artificial Intelligence, 4 (2023), [10.1016/j.caeai.2023.100147](https://doi.org/10.1016/j.caeai.2023.100147)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=The%20effect%20of%20generative%20artificial%20intelligence%20-based%20tool%20use%20on%20students%20computational%20thinking%20skills%2C%20programming%20self-efficacy%20and%20motivation&publication_year=2023&author=R.%20Yilmaz&author=K.F.G.%20Yilmaz)\n\n105. [Zavala and Mendoza, 2018](https://www.sciencedirect.com/www.sciencedirect.com#bbib110)\n\n\n L. Zavala, B. Mendoza\n\n\n\n On the use of semantic-based AIG to automatically generate programming exercises\n\n\n\n Proceedings of the 49th ACM technical symposium on computer science education (SIGCSE ’18), Association for Computing Machinery, New York, NY, USA (2018), pp. 14-19, [10.1145/3159450.3159608](https://doi.org/10.1145/3159450.3159608)\n\n [View in Scopus](https://www.scopus.com/inward/record.url?eid=2-s2.0-85046108413&partnerID=10&rel=R3.0.0) [Google Scholar](https://scholar.google.com/scholar_lookup?title=On%20the%20use%20of%20semantic-based%20AIG%20to%20automatically%20generate%20programming%20exercises&publication_year=2018&author=L.%20Zavala&author=B.%20Mendoza)\n\n106. [Zhou et al., 2023](https://www.sciencedirect.com/www.sciencedirect.com#bbib111)\n\n\n Y. Zhou, L. Gan, J. Chen, T.T. Wijaya, Y. Li\n\n\n\n Development and validation of a Higher-Order Thinking Skills assessment scale for pre-service teachers\n\n\n\n Thinking Skills and Creativity, 48 (2023), [10.1016/j.tsc.2023.101272](https://doi.org/10.1016/j.tsc.2023.101272)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=Development%20and%20validation%20of%20a%20Higher-Order%20Thinking%20Skills%20assessment%20scale%20for%20pre-service%20teachers&publication_year=2023&author=Y.%20Zhou&author=L.%20Gan&author=J.%20Chen&author=T.T.%20Wijaya&author=Y.%20Li)\n\n107. [Zviel-Girshin, 2024](https://www.sciencedirect.com/www.sciencedirect.com#bbib112)\n\n\n R. Zviel-Girshin\n\n\n\n The good and bad of AI tools in novice programming education\n\n\n\n Education Sciences, 14 (10) (2024), [10.3390/educsci14101089](https://doi.org/10.3390/educsci14101089)\n\n [Google Scholar](https://scholar.google.com/scholar_lookup?title=The%20good%20and%20bad%20of%20AI%20tools%20in%20novice%20programming%20education&publication_year=2024&author=R.%20Zviel-Girshin)\n\n\n© 2025 The Authors. Published by Elsevier Ltd.\n\n## Cookie Preference Center\n\nWe use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our [Cookie Policy](https://www.elsevier.com/legal/cookienotice/_nocache) and the list of [Google Ad-Tech Vendors](https://support.google.com/admanager/answer/9012903).\nYou may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.\n\nAllow all\n\n### Manage Consent Preferences\n\n#### Strictly Necessary Cookies\n\nAlways active\n\nThese cookies are necessary for the website to function and cannot be switched off in our systems. They are usually only set in response to actions made by you which amount to a request for services, such as setting your privacy preferences, logging in or filling in forms. You can set your browser to block or alert you about these cookies, but some parts of the site will not then work.\n\nCookie Details List‎\n\n#### Performance Cookies\n\nPerformance Cookies\n\nThese cookies allow us to count visits and traffic sources so we can measure and improve the performance of our site. They help us to know which pages are the most and least popular and see how visitors move around the site.\n\nCookie Details List‎\n\n#### Contextual Advertising Cookies\n\nContextual Advertising Cookies\n\nThese cookies are used for properly showing banner advertisements on our site and associated functions such as limiting the number of times ads are shown to each user.\n\nCookie Details List‎\n\n### Cookie List\n\nClear\n\n- checkbox labellabel\n\n\nApplyCancel\n\nConsentLeg.Interest\n\ncheckbox labellabel\n\ncheckbox labellabel\n\ncheckbox labellabel\n\nConfirm my choices"}
{"title": "The impact of generative AI on academic integrity of authentic ...", "content": "\n \n \n Abstract \n \n \n \n \n Generative AI (hereinafter GenAI) technology, such as ChatGPT, is already influencing the higher education sector. In this work, we focused on the impact of GenAI on the academic integrity of assessments within higher education institutions, as GenAI can be used to circumvent assessment approaches within the sector, compromising their quality. The purpose of our research was threefold: first, to determine the extent to which the use of GenAI can be detected via the marking and moderation process; second, to understand whether the presence of GenAI affects the marking process; and finally, to establish whether authentic assessments can safeguard academic integrity. We used a series of experiments in the context of two UK-based universities to examine these issues. Our findings indicate that markers, in general, are not able to distinguish assessments that have had GenAI input from assessments that did not, even though the presence of GenAI affects the way markers approach the marking process. Our findings also suggest that the level of authenticity in an assessment has no impact on the ability to safeguard against or detect GenAI usage in assessment creation. In conclusion, we suggest that current approaches to assessments in higher education are susceptible to GenAI manipulation and that the higher education sector cannot rely on authentic assessments alone to control the impact of GenAI on academic integrity. Thus, we recommend giving more critical attention to assessment design and placing more emphasis on assessments that rely on social experiential learning and are performative rather than output-based and asynchronously written. \n \n \n \n \n Practitioner notes \n What is already known about this topic\n \n \n GenAI has enabled students to complete higher education assessments quickly and with good quality, leading to challenges in academic integrity. \n \n GenAI has transformed the requirements and considerations in assessment design in higher education. \n \n Authentic assessments are seen as a prominent way to tackle the GenAI challenge. \n \n What this paper adds\n \n \n We provide quantitative and qualitative experimental evidence suggesting that GenAI can generate authentic assessments that pass the scrutiny of experienced academics. \n \n We demonstrate how the use of authentic assessments alone does not protect the academic integrity of students in higher education. \n \n Our qualitative analysis indicates that markers may generate false positive and false negative results if they suspect GenAI tampering in an assessment. Thus, students' learning is not assessed correctly. \n \n Implications for practice and/or policy\n \n \n When universities and national organisations design policies regarding GenAI, authentic assessments are not the panacea; the focus must remain on assessment design. \n \n Assessments of learning need to shift from assessing output to focusing on process and relevance to the workplace. That would mean a paradigmatic shift from written assessments to synchronous interpersonal assessments. \n \n The move away from written assessments has implications that are far reaching for the academy if written assessments cannot be trusted as a reliable indicator for and of learning. \n \n \n \n \n \n \n \n \n \n INTRODUCTION \n \n ChatGPT rose to prominence in media headlines in late 2022 and within days acquired a million users (Marr,  2023). OpenAI's ChatGPT is an example of a generative artificial intelligence (GenAI) system. GenAI systems offer free and paid access, and anyone with internet access and the inclination can utilise such services to produce content. GenAI systems take instructions, also known as prompts, from users and respond by generating text, images, or other artefacts. Users can interact and engage with such systems to clarify questions and develop the responses the system produces. Recently, ChatGPT entered public discourse for three reasons: first, it is highly integrated into systems users are familiar with, such as web browsers, search engines, and word editors (Pastis,  2023); second, ChatGPT's responses have given the impression to users that there is genuine intelligence in the system (Deng &amp; Lin,  2022); and third, GenAI systems can appear to be experts on any subject because of the comprehensive way they respond to questions and prompts (Herbold et al.,  2023). \n \n The use of GenAI involves a range of ethical issues (Cotton et al.,  2023). As GenAI systems continue to develop at a very fast pace, they often outpace efforts to define clear ethical boundaries for appropriate use, providing an opportunity for users to adopt a consequentialist approach (Sinnott-Armstrong,  2003) in the usage of GenAI. The consequentialist approach is an ethical framework that evaluates the morality of actions based on their outcomes or consequences. In the case of higher education assessments, students weigh the potential positive outcomes (eg, efficiency and ease) against the possible negative consequences (eg, getting caught for academic dishonesty). If they determine that the benefits outweigh the risks, they may choose to use GenAI in ways that compromise academic integrity. Circumventing the assessment process in that way can undermine expected standards and norms in academic writing and assessment (Cronan et al.,  2018; Sutherland-Smith,  2008). \n \n Assessment is a vital part of learning and teaching in higher education, and as educators, we are mindful of ensuring that students are engaging honestly with formative and summative submissions in a way that facilitates learning. Universities have moved from relying on human markers to determine authorship of assessments to using antiplagiarism software such as Turnitin (Rolfe,  2011). However, with the rise of essay mills, ghostwriting services and contract cheating, it has become more challenging to determine the authorship of assessments (Bartlett,  2009). Essay mills and ghostwriting services allow students to outsource their work to third parties, who produce original content on their behalf, making it nearly impossible to detect their inputs through traditional plagiarism detection tools (Sweeney,  2023). This type of contract cheating undermines the academic process, as it circumvents the need for students to engage with the material and learn. The recent emergence of GenAI further complicates this issue, as GenAI can produce high-quality, seemingly original work that is difficult to distinguish from student-authored content (Spennemann et al.,  2024). If educators cannot reliably determine the authorship of an assessment, the value of higher education degrees can be undermined, posing a serious threat to the higher education sector. \n \n There is an ongoing debate about whether GenAI is fully capable of producing an assessment (Kocoń et al.,  2023); however, there is evidence to suggest that written types of assessments commonly used in institutions, such as reports and essays and even take-home exams, can be vulnerable to the use of GenAI (Scarfe et al.,  2024). These vulnerabilities are the result of two qualities that GenAI possesses: the ability to produce unique text rapidly (Kolade et al.,  2024; Rudolph et al.,  2023) and the ability to produce outputs that appear to be of high quality (Herbold et al.,  2023). The question for universities and educators is how to balance the potential benefits of GenAI, such as its ability to help students understand their assessment, to outline what might be written, and to brainstorm ideas (Sok &amp; Heng,  2023), against inappropriate uses such as cheating on an exam (Giannos &amp; Delardas,  2023) or on other assessments (Ventayen,  2023) or asking GenAI to devise ways of circumventing detection (Spennemann et al.,  2024). One potential answer offered in the literature is to return to invigilated exams, a suggestion that is not favoured by many educators, as exams can be seen as a rather inauthentic assessment of learning, even though that format would enhance the academic integrity of the work produced (Bower et al.,  2024; Forsyth,  2022). Another suggestion has been to develop assessments that are more authentic, that are more closely aligned to the world of work and to the kind of problems students face after graduation (Ellis et al.,  2020; Sotiriadou et al.,  2020). \n \n Within this context, this work set out to explore how GenAI influences the outcomes of assessments. We focused on the impact of GenAI on the assessment marking process in two different UK higher education institutions (HEIs) within the field of business studies. Our study was exploratory, and we used a range of assessments widely used by academics across the world to determine the answers to three research questions:\n \n \n RQ1: Can assessment markers differentiate between human-authored assessments, GenAI-modified assessments, and GenAI-generated assessments? \n \n RQ2: Does the presence of GenAI have the potential to influence the marking and moderation process? \n \n RQ3: Would different levels of authenticity in assessments have an impact on the ease of detection of GenAI usage? \n \n \n \n Participants in the study marked a range of assessments, with three versions: (a) assessments genuinely produced by students, which had already been marked with grades agreed upon, even though the particular submissions and their corresponding grades were initially unknown to the participants; (b) versions of the same assessments modified by GenAI with the tool ChatGPT 3.5; (c) assessments solely produced using GenAI that followed the requirements of the assessment brief. Our results indicate that GenAI can support students in circumventing the necessary effort and learning required to produce an assessment. Such efforts would not be reliably detected by human markers, but the knowledge that GenAI may have been used can affect markers' behaviour and judgement. Finally, we determined that the level of authenticity in the assessment has had a very limited impact in terms of GenAI usage detection. \n \n The paper comprises five sections. The first is a literature review on GenAI and the importance of assessment in higher education, followed by a section that details the mixed methods research design. The third section comprises findings that aim to provide preliminary answers to our questions, followed by a discussion regarding our findings. In the concluding section, we provide insights on the impact of GenAI on the marking process and recommendations for action in terms of assessment design. \n \n \n \n LITERATURE REVIEW \n \n \n \n Generative artificial intelligence and its impact on higher education \n \n For the general public, and many academics who were not involved in AI-related activities, awareness of the potential benefits and risks of GenAI began with the release of OpenAI's GPT 3.5 product in November 2022 (OpenAI,  2024). The system had a fixed dataset that was set back to September 2021, and the initial abilities of GPT 3.5 were enough to provoke much academic debate (Cao et al.,  2023; Wu,  2024) and to promote the development of this study. GenAI's development quickly upended efforts by academics to ensure academic integrity and the honest production of students' assessments (Rahman &amp; Watanobe,  2023). The problem of interference by a third party is not new; however, in the past the operators of services were human and there were cost implications for students (Bartlett,  2009; Medway et al.,  2018). However, GenAI assessments can now be generated for free, or very cheaply. Unlike lecturers and higher education support systems, GenAI is available 24 hours a day and can provide responses to questions and quickly produce a fully fleshed-out and plausible-looking assessment (Aydın &amp; Karaarslan,  2023; Dowling &amp; Lucey,  2023). For some students, GenAI appears to possess an air of intellectual authority (Firth et al.,  2024; Sok &amp; Heng,  2023; Sullivan et al.,  2023; Sweeney,  2023), and for students who are experiencing a change in the way they are learning (eg, studying in the UK), there may be a temptation to use GenAI-generated text, as they may perceive it as superior to the prose they could write themselves. However, proving that a student purchased an assessment or used GenAI is difficult, and academics in our respective institutions have resorted to reviewing their in-person interactions and perceptions of students' academic abilities or conducting vivas to identify misconduct. \n \n If a student elects to utilise GenAI to help write or fully develop an assessment, what are the potential risks aside from violating academic integrity rules? GenAI writing presents five main challenges. First, the GenAI systems' underlying training that produces responses to users may exhibit biases, including political (Rozado,  2023), racial and cultural (Ray,  2023), and gender (Gross,  2023) biases. Second, many systems are trained to absorb data from online sources, and these sources may contain data that are not representative or the framing of that data can lead to lawsuits (Appel et al.,  2023). Under-representative data refer to sources are often disproportionately populated by English-language and Western-centric content. Even when non-Western languages are included, the data tends to be limited in volume, context and domain diversity. This underrepresentation creates a gap in the model's ability to understand, generate, or process text that reflects the cultural and linguistic nuances of these communities (Guo et al., 2024). Third, GenAI can ‘hallucinate’, or make ‘mistakes’ with data and facts (Kocoń et al.,  2023; Rudolph et al.,  2023). Fourth, and connected to the third point, like all computer systems, GenAI responds to inputs from humans, and the language used by users is not always precise and clear. Users must curate their prompts carefully to get the information they require from a GenAI system (Giray,  2023; Lo,  2023). Finally, not all students utilise appropriate levels of autonomy (Carnell,  2016) and criticality when examining information sources and data. This refers to the earlier point around intellectual authority and a deferral of responsibility to someone or something else to complete a task. To compound the problem, the tools academics typically rely upon to check for use of GenAI in assessment writing can be biased and are considered inaccurate (Sullivan et al.,  2023). \n \n In the current UK socioeconomic climate, students face very high pressures: family life and caring responsibilities, attending university to study, often work responsibilities and higher costs of living. Under pressure, students may not be aware of or may choose to ignore institutional policies and guidance regarding academic practice (and malpractice). It used to be cost-prohibitive for students to seek the services of a third-party author; now free GenAI services or paid services with minimal cost are available. Thus, there is a strong temptation for students to adopt a consequentialist approach (Sinnott-Armstrong,  2003) to complete their assessments, leading to students prioritising task completion over falling foul of the institution's rules on academic practice. Thus, GenAI's expedient and proficient creation of an assessment (Ventayen,  2023) presents an existential threat to universities and their assessment processes. \n \n \n \n \n Importance of assessment in higher education \n \n Assessments are an important component of higher education and represent a prime measurement of students' competence and learning (Cilliers et al.,  2012). Assessments fall into two categories: formative and summative. Formative assessments encompass any assessment for learning that aids students' understanding of assessment requirements (Brown,  2005; Newton,  2007). Summative assessments measure learning (Broadbent et al.,  2018; Kofinas,  2018) and are directly linked to certification and progress (Newton,  2007). Student engagement with a combination of formative and summative assessments can help educators evaluate the level of learning that occurs within the classroom. \n \n In the higher education setting, students participate in formative activities within a module of study to engage with content to learn and/or achieve a higher grade in a summative assessment (Kolb &amp; Kolb,  2005; Lu et al.,  2003). Students are often strategic and focus on summative assessments, a phenomenon that Biggs ( 2003) labelled backwash. If summative assessments are disproportionately influential in driving students' learning (Brown,  2005; Holmes,  2015; Iannone &amp; Simpson,  2016; Raupach et al.,  2013), intelligent assessment design would facilitate learning via summative assessments and would use formative assessments in a manner that aligns closely with the summative (Broadbent et al.,  2018; López-Pastor et al.,  2013; Trotter,  2006). Biggs ( 2003) proposed in his constructive alignment model that the backwash phenomenon should be considered in assessment design and that educators should develop their modules starting from the summative assessments and working their way backwards towards the learning objectives of the module. \n \n As a consequence of this constructive alignment, an educator should link all aspects of learning in a module to the summative assessment while ensuring that this connection is communicated clearly. A well-designed assessment approach interweaves formative and summative assessments carefully to ensure that the learning happens in a thoughtful, well-scaffolded manner to take advantage of the backwash and to enhance the deep learning of the students (Biggs,  2003; Pereira et al.,  2015). Consequently, the quality of assessment determines whether the students learn what they are meant to learn, and the academic integrity of the assessments becomes a crucial academic quality issue (Glendinning,  2022; Harlen,  2004). HEIs have implemented various measures to promote academic integrity in their summative assessments, including codes of conduct, academic integrity policies and other educational programmes (Cotton et al.,  2023; Harlen,  2004; Morris,  2018). \n \n Given the importance of assessment in higher education, GenAI poses two challenges for assessment design: first, it provides the possibility for students to develop assessments directly rather than going through an iterative developmental process (Cotton et al.,  2023; Rasul et al.,  2023). Second, GenAI can quickly produce outputs that appear credible and original, even though there may be factual mistakes, a phenomenon known as hallucination (Beutel et al.,  2023). GenAI has made it very difficult to ascertain when an assessment that is submitted is an original assessment that demonstrates the student's level of learning. Our first two research questions explore this issue of GenAI detection that academics face and the impact it may have in the grading process. \n \n The response to the GenAI challenge from organisations such as the Quality Assurance Agency for Higher Education ( 2024) and Advance HE ( 2024) has been that universities need to move towards more innovative, authentic assessments. Authentic assessments link learning to the actual world of work and consequently provide learning experiences in activities, tasks and ideas that are directly applicable to the workplace (Lund,  1997; Mueller,  2005). Hobbins et al. ( 2022) suggested that authentic assessments need to meet four dimensions: realism, cognitive challenge, evaluative judgement criteria, and evaluative judgement feedback. Kaider et al. ( 2017) suggested that an assessment is authentic when it provides proximity to the world of business as well as an authentic task as the foundation for the assessment. Authentic assessments are considered harder to circumvent and have been considered a potential way to respond to the GenAI challenge (Ellis et al.,  2020; Sotiriadou et al.,  2020). \n \n Alternatively, if higher education providers cannot control access to GenAI, they may be able to direct this educational technology towards productive usage by encouraging students to use GenAI in their assessment preparation. That would be in accord with the emerging view among scholars that students should know how to use GenAI, as it is becoming a critical employability skill (Pagani et al.,  2023). Authentic assessments alongside other types of assessments, such as other interactive oral assessments (Krautloher,  2024; Ward et al.,  2023) and role-play–type assessments are seen as potential types of assessment that would support the usage of GenAI as a learning tool while safeguarding the academic integrity of the assessment. \n \n In this work, we focused on a range of authentic assessments to test whether the authenticity of assessment would assist the educators in identifying GenAI-generated text and thus facilitate the graders' evaluation of the quality of the assessments produced. \n \n \n \n \n METHODOLOGY \n \n This exploratory research work involved two medium-sized post-92 business schools within the UK. The research team worked at these two business schools; thus, convenience dictated the choice of these settings. The assessments we have chosen to run our experiments are widely used in the higher education sector. The processes for marking and moderation align with sector norms, with first marking and then moderation being the standard process for all undergraduate marking. \n \n To answer the research questions, we conducted a two-phased within-subjects experimental design to compare AI writing to human writing. We chose the within-subjects experimental design to achieve reduced variability in marking standards and efficiency while being mindful of order effects (Charness et al.,  2012). \n \n \n \n Participants \n \n Two undergraduate degree programmes, the Bachelor of Science in Business Management and the Bachelor of Arts in Business Purchasing and Supply Chain Management, were identified through the research team's professional networks. Upon receiving module leaders' agreement, one module at each undergraduate academic level (ie, levels 4 to 6) within each programme was selected to generate writing samples. Through module teams' recommendations, two pairs of academics from each programme who were familiar with the modules (eg, through teaching, marking, module/programme leadership) but were not involved in marking the selected writing samples were invited to mark the samples based on the established assessment rubrics. Thus, in total, four pairs of academics, totalling eight, participated in the experiment. They read the participant information sheets and gave consent. Participants' full-time work experience in higher education ranged from 3 to 15 years. Participants were advised that they should not discuss the individual details of assessments outside of the research interviews for the duration of the experiment. \n \n Each pair of academics was asked to evaluate three types of assessments with no prior grade knowledge: (a) existing unaltered student assessments; (b) assessments entirely authored using GenAI; and (c) GenAI-modified assessments (assessments where we modified sections of the assessment with content generated by GENAI software). ChatGPT 3.5 was used for this experiment, and a protocol was followed in developing each assessment. In the two-phased experiment, the four pairs of participating markers were first asked to mark randomly coded writing samples across three undergraduate academic levels independently. Then each pair of markers met with a member of the research team to reach an agreement on the marks, followed by researcher debrief and interview. The research team then used the agreed marks to provide descriptive statistics in answering the research questions, supplemented by interview data. The descriptive statistics from the experimental design, together with the textual information obtained from the interviews, formed our mixed-methods research design. Such a design allows for a more comprehensive understanding of a phenomenon and validation and corroboration of findings across different types of data (Cohen et al.,  2011; Turner &amp; Turner,  2009). For example, qualitative insights gained from our interview data explained anomalies that emerged in the quantitative data. Given that we explored new phenomena, this design was particularly beneficial in helping us explore in-depth answers to our research questions. \n \n \n \n \n Ethical considerations \n \n Institutional ethics permission was sought individually from each of the two universities and was obtained prior to data collection. When participants were recruited, they were informed that they would be evaluating writing samples, some of which had been modified using GenAI. However, we did not specify which samples had undergone GenAI treatment, nor did we disclose the exact nature of the GenAI modifications for each assessment. \n \n We had to address several ethical considerations. The recruitment of participants followed a convenient sampling approach where we approached module leaders to provide us access to appropriate members of the teams. The study required GenAI-driven modification of existing student assessments, which were anonymised and modified as required. With regard to the marking process, we followed standard marking procedures without any modification or deviation, and we had an early brief with all staff involved in our experiments and a debrief after the marking but before the interviews where we revealed all aspects of the experiment as a stimulus for the discussion. \n \n \n \n \n Writing sample selection \n \n The writing samples at each module contained work of three types. The first type consisted of three pieces of work written and marked at three grade bands (below pass mark ≤40%; 50%–60%; and first-class, ie, around 70% or more) by past students; these stood for the human-authored assessments, as they had been marked and had a healthy Turnitin similarity score. In the second group, GenAI (specifically ChatGPT 3.5) was used to modify the same three assessments, generating GenAI-modified versions of these assessments. In the third group, based on assessment briefs in each of the chosen modules, the research team created one assessment that was solely GenAI-authored. To achieve this, the research team took an assessment brief and used prompts to generate a piece of work within 1½ hours, simulating a ‘mischievous’ student. Appendix  A shows an example of prompts used in a Level 6 assessment. \n \n Therefore, for each programme, seven writing samples (three human-authored, three GenAI-modified, and one GenAI-authored) were prepared for each undergraduate academic level, resulting in a total of 21 writing samples, which were then randomly coded. We used a simple coding scheme, with HE1 and HE2 for each university and Levels 4–6 to indicate the year. We then used letters to indicate the version of the assignment. For example, HE1-L4-J denoted the assessment we chose for L4 from the first HEI and version J of that assessment. All assessment variations were coded and presented in that manner. \n \n The research team carefully selected assessments that represented a variety of approaches but had an explicit output, such as essays, reports and case study analyses, where GenAI could have an impact. Thus, we avoided assessments that included class presentations or exams, deeming that GenAI would probably have limited impact. Furthermore, to ensure that participating markers evaluated the writing quality of each sample reliably, each assessment was anonymised, so that it had no information that could identify the original author or a third party. We ensured that the assessment was not involved in any prior academic misconduct cases and did not score high on Turnitin similarity or AI indices. In addition, the writing samples were reformatted and were similar in terms of topic and length. \n \n We used two different ways to map out the authenticity of each assessment. First, Hobbins et al. ( 2022) suggested that authentic assessments need to meet four dimensions: realism, cognitive challenge, evaluative judgement criteria and evaluative judgement feedback. Table  1 maps our assessments based on these criteria. \n \n \n \n \n \n \n TABLE 1.\n Module assessment selection based on the authentic assessment tool developed by Hobbins et al. ( 2022). \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Institution and academic level \n \n Realism assessment engages students with problems or important questions relevant to everyday life beyond the classroom \n \n Cognitive challenge categories of cognitive processes related to using, modifying or rebuilding knowledge into something new \n \n Evaluative judgement criteria assessment provides opportunities for students to critically judge their own performance based on clear expectations \n \n Evaluative judgement feedback assessment engages students with meaningful feedback to allow for improvement \n \n \n \n \n \n \n \n HEI1-L4 \n \n Moderate \n \n Moderate \n \n High \n \n Moderate \n \n \n \n \n HEI2-L4 \n \n Moderate \n \n Moderate \n \n Moderate \n \n Low \n \n \n \n \n HEI1-L5 \n \n Moderate \n \n Moderate \n \n Moderate \n \n Moderate \n \n \n \n \n HEI2-L5 \n \n High \n \n Moderate \n \n Moderate \n \n Moderate \n \n \n \n \n HEI1-L6 \n \n Low \n \n Moderate \n \n Low \n \n Moderate \n \n \n \n \n HEI2-L6 \n \n Low \n \n Moderate \n \n Moderate \n \n Low \n \n \n \n \n \n \n \n \n \n Our sample had three assessments that were moderate/low in terms of authenticity, one that was medium and two that were medium/high. \n \n To validate this evaluation, we further mapped the six assessments against a second framework suggested by Kaider et al. ( 2017). They suggested that we can determine the level of authenticity on two dimensions: in terms of learning activities that approximate activities in the world of work (authentic activity) as well as the level of proximity the students experience to the world of work. Table  2 reallocates assessments based on the Kaider et al. ( 2017) matrix. \n \n \n \n \n \n \n TABLE 2.\n Module assessment selection based on Kaider et al. ( 2017) authenticity-proximity framework. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Proximity \n \n \n \n \n Learning experiences that occur in real workplaces and professional contexts, in online or live complex simulated workplace environments, and those that enable students to interact directly with industry practitioners or community members on work-related activities \n \n \n \n \n \n \n \n \n \n Authenticity \n \n Learning activities and assessments require students to work on problems, processes and projects that they may encounter in their professions and produce artefacts reflecting professional practice \n \n \n \n \n Low proximity \n \n \n Medium \n proximity \n \n \n \n High \n proximity \n \n \n \n \n \n High authenticity \n \n \n Active case studies and scenarios \n HEI1-L4 and HEI2-L5 \n \n \n \n \n \n \n \n \n \n Medium authenticity \n \n HEI1-L6 and HEI1-L5 \n \n \n \n \n \n \n \n \n Low authenticity \n \n \n Critical literature review \n HEI2-L4 and HEI2-L6 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Based on this framework, we had two assessments of high authenticity, two of medium and two of low, thus ensuring a nice distribution of assessments. Unfortunately, none of these assessments scored very high in terms of business proximity, meaning they were not conducted in the actual workplace or within professional environments. \n \n Looking at the results of the mapping across both frameworks, it is clear that assessments HEI1-L4 and HEI2-L5 scored high on authenticity, while assessments HEI2-L4 and HEI2-L6 scored low. Thus, we were reasonably assured that our assessments represented a range of high and low authenticity assessments. \n \n \n \n \n Data collection procedure \n \n The two-phased experiment consists of (1) marking and (2) mark reconciliation, debrief, and interview. A day to a week passed between Phase 1 and 2 to allow participants time to mark. In Phase 1 marking, markers were emailed three assessment briefs and marking criteria for L4, L5, and L6 assessments, from which the research team selected 12 assessments (four per level) that were a mix of human-authored, GenAI-augmented, and GenAI-generated samples. Each sample had a randomly assigned code, leaving limited room for ‘mark guessing’. As an independent task, each marker was asked to assign grades against the marking criteria using a provided mark sheet. Once 12 assessments were marked, each marker was sent the remaining nine assessments to a total of 21 assessments. The Phase 1 marking procedure took the markers about 3 hours. \n \n In Phase 2, four semi-structured in-depth interviews were conducted, each lasting approximately 2 hours (see Appendix  B for the interview protocol). Initially, researchers merged the mark entry sheets collected from each pair of markers. A researcher in the interview then facilitated discussions between the markers to reach a grade consensus on all 21 writing samples while providing a justification for the agreed grade. If there was a significant difference in their scores, the markers reviewed the assessment criteria and discussed the specific elements of the writing samples that led to these discrepancies. After discussing and reconciling their differences, the markers agreed on a final mark that reflected their consensus, ensuring fairness and accuracy in grading. Unlike mark agreements in real-world scenarios, where a third marker or moderator would be assigned if the initial markers could not agree, our experiment did not involve a third marker. \n \n After reaching an agreement on marks, the interviewer conducted a debriefing, revealing the identities of the assessments, including the original marks and feedback given to the human submissions, the GenAI-augmented samples, and the GenAI-generated samples. Participants were then asked to evaluate the similarities and differences between the original assessments and the GenAI-augmented and GenAI-generated assessments. They were also asked to share their usual approaches to identifying academic misconduct and their views on the future use of GenAI tools in higher education. In summary, the participants' overall impressions, grading differences and reflections were gathered. The process was carefully designed to minimise order effects and sources of bias (Charness et al.,  2012) while ensuring academic integrity. All participants were thoroughly briefed and debriefed. \n \n \n \n \n Data analysis \n \n Quantitative data, in the form of marks given to each assessment, were first collected from each of the eight participants during Phase 1. During Phase 2, the research team used the agreed grades from reconciliation as descriptive statistics to contribute towards answering the first two research questions. Quantitative data were analysed using standard descriptive statistics, including the calculation of means and differences in marks between human-authored, GenAI-modified and GenAI-generated assessments. \n \n Qualitative data were gathered from interview notes taken during the debriefing sessions and follow-up interviews with participants. The data were analysed using thematic analysis, a method that identifies themes and patterns to understand how markers' awareness of GenAI's involvement influenced their grading. The recorded interview data were transcribed and systematically analysed following the steps outlined by Boyatzis ( 1998). These steps included familiarising oneself with the data through repeated readings of the transcriptions, generating initial codes by identifying and labelling relevant segments of text, and then examining these codes to detect patterns and broader themes. These themes were reviewed, refined and related to our research questions, both inductively from the raw data and deductively from existing pedagogic literature. Table  3 provides an example of how codes emerged from interview extracts and were subsequently developed into themes. \n \n \n \n \n \n \n TABLE 3.\n Example of thematic coding. \n \n \n \n \n \n \n \n \n \n \n \n \n \n Interview extract \n \n Codes \n \n Theme \n \n \n \n \n \n \n \n There's not a single grammatical mistake, not single punctuation [mistake] or single spelling is usually in American English \n \n Perfection and lack of errors \n \n Characteristics of AI-generated texts \n \n \n \n \n I did catch a student using ChatGPT and how I did it was that I asked ChatGPT the question and it came back with a particular form of words. It is not a silver bullet and I found those form of words in the conclusions of four essays \n \n Uniformity in structure and style \n \n \n \n \n I normally tend to check at least a few references and if I checked a couple of a few of those and I see that there is no, it doesn't exist out, then would have raised this as GPT to use \n \n Referencing style and authenticity \n \n \n \n \n The type of the language that they use in terms of writing the, here I think it'll be very, very generic \n \n Generic and descriptive language \n \n \n \n \n What AI is doing is use lot of words. As though you know in the same sentence, what after what, after what meaning the same thing and then leading to a conclusion. Umm. That's helpful this pattern \n \n Repetitiveness and over-descriptiveness \n \n \n \n \n \n \n \n \n \n \n \n \n RESULTS \n \n To answer RQ1, before the researcher debriefing, the four pairs of markers were informed that some of the samples were generated or modified using GenAI. They were then asked to ‘guess’ (after the reconciliation of marks had been completed) which those were. Most markers were able to ‘sense’ AI-modified samples but were much less able to differentiate between human-authored or GenAI-authored coursework with confidence and accuracy, demonstrating the sophistication of AI's output. As shown in Tables  4 and 5, among the four pairs, the accuracy of guessing ranged between 33.3% (7 out of 21) and 85.7% (18 out of 21). \n \n \n \n \n \n \n TABLE 4.\n Writing sample identities and markers' predictions in Higher Education Institution 1. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Academic level \n \n Grade band \n \n Writing sample code \n \n Sample identity: Original (O), AI-modified (M), AI-generated (G) \n \n Pair 1 \n \n Pair 2 \n \n \n \n \n Guess of ChatGPT: Yes (Y), No (N), Unsure (U) \n \n Guess of ChatGPT: Yes (Y), No (N), Unsure (U) \n \n \n \n \n \n \n \n Level 4 \n \n ≦40 \n \n HE1-L4-Z \n \n O \n \n N \n \n N \n \n \n \n \n HE1-L4-F \n \n M \n \n Y \n \n Y \n \n \n \n \n 50–59 \n \n HE1-L4-J \n \n O \n \n N \n \n N \n \n \n \n \n HE1-L4-Q \n \n M \n \n Y \n \n Y \n \n \n \n \n ≧70 \n \n HE1-L4-R \n \n O \n \n N \n \n N \n \n \n \n \n HE1-L4-E \n \n M \n \n Y \n \n Y \n \n \n \n \n HE1-L4-A \n \n G \n \n Y \n \n Y \n \n \n \n \n Level 5 \n \n ≦40 \n \n HE1-L5-A \n \n O \n \n N \n \n U \n \n \n \n \n HE1-L5-G \n \n M \n \n Y \n \n U \n \n \n \n \n 50–59 \n \n HE1-L5-K \n \n O \n \n N \n \n U \n \n \n \n \n HE1-L5-R \n \n M \n \n U \n \n U \n \n \n \n \n ≧70 \n \n HE1-L5-S \n \n O \n \n N \n \n U \n \n \n \n \n HE1-L5-F \n \n M \n \n U \n \n U \n \n \n \n \n HE1-L5-B \n \n G \n \n Y \n \n U \n \n \n \n \n Level 6 \n \n ≦40 \n \n HE1-L6-B \n \n O \n \n N \n \n U \n \n \n \n \n HE1-L6-H \n \n M \n \n Y \n \n U \n \n \n \n \n 50–59 \n \n HE1-L6-L \n \n O \n \n N \n \n U \n \n \n \n \n HE1-L6-S \n \n M \n \n Y \n \n U \n \n \n \n \n ≧70 \n \n HE1-L6-T \n \n O \n \n N \n \n U \n \n \n \n \n HE1-L6-G \n \n M \n \n Y \n \n U \n \n \n \n \n HE1-L6-C \n \n G \n \n U \n \n U \n \n \n \n \n Accuracy of guess percentage \n \n \n \n 85.70% \n \n 33.30% \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n TABLE 5.\n Writing sample identities and markers' predictions in Higher Education Institution 2. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Academic level \n \n Grade band \n \n Writing sample code \n \n Sample identity: Original (O), AI-modified (M), AI-generated (G) \n \n Pair 3 \n \n Pair 4 \n \n \n \n \n Guess of ChatGPT: Yes (Y), No (N), Unsure (U) \n \n Guess of ChatGPT: Yes (Y), No (N), Unsure (U) \n \n \n \n \n \n \n \n Level 4 \n \n ≦40 \n \n HE2-L4-K \n \n O \n \n N \n \n Y \n \n \n \n \n HE2-L4-H \n \n M \n \n Y \n \n N \n \n \n \n \n 50–59 \n \n HE2-L4-C \n \n O \n \n N \n \n N \n \n \n \n \n HE2-L4-L \n \n M \n \n Y \n \n Y \n \n \n \n \n ≧70 \n \n HE2-L4-N \n \n O \n \n U \n \n N \n \n \n \n \n HE2-L4-G \n \n M \n \n U \n \n Y \n \n \n \n \n HE2-L4-Z \n \n G \n \n N \n \n Y \n \n \n \n \n Level 5 \n \n ≦40 \n \n HE2-L5-Z \n \n O \n \n Y \n \n Y \n \n \n \n \n HE2-L5-L \n \n M \n \n N \n \n N \n \n \n \n \n 50–59 \n \n HE2-L5-N \n \n O \n \n U \n \n U \n \n \n \n \n HE2-L5-Y \n \n M \n \n U \n \n U \n \n \n \n \n ≧70 \n \n HE2-L5-T \n \n O \n \n U \n \n U \n \n \n \n \n HE2-L5-B \n \n M \n \n U \n \n U \n \n \n \n \n HE2-L5-S \n \n G \n \n Y \n \n U \n \n \n \n \n Level 6 \n \n ≦40 \n \n HE2-L6-D \n \n O \n \n N \n \n Y \n \n \n \n \n HE2-L6-G \n \n M \n \n Y \n \n N \n \n \n \n \n 50–59 \n \n HE2-L6-H \n \n O \n \n N \n \n N \n \n \n \n \n HE2-L6-O \n \n M \n \n Y \n \n Y \n \n \n \n \n ≧70 \n \n HE2-L6-Q \n \n O \n \n Y \n \n Y \n \n \n \n \n HE2-L6-L \n \n M \n \n Y \n \n N \n \n \n \n \n HE2-L6-A \n \n G \n \n N \n \n N \n \n \n \n \n Accuracy of guess percentage \n \n \n \n 42.90% \n \n 33.3% \n \n \n \n \n \n \n \n \n \n Pair 2 had 33% accuracy in detecting AI versus non-AI work. One participant in Pair 2 mentioned they tried to spot potential AI-influenced work at the beginning of marking but gave up as they continued. This was not only due to the difficulty in discerning AI from non-AI work, but also because the quality of GenAI work may be dependent on “prompt engineering”.\n It is difficult…. It's not easy to confirm because when you're using AI, it's really important to say how we train it. If we give the AI more specific guidance or we clearly tell it what would be our expectation and we give AI more like a learning materials or paper, …we ask it to construct a better quality one. It could be, but yeah, it depends. \n \n \n \n \n Yet, with the research team's facilitation, Pair 2 was able to identify GPT-modified work at Level 4. One participant noted:\n The AI work is, … I mean, the piece is a little bit better [in terms of the writing quality and writing skills]. Maybe HEI2-L4-E is written by AI, and I suppose HEI2-L4-A is written by an AI. \n \n \n \n \n Pair 1 had 85.7% accuracy in detecting AI versus human work. One participant in Pair 1 was the module leader of Level 4 and 6 modules from which the writing samples were derived. They were very familiar with the design of these modules' assessments and had taught small cohorts of about 20 students in each module. As this pair was interviewed, both participants reported that the ‘writing style’ helped them differentiate between AI and human work. They both said that every writer had a distinct, nonperfect writing style:\n The sort of everyone in their writing style makes the same kind of errors. Everyone has a distinct referencing style, whether they're using a tool or not. They have a very distinct way of doing that, and that's quite easy to spot as well. \n \n \n \n \n Both participants described GenAI as not seeming to have a writing style, or in other words, GenAI was “too perfect”:\n Human work, …. they're gonna do with it what they feel. It's their own style, their own way, or how they make sense of it. Styles of paragraphs are usually around the same if it's fully written by AI that they should be quite on the genius.… Whereas I feel the ChatGPT tends to follow a very strict structure…. There's not a single grammatical mistake, not single punctuation [mistake]…. Spelling is usually in American English, which doesn't really necessarily mean anything, because you have such a diverse cohort, but usually tends to ring bells, and they see American English a lot. \n \n \n \n \n We speculate that there were both false positive and false negative cases. False positives occurred when markers incorrectly identified original, unaltered student submissions as being influenced by GenAI, at times mistakenly flagging genuine work as dishonest. This happened when markers answered “Y” or “U” to “O” samples in Tables  4 and 5, resulting in six incidents in our experiment. This implies that students who are not cheating have been penalised on suspicion alone. \n \n Conversely, false negatives occurred when assessments that have been modified or generated by GenAI were not recognised as such and were mistakenly considered as original student work. It appears in seven cases where markers answered “U” and “N” to “M” and “G” samples in Tables  4 and 5. This occurrence highlights the challenges in accurately detecting GenAI involvement, potentially leading to unjust penalties for honest students and failing to identify actual instances of GenAI use. \n \n To answer RQ2, in Tables  6 and 7 we compared the mark difference between the original samples and the GenAI-modified samples. It was found that the GenAI-augmented samples only enhanced the original student-written work at certain grade bands. There seemed to be consistency in improvement at the lower second grade band (nine out of 12 cases, increasing by two to eight percentage points) and some mark improvement at the below-pass-mark grade band (five out of 12 cases, increasing by three to 20 percentage points), but not at the first-class grade band. There was also a pattern of consistency at the below-pass-mark grade band. In seven out of 12 cases, markers awarded the same grade for the original submission and the GPT-modified sample. One participant in Pair 4 explained that because the structure in the human work (HEI1-L4-K) was poor, even with GenAI intervention, it did not improve much in structure or academic style. Similarly, both participants in Pair 3 stated that in several cases, the original submission sample and the GPT-augmented sample appeared very similar. \n \n \n \n \n \n \n TABLE 6.\n Comparisons of marks awarded to human-authored work and ChatGPT modified work in Higher Education Institution 1. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Grade band \n \n Academic level \n \n Writing sample code \n \n Sample identity: Original (O), AI-modified (M) \n \n Pair 1 \n \n Pair 2 \n \n \n \n \n Remarks \n \n Mark difference (M) − (O) \n \n Remarks \n \n Mark difference (M) − (O) \n \n \n \n \n \n \n \n ≦40 \n \n Level 4 \n \n HE1-L4-Z \n \n O \n \n 38 \n \n 0 ∆ \n \n 40 \n \n 0 ∆ \n \n \n \n \n HE1-L4-F \n \n M \n \n 38 \n \n 40 \n \n \n \n \n Level 5 \n \n HE1-L5-A \n \n O \n \n 38 \n \n 20 ↑ \n \n 45 \n \n 0 ∆ \n \n \n \n \n HE1-L5-G \n \n M \n \n 58 \n \n 45 \n \n \n \n \n Level 6 \n \n HE1-L6-B \n \n O \n \n 35 \n \n 5 ↑ \n \n 38 \n \n 0 ∆ \n \n \n \n \n HE1-L6-H \n \n M \n \n 40 \n \n 38 \n \n \n \n \n 50–59 \n \n Level 4 \n \n HE1-L4-J \n \n O \n \n 50 \n \n 2 ↑ \n \n 55 \n \n 5 ↑ \n \n \n \n \n HE1-L4-Q \n \n M \n \n 52 \n \n 60 \n \n \n \n \n Level 5 \n \n HE1-L5-K \n \n O \n \n 52 \n \n 8 ↑ \n \n 52 \n \n 3 ↑ \n \n \n \n \n HE1-L5-R \n \n M \n \n 60 \n \n 55 \n \n \n \n \n Level 6 \n \n HE1-L6-L \n \n O \n \n 45 \n \n 3 ↑ \n \n 35 \n \n 7 ↓ \n \n \n \n \n HE1-L6-S \n \n M \n \n 48 \n \n 28 \n \n \n \n \n ≧70 \n \n Level 4 \n \n HE1-L4-R \n \n O \n \n 70 \n \n 0 ∆ \n \n 55 \n \n 3 ↑ \n \n \n \n \n HE1-L4-E \n \n M \n \n 70 \n \n 58 \n \n \n \n \n Level 5 \n \n HE1-L5-S \n \n O \n \n 70 \n \n 0 ∆ \n \n 60 \n \n 8 ↑ \n \n \n \n \n HE1-L5-F \n \n M \n \n 70 \n \n 68 \n \n \n \n \n Level 6 \n \n HE1-L6-T \n \n O \n \n 70 \n \n 0 ∆ \n \n 60 \n \n 0 ∆ \n \n \n \n \n HE1-L6-G \n \n M \n \n 70 \n \n 60 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n TABLE 7.\n Comparisons of marks awarded to human-authored work and ChatGPT-modified work in Higher Education Institution 2. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Grade band \n \n Academic level \n \n Writing sample code \n \n Sample identity: Original (O), AI-modified (M) \n \n Pair 3 \n \n Pair 4 \n \n \n \n \n Remarks \n \n Mark difference (M) − (O) \n \n Remarks \n \n Mark difference (M) − (O) \n \n \n \n \n \n \n \n ≦40 \n \n Level 4 \n \n HE2-L4-K \n \n O \n \n 35 \n \n 10 ↑ \n \n 42 \n \n 0 ∆ \n \n \n \n \n HE2-L4-H \n \n M \n \n 45 \n \n 42 \n \n \n \n \n Level 5 \n \n HE2-L5-Z \n \n O \n \n 52 \n \n 3 ↑ \n \n 48 \n \n 4 ↑ \n \n \n \n \n HE2-L5-L \n \n M \n \n 55 \n \n 52 \n \n \n \n \n Level 6 \n \n HE2-L6-D \n \n O \n \n 42 \n \n 0 ∆ \n \n 38 \n \n 0 ∆ \n \n \n \n \n HE2-L6-G \n \n M \n \n 42 \n \n 38 \n \n \n \n \n 50–59 \n \n Level 4 \n \n HE2-L4-C \n \n O \n \n 55 \n \n 3 ↓ \n \n 55 \n \n 7 ↑ \n \n \n \n \n HE2-L4-L \n \n M \n \n 52 \n \n 62 \n \n \n \n \n Level 5 \n \n HE2-L5-N \n \n O \n \n 45 \n \n 3 ↑ \n \n 48 \n \n 3 ↓ \n \n \n \n \n HE2-L5-Y \n \n M \n \n 48 \n \n 45 \n \n \n \n \n Level 6 \n \n HE2-L6-H \n \n O \n \n 45 \n \n 7 ↑ \n \n 42 \n \n 6 ↑ \n \n \n \n \n HE2-L6-O \n \n M \n \n 52 \n \n 48 \n \n \n \n \n ≧70 \n \n Level 4 \n \n HE2-L4-N \n \n O \n \n 58 \n \n 7 ↑ \n \n 62 \n \n 10 ↓ \n \n \n \n \n HE2-L4-G \n \n M \n \n 65 \n \n 52 \n \n \n \n \n Level 5 \n \n HE2-L5-T \n \n O \n \n 58 \n \n 0 ∆ \n \n 52 \n \n 3 ↑ \n \n \n \n \n HE2-L5-B \n \n M \n \n 58 \n \n 55 \n \n \n \n \n Level 6 \n \n HE2-L6-Q \n \n O \n \n 58 \n \n 10 ↓ \n \n 62 \n \n 10 ↓ \n \n \n \n \n HE2-L6-L \n \n M \n \n 48 \n \n 52 \n \n \n \n \n \n \n \n \n \n To our surprise, almost all pairs graded the writing samples of originally first-class grades much lower (except Pair 1). One participant in Pair 3 admitted:\n Some of this work is presented really nicely, and if people are not marking consistently, it's going to be very easy to look at something and go: That's got all the component parts, and it's ticking all the boxes from the assessment because the buzzwords are there. Because I think, you know, partly … when we're marking … there are things that we're hoping to see. If at the level you see things and tick them off, your mental list goes there. That said, that's there. You're kind of missing the substance behind what's actually been written. \n \n \n \n \n We found that high-scoring samples seem to be adversely affected by false positives. In three out of 12 cases (primarily involving pair 3 and pair 4) at the first-class grade band in both Tables  6 and 7, markers assigned scores that were 10 percentage points lower on GenAI-modified assessments compared to the original submissions. Additionally, pairs 2, 3 and 4 awarded lower scores to original assessments that were initially awarded 70 and above, reducing them to the 60s or even lower. We suspect that the presence of GenAI indeed influenced the markers' grading process. Considering that the markers were aware that some of the samples they were marking had been generated by GenAI, it seems possible that markers may have subconsciously deducted marks from work they perceived as “too perfect.” \n \n Six GenAI-authored samples (ie, HE1-L4-A, HE1-L5-B, HE1-L6-C, HE2-L4-Z, HE2-L5-S, and HE2-L6-A) were generated from scratch by the research team using GenAI (see Tables  4 and 5). From the four pairs of participants' marking, the marks ranged between 55 and 70, or the upper-second level. We suspect that, as the assessments were selected for relative ease in using GenAI (eg, ChatGPT), students were not required to draw on learning experiences that occur in real workplaces and professional contexts, making it easier for them to use GenAI to complete an assessment. Since each of these six writing samples was generated within 90 minutes, GenAI appears to be a convenient, low-cost and powerful tool that may be misused by a ‘mischievous’ student without prior knowledge of a subject to pass assessments. \n \n \n \n DISCUSSION \n \n In response to RQ1, our results strongly indicate that assessments were easily compromised using GenAI, and many of our markers found it challenging to identify which were human-authored, which were GenAI-modified, and which were GenAI-authored. While the literature remains ambivalent with regard to the impact of GenAI on assessments (Bower et al.,  2024), our findings suggest that there is an impact and that it is challenging to identify GenAI usage in assessments. \n \n As revealed in our data analysis, although marked improvement at the lower grade bands from GenAI-augmented samples was limited, in higher grade bands, mischievous students—despite the concerns raised around GenAI competence (Kocoń et al.,  2023; Rudolph et al.,  2023)—would benefit from using GenAI to generate completely “original” work because of its low cost, high speed and relatively hard-to-detect features. Our results also indicated that GenAI-generated assessments, with adequate knowledge of prompt engineering (Giray,  2023; Lo,  2023), would easily assist a student in passing a module without having to engage in deep learning. This raises concerns about current approaches to assessment. \n \n A common response might be to suggest that software exists to detect AI-generated content. However, using such tools can be problematic, as markers may not easily assess the level of knowledge demonstrated by the student (Gorichanaz,  2023) without further assessment. In fact, in many universities, current guidance regarding the usage of GenAI suggests that for all assessments that score high on AI detection, students would need to undergo an oral examination, making the marking process far more onerous and time-consuming. Extrapolating from this, if many written assessment submissions require a second layer of oral examinations to prove their academic integrity, we could argue that such assessments should be replaced altogether with face-to-face types of assessments based on performance or oral presentation. There are many interesting approaches to such assessments; for example, interactive oral assessments (Krautloher,  2024; Ward et al.,  2023) and role-play–type assessments that allow for thorough evaluation of the student, thereby overcoming the GenAI challenge. \n \n In response to RQ2, our findings indicated that the existence of GenAI influenced the marking process for staff, as they began second-guessing the authorship and attempted to spot GenAI-modified and GenAI-authored work. That led to unusually large grade disparities between first and second markers, as it appears that in some cases, markers may have subconsciously or consciously marked down work they suspected to be GenAI-modified or authored. This dynamic is noteworthy and indicates that the presence and awareness of GenAI have impacted the way academics mark and reconcile grades. Another interesting consequence of the markers' awareness of GenAI was that all human-authored work originally graded as first class was graded below first class, and in several cases, the two markers had significantly different grades. As indicated in our findings, good work was often viewed as work done by GenAI. \n \n It is worth noting that as GenAI technology becomes more advanced, many of the criteria that our more successful markers (pair 1, for example) used to identify GenAI-modified and GenAI-authored assessments will not stand the test of time. For example, a couple of interviewees noted disjointedness in GenAI-manipulated work; this was due to the limitations in ChatGPT 3.5, which did not allow manipulation of text longer than 700 words. Another pair of markers highlighted the flow of language that GenAI tends to generate, an issue that could be easily overcome by smarter prompt engineering. \n \n In response to RQ3, it seems that moderate/high-level authentic assessments are neither a shield for academic integrity nor an immediate solution to the GenAI challenge. As we saw in the methodology section, some assessments were of low authenticity, and others were of high authenticity; however, this made very little difference in detecting GenAI usage. All nine assessments were relatively easy to reproduce or modify using GenAI, and the markers could not readily identify the difference between human-authored and GenAI-augmented or GenAI-generated variations. Thus, it is doubtful whether authentic assessments are the panacea that the Quality Assurance Agency for Higher Education ( 2024) and Advance HE ( 2023) suggest when dealing with GenAI. \n \n Authentic assessments pose certain challenges (Ajjawi et al.,  2020; Ellis et al.,  2020) that the rhetoric around assessments does not seem to consider. Here we will focus on three immediate challenges posed by authentic assessments. \n \n The first challenge relates to the authenticity concept itself. In a sense, all assessments are authentic—they provide a measurement of learning that should, by definition, be relevant in the workplace (Kaider et al.,  2017). Thus, when suggesting that authentic assessments may help us manage the GenAI challenge, we need to be clearer about what type of authentic assessments we are considering. \n \n The second challenge relates to the complexity of authentic assessments. Authentic assessments tend to be more complex, especially those that score high on authenticity, proximity, or both (Kaider et al.,  2017). It is generally easier to manage the creation and execution of an exam (low authenticity, low proximity) than to arrange and manage a live project (medium/high authenticity, medium proximity). The former is predictable, with parameters known in advance, while the latter is highly unpredictable, with more diverse intended learning outcomes and higher risks due to the involvement of additional stakeholders. In general, the more authentic an assessment, the more time-consuming and complex it is to manage, particularly with high student volumes (Ajjawi et al.,  2020; Ashford-Rowe et al.,  2014). \n \n The third challenge is the speed of G en AI evolution. Authentic assessments by themselves cannot provide enough of a safeguard against using GenAI to circumvent assessments (Ellis et al.,  2020); the GenAI technology is evolving too rapidly, putting at risk increasingly complex types of assessment. Consider the introduction of similarity detection services (such as Turnitin), which led to the development of essay mills and other third-party customised writing services. GenAI may further escalate the continuous efforts by HEIs to protect their assessments' academic integrity. \n \n \n \n CONCLUSIONS \n \n Our work indicates that if we are to mitigate the risks posed by GenAI, we may have to reconsider our approach to assessment design. Our experimental results suggest that with GenAI tools, it is becoming challenging to use written types of assessment to evaluate students, and academics will be affected by their judgments of students' GenAI usage when marking such work, thus leading to doubts regarding the reliability of the marking and moderation process. This weakens output-based assessments and leads us to advocate for more performative and interactive types of assessments in lieu of written assessments. \n \n As shown in our findings, while authentic assessments are often offered in the literature as the solution and can measure multidimensional outcomes and provide a semblance of real-world relevance, they are not immune to the challenges GenAI poses. Intelligent assessment design may still be important in safeguarding academic integrity, regardless of the degree of authenticity and workplace proximity an assessment may demonstrate (Ajjawi et al.,  2020). \n \n Thus, managing the impact of GenAI requires a paradigm shift in assessment philosophy and design (Adiguzel et al.,  2023; Gorichanaz,  2023). Instead of viewing GenAI solely as a challenge or threat to academic integrity and assessment design, if we are intelligent in our assessment design, we can convert GenAI into a tool for further learning (Salinas-Navarro et al.,  2024). For example, GenAI can be used to simulate real-world professional environments where students must solve complex, authentic problems. This includes tasks like designing marketing campaigns with AI-generated consumer data, conducting AI-facilitated business negotiations or analysing AI-driven case studies tailored to specific industries. Furthermore, GenAI can generate adaptive learning content, offering students iterative feedback on projects, such as refining an AI-drafted research proposal or creating multiple drafts of a business report based on AI-provided critiques. These applications transform GenAI into an active partner in experiential and collaborative learning rather than a passive content generator. \n \n However, this would mean abandoning some current assessment practices, which may have become obsolete. Our experiment was exploratory, and the sample was small; however, our results raise doubts about the nature of knowledge and learning and the value of written assessments. Perhaps learning and knowledge creation are socialised, situated in people and their interactions and as such experiential and tacit (Tsoukas,  1996; von Krogh &amp; Roos,  1995). The advent of GenAI has made this perspective even more pronounced by putting a premium on socialised learning, as explicit knowledge and learning can be rapidly reproduced and reconfigured. Thus, what HEIs should assess is knowledge application and socialised knowledge which, likewise, is socially situated and experiential. That would mean a shift towards an assessment paradigm where we assess knowledge as generated in social settings, synchronous, experiential learning which is situated within social networks and social interactions (Kofinas &amp; Tsay,  2021). Kofinas and Tsay ( 2021) in their work emphasised that large classes function as a social microcosm, leveraging diverse interactions and weak ties to foster socialised experiential learning. GenAI can enable rich learning experiences by facilitating collaborative projects where students can leverage GenAI simulated market trends and information to foster both individual and collective problem-solving skills. However, what would be assessed would be the ability of students to perform and communicate what they learned in a synchronous, interpersonal manner. \n \n Moving away from assessing learning and knowledge using written work and static artefacts could have far-reaching ramifications, as they are currently an important and significant portion of the full range of higher education assessment types. Thus, more research is needed to evaluate the relevance of written assessments in a GenAI-dominated world and the nature of learning students should be engaging in, which would embrace GenAI as a tool. The ramifications on other modes of learning, such as online learning, distance learning, and other writing-dominated approaches to higher education, can be severe. A move away from text as an indicator of knowledge and learning has wider ramifications in the realm of research, as currently the main currency of research tends to be written published work such as journal articles and books, and with GenAI the value of such outputs becomes increasingly questionable. These are all fruitful areas for further research in this field as GenAI will continue impacting higher education for many years to come. \n \n \n \n FUNDING INFORMATION \n \n There was no funding support for this research. \n \n \n \n CONFLICT OF INTEREST STATEMENT \n \n The authors have declared no conflicts of interest. \n \n \n \n ETHICS STATEMENT \n \n None. \n \n \n \n \n APPENDIX A: SAMPLE PROMPTS USED IN A LEVEL 6 ASSESSMENT \n \n \n \n This Level 6 assessment is a 2000-word critical review that requires a student to review one paper from the List of Articles for Critical Review on the virtual learning environment. The list contains 18 papers. Students are advised not to select a paper at random, but to consider their reasons for selection and develop them in the review. Students are advised to make use of the concepts and notions taught throughout the module. Students should be citing a wide range of academic literature, both from the tutorials and their own research.\n \n \n \n \n Prompt \n Researcher question \n Result \n \n \n \n \n 1 \n Would you please summarise this assessment brief and the marking criteria? \n GenAI had a clear understanding of this assessment \n \n \n 2 \n Select one of the articles from the list below for your review process. Do not select at random; go through them and select one. Develop/justify your reasons for selection \n GenAI selected an article and provided reasons \n \n \n 3 \n That's very good. Thank you. Can you create an outline for the critical review of this article? \n GenAI created a clear structure for the outline \n \n \n 4 \n In order to create a 2000-word critical review, can you suggest a word length for each section in the outline above? \n GenAI provided a recommended length for each section \n \n \n 5 \n Thank you. Please indicate the chosen article and write a 200-word introduction for the critical review of [article reference]. In the introduction, please justify the selection of article and signpost the structure of the critical review \n GenAI did what it was asked and generated a 208-word introduction \n \n \n 6 \n That's excellent. Would you please write according to the outline you made and create a summary section of the article for 400 words? \n GenAI responded with 437 words \n \n \n 7 \n According to the outline you created, would you please write a section of critical analysis for 600 words? Consider different viewpoints and use third person in writing. For each issue identified, develop arguments and use a wide range of academic literature to support \n GenAI initially generated 607 words and stopped because of word count. Then the researcher asked it to continue \n \n \n 8 \n Continue please \n GenAI continued \n \n \n 9 \n Would you please provide full references for the articles you cited? \n GenAI came up with full references using the Harvard Referencing Style and reminded the researcher to present references according to the institutional requirements \n \n \n 10 \n For the Critical Analysis section, would you paraphrase and come up with appropriate subheadings? \n This time GenAI only came up with 400 words, but it should be acceptable as the researcher will take the subheadings and add back to the GPT response to Prompt 7 \n \n \n 11 \n According to the outline you created, would you please write a section of “Discussion of Sustainable Development Elements” (400 words). In this section, please add subheadings where appropriate. Consider different viewpoints and use third person in writing. For each issue identified, develop arguments and use a wide range of academic literature to support \n GenAI generated a response with 439 words. Headings were provided and in-text citations included \n \n \n 12 \n Would you please provide full references for the articles you cited? \n GenAI did as requested \n \n \n 13 \n According to the outline you created, would you please write a section of Insights and Recommendations (300 words). In this section, please add subheadings where appropriate. Consider different viewpoints and use third person in writing. For each issue identified, develop arguments and use a wide range of academic literature to support \n GenAI did as requested and generated 287 words \n \n \n 14 \n Thanks. If there are any new citations, please provide full references \n GenAI did as requested \n \n \n 15 \n Please write a conclusion (100 words) for this critical review \n After the conclusion, GPT came up with a critical review of 2058 words, which is perfect \n \n \n 16 \n (Cut and paste all the references that GenAI has generated in this chat) Would you please reorganise the references here to make sure they are ordered and in compliance with the Harvard referencing standards? \n GenAI did as requested \n \n \n \n \n \n \n \n \n \n \n APPENDIX B: INTERVIEW PROTOCOL \n \n \n \n \n Section 1: Questions about your experience and yourself (10 minutes) \n \n \n 5 minutes: Meet and greet. Explain the purpose of the research based on Appendix  A, Participant Information Sheet. Ask participants to give consent if they haven't.\n \n \n Which department do you work in? \n \n How long have you been working in higher Education? _______ year(s) ________ month(s) \n \n How long have you taught or moderated for [module/unit name]? \n \n What is your primary connection to [module/unit name]? \n \n \n \n \n Section 2: Researcher facilitation of moderation (60 minutes) \n \n \n Reveal the mark entry sheet where marks of 21 writing samples were assigned by each participant. \n \n \n \n \n Ask each participant to justify marks assigned and reach agree marks for all writing samples. Questions may include\n \n \n Using the marking criteria, can you explain as you examined the assignment how you arrived at the grade for the assessment? \n \n \n \n \n \n \n \n Section 3: Researcher debriefs and interview (50 minutes) \n \n \n Present the full set of assessments to the participants and the original marks and feedback given to the human submissions. \n \n \n Explain which versions of assessments were GenAI generated. \n \n \n \n \n Evaluate how the marking results were different. NB: It is important to remind participants that the objective was not to trick them, but rather to see if GenAI could generate a reasonable approximation of an assessment.\n \n \n First, compare the original marks and the marks agreed upon by two participant markers on human-written assessments vis-à-vis the ChatGPT-generated assessment. Ask participants why they got it right (or wrong). Were there any patterns that made the GenAI-generated assessment recognisable? \n \n When comparing the originally graded assessment and the grade you gave, are you prepared to maintain the same grade? (and if so why?) (Repeat for each level of study) \n \n Compare marks between the human and AI-generated assessments. Discuss any grading differences. \n \n \n \n Suggested line of questioning: \n \n \n “Comparing [assessment code] and [assessment code], in what ways is the GenAI written assessment better or worse than the human written assessment?” \n \n \n \n “If your grade for the GenAI assessment [assessment code] was lower, what changes would have led to a higher grade? In other words, how could GenAI perform better?” \n \n \n \n “You gave a higher grade on the GenAI assessment [assessment code] than the human written assessment [assessment code]. What differences prompted you to give a higher grade?” \n \n \n \n “Does GenAI do a better job at [academic level x/year group x]?” \n \n \n \n \n \n \n The future use of AI-assisted tools in higher education\n \n \n What is your view of GenAI tools and their role in higher education? \n \n Are there particular types of assessment you would consider to be more vulnerable to GenAI usage? \n \n In what ways could assessments be redesigned to mitigate the risk of GenAI usage? \n \n In what ways do you see GenAI writing tools being used to improve students' assessment literacies? For example, where a student couldn't understand how an assessment might be written. \n \n \n \n \n \n \n \n \n \n Thank participants and assure them that no personal identifying information will be used when presenting research findings. \n \n \n \n \n \n REFERENCES \n \n \n \n \n \n"}
{"title": "the impact of generative AI on student learning outcomes", "content": "## **ABSTRACT**\n\nGenerative AI (GenAI) has had a significant impact across industries since the launch of ChatGPT in late 2022. Much of the focus of existing research in the higher education space has considered the impact GenAI has had on academics and institutions. Conversely, research has been less focused on the impact this technology will have on students. Our research investigates how GenAI impacts student learning outcomes in higher education. We applied a quasi-experimental lens to analyse qualitative data of 192 student reflections and apply quantitative content analysis (QCA). Results indicate that a higher level of learning occurs when students use GenAI to construct and augment knowledge (mastery approach). In contrast, lower-level learning outcomes resulted from using GenAI procedurally without augmenting knowledge (procedural approach). Through a practical lens, the course curriculum can be designed to include GenAI to scaffold students’ learning from basic knowledge construction tasks to more complex augmentation of knowledge. Assessment design can be adjusted to promote mastery goal structures, encouraging students to critically engage with GenAI outputs rather than simply reproducing them, fostering optimal learning outcomes.\n\n## Introduction\n\nGenerative AI (GenAI) has gained significant attention in education, driven by the public launch of Open AI’s ChatGPT-3 in November 2022. The platform attracted one million users within five days of launching, reaching 100 million users just three months later, marking an unprecedented rate of adoption in the technology sector (Imran and Almusharraf [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). While AI itself is not new, what sets GenAI apart from traditional AI is the capability to generate contextual responses, where traditional AI can be strategic and efficient but within boundaries; a set of rules that it has learned (e.g. grammatical expression, playing chess). Within the educational context, GenAI becomes especially important for this capability to generate something new, and thereby potentially replacing students’ original works. This rapid growth in popularity sparked a flurry of GenAI-related research in education (Baidoo-Anu and Ansah [Citation2023](http://www.tandfonline.com/www.tandfonline.com); Lim et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)).\n\nInitial studies considered the ability for GenAI to complete assignment tasks (Cotton, Cotton, and Shipway [Citation2023](http://www.tandfonline.com/www.tandfonline.com); Dehouche [Citation2021](http://www.tandfonline.com/www.tandfonline.com)). They consider the occurrence of GenAI-based plagiarism in producing and submitting essays, potentially leading to the devaluation of degrees and other forms of higher education. Other studies have considered best practices for working in collaboration with GenAI, suggesting opportunities at various levels of study (Kasneci et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)), as well as the acceptance of students in adopting this new technology (Strzelecki [Citation2024](http://www.tandfonline.com/www.tandfonline.com)). Research has also considered the paradoxes of GenAI, investigating the polarizing areas of GenAI’s impact on education (Lim et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). However, the unique and complex landscape of GenAI, along with its potential impact on the student experience and implications for learning outcomes, remains largely unknown.\n\nThe current debate on GenAI in education centres on whether the positive benefits to learning – such as creating personalized learning experiences, adapting content to students’ diverse and unique learning preferences, and providing real-time assistance and feedback – outweigh the negative consequences, which include concerns around the accuracy and quality of AI-generated content, ethical issues surrounding data use and privacy, and the potential for deepening social inequalities in educational access and outcomes.\n\nUniversities responded swiftly by amending plagiarism guidelines, updating integrity modules, or by creating their own ‘controlled’ versions of GenAI for students. On a micro level, educators focused on detecting plagiarism and how GenAI could assist student learning. For example, ChatGPT is notorious for incorrectly citing sources, with up to 39% invalid DOIs being used in prompt responses (Salamin, Russo, and Rueger [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). While these efforts represent a quick and necessary response to the impact GenAI has in education, they are not necessarily evidence-based. More pertinently, they do not provide direct and scholarly informed insights into how GenAI influences the learning process, learning outcomes, and overall student experience.\n\nResearch on GenAI is rapidly emerging, with the focus slowly shifting to its impact on student learning outcomes and engagement (Nguyen et al. [Citation2024b](http://www.tandfonline.com/www.tandfonline.com)). For example, recent research has found GenAI can enhance critical thinking skills, particularly for tasks at lower cognitive levels such as understanding and application (Essien et al. [Citation2024](http://www.tandfonline.com/www.tandfonline.com)). However, this research was conducted on student perceptions of their experience with AI, and therefore, the actual impact of using GenAI on the learning process and achievement of learning outcomes is still underexplored. Thus, warranting further academic investigation to better understand the benefits and drawbacks of GenAI in tertiary education.\n\nOur research aims to provide empirical insights into how GenAI influences student learning and experiences by applying the Achievement Goals Framework (Elliot [Citation2005](http://www.tandfonline.com/www.tandfonline.com); Nicholls [Citation1984](http://www.tandfonline.com/www.tandfonline.com)). By doing so, it investigates the impact of using GenAI on the student experience, examining how they perceive AI has assisted (or detracted from) their educational experience. This work is grounded in goal structures (performance versus mastery goals) to help explain differing attitudes to the use of GenAI and better understand its influence on student learning – Performance goal structures being centred around demonstrating competence and outperforming others, whereas mastery goal structures prioritize the development of competence and the pursuit of mastery. From an institutional perspective, many of the current educational policies focused on GenAI use in higher education, adopt a view in which the involvement of GenAI is a separate force to students’ individual efforts and intellectual contributions (Luo [Citation2024](http://www.tandfonline.com/www.tandfonline.com)). The consequence of this results in a dichotomous view of opposing forces, rather than considering the impact of collaboration between GenAI and students. Further, there is an increasing emphasis on learning outcomes such as critical reasoning and information literacies, in the changing landscape of higher education (Chiu [Citation2024](http://www.tandfonline.com/www.tandfonline.com)), with a push for greater understanding in determining the essential higher-level learning outcomes assessed in GenAI contexts (Weng et al. [Citation2024](http://www.tandfonline.com/www.tandfonline.com)). We justify the focus on goal structures seeing that GenAI may assist in shaping students’ Zone of Proximal Development (ZPD) (Vygotsky [Citation1978](http://www.tandfonline.com/www.tandfonline.com)) in terms of their ability to independently acquire new skills and knowledge, which would likely depend on the goal structure that a student has adopted. To this end, our research question intends to apply achievement goal structures to investigate how students engage with GenAI and the impact of this on their learning outcomes.\n\n**RQ:** By what means does goal structure relate to how students use GenAI to craft knowledge outputs and achieve learning outcomes?\n\nWe address this research question through two primary objectives (1) to explore whether the use of GenAI by students is affected by goal orientations, and (2) how the use of GenAI by students affects their learning outcomes.\n\nGiven the transformative potential of GenAI, this study is not only timely, but crucial for educators, policy makers, and researchers alike in shaping the future trajectory of education in the era of GenAI.\n\n## Literature review\n\nAs with any phenomenon, there are multiple perspectives to consider. A seminal paper in this area proposed four paradoxes of GenAI in education (Lim et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)) and considers the benefits and challenges from different perspectives. We consider two of these in relation to our current study. The first paradox outlines the ability of GenAI to be a ‘friend’ yet a ‘foe’ (Lim et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). GenAI has the ability to act in a human way through the generation of responses which can help fill gaps in students’ knowledge, despite this, the authors also highlight it could be considered a way of avoiding learning (Lim et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)) which has a direct consequence on student learning outcomes. The second paradox relevant to our context, explains that GenAI is ‘capable’ yet ‘dependent’ (Lim et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). While GenAI tools are becoming increasingly efficient at generating responses from a broad range of topic areas, they still are highly dependent on the prompt given and the prior training received. As such, GenAI tools can provide incorrect information and other falsehoods, such as made-up references (Chatterjee and Dethlefs [Citation2023](http://www.tandfonline.com/www.tandfonline.com); Terwiesch [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). While GenAI can give a quick and succinct answer, caution must be applied as the answer may not be entirely factual. As an acknowledgement of this, an increasing amount of GenAI tools include disclaimers. For example, Claude.ai includes a disclaimer below all generated text: ‘Claude can make mistakes. Please double-check responses’ (Anthropic [Citation2024](http://www.tandfonline.com/www.tandfonline.com)). Thus, implying to the user that the GenAI outputs may include false or incorrect information, shifting the onus and responsibility directly to the user on the interpretation of the information provided.\n\nThe majority of existing educational GenAI studies investigate the use of the AI tool or platform, examining how institutions and educators can best implement and adopt GenAI into their curriculum or pedagogy. Yet, there are limited studies that have collected student data to understand the impact AI-based technologies have had on the learning experience. Zheng et al. ([Citation2021](http://www.tandfonline.com/www.tandfonline.com)) conducted a meta-analysis on the effectiveness of AI on learning achievement and perception. However, their meta-analysis focused on articles from 2001 through 2020, and as a result, has not captured the unique implications of GenAI; its exponential rate of adoption; the disruptive nature of its diffusion across the sector; and educational case studies in modern learning environments. Chan and Zhou ([Citation2023](http://www.tandfonline.com/www.tandfonline.com)) considered student perceptions on GenAI and found correlations between the value students perceive from the technology and their intention to use. Their research considered students’ general attitudes towards GenAI and their intention to use the technology but did not consider the impact of this once they had completed an assessment task, thereby reducing any insights into learning outcomes relative to attitudes. Nguyen et al. ([Citation2024a](http://www.tandfonline.com/www.tandfonline.com)) applied modelling to identify that high-performing research students were utilizing GenAI to enrich their writing processes, whereas low-performing students appear to either not make full use of the tool or view it only as an additional resource. However, the authors acknowledge the limitations of focusing on doctoral students who have heightened experience with the subject matter and do not necessarily uniformly represent broader student experiences. Crawford et al. ([Citation2024](http://www.tandfonline.com/www.tandfonline.com)) discusses the mixed results emerging studies have when considering the impact of AI on student grades, emphasizing the need for further insight.\n\nTo the best of the research team’s knowledge, previous studies have not investigated the following: (1) the educational impact of working alongside GenAI, in a deliberate, structured setting, (2) the impact GenAI tools have on students’ ability to successfully complete assessment tasks, and (3) how the use of GenAI impacts student learning experiences and outcomes.\n\n### Generative AI and learning – concerns and opportunities\n\nEarly studies have primarily focused on the implications of GenAI on academic integrity such as cheating and plagiarism (Cotton, Cotton, and Shipway [Citation2023](http://www.tandfonline.com/www.tandfonline.com)), and impacts on data privacy and security, such as personal identifiable information (Adiguzel, Kaya, and Cansu [Citation2023](http://www.tandfonline.com/www.tandfonline.com); Crawford, Cowling, and Allen [Citation2023](http://www.tandfonline.com/www.tandfonline.com); Lodge, Thompson, and Corrin [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). The use of GenAI in educational settings raises concerns regarding cheating and academic integrity, as AI models like ChatGPT can potentially be misused by students to complete assignments or generate content without engaging in the learning process (Cotton, Cotton, and Shipway [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). While there are different ways in which students can cheat in relation to their academic studies, it can be broadly defined as a violation of academic rules that is intended to create an academic advantage to persons involved (Waltzer and Dahl [Citation2022](http://www.tandfonline.com/www.tandfonline.com)). Although this is a broad definition, constituting many different behaviours, research suggests that up to as many as 90% of students cheat at least once throughout their academic studies (Curtis and Vardanega [Citation2016](http://www.tandfonline.com/www.tandfonline.com); McCabe, Butterfield, and Trevino [Citation2012](http://www.tandfonline.com/www.tandfonline.com); Waltzer and Dahl [Citation2022](http://www.tandfonline.com/www.tandfonline.com)). Interestingly, the action of a student cheating in academic studies correlates to dishonesty within the workforce (Evans, Oldroyd, and Bingham [Citation2022](http://www.tandfonline.com/www.tandfonline.com)). In the context of GenAI, the accessibility of AI tools may provide students with the opportunity to cheat, while academic or personal pressures might motivate them to engage in this category of behaviour.\n\nThe accessibility of information is an important factor driving the discussion around the positive factors of GenAI and the impact on the educational landscape. GenAI technologies have demonstrated the potential to democratize access to information for students with diverse learning needs and preferences (Watters [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). It also has the potential to enhance student learning and understanding of key concepts by offering personalized, engaging, and interactive educational experiences. GenAI tools can find and summarize relevant information (Cascella et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)), making it easier for students to access refined information in a timely manner. From a pedagogical perspective, this means that students can save time accessing information, focusing more time on reading and critically reflecting on the given information. Studies also suggest that GenAI can offer personalized learning experiences by dynamically generating content tailored to individual students’ needs, strengths, and weaknesses. This personalization can lead to increased student engagement and improved learning outcomes (Cho, Kim, and Han [Citation2019](http://www.tandfonline.com/www.tandfonline.com); Xu et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)).\n\nFor educators, these tools can assist in identifying and creating relevant teaching materials. It can also help generate lesson plans for teaching within a set of parameters and constraints (Zhai [Citation2022](http://www.tandfonline.com/www.tandfonline.com)). One can envision how GenAI has the potential to decrease workload for academics through the creation of lesson plans, assignments, and rubrics, thereby freeing up time and energy to focus on content, pedagogical development, and delivery.\n\n### Achievement goal structures\n\nAchievement Goals Framework (Elliot [Citation2005](http://www.tandfonline.com/www.tandfonline.com); Nicholls [Citation1984](http://www.tandfonline.com/www.tandfonline.com)) is a theory widely applied in the education literature, both in the context of cheating, and for explaining how positive learning outcomes are achieved; hence it is highly relevant to the context of GenAI in education. In short, students are assumed to adopt performance goals and/or mastery goals to their learning. Performance goal structures are centred around the desire to demonstrate competence and outperform others. Students with a performance-oriented mindset tend to focus on grades and external validation. While performance goals can be motivating in the short term, they may hinder deep learning and discourage students from taking risks or exploring beyond their comfort zones (Alhadabi and Karpinski [Citation2020](http://www.tandfonline.com/www.tandfonline.com); Huang [Citation2011](http://www.tandfonline.com/www.tandfonline.com); Katz-Vago and Benita [Citation2024](http://www.tandfonline.com/www.tandfonline.com); Matos et al. [Citation2017](http://www.tandfonline.com/www.tandfonline.com)). Mastery goal structures, on the other hand, prioritize the development of competence and the pursuit of mastery in a particular subject or skill. Students with a mastery-oriented mindset view challenges as opportunities for growth and learning. Mastery goals promote intrinsic motivation and a deeper understanding of the material, leading to long-term academic success (Ames [Citation1992](http://www.tandfonline.com/www.tandfonline.com); Bieg, Reindl, and Dresel [Citation2017](http://www.tandfonline.com/www.tandfonline.com); Huang [Citation2011](http://www.tandfonline.com/www.tandfonline.com); Katz-Vago and Benita [Citation2024](http://www.tandfonline.com/www.tandfonline.com); Matos et al. [Citation2017](http://www.tandfonline.com/www.tandfonline.com)). While this theory is commonly used in education literature, it is also recognized that assuming students are solely motivated by either mastery or performance goals oversimplifies the matter. Perhaps more accurately, this approach helps us understand how goal structures can direct or influence and moderate behaviour in different ways. For example, Katz-Vago and Benita ([Citation2024](http://www.tandfonline.com/www.tandfonline.com)) showed that personal academic goals also play an important role in student learning, although to a lesser extent compared to mastery versus performance goals. They show that mastery and performance goals moderate how the personal academic goals influence learning outcomes. In this paper, we suggest a similar effect takes place when it comes to how students apply GenAI into their learning experiences.\n\nFor example, research has found cheating is less likely to occur in settings of perceived mastery goal structures as opposed to performance goal structures (Anderman and Won [Citation2019](http://www.tandfonline.com/www.tandfonline.com)). When students perceived that mastering the content of the material was the main goal of the class, they were much less inclined to participate in cheating behaviours than if they were engaged with performance goals instead. Conversely, when students adopt a mastery goal structure in an environment that allows for constructive learning (e.g. collaborative activity-based), it is more conducive to the student learning experience (Kwan and Wong [Citation2015](http://www.tandfonline.com/www.tandfonline.com); Svinicki [Citation2010](http://www.tandfonline.com/www.tandfonline.com)). Kwan and Wong ([Citation2015](http://www.tandfonline.com/www.tandfonline.com)) and Svinicki ([Citation2010](http://www.tandfonline.com/www.tandfonline.com)) show that students who adopt a mastery goal display more critical thinking and augmentation of knowledge than students who adopt a performance goal.\n\nSubsequently, this research investigates whether students’ attitudes towards, and use of GenAI, are linked to their goal structures. Namely, students with a performance-based goal structure might depend on GenAI to reproduce knowledge without critically analysing it, possibly leading to increased inclination to use it for cheating. On the other hand, students who prioritize a mastery goal structure are more likely to evaluate and enhance the knowledge themselves, relying less on the precise accuracy of GenAI tools. They assess GenAI based on their own learning experiences rather than considering any comparative advantage it may give others.\n\nBoth the cognitive orientation and strategic use of GenAI influence the students’ goals, performance, and learning outcomes. Should the students adopt either a mastery or performance goal, there would be a notable difference in how they augment their learning using GenAI and other AI technologies.\n\n### Addressing the student knowledge gap\n\nThe concerns and opportunities linked to the educational use of GenAI are important considerations regarding the progression of educational practices, but in contrast, it does require proactive engagement from educators and their institutions. By understanding the mechanisms behind students’ attitudes toward and use of GenAI in their learning will provide clearer guidance on how to tackle concerns and leverage opportunities.\n\nIn higher education, constructivist approaches play a pivotal role in shaping effective and student-centred learning environments (Baeten et al. [Citation2010](http://www.tandfonline.com/www.tandfonline.com)). These approaches, grounded in the philosophy that knowledge is actively constructed by learners rather than passively received, align seamlessly with the Zone of Proximal Development (ZPD) concept. ZPD refers to the difference between what a learner can do without help and what they can achieve with guidance and encouragement from a more knowledgeable individual (Vygotsky [Citation1978](http://www.tandfonline.com/www.tandfonline.com)). This ‘zone’ is dynamic, changing as learners acquire new skills and knowledge. The lower limit of ZPD is the level of skill or knowledge that the learner can reach alone, while the upper limit is what they can accomplish with help from a more knowledgeable individual, such as an educator or peer (Ferguson, van den Broek, and van Oostendorp [Citation2022](http://www.tandfonline.com/www.tandfonline.com)). The theory underlines the importance of collaborative learning and guided instruction in pushing learners beyond their current capabilities and promoting optimal development.\n\nConstructivist pedagogies emphasize engaging students in authentic and collaborative learning experiences that challenge them within their ZPD. By incorporating activities that promote active exploration, critical thinking, and problem-solving, educators foster an environment where students can bridge the gap between their current understanding and their potential for deeper comprehension (Schnotz and Kürschner [Citation2007](http://www.tandfonline.com/www.tandfonline.com)). This is relevant in higher education when considering implementing the use of GenAI, as the GenAI tool can take the place of the instructor supporting students across multiple dimensions of learning (Fink [Citation2013](http://www.tandfonline.com/www.tandfonline.com)) and allows for more individualized and rapid feedback helping to bridge the knowledge gap for students when engaging with new learning material.\n\nFurther to this point, as GenAI can adapt in real time, based on the prompt given, it is able to adapt as the student’s zone shifts. Applying the Constructivist Learning Theory lens, GenAI can cater to the individual needs of each individual student. This helps students construct their own knowledge and build upon this, developing a deeper understanding of concepts relative to their starting point. As identified in Bloom’s revised taxonomy, students typically progress through increasingly complex cognitive processes, from basic understanding through to knowledge creation and evaluation (Krathwohl [Citation2002](http://www.tandfonline.com/www.tandfonline.com)). As GenAI can adapt based on the input that is received, students are able to start from specific points in their individual learning journey. At the first stage of Bloom’s taxonomy of understanding, GenAI can offer explanations and examples tailored to the student's current level of comprehension. As students advance through and can achieve higher levels of learning within the context of their studies, GenAI can help test ideas, provide feedback, and refine the students’ own work. This progression aligns with constructivist principles as students are actively building their knowledge while receiving scaffolded support within their ZPD. This can help the students who have less foundational knowledge to keep up with the cohort and not be lost in the content, and it can also help to extend the more knowledgeable students without having to wait for others to catch up.\n\nAs such, achievement goal structures provide a framework to understand the reasons behind students’ motivational approaches to learning with GenAI – whether they view it as a tool for mastery and understanding (mastery orientation) or as a means to demonstrate performance (performance orientation). ZPD can provide a lens to understand how these goal orientations manifest in the actual use of the GenAI tools. Students with mastery goals may be more likely to use GenAI as a tool to extend their competency, actively constructing knowledge and pushing beyond their current capabilities. In contrast, those with performance goals may use GenAI in ways for regurgitation, remaining within their existing competence zone.\n\nThere is an opportunity for educators to embrace GenAI in the delivery of education to (1) act as the more experienced individual providing support, and (2) provide a basis for which to construct their own understanding. Further, the potential impact of embracing GenAI on learning outcomes can be evaluated through multiple frameworks, including Bloom's and Fink's respective taxonomies, particularly in how GenAI supports or potentially hinders development across these areas. However, it is also important to keep in mind the accuracy with which GenAI is able to provide an answer. While GenAI is often confident in the response, the possibility of the answer being incorrect is still a consideration (Lim et al. [Citation2023](http://www.tandfonline.com/www.tandfonline.com)). We apply the theories of motivational goal structures as a potential mechanism to explain how GenAI is used by students, and whether it leads to more positive or negative learning outcomes.\n\n## This research\n\nThis research assesses students’ attitudes as well as student learning processes and outcomes in relation to performance and mastery goals. This study was submitted and approved through the ethics committees at all involved institutions. The lead institution approval details reference project number 20236992-13592.\n\nOur study assesses how students’ utilization of GenAI influences their learning achievements and processes across three universities. In alignment with the ZPD theory, we assess the extent to which students use GenAI to augment knowledge and bridge their knowledge gaps. We will also examine the level to which they display critical and deep reflective thinking, and finally, whether their varied use of GenAI in their learning process is related to mastery versus performance goal structures.\n\nWe adopt a qualitative quasi-experimental lens. Ethical considerations, as well as natural circumstances, prevent us from exposing one group to GenAI while withholding it from another, as GenAI was already omnipresent. Directly asking students about their goal structures may generate socially desirable answers, especially due to perceived power imbalances between the teaching team and students. Hence, we opted for a qualitative approach, coding mastery and performance goal structures to obtain more insights.\n\n### Contextualizing GenAI use\n\nPretest survey data was collected to help contextualize GenAI use from students enrolled in one of two units offered at two different universities located in Melbourne, Australia. Thus, offering insight into the perceptions of GenAI within these student cohorts. A survey was distributed to students prior to semester commencing and before starting a task where they were asked to engage with GenAI. The survey resulted in 61 complete responses Of these, 32 were from undergraduate students at the first university, while 29 were from postgraduate students at the second university, with all participants studying Marketing.\n\nIn a free-text question, students were asked: ‘Do you think generative AI such as ChatGPT could potentially be used to cheat in a university assessment?’.\n\nAssessing their free-text responses, we started to see some students focus on the procedural applications of using GenAI and emphasized how it would provide others with an advantage comparative to themselves. This focus on competition and results is highlighted in the following comment from a student who explained ‘I don’t believe it is fair to be compared against work that has been created using generative AI'.\n\nOn the other hand, some students acknowledged the potential of GenAI to augment their existing knowledge, illustrated through the following comment ‘I don’t think so. University assignments are more complex, you need the form all the understanding of certain topic, critical thinking and creativity to complete the assessment'.\n\nThese responses are useful in understanding students’ acknowledgment and acceptance towards GenAI in a tertiary context, as well as the relevance of goal structures in researching GenAI. While the pretest results offer an initial indication of students’ GenAI use, they do not provide insights into how the actual use of GenAI influences their learning process and outcomes. Our aim is to gain insights into how the use of GenAI and motivational goal structures influences student learning and outcomes in a study that incorporates GenAI in assessment tasks.\n\n## Methodology\n\nTo conduct our study, we explore how university students use GenAI to create a definition for a unit concept, then compare this to their own definition of the same concept after completing a 12-week semester. Students were asked to reflect on their learning experience as part of a formal written assessment task. 192 students submitted a personal reflection of how their understanding of the unit topic had evolved over the semester as compared to the original definition generated through ChatGPT-3 (Semester 1, 2023).\n\nThis study was conducted using a mixed method approach, specifically quantitative content analysis (QCA), in which elements of qualitative and quantitative approaches are combined for the purpose of breadth and depth of understanding (Poldner et al. [Citation2012](http://www.tandfonline.com/www.tandfonline.com); Yesilbursa [Citation2011](http://www.tandfonline.com/www.tandfonline.com)). In line with this approach, we first coded the reflections according to a coding framework that was developed based on theory to then further analyse this data quantitatively. We have outlined this in further detail below. This approach was selected as it allowed for the depth and complexity of participants’ experiences to be explored, with the aim of understanding how these students navigate the use of GenAI in their approach to learning while identifying any potential benefits and/or limitations.\n\nIn our sample, we had two undergraduate units with 56 and 84 student enrolments, and one postgraduate unit with 58 enrolments. Six students did not complete the assessment, leaving 192 reflections able to be included in the analysis. In all units, students were asked to use GenAI to develop a definition of a concept for their respective units in week 1. Then, after completing the 12-week unit, they were asked to write their own definition and compare and contrast with the AI-generated definition, reflecting on their learning. This resulted in approximately 75,000 words for analysis.\n\nIn line with standard deductive qualitative data analyses practices (Miles and Huberman [Citation1994](http://www.tandfonline.com/www.tandfonline.com)), we took a deductive approach to qualitative data analysis and developed a coding framework, a priori to analysing the reflections of students on their use of GenAI. The coding framework aimed to capture the different ways in which students used GenAI in reflecting on their knowledge and understanding of the key concepts taught in the units, as well as learning outcomes displayed by students.\n\nThese codes (see Appendix 2) were grouped into broader themes, which were refined and reviewed by the research team. We created codes that allowed us to assess whether GenAI was used in line with a mastery goal structure (showing evidence of _constructive_ and _augmentative_ approaches to using GenAI) or a performance goal structure (showing evidence of _regurgitation_ and adopting a _procedural_ approach to using GenAI). We also coded for evidence of different types of learning outcomes (information literacy, level of knowledge, discipline knowledge) and types of thinking capabilities (critical thinking, applied knowledge, learning autonomy). These codes were informed by the literature and all researchers familiarized themselves with these codes before analysis occurred. First, two authors coded the data and scored each reflection on whether they demonstrated the code’s process/learning/capability to a low, medium or high level. Then these codes and ratings were checked by two more researchers and if there were any discrepancies in interpretations, the research team discussed, using a consensus-based inter-coding process, until agreement was achieved. The researchers involved in the coding process were academics with advanced content knowledge that is specific to each of the units involved. We opted for a consensus-based inter-coding approach to understand any nuanced interpretations as each unit had unique learning outcomes (Cascio et al. [Citation2019](http://www.tandfonline.com/www.tandfonline.com)), opposed to statistical inter-coding approaches like Cohen’s Kappa as the complexity of qualitative data can distort measures of reliability (Friese [Citation2020](http://www.tandfonline.com/www.tandfonline.com)). The researchers also possess a deep understanding of how learning outcomes and skills are demonstrated by students in their assessment tasks; ensuring that the coding process was both accurate and insightful. NVivo was used to manage and organize the data throughout the analysis process. For each student, we also had their final unit marks (%) and their assignment marks (%) enabling us to use this as the outcome of their learning for both the individual task and overall unit performance.\n\n## Results\n\nWe assessed whether the approaches that students used in reflecting on their knowledge and understanding of the concepts taught using GenAI explained their assignment and unit marks, using t-tests. displays significant results.\n\n### Table 1. Differences in learning approach.\n\nWe found that when students take a constructive approach to using GenAI in their reflections, their overall marks as well as the assignment marks were significantly higher. In contrast, we found that when they used procedural approaches to reflect on their knowledge and understanding using GenAI, their marks were lower than if they did not use a procedural approach. Further, when students took an augmentative approach to using GenAI in their reflections, their overall marks were significantly higher to when they did not use this approach. We did not see this reflected in the assignment marks. Conversely, we see that when students use GenAI to regurgitate knowledge in their reflections, their overall grades are significantly lower than if students do not use GenAI in a regurgitative manner.\n\nGrades represent one indication of whether the learning outcomes were achieved. To gain a deeper understanding of the type of learning that was achieved we assess the relationships between the different approaches to using GenAI with learning outcomes in terms of general knowledge attainment (discipline knowledge and information literacy) and thinking capabilities (applied knowledge, critical thinking, learning autonomy). We note that overall, only 6 out of 192 showed _no_ discipline knowledge and 8 out of 192 showed no information literacy, which prevented us from looking at these differences.\n\nUsing logistic regressions, we find that when students use GenAI to augment knowledge, this positively affects the demonstration of applied knowledge, learning autonomy, and critical thinking as shown in .\n\n### Table 2. Comparison of outcomes.\n\nWe see similar results, but in the opposite direction for when students used GenAI to regurgitate knowledge. When students used GenAI to regurgitate knowledge, this negatively affects the demonstration of applied knowledge, learning autonomy, and critical thinking.\n\nOur analysis found that when students use GenAI to construct knowledge, this positively affects the demonstration of applied knowledge and critical thinking. No significant effects were found for the demonstration of learning autonomy (note that all students who showed constructive use of GenAI also showed learning autonomy, explaining the non-significant results).\n\nSimilar results are observed but in the opposite direction, for student use of GenAI in a procedural approach. When students use GenAI in a procedural manner, this negatively affects the demonstration of applied knowledge, learning autonomy, and critical thinking.\n\n## Discussion\n\nThis study shows that using GenAI to construct and augment human knowledge is associated with higher learning outcomes for students in grades and learning capabilities and capacities, but not for general knowledge attainment (due to low variance between students/high knowledge demonstration). On the other hand, when students use GenAI in a procedural and regurgitative approach, taking information that is generated at face value and not augmenting with their own understanding, they show lower learning outcomes (as assessed through their achieved grades and learning capacities and capabilities). One possible explanation for this is, when students adopt learning approaches aligning with a mastery goal structure (using AI to construct and augment knowledge) and use GenAI to fill their knowledge gaps to create deeper understanding, they achieve better learning outcomes. In contrast, when students adopt approaches to learning with a performance goal structure, thus, regurgitating GenAI outputs and being procedural in their answers, then their learning outcomes appear lower.\n\nOur findings extend knowledge and understanding of how GenAI impacts student learning outcomes and highlights considerations for effectively approaching the use of GenAI in higher education. Our results show a higher level of learning occurrence for students who used AI to construct and augment knowledge, and thus adopted a mastery goal structure to their learning. Students demonstrated applied, autonomous, and critical learning skillsets, aligning with ZPD theory, in which learning occurs most effectively when learners actively engage with support that bridges their current and potential abilities (Vygotsky [Citation1978](http://www.tandfonline.com/www.tandfonline.com).) On the other hand, when students use GenAI in a procedural and regurgitative approach, taking information that is generated at face value and not augmenting this with their own understanding, they show lower learning outcomes (as assessed through their achieved grades and learning capacities and capabilities), remaining within their existing zone of competence. It demonstrates that the way students engage with GenAI – either as a tool for knowledge construction and augmentation, or as a source of knowledge for regurgitation purposes – influences their learning outcomes. Our study provides a view of both the perceived and actual impacts of GenAI in higher education, highlighting the role of students’ goal structures and approaches to learning in determining the educational value of this technology.\n\nThese findings have significant implications for educators in navigating the integration of GenAI into student assessment. The results suggest that rather than viewing GenAI as a threat to academic integrity or a tool for cheating, there is an opportunity to encourage the critique and augmentation of AI-generated content rather than regurgitation. By encouraging students to approach GenAI to enhance their understanding and knowledge building, educators can potentially leverage this technology to help students expand their abilities beyond their zone of competence.\n\nFurthermore, these studies highlight the importance of developing these higher-order skills in students. As GenAI becomes more prevalent in academic and professional settings, students need the ability to critically evaluate, contextualize, and build upon AI-generated content. This involves not only technical skills but also the ability to critically reflect on their learning process and identify areas where GenAI can fill in their knowledge gaps.\n\n### Theoretical implications\n\nThis study builds upon existing learning frameworks and theories by considering these through the lens of GenAI and assessing the impact of this new technology on how students approach their learning. Existing studies demonstrate that a mastery goal structure leads to higher learning outcomes, and the findings further demonstrate this in the context of the use of GenAI.\n\nAs posed at the beginning of this research, GenAI has the potential to act as a scaffold mechanism within a course, allowing students to operate within their ZPD. Students who demonstrated a mastery goal structure, augmenting and constructing knowledge with GenAI, demonstrated positive impacts on their applied knowledge, critical thinking, and learning autonomy. Thereby tackling problems and concepts that may have initially been beyond their current capabilities. With this view, it is possible for GenAI to be viewed as a supportive tool, providing the necessary assistance to bridge the gap between student’s actual developmental level and their potential development level, leading to higher overall learning outcomes.\n\nThese findings can also be considered in relation to Fink’s taxonomy. Fink’s taxonomy includes the categories of foundational knowledge, application skills, integration, human dimension, caring, and learning how to learn (Fink [Citation2013](http://www.tandfonline.com/www.tandfonline.com)). While all students demonstrated proficiency in foundational knowledge, only those who leveraged AI as a constructive and augmentative tool, as opposed to regurgitating AI outputs, progressed to the significant learning levels of application, integration, and learning how to learn.\n\nThe study results align with higher-order cognitive skills emphasized in Bloom's revised taxonomy. This taxonomy of learning includes the categories: remember, understand, apply, analyse, evaluate, and create (Krathwohl [Citation2002](http://www.tandfonline.com/www.tandfonline.com)). Students who had a mastery approach in their learning were attaining the higher-order levels of learning of applying, analysing, evaluating, and creating. They analysed the GenAI output and applied their conceptual learning to create original work. In contrast, students who did not engage with AI in this manner but simply regurgitated the information they were given, appeared to remain at the lower levels of learning, focused on remembering and understanding factual information only. Therefore, demonstrating GenAI may be a potential barrier to the achievement of learning outcomes, specifically critical thinking, for students who take on a performance goal structure. As we did not measure the different learning types in Bloom’s taxonomy directly, we cannot indicate exactly which levels of learning the students who adopted a mastery approach achieved. However, given the increase in critical thinking, applied learning, and learning autonomy observed, we believe this demonstrates the applying, analysing, and evaluating levels have been obtained. Whether creativity is achieved can be suggested due to the fact that students constructed new and original definitions of terms in their assessments as a result. A future study could assess whether the use of AI paired with a mastery motivation allows students to progress to the highest level of learning achievable in Bloom’s taxonomy.\n\n### Practical implications\n\nOur findings have important implications when it comes to learning design in higher education. There is an opportunity to embed the use of GenAI into the course curriculum in a positive way that will contribute to the construction of knowledge. For example, a course curriculum can be designed to scaffold students’ learning from basic knowledge construction tasks through to more complex augmentations. This can be encouraged through the assessment and/or activity design such as asking students to compare and contrast GenAI responses to their own. Students could also be encouraged to discuss how they worked with GenAI to reach the answer, such as discussing the prompting steps used to develop their answers and show their working. This requires students to be able to connect the GenAI output back to the course content, developing their logic and reasoning ability. This approach can help students recognize how GenAI can function as a more knowledgeable source within their ZPD.\n\nWhen developing learning activities, educators should consider the structure of activities and assessments to promote progressive mastery as students’ progress through both their respective units and the overall degree. For example, activities could begin with basic GenAI interactions that build learner confidence and then advance to more complex tasks requiring critical evaluation of GenAI outputs. To further foster mastery goal orientations, educators may provide opportunities to teach explicit instructions to optimize prompting within GenAI tools, and design assessment rubrics that reward critical thinking when engaging with GenAI outputs.\n\nEducators can also gain valuable insights into curriculum development. Specifically, in preparing students for the modern workforce by providing exposure to GenAI during their tertiary education. This exposure provides context on how AI-based technology will be implemented in their field of study (Samala et al. [Citation2024](http://www.tandfonline.com/www.tandfonline.com)). Our research offers a blueprint for utilizing GenAI in a course-based environment, demonstrating how its integration into the curriculum can support lifelong learning strategies if introduced correctly, but may hinder learning if not implemented thoughtfully. For example, using GenAI as learning aids can accelerate comprehension of subject matter, enabling students to master their material more effectively. In addition, our study indicates that GenAI isn’t an effective tool for student learning if they are using it in a procedural manner, such as replication and knowledge regurgitation, but it may provide an efficient learning modality if used to help obtain subject mastery.\n\n### Limitations and future research\n\nIn our study, evidence of augmentative and constructive learning approaches was used as a proxy for mastery goal adoption, and evidence of regurgitative and procedural learning approaches as a proxy for performance goal adoptions. However, this research did not directly measure or manipulate goal structures due to ethical concerns. This limits the ability to test goal structure adoption on learning directly.\n\nSimilarly, while this research used data and insights from three marketing units, allowing for rich and generalizable insights, we were unable to control for any confounds which would have allowed for cause-and-effect relationships to be tested. Hence, this current work is presented as exploratory. Future research could employ a quasi-experimental approach within one course where use of GenAI is tightly controlled and learning outcomes are compared across groups of students who are prompted and guided to adopt mastery goal structures in their learning versus others who are prompted and guided to adopt performance goal structures.\n\nThis research provides insights into student learning when it comes to capabilities and competencies but fails to provide insights on how GenAI can be used to positively influence knowledge attainment. Our sample showed high levels of foundational knowledge and literacy for all students. The fact that foundational knowledge was demonstrated by all students is somewhat unsurprising, as there is some level of expected knowledge required by students entering a degree program. Therefore, it is implied that students should be able to demonstrate some foundational knowledge. Still, a future study might investigate how GenAI impacts the attainment of foundational knowledge and literacy more directly. A future study might investigate how GenAI impacts the attainment of foundational knowledge and literacy, directly employing a longitudinal design by tracking students from their initial exposure to discipline-specific content through to advanced concept mastery. It could be speculated that GenAI only has a positive role to play when students already have a certain foundational level of knowledge, and it negatively impacts knowledge attainment when students are novices in the discipline. A future study similar to this could help determine whether GenAI's effectiveness varies based on students’ prior knowledge levels and whether its benefits are sustained or diminish as students gain discipline knowledge.\n\nMore broadly, we conducted our study when the most commonly used model was ChatGPT-3. GenAI technology is rapidly evolving and changing in ability and accessibility. There is an opportunity for a longitudinal study to track both the evolution of GenAI technologies, including testing different models, alongside the impact this technology has on higher education, and if the evolution of AI shapes the future of education.\n\n## Conclusion\n\nThis research seeks to understand students’ perspectives on GenAI, investigate whether their goal orientations affect their engagement with GenAI tools and platforms, and explore the potential impact on their learning outcomes. Our initial pre-study findings found that undergraduate and postgraduate students had differing views when it came to the use of GenAI, with undergraduate students focusing on the lack of fairness, and postgraduate students recognizing the potential for knowledge construction. Our main study provided empirical evidence indicating students who align their GenAI use with a mastery goal structure to construct and augment knowledge within their ZPD achieved higher learning outcomes. This was evidenced through both achieved grades and demonstrated learning capabilities.\n\nThese findings make several important contributions to our understanding of GenAI in education. First, this study explores the educational value of GenAI and is associated with students’ goal structures. Second, they demonstrate how GenAI can function as an effective scaffolding tool within students’ ZPD when approached with a mastery orientation. Third, they provide empirical evidence that the integration of GenAI into higher education requires careful consideration of students’ goal structures and learning approaches.\n\nOur research suggests that educational institutions might benefit from shifting their focus from potential misuse of GenAI to fostering mastery goal orientations among students in their approach to GenAI use. While the evolution of GenAI presents ongoing challenges for educational research and practice, our findings provide initial insight into how students’ goal structure orientations mediate the relationship between GenAI use and learning outcomes.\n\nAs AI continues to evolve, further research is needed to understand the long-term implications of GenAI in education and develop best practices for its responsible and effective use. At the time of writing this paper, further advancements in GenAI technology have already occurred, and are ongoing. This is an area of research that is constantly evolving and will have a continual impact on the student learning experience.\n\n## Disclosure statement\n\nNo potential conflict of interest was reported by the author(s)."}
{"title": "The Impact of Generative AI on Critical Thinking", "content": "- [Consent](https://dl.acm.org/dl.acm.org)\n- [Details](https://dl.acm.org/dl.acm.org)\n- [\\[#IABV2SETTINGS#\\]](https://dl.acm.org/dl.acm.org)\n- [About](https://dl.acm.org/dl.acm.org)\n\nThis website uses cookies\n\nWe occasionally run membership recruitment campaigns on social media channels and use cookies to track post-clicks. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you’ve provided to them or that they’ve collected from your use of their services. Use the check boxes below to choose the types of cookies you consent to have stored on your device.\n\nConsent Selection\n\n**Necessary**\n\n**Preferences**\n\n**Statistics**\n\n**Marketing**\n\n[Show details](https://dl.acm.org/dl.acm.org)\n\nDetails\n\n- Necessary 10\n\n\n\n\n\nNecessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website. The website cannot function properly without these cookies. These cookies do not gather information about you that could be used for marketing purposes and do not remember where you have been on the internet.\n\n\n\n\n\n\n\n- ACM\n5\n[Learn more about this provider](https://www.acm.org/privacy-policy)\n\n\n**\\_\\_cf\\_bm \\[x2\\]** This cookie is used to distinguish between humans and bots. This is beneficial for the website, in order to make valid reports on the use of their website.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**\\_cfuvid** This cookie is a part of the services provided by Cloudflare - Including load-balancing, deliverance of website content and serving DNS connection for website operators.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**cf\\_chl\\_rc\\_ni** This cookie is a part of the services provided by Cloudflare - Including load-balancing, deliverance of website content and serving DNS connection for website operators.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**JSESSIONID** Preserves users states across page requests.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n- Cloudflare\n1\n[Learn more about this provider](https://www.cloudflare.com/privacypolicy/)\n**cf.turnstile.u** This cookie is used to distinguish between humans and bots.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n- Cookiebot\n2\n[Learn more about this provider](https://www.cookiebot.com/goto/privacy-policy/)\n\n\n**CookieConsent** Stores the user's cookie consent state for the current domain\n\n**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie\n\n\n\n\n\n**1.gif** Used to count the number of sessions to the website, necessary for optimizing CMP product delivery.\n\n**Maximum Storage Duration**: Session**Type**: Pixel Tracker\n\n- c.disquscdn.com\n2\n\n\n\n**\\_\\_jid** Used to add comments to the website and remember the user's Disqus login credentials across websites that use said service.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**disqusauth** Registers whether the user is logged in. This allows the website owner to make parts of the website inaccessible, based on the user's log-in status.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n- Preferences 5\n\n\n\n\n\nPreference cookies enable a website to remember information that changes the way the website behaves or looks, like your preferred language or the region that you are in.\n\n\n\n\n\n\n\n- ACM\n1\n[Learn more about this provider](https://www.acm.org/privacy-policy)\n**MACHINE\\_LAST\\_SEEN** Pending\n\n**Maximum Storage Duration**: 300 days**Type**: HTTP Cookie\n\n- Mopinion\n1\n[Learn more about this provider](https://mopinion.com/privacy/)\n**mopDeploy** Pending\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n- c.disquscdn.com\n3\n\n\n\n**aet-dismiss** Necessary for the functionality of the website's comment-system.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**drafts.queue** Necessary for the functionality of the website's comment-system.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**submitted\\_posts\\_cache** Necessary for the functionality of the website's comment-system.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n- Statistics 9\n\n\n\n\n\nStatistic cookies help website owners understand how visitors interact with websites by collecting and reporting information anonymously.\n\n\n\n\n\n\n\n- Google\n4\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\nSome of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n\n\n**\\_ga** Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n\n**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie\n\n\n\n\n\n**\\_ga\\_#** Used by Google Analytics to collect data on the number of times a user has visited the website as well as dates for the first and most recent visit.\n\n**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie\n\n\n\n\n\n**\\_gat** Used by Google Analytics to throttle request rate\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**\\_gid** Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n- Hotjar\n4\n[Learn more about this provider](https://www.hotjar.com/legal/policies/privacy/)\n\n\n**\\_hjSession\\_#** Collects statistics on the visitor's visits to the website, such as the number of visits, average time spent on the website and what pages have been read.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**\\_hjSessionUser\\_#** Collects statistics on the visitor's visits to the website, such as the number of visits, average time spent on the website and what pages have been read.\n\n**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie\n\n\n\n\n\n**\\_hjTLDTest** Registers statistical data on users' behaviour on the website. Used for internal analytics by the website operator.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**\\_hjCookieTest** Collects data on the user’s navigation and behavior on the website. This is used to compile statistical reports and heatmaps for the website owner.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n- c.disquscdn.com\n1\n\n**disqus\\_unique** Collects statistics related to the user's visits to the website, such as number of visits, average time spent on the website and loaded pages.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n- Marketing 18\n\n\n\n\n\nMarketing cookies are used to track visitors across websites. The intention is to display ads that are relevant and engaging for the individual user and thereby more valuable for publishers and third party advertisers.\n\n\n\n\n\n\n\n- Google\n1\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\nSome of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n\n\n**NID** Registers a unique ID that identifies a returning user's device. The ID is used for targeted ads.\n\n**Maximum Storage Duration**: 6 months**Type**: HTTP Cookie\n\n- YouTube\n17\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\n**\\_\\_Secure-ROLLOUT\\_TOKEN** Used to track user’s interaction with embedded content.\n\n**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie\n\n\n\n\n\n**\\_\\_Secure-YEC** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**LAST\\_RESULT\\_ENTRY\\_KEY** Used to track user’s interaction with embedded content.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**LogsDatabaseV2:V#\\|\\|LogsRequestsStore** Used to track user’s interaction with embedded content.\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**remote\\_sid** Necessary for the implementation and functionality of YouTube video-content on the website.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**TESTCOOKIESENABLED** Used to track user’s interaction with embedded content.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**VISITOR\\_INFO1\\_LIVE** Tries to estimate the users' bandwidth on pages with integrated YouTube videos.\n\n**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie\n\n\n\n\n\n**YSC** Registers a unique ID to keep statistics of what videos from YouTube the user has seen.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**ytidb::LAST\\_RESULT\\_ENTRY\\_KEY** Used to track user’s interaction with embedded content.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**YtIdbMeta#databases** Used to track user’s interaction with embedded content.\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**yt-remote-cast-available** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-cast-installed** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-connected-devices** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-device-id** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-fast-check-period** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-session-app** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-session-name** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n- Unclassified 12\n\n\n\nUnclassified cookies are cookies that we are in the process of classifying, together with the providers of individual cookies.\n\n\n\n\n\n\n\n- ACM\n10\n[Learn more about this provider](https://www.acm.org/privacy-policy)\n\n\n**book\\_reader\\_settings** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**chapter\\_reader\\_settings** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**MAID** Pending\n\n**Maximum Storage Duration**: 300 days**Type**: HTTP Cookie\n\n\n\n\n\n**sharedOffline#availableContents** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**sharedOffline#formats** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**sharedOffline#libraryContents** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**sharedOffline#metadataAttachment** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**sharedOffline#referencesAttachment** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**sharedOffline#relationsAttachment** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**tipKey** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n- Google\n1\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\nSome of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n\n\n**GSP** Pending\n\n**Maximum Storage Duration**: 400 days**Type**: HTTP Cookie\n\n- c.disquscdn.com\n1\n\n**disqus.thread** Pending\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n[Cross-domain consent1](https://dl.acm.org/dl.acm.org) Your consent applies to the following domains:\n\nList of domains your consent applies to:[dl.acm.org](https://dl.acm.org)\n\nCookie declaration last updated on 10/7/25 by [Cookiebot](https://www.cookiebot.com)\n\n\\[#IABV2\\_TITLE#\\]\n\n\\[#IABV2\\_BODY\\_INTRO#\\]\n\n\\[#IABV2\\_BODY\\_LEGITIMATE\\_INTEREST\\_INTRO#\\]\n\n\\[#IABV2\\_BODY\\_PREFERENCE\\_INTRO#\\]\n\n\\[#IABV2\\_LABEL\\_PURPOSES#\\]\n\n\\[#IABV2\\_BODY\\_PURPOSES\\_INTRO#\\]\n\n\\[#IABV2\\_BODY\\_PURPOSES#\\]\n\n\\[#IABV2\\_LABEL\\_FEATURES#\\]\n\n\\[#IABV2\\_BODY\\_FEATURES\\_INTRO#\\]\n\n\\[#IABV2\\_BODY\\_FEATURES#\\]\n\n\\[#IABV2\\_LABEL\\_PARTNERS#\\]\n\n\\[#IABV2\\_BODY\\_PARTNERS\\_INTRO#\\]\n\n\\[#IABV2\\_BODY\\_PARTNERS#\\]\n\nAbout\n\nCookies are small text files that can be used by websites to make a user's experience more efficient. Other than those strictly necessary for the operation of the site,  we need your permission to store any type of cookies on your device. Learn more about ACM, how you can contact us, and how we process personal data in our [Privacy Policy](https://www.acm.org/privacy-policy). Also please consult our [Cookie Notice](https://www.acm.org/cookie-notice).\n\nYou can change or withdraw your consent from the Cookie Declaration on our website at any time by visiting the [Cookie Declaration](https://dl.acm.org/cookie-declaration) page. If contacting us regarding your consent, please state your consent ID and date from that page.\n\n**Do not sell or share my personal information**\n\nAllow all cookiesCustomizeAllow selected cookiesUse necessary cookies only\n\n [skip to main content](https://dl.acm.org/dl.acm.org#skip-to-main-content)\n\nContents\n\n## Abstract\n\nThe rise of Generative AI (GenAI) in knowledge workflows raises questions about its impact on critical thinking skills and practices. We survey 319 knowledge workers to investigate 1) when and how they perceive the enaction of critical thinking when using GenAI, and 2) when and why GenAI affects their effort to do so. Participants shared 936 first-hand examples of using GenAI in work tasks. Quantitatively, when considering both task- and user-specific factors, a user’s task-specific self-confidence and confidence in GenAI are predictive of whether critical thinking is enacted and the effort of doing so in GenAI-assisted tasks. Specifically, higher confidence in GenAI is associated with less critical thinking, while higher self-confidence is associated with more critical thinking. Qualitatively, GenAI shifts the nature of critical thinking toward information verification, response integration, and task stewardship. Our insights reveal new design challenges and opportunities for developing GenAI tools for knowledge work.\n\n## 1 Introduction\n\nGenerative AI ( **GenAI**) tools, defined as any _“end user tool \\[...\\] whose technical implementation includes a generative model based on deep learning”_, [1](https://dl.acm.org/dl.acm.org#fn1) are the latest in a long line of technologies that raise questions about their impact on the quality of human thought, a line that includes writing (objected to by Socrates), printing (objected to by Trithemius), calculators (objected to by teachers of arithmetic), and the Internet.\n\nSuch consternation is not unfounded. Used improperly, technologies can and do result in the deterioration of cognitive faculties that ought to be preserved. As Bainbridge \\[ [7](https://dl.acm.org/dl.acm.org#Bib0007)\\] noted, a key irony of automation is that by mechanising routine tasks and leaving exception-handling to the human user, you deprive the user of the routine opportunities to practice their judgment and strengthen their cognitive musculature, leaving them atrophied and unprepared when the exceptions do arise.\n\nIn response, research has begun looking closely at how different activities are impacted by GenAI and the extent to which cognitive offloading \\[ [8](https://dl.acm.org/dl.acm.org#Bib0008)\\] occurs, and whether this may be an undesirable thing. Some work has focused, for instance, on studying the effects of GenAI use on memory (e.g., \\[ [1](https://dl.acm.org/dl.acm.org#Bib0001), [106](https://dl.acm.org/dl.acm.org#Bib0106)\\]) and on creativity (e.g., \\[ [28](https://dl.acm.org/dl.acm.org#Bib0028), [100](https://dl.acm.org/dl.acm.org#Bib0100)\\]). Moreover, design research has also been developing interventions that _improve_ the ability of people to think in certain ways (e.g., \\[ [24](https://dl.acm.org/dl.acm.org#Bib0024)\\]). We review these lines of work in Section [2](https://dl.acm.org/dl.acm.org#sec-2).\n\nIn this paper, we focus on a higher-level concept that captures another aspect of thought considered desirable and worthy of preservation: _critical thinking_ (defined in Section [2](https://dl.acm.org/dl.acm.org#sec-2)). The effect of the use of GenAI tools on critical thinking, as a direct object of inquiry, has not yet been explored.\n\nMoreover, we focus on critical thinking for _knowledge work_ (as conceptualised by Drucker \\[ [30](https://dl.acm.org/dl.acm.org#Bib0030)\\] and Kidd \\[ [67](https://dl.acm.org/dl.acm.org#Bib0067)\\]). Much research on the effect of GenAI on thinking skills is focused on educational settings, where concern for skill cultivation is most acute (e.g., the effect of GenAI code completion tools on programming and computer science education \\[ [107](https://dl.acm.org/dl.acm.org#Bib0107)\\]). As previously noted \\[ [116](https://dl.acm.org/dl.acm.org#Bib0116), [119](https://dl.acm.org/dl.acm.org#Bib0119)\\], critical thinking has been operationalised in detail in certain specific disciplines, such as academic history, clinical psychology, and nursing. But the ostensible shifts in critical thinking behaviours brought about by GenAI extend to a broad set of professions and knowledge workflows — GenAI tools are now widely used in knowledge work \\[ [13](https://dl.acm.org/dl.acm.org#Bib0013)\\] — and little is known about the critical thinking demands of these. We lack broad-based empirical examples of what _kinds_ of knowledge work activities are considered by professionals to require critical thinking.\n\nRecent work has motivated the need for critical thinking support in AI-assisted knowledge work \\[ [116](https://dl.acm.org/dl.acm.org#Bib0116), [119](https://dl.acm.org/dl.acm.org#Bib0119)\\]. It is motivated primarily by the observation of the tendency of AI-assisted knowledge workflows to be subject to “mechanised convergence” \\[ [114](https://dl.acm.org/dl.acm.org#Bib0114)\\], i.e., that users with access to GenAI tools produce a less diverse set of outcomes for the same task, compared to those without. This tendency for convergence reflects a lack of personal, contextualised, critical and reflective judgment of AI output and thus can be interpreted as a deterioration of critical thinking.\n\nHowever, we lack direct empirical evidence for an interpretation that posits a connection between mechanised convergence and critical thinking. Output diversity is a _proxy_ for critical thinking, and a flawed one. For instance, users who reuse GenAI output without editing it may have nonetheless performed a critical, reflective judgment in forming the decision not to edit it. Such reflective thinking is invisible to measures that focus only on the ultimate artefact produced. Without knowing how knowledge workers enact critical thinking when using GenAI and the associated challenges, we risk creating interventions that do not address workers’ real needs.\n\nIn this paper, we aim to address this gap by conducting a survey of a professionally diverse set of knowledge workers ( _n_ = 319), eliciting detailed real-world examples of tasks (936) for which they use GenAI, and directly measuring their perceptions of critical thinking during these tasks: when is critical thinking necessary, how is critical thinking enacted, whether GenAI tools affect the effort of critical thinking, and to what extent (Section [3](https://dl.acm.org/dl.acm.org#sec-3)). We focus on “enaction” (i.e., actions that are signals or manifestations) of critical thinking rather than critical thinking _per se_, because critical thinking itself as a pure mental phenomenon is difficult for people to self-observe, reflect on, and report.\n\nConcretely, we aim to answer two research questions:\n\nRQ1\n\nWhen and how do knowledge workers perceive the enaction of critical thinking when using GenAI?\n\nRQ2\n\nWhen and why do knowledge workers perceive increased/ decreased effort for critical thinking due to GenAI?\n\nWith respect to RQ1 (Section [4](https://dl.acm.org/dl.acm.org#sec-4)), the study reveals that knowledge workers engage in critical thinking when using GenAI tools primarily to ensure the quality of their work. They define critical thinking as setting clear goals, refining prompts, and assessing AI-generated content to meet specific criteria and standards. Their reflective approach involves verifying outputs against external sources and their own expertise, especially in tasks that require higher accuracy.\n\nThe data identify key motivators for critical thinking: the desire to enhance work quality, avoid negative outcomes, and develop skills. However, several barriers inhibit this reflective process, including lack of awareness, limited motivation due to time pressure or job scope, and difficulty improving AI responses in unfamiliar domains. Surprisingly, while AI can improve efficiency, it may also reduce critical engagement, particularly in routine or lower-stakes tasks in which users simply rely on AI, raising concerns about long-term reliance and diminished independent problem-solving.\n\nRegarding RQ2 (Section [5](https://dl.acm.org/dl.acm.org#sec-5)), GenAI tools appear to reduce the perceived effort required for critical thinking tasks among knowledge workers, especially when they have higher confidence in AI capabilities. However, workers who are confident in their own skills tend to perceive greater effort in these tasks, particularly when evaluating and applying AI responses.\n\nThe data shows a shift in cognitive effort as knowledge workers increasingly move from task execution to oversight when using GenAI. While this shift “from material production to critical integration” has been observed in prior studies \\[ [114](https://dl.acm.org/dl.acm.org#Bib0114)\\], such studies are typically controlled studies in narrow domains with small participant samples. Our data provides complementary evidence that this also occurs in real-world use of GenAI tools, across a wide variety of tasks and professions. For tasks like knowledge retrieval, AI reduces effort by automating information gathering, but workers must now invest more in verifying the accuracy of AI outputs. Similarly, while AI simplifies content creation, workers still need to spend time aligning outputs with specific needs and quality standards.\n\nOur paper makes the following contributions:\n\n•\n\nWe review the literature on interaction design interventions for critical thinking, and studies of the effects of automation on knowledge workflows (Section [2](https://dl.acm.org/dl.acm.org#sec-2)).\n\n•\n\nWe describe the development and deployment of a survey for gathering empirical evidence for knowledge workers’ experiences and perceptions of the effect of GenAI on critical thinking (Section [3](https://dl.acm.org/dl.acm.org#sec-3)). We find that GenAI tools reduce the perceived effort of critical thinking while also encouraging over-reliance on AI, with confidence in the tool often diminishing independent problem-solving. As workers shift from task execution to AI oversight, they trade hands-on engagement for the challenge of verifying and editing AI outputs, revealing both the efficiency gains and the risks of diminished critical reflection (Sections [4](https://dl.acm.org/dl.acm.org#sec-4) and [5](https://dl.acm.org/dl.acm.org#sec-5)).\n\n•\n\nDrawing from our survey insights, we highlight how the use of GenAI tools creates new challenges for critical thinking. We outline implications for designing GenAI to support knowledge workers to enhance their awareness, motivation, and ability to think critically (Section [6](https://dl.acm.org/dl.acm.org#sec-6)).\n\n## 2 Related Work\n\n### 2.1 Critical thinking\n\nWe adopt the definition of critical thinking developed by Bloom et al. \\[ [12](https://dl.acm.org/dl.acm.org#Bib0012), [54](https://dl.acm.org/dl.acm.org#Bib0054)\\], a hierarchical taxonomy that characterises student learning objectives into six types: knowledge (recall of ideas), comprehension (demonstrating understanding of ideas), application (putting ideas into practice), analysis (contrasting and relating ideas), synthesis (combining ideas), and evaluation (judging ideas through criteria).\n\nThis definition of critical thinking is not uncontested. There are multiple alternative frameworks \\[ [36](https://dl.acm.org/dl.acm.org#Bib0036), [37](https://dl.acm.org/dl.acm.org#Bib0037), [38](https://dl.acm.org/dl.acm.org#Bib0038), [104](https://dl.acm.org/dl.acm.org#Bib0104)\\], and critical thinking is sometimes also referred to as reflective thinking \\[ [26](https://dl.acm.org/dl.acm.org#Bib0026)\\], though not all scholars conflate them. There have been multiple proposals for connecting and reconciling this multiplicity of frameworks \\[ [32](https://dl.acm.org/dl.acm.org#Bib0032), [74](https://dl.acm.org/dl.acm.org#Bib0074), [96](https://dl.acm.org/dl.acm.org#Bib0096)\\].\n\nWe adopt the Bloom et al. framework for multiple reasons. First, as one of the earliest frameworks, it has strong support in the research literature and wide adoption in education systems — its definition of critical thinking has been widely influential, and has withstood severe criticism and scrutiny \\[ [40](https://dl.acm.org/dl.acm.org#Bib0040)\\]. Second, it is relatively simple, having only six core dimensions (as opposed to, for instance, the nuanced Paul-Elder framework \\[ [104](https://dl.acm.org/dl.acm.org#Bib0104)\\] which consists of eight “elements of thought”, ten “intellectual standards”, and eight “intellectual virtues”). The simplicity of the Bloom et al. framework — its small set of dimensions with clear definitions — renders it more suitable as the basis of a survey instrument.\n\nCritical thinking skills can be developed in sequential stages \\[ [70](https://dl.acm.org/dl.acm.org#Bib0070), [98](https://dl.acm.org/dl.acm.org#Bib0098), [104](https://dl.acm.org/dl.acm.org#Bib0104)\\]. Despite concerns about whether critical thinking can be taught \\[ [138](https://dl.acm.org/dl.acm.org#Bib0138)\\], research in education has developed a number of approaches to teaching critical thinking \\[ [104](https://dl.acm.org/dl.acm.org#Bib0104), [139](https://dl.acm.org/dl.acm.org#Bib0139)\\], such as structured argumentation exercises \\[ [25](https://dl.acm.org/dl.acm.org#Bib0025), [70](https://dl.acm.org/dl.acm.org#Bib0070), [72](https://dl.acm.org/dl.acm.org#Bib0072), [133](https://dl.acm.org/dl.acm.org#Bib0133)\\]. Critical thinking can be measured through self-, peer-, or expert evaluation \\[ [66](https://dl.acm.org/dl.acm.org#Bib0066)\\], using a range of questionnaires \\[ [35](https://dl.acm.org/dl.acm.org#Bib0035), [65](https://dl.acm.org/dl.acm.org#Bib0065), [73](https://dl.acm.org/dl.acm.org#Bib0073), [145](https://dl.acm.org/dl.acm.org#Bib0145), [146](https://dl.acm.org/dl.acm.org#Bib0146)\\], justified multiple choice questions, structured essays, protocols for whole-portfolio assessment, task observation, and peer interaction \\[ [34](https://dl.acm.org/dl.acm.org#Bib0034), [105](https://dl.acm.org/dl.acm.org#Bib0105)\\]. In our study, we apply a one-item five-point scale assessment for each of the six cognitive activities associated with critical thinking (six items in total, see Section [3.1.3](https://dl.acm.org/dl.acm.org#sec-3-1-3)), similar to previous work (e.g., Alaoutinen and Smolander \\[ [3](https://dl.acm.org/dl.acm.org#Bib0003)\\]).\n\n### 2.2 Design research for critical and reflective thinking\n\nPrevious research has investigated how interaction design can encourage critical or reflective thinking. Various dimensions of the space of critical thinking interventions have been explored. For instance, whether the system should be proactive, i.e., introduce critical thinking prompts without an explicit user request \\[ [69](https://dl.acm.org/dl.acm.org#Bib0069), [109](https://dl.acm.org/dl.acm.org#Bib0109)\\]. Or the extent to which user participation and engagement is important in creating critical thinking outcomes, e.g., presenting AI explanations as questions rather than statements improves logical discernment \\[ [24](https://dl.acm.org/dl.acm.org#Bib0024)\\], questions also improve critical reading \\[ [110](https://dl.acm.org/dl.acm.org#Bib0110), [142](https://dl.acm.org/dl.acm.org#Bib0142)\\], attention checks promote systematic thinking \\[ [49](https://dl.acm.org/dl.acm.org#Bib0049)\\], conflict-filled discussion induces critical thinking \\[ [78](https://dl.acm.org/dl.acm.org#Bib0078)\\], and in general increased engagement results in behavioural changes \\[ [82](https://dl.acm.org/dl.acm.org#Bib0082), [92](https://dl.acm.org/dl.acm.org#Bib0092)\\]. Research has explored the effectiveness of gamification of critical thinking \\[ [31](https://dl.acm.org/dl.acm.org#Bib0031), [91](https://dl.acm.org/dl.acm.org#Bib0091), [129](https://dl.acm.org/dl.acm.org#Bib0129)\\]. Research has also explored the extent to which interventions ought to be presented in an agentised or anthropomimetic manner \\[ [99](https://dl.acm.org/dl.acm.org#Bib0099), [131](https://dl.acm.org/dl.acm.org#Bib0131), [141](https://dl.acm.org/dl.acm.org#Bib0141)\\].\n\nThere are domains and activities, some of which are relevant to common knowledge workflows, where critical thinking interventions have been heavily studied. For example, design for critical thinking can aid in the prevention and verification of misinformation, e.g., through structured thinking aids \\[ [50](https://dl.acm.org/dl.acm.org#Bib0050), [51](https://dl.acm.org/dl.acm.org#Bib0051)\\], analytical thinking nudges \\[ [143](https://dl.acm.org/dl.acm.org#Bib0143)\\], worksheets and group discussion \\[ [136](https://dl.acm.org/dl.acm.org#Bib0136)\\], and gamification \\[ [129](https://dl.acm.org/dl.acm.org#Bib0129)\\]. Or in writing, ideation and argumentation tools, such as through visualising argument structure \\[ [126](https://dl.acm.org/dl.acm.org#Bib0126), [133](https://dl.acm.org/dl.acm.org#Bib0133)\\], reflecting on future scenarios \\[ [132](https://dl.acm.org/dl.acm.org#Bib0132)\\], ideation and evaluation support \\[ [45](https://dl.acm.org/dl.acm.org#Bib0045)\\], assessing risks in research impact statements \\[ [94](https://dl.acm.org/dl.acm.org#Bib0094)\\]. Another common area for reflective thinking interventions is in mental health and wellbeing, e.g., to support cognitive reappraisal \\[ [71](https://dl.acm.org/dl.acm.org#Bib0071)\\], reduce compulsive smartphone use \\[ [80](https://dl.acm.org/dl.acm.org#Bib0080), [81](https://dl.acm.org/dl.acm.org#Bib0081)\\], improve time management \\[ [55](https://dl.acm.org/dl.acm.org#Bib0055)\\], create journaling prompts \\[ [97](https://dl.acm.org/dl.acm.org#Bib0097)\\], encourage reflection on book highlights \\[ [61](https://dl.acm.org/dl.acm.org#Bib0061)\\], support prayer \\[ [75](https://dl.acm.org/dl.acm.org#Bib0075)\\], coaching for leadership growth \\[ [4](https://dl.acm.org/dl.acm.org#Bib0004)\\], and reflection on cherished objects \\[ [57](https://dl.acm.org/dl.acm.org#Bib0057)\\]. Critical thinking interventions have also been explored in data analysis \\[ [44](https://dl.acm.org/dl.acm.org#Bib0044), [48](https://dl.acm.org/dl.acm.org#Bib0048)\\].\n\nOverreliance, defined as “users accepting incorrect recommendations, i.e., making errors of commission” \\[ [102](https://dl.acm.org/dl.acm.org#Bib0102)\\], is closely related to (the lack of) critical thinking. Buçinca et al. \\[ [17](https://dl.acm.org/dl.acm.org#Bib0017)\\] found that “cognitive forcing functions” such as requiring the user to wait before receiving AI output, or to make interactive updates to AI output, significantly reduce overreliance compared to simpler AI explanations. Though there is overlap, overreliance is not strictly the same problem as (and is perhaps a special case of) a lack of critical thinking. A lack of critical thinking may also manifest through accepting a solution that merely meets a baseline aspirational threshold \\[ [6](https://dl.acm.org/dl.acm.org#Bib0006), [119](https://dl.acm.org/dl.acm.org#Bib0119)\\] — in such cases, the AI solution is correct (albeit potentially of poor quality) and therefore not overreliance, strictly speaking.\n\nCollectively, these can inform design interventions to support critical thinking for knowledge workers. Still, these systems and tools do not engage with how the need for critical thinking support changes due to shifts in workflow caused specifically by the use of GenAI. We also lack empirical foundations for understanding how knowledge workers enact critical thinking in real-world GenAI workflows.\n\n### 2.3 Effects of automation on thinking and knowledge workflows: writing and memory\n\n_Effects on writing_. Generative AI tools like Copilot and ChatGPT can boost writing productivity by assisting with tasks such as content generation, idea creation, and stylistic editing, helping both expert and novice writers \\[ [18](https://dl.acm.org/dl.acm.org#Bib0018), [84](https://dl.acm.org/dl.acm.org#Bib0084), [112](https://dl.acm.org/dl.acm.org#Bib0112), [135](https://dl.acm.org/dl.acm.org#Bib0135)\\]. However, there are concerns that novice writers may become overly reliant on these tools, potentially impairing their long-term skill development by bypassing critical writing processes such as constructing logical arguments and understanding subject matter \\[ [14](https://dl.acm.org/dl.acm.org#Bib0014), [53](https://dl.acm.org/dl.acm.org#Bib0053), [63](https://dl.acm.org/dl.acm.org#Bib0063), [64](https://dl.acm.org/dl.acm.org#Bib0064)\\]. To mitigate this, using GenAI for individualised, content-focused feedback may help novice writers develop writing skills while improving productivity \\[ [58](https://dl.acm.org/dl.acm.org#Bib0058), [86](https://dl.acm.org/dl.acm.org#Bib0086), [144](https://dl.acm.org/dl.acm.org#Bib0144)\\]. Although human feedback has traditionally been necessary for effective self-improvement, the integration of AI into tools like Microsoft Word could democratise access to writing skill development by providing consistent, low-cost feedback \\[ [2](https://dl.acm.org/dl.acm.org#Bib0002), [123](https://dl.acm.org/dl.acm.org#Bib0123)\\]. Early studies suggest that AI-generated feedback can improve writing quality and logical structure, especially for lower-performing students and less confident English learners \\[ [79](https://dl.acm.org/dl.acm.org#Bib0079), [101](https://dl.acm.org/dl.acm.org#Bib0101), [128](https://dl.acm.org/dl.acm.org#Bib0128), [135](https://dl.acm.org/dl.acm.org#Bib0135)\\]. Thus, equipping AI tools with better feedback mechanisms could foster long-term writing skill development while addressing inequalities in access to writing education \\[ [2](https://dl.acm.org/dl.acm.org#Bib0002), [79](https://dl.acm.org/dl.acm.org#Bib0079)\\], and enable humans and AI to interact over time to maximise both productivity and learning outcomes \\[ [128](https://dl.acm.org/dl.acm.org#Bib0128), [135](https://dl.acm.org/dl.acm.org#Bib0135)\\].\n\n_Effects on memory_. While GenAI and conversational search engines can streamline tasks like literature reviews, some fear that outsourcing this work could harm our ability to learn and remember, in what is sometimes referred to as “digital amnesia” \\[ [47](https://dl.acm.org/dl.acm.org#Bib0047), [111](https://dl.acm.org/dl.acm.org#Bib0111)\\], though evidence for this effect is largely inconclusive \\[ [19](https://dl.acm.org/dl.acm.org#Bib0019), [21](https://dl.acm.org/dl.acm.org#Bib0021), [27](https://dl.acm.org/dl.acm.org#Bib0027), [127](https://dl.acm.org/dl.acm.org#Bib0127)\\]. Research shows that summarising material and follow-up writing practice enhance memory by integrating new knowledge with existing knowledge \\[ [62](https://dl.acm.org/dl.acm.org#Bib0062), [93](https://dl.acm.org/dl.acm.org#Bib0093), [134](https://dl.acm.org/dl.acm.org#Bib0134)\\], but real-world summary writing is often passive and ineffective \\[ [15](https://dl.acm.org/dl.acm.org#Bib0015), [16](https://dl.acm.org/dl.acm.org#Bib0016), [41](https://dl.acm.org/dl.acm.org#Bib0041), [121](https://dl.acm.org/dl.acm.org#Bib0121), [140](https://dl.acm.org/dl.acm.org#Bib0140)\\], and thus may not improve recall in comparison to simply re-reading the text \\[ [124](https://dl.acm.org/dl.acm.org#Bib0124)\\]. GenAI tools like ChatGPT and Copilot can mitigate these drawbacks, especially for less experienced learners, by providing high-quality summaries upon which collaborative, self-monitored writing tasks can be conducted \\[ [120](https://dl.acm.org/dl.acm.org#Bib0120), [125](https://dl.acm.org/dl.acm.org#Bib0125)\\]. Cognitive science shows that effective learning requires “grounding” information through multiple perspectives and examples \\[ [10](https://dl.acm.org/dl.acm.org#Bib0010), [11](https://dl.acm.org/dl.acm.org#Bib0011), [68](https://dl.acm.org/dl.acm.org#Bib0068)\\], and GenAI can offer personalised analogies to aid this process \\[ [77](https://dl.acm.org/dl.acm.org#Bib0077), [90](https://dl.acm.org/dl.acm.org#Bib0090)\\].\n\n**In summary**, previous work has defined critical thinking and investigated ways to develop and measure this skill in educational settings. Separately, design research has investigated ways of developing technology that induces critical reflection. It has also been found that AI tools can significantly impact common knowledge workflows, such as writing. However, there is a gap in understanding knowledge workers’ perceptions of how GenAI affects their enaction of critical thinking, and the effort of doing so, across a broad range of use cases. This is the gap we address with our survey.\n\n## 3 Method\n\nTo answer our research questions — when and how knowledge workers perceive the enaction of critical thinking when using GenAI (RQ1), and when and why do knowledge workers perceive increased/decreased effort for critical thinking due to GenAI (RQ2) — we conducted an online survey on the Prolific platform [2](https://dl.acm.org/dl.acm.org#fn2) to study knowledge workers’ experiences with critical thinking when using GenAI tools for their work.\n\nTo ensure participants fully understood the scope and meaning of our questions on critical thinking, as part of the survey study onboarding, they were introduced to the concept of critical thinking in the context of using GenAI through concrete examples of how critical thinking could be applied at various levels of Bloom’s taxonomy (e.g., checking the tone of generated emails, verifying the accuracy of code snippets, and assessing potential biases in data insights). These examples served to sensitise participants to the various dimensions of critical thinking while avoiding conceptualising critical thinking too narrowly. These acted as “cognitive priming”, helping participants better understand the concept of critical thinking, thus soliciting better recognition of critical thinking behaviours in participants’ daily GenAI use.\n\nIn total, we received 319 survey responses, in which participants shared a total of 936 real-world examples where they used a GenAI tool for their work, and shared how critical thinking played a role in these tasks.\n\nTo answer **RQ1**, we created an explanatory regression model with a dependent variable measuring _whether participants perceived the enaction of critical thinking_ when using GenAI tools for the tasks they shared, and independent variables corresponding to two sets of factors that we hypothesised might correlate with the tendency to engage with tasks critically: 1) **task factors**: measures about the task at hand — e.g., task type, confidence in doing the task. 2) **User factors**: measures about users — e.g., age, gender, occupation, tendency to reflect in work, and trust in GenAI. In addition, we analysed participants’ motivators and inhibitors for critical thinking from their free-text responses.\n\nTo answer **RQ2**, we create explanatory regression models with dependent variables measuring _whether participants perceived different cognitive activities constituting critical thinking (e.g., breaking down a problem, putting together ideas) to be more or less effortful_ when using a GenAI tool for the tasks compared to when not using one. Independent variables included the same set of factors as for RQ1 above. We also analysed participants’ free-text responses to understand why they perceived these cognitive activities as more or less effortful due to GenAI.\n\n### 3.1 Survey Design\n\nTo model the relationship between task and user factors as they relate to critical thinking activities, we designed a survey as follows (see Appendix [A.1](https://dl.acm.org/dl.acm.org#sec-9-1) for the complete survey).\n\n#### 3.1.1 Task-Related Factors.\n\nPrior studies have shown that knowledge workers apply GenAI tools for a range of tasks and express different needs while doing these tasks \\[ [13](https://dl.acm.org/dl.acm.org#Bib0013)\\], and that their perceived confidence in themselves and AI doing the tasks can influence their use and reliance on the tool \\[ [20](https://dl.acm.org/dl.acm.org#Bib0020), [22](https://dl.acm.org/dl.acm.org#Bib0022), [83](https://dl.acm.org/dl.acm.org#Bib0083), [130](https://dl.acm.org/dl.acm.org#Bib0130)\\]. We hypothesised that factors relating to the user’s task, including task type, confidence in themselves, and AI doing the task, could affect their critical thinking.\n\n_Task type_.\n\n| | | |\n| --- | --- | --- |\n| **Category** | **Sub-category** | **Description** |\n| Creation | Artefact | Generate a new artefact to be used directly or with some modification |\n| Idea | Generate an idea, to be used indirectly |\n| Information | Search | Seek a fact or piece of information |\n| Learn | Learn about a new topic more broadly |\n| Summarise | Generate a shorter version of a piece of content that describes the important elements |\n| Analyse | Discover a new insight about information or data |\n| Advice | Improve | Generate a better version |\n| Guidance | Get guidance about how to make a decision |\n| Validation | Check whether an artefact satisfies a set of rules or constraints |\n\nCategories and sub-categories for GenAI tool usage \\[ [13](https://dl.acm.org/dl.acm.org#Bib0013)\\].\n\nBrachman et al. \\[ [13](https://dl.acm.org/dl.acm.org#Bib0013)\\] classify knowledge workers’ current usage of GenAI tools into nine types (See Table [1](https://dl.acm.org/dl.acm.org#tab1)), grouped into three major categories: 1) for **creation**, 2) to find or work with **information**, 3) to get **advice**. This taxonomy offers clear distinctions among the major categories of task type, which we hypothesised would correlate with users’ critical thinking due to differing objectives and requirements. We follow Brachman et al. \\[ [13](https://dl.acm.org/dl.acm.org#Bib0013)\\]’s taxonomy and operationalise their task type categorisation in our survey, focusing on the major categories. For each GenAI tool use example, participants were first asked to describe in detail the task they did (i.e., _Please tell us: 1) what you were trying to achieve, 2) in what GenAI tool, and 3) how you used the GenAI tool, including any prompts._). Then, they were asked to pick one of the nine task types that best described their task. Using this information, we classified each example as creation, information, or advice, per the Brachman et al. \\[ [13](https://dl.acm.org/dl.acm.org#Bib0013)\\] taxonomy.\n\n_Task confidence_. Guided by prior studies on user confidence in AI-assisted decision-making \\[ [20](https://dl.acm.org/dl.acm.org#Bib0020), [85](https://dl.acm.org/dl.acm.org#Bib0085), [130](https://dl.acm.org/dl.acm.org#Bib0130)\\], for each self-reported task we consider three aspects of user confidence: 1) **confidence in self** (i.e., _How confident are you in your ability to do this task without GenAI?_), 2) **confidence in GenAI** (i.e., _How confident are you in the ability of GenAI to do this task?_), and 3) **confidence in evaluation** (i.e., _How confident are you, in the course of your normal work, in evaluating the output that AI produces for this task?_). Participants rated each aspect of confidence on a five-point scale ranging from _“not at all confident”_ (1) to _“extremely confident”_ (5).\n\n#### 3.1.2 User factors.\n\nWe hypothesised that participants’ general tendency to reflective thinking and trust in GenAI would affect their baseline critical thinking awareness and practice, and adapted validated instruments from prior work to measure this.\n\n_Tendency to reflect on work_. We use Kember et al. \\[ [65](https://dl.acm.org/dl.acm.org#Bib0065)\\]’s Reflective Thinking Inventory to measure participants’ baseline tendency to think reflectively. Reflective thinking is closely related to critical thinking (Section [2](https://dl.acm.org/dl.acm.org#sec-2)) and the Kember et al. inventory can be interpreted as a proxy for the disposition to think critically \\[ [38](https://dl.acm.org/dl.acm.org#Bib0038)\\].\n\n_Trust in generative AI_. We measure participants’ overall trust in GenAI, which has been shown to correlate with users’ attitudes and adoption of the use of the technologies \\[ [43](https://dl.acm.org/dl.acm.org#Bib0043), [76](https://dl.acm.org/dl.acm.org#Bib0076)\\]. To that end, we adapted the six-item Propensity to Trust Technology scale \\[ [56](https://dl.acm.org/dl.acm.org#Bib0056)\\], replacing the word “technology” with “GenAI”.\n\n_Gender, age, and occupation_. We collect demographic information, including gender, age range and occupation. For occupation, participants self-selected the most appropriate occupation category from the Occupational Information Network (O\\*NET)’s occupational listings [3](https://dl.acm.org/dl.acm.org#fn3). We classify occupations as being **in risk of automation** based on the economic analyses of Ghosh et al. \\[ [42](https://dl.acm.org/dl.acm.org#Bib0042)\\], including the categories of Office and Administrative Support, Sales and Related, Computer and Mathematical, Business and Financial Operations, and Arts, Design, Entertainment, Sports, and Media.\n\n#### 3.1.3 Critical Thinking, Associated Cognitive Activities, and Effort.\n\n_Perceived enaction of critical thinking_. A key dependent variable of **RQ1** — _when_ knowledge workers perceive the enaction to think critically — was answered using a pair of questions, first asking whether participants perceived that they had _performed_ critical thinking for that task (a binary yes/no question), followed by a free text question asking them to justify their response. If participants answered “yes” to the first question, they were asked to elaborate why and how they enacted critical thinking in free text (i.e., _Please share one real-world example when you applied the critical thinking tactic(s) to this task, and explain why you did critical thinking._), as well as the challenges, if any, they faced while doing so (i.e., _When applying this critical thinking tactic during your use of GenAI tool, have you ever encountered any challenges and obstacles?_). If the participants answered “no” to the question, they were asked to elaborate on why they did not think critically for the task, in free text.\n\n_Perceived effort in critical thinking: Bloom’s taxonomy_. As discussed in Section [2](https://dl.acm.org/dl.acm.org#sec-2), we selected Bloom’s taxonomy as the framework to operationalise the measurement of critical thinking activities \\[ [12](https://dl.acm.org/dl.acm.org#Bib0012)\\]. The taxonomy includes six different levels of cognitive activities: Knowledge (i.e., recall), Comprehension (i.e., organising/translating ideas), Application (i.e., problem-solving), Analysis (i.e., breaking down a problem), Synthesis (i.e., putting together ideas), and Evaluation (i.e., evaluating and quality checking). See Table [2](https://dl.acm.org/dl.acm.org#tab2) for more details.\n\n| | |\n| --- | --- |\n| **Cognitive activity** | **Description** |\n| Knowledge | Recognising or remembering facts, terms, basic concepts, or answers |\n| Comprehension | Organising, summarising, translating, generalising, giving descriptions, and stating the main ideas |\n| Application | Using acquired knowledge to solve problems in new situations |\n| Analysis | Examining and breaking information into component parts, determining how the parts relate to one another, identifying motives or causes, making inferences, and finding evidence to support generalisations |\n| Synthesis | Building a structure or pattern from diverse elements; putting parts together to form a whole or bringing pieces of information together to form a new meaning |\n| Evaluation | Presenting and defending opinions by making judgments about information, the validity of ideas, or quality of work based on a set of criteria |\n\nCognitive activities defined in Bloom’s taxonomy \\[ [12](https://dl.acm.org/dl.acm.org#Bib0012)\\].\n\nFor each task example, participants were asked if, and how much, the use of the GenAI tool changed the effort of critical thinking activities compared to when they did not use the AI tool. We used the five-point scale _“much less effort”_, _“less effort”_, _“about the same”_, _“more effort”_, to _“much more effort”_ (which we code as integers ranging between − 2 and + 2). Participants could choose “N/A” if they thought that a cognitive activity was not relevant to the task. Finally, participants were asked to elaborate in free-text why they had marked any critical thinking activities as requiring more or less effort with GenAI.\n\n### 3.2 Study Setup and Recruitment\n\nWe recruited participants through the Prolific platform who self-reported using GenAI tools at work at least once per week. This criterion ensured the study focused on knowledge workers with direct, ongoing experience integrating GenAI tools into their day-to-day work tasks. We received 333 responses but excluded 14 from the analysis due to low response quality (i.e., low-effort free-text responses). For the remaining 319 responses, participants spent an average of 43.19 minutes (STD=23.13) in completing the survey. The 319 participants (159 men, 153 women, 5 non-binary/gender diverse, 2 prefer not to say) came from diverse age groups, occupations, and countries of residence (see Table [3](https://dl.acm.org/dl.acm.org#tab3)). Participants were compensated with GBP £10 for completing the study. Our study protocol was approved by our institution’s ethics and compliance review board. All participants were briefed and signed a consent form.\n\n| | | |\n| --- | --- | --- |\n| **Dimension** | **Sub-dimension** | **Participants** |\n| Gender | Man | 159 (49.84%) |\n| Woman | 153 (47.96%) |\n| Non-binary/gender diverse | 5 (1.57%) |\n| Prefer not to say | 2 (0.63%) |\n| Age | 18-24 | 86 (26.96%) |\n| 25-34 | 143 (44.83%) |\n| 35-44 | 62 (19.44%) |\n| 45-54 | 21 (6.58%) |\n| 55+ | 7 (2.19%) |\n| GenAItool use\\*(top 5) | ChatGPT | 309 (96.87%) |\n| Microsoft Copilot (website) | 74 (23.20%) |\n| Gemini (website) | 69 (21.63%) |\n| Copilot in Microsoft products (e.g., Word) | 60 (18.81%) |\n| Gemini in Google products (e.g., Google Slides) | 49 (15.36%) |\n| Occupation(top 5) | Computer and Mathematical | 59 (18.50%) |\n| Arts, Design, Entertainment, Sports, and Media | 44 (13.79%) |\n| Office and Administrative Support | 38 (11.91%) |\n| Business and Financial Operations | 35 (10.97%) |\n| Educational Instruction and Library | 23 (7.21%) |\n| Countryof residency(top 5) | United Kingdom | 37 (11.60%) |\n| Canada | 25 (7.84%) |\n| United States | 20 (6.27%) |\n| South Africa | 18 (5.64%) |\n| Poland | 17 (5.33%) |\n\nParticipant demographics.\n\n\\*participants selected all the GenAI tools they use at work\n\n### 3.3 Analysis Procedure\n\nIn our survey, participants were asked to share three real examples of their GenAI tool use at work. To increase the variety of examples collected, participants were asked to think of three different examples, one for each task type: Creation, Information, and Advice (see Section [3.1.1](https://dl.acm.org/dl.acm.org#sec-3-1-1)). Then, participants were asked to share an example of each task type in detail. The order of task types was randomised to avoid order and fatigue effects. For each example, as mentioned, we measure participants’ perceived enaction of critical thinking, perceived effort in critical cognitive activities, and perceived confidence. All participants shared three examples. However, they were allowed to skip any task type they did not have experience of and substitute another task type — e.g., a participant could share two examples about Creation and one example about Advice, if they had no experience of an Information task.\n\nAfter participants shared three examples of using GenAI tools, the survey assessed their overall reflective thinking tendency, trust in GenAI, and demographic details such as gender, age group, and occupation.\n\nWe employed quantitative and qualitative analyses, guided by our research questions. Both **RQ1** — when and how do knowledge workers perceive the enaction of critical thinking when using GenAI? — and **RQ2** — when and why do knowledge workers perceive increased/decreased effort for critical thinking due to GenAI? — were answered via both quantitative and qualitative analysis (See Figure [1](https://dl.acm.org/dl.acm.org#fig1) for an overview of our approach).\n\nA diagram representing an analysis pipeline for our survey data. Each survey involves three GenAI tool use examples, and for each example the survey asks about task factors (i.e., task type and confidence), and critical thinking assessment (i.e., perceived enaction of critical thinking, perceived effort in critical thinking, and free-text responses). Each survey also asks about user factors like tendency to reflect on work, trust in GenAI, gender, age, and occupation. The analysis is divided into qualitative and quantitative analysis sections. On the left, the qualitative analysis involves the free-text responses from the critical thinking assessment and focuses on how knowledge workers perceive the enaction and effort for critical thinking to be more or less effortful when using GenAI tools, referencing Sections 4.1, 4.3, and 5.2. On the right, the quantitative analysis involves all the data except for free-text responses, and focuses on when workers perceive the enaction and effort for critical thinking to be more or less effortful when using GenAI tools, referencing Sections 4.2 and 5.1.\n\nSchematic overview of the survey design and our corresponding analysis approach.\n\n#### 3.3.1 Dataset Cleaning and Overview.\n\nOur 319 participants shared a total of 957 real-world examples of their use of GenAI tools at work. We removed 11 examples lacking sufficient detail to analyse (e.g., brief or vague examples like “To build my portfolio.”). We also removed 11 examples for which a participant shared duplicated or non-GenAI tool use examples in their responses.\n\nWe retained 936 examples, including 374 (39.96%) related to Creation, 303 (32.37%) related to Information, and 259 (27.67%) related to Advice. Our participants self-reported to have enacted critical thinking for 555 (59.29%) of the examples they shared, and perceived critical thinking activities, overall, to require less effort when using a GenAI tool compared to when not using one (see _DV distribution_ in Table [4](https://dl.acm.org/dl.acm.org#tab4)).\n\n#### 3.3.2 Quantitative Analysis.\n\nTo model the relationship between task and user factors (independent variables) with (1) a binary measure of users’ perceived enaction of critical thinking and (2) six five-point scales of users’ perceived effort in cognitive activities associated with critical thinking, we respectively fit (1) one random-intercepts logistic regression model and (2) six random-intercepts linear regression models. To account for repeated measures, we include Participant ID as a random intercept term. For all categorical variables, we selected the most common factor level as the baseline reference. To correct for multiple comparisons, we apply the Benjamini–Hochberg procedure \\[ [9](https://dl.acm.org/dl.acm.org#Bib0009)\\] with a total of 98 hypothesised predictors across the seven models, yielding a corrected p-value threshold of 0.007. We adjust the p-values accordingly and report significant effects based on these corrected values.\n\nTable [4](https://dl.acm.org/dl.acm.org#tab4) summarises the seven models and reports the corrected p-values. For interpretability, we computed z-scores to standardise each numeric user factor (i.e., overall tendency to reflect, overall trust in GenAI). Thus, a positive coefficient implies the increase in log odds (in the logistic regression model) or the value (in the linear regression models), for every one standard deviation increase of that factor. A negative coefficient implies the opposite. For confidence scales (i.e., confidence in self, confidence in GenAI, confidence in evaluation), a positive coefficient is the increase in log odds/values for every one-point increase above the base score (1: not at all confident), and a negative coefficient implies the opposite. For categorical and binary factors (i.e., task type, gender, age group, occupation in risk of automation), the coefficient is the predicted difference in log odds/increase of the values for a given factor level relative to a baseline level. Positive coefficients imply increased log odds/values relative to the reference level and vice versa.\n\n#### 3.3.3 Qualitative Analysis.\n\nGuided by our research questions, we open-coded \\[ [23](https://dl.acm.org/dl.acm.org#Bib0023)\\] participants’ free-text responses on i) why they did or did not think critically when using GenAI tool for the task, ii) why they perceived more or less effort to perform critical thinking activities with the GenAI tool. One researcher performed the initial coding on 50 survey responses in discussion with three other researchers to iteratively construct a codebook. Another researcher joined the coding process when the initial codebook was constructed, and was trained with the initial codebook. The two researchers then coded the remaining 269 survey responses. All research team members regularly met and discussed emerging themes during the coding process. Disagreements were negotiated and resolved at each stage, using negotiated agreement best practices \\[ [87](https://dl.acm.org/dl.acm.org#Bib0087)\\]. We report our findings in Sections [4](https://dl.acm.org/dl.acm.org#sec-4) and [5](https://dl.acm.org/dl.acm.org#sec-5), and include the codebook in Appendix Table [5](https://dl.acm.org/dl.acm.org#tab5). We also report on how frequently participants discussed the identified themes.\n\n## 4 Findings for RQ1: _When and how do knowledge workers perceive the enaction of critical thinking when using GenAI?_\n\nTo answer RQ1, we investigated how knowledge workers define critical thinking (Section [4.1](https://dl.acm.org/dl.acm.org#sec-4-1)), and when (Section [4.2](https://dl.acm.org/dl.acm.org#sec-4-2)) and why (Section [4.3](https://dl.acm.org/dl.acm.org#sec-4-3)) they enact critical thinking in their use of GenAI tools. Qualitatively, we found that knowledge workers view critical thinking as ensuring the objectives and quality of their work. Through our quantitative analysis of _when_ knowledge workers do critical thinking, we found their confidence in themselves doing and evaluating the task, and their general tendency to reflect on work strongly correlated with their perceived enaction of critical thinking. We also found a negative correlation between the perceived enaction of critical thinking and their confidence in AI doing the task. Finally, we qualitatively analysed participants’ free-text responses to understand why they do or do not enact critical thinking, identifying three key motivators (work quality, potential negative outcomes, skill development) and three inhibitors (awareness, motivation, ability) for critical thinking.\n\n### 4.1 How knowledge workers enact critical thinking\n\nWe first explored knowledge workers’ definition and perceived enaction of critical thinking by examining the activities they describe as performing critical thinking. While our participants worked across diverse occupations, the common denominator was that they viewed critical thinking in their GenAI tool use as cognitive activities performed to ensure the quality of AI responses, and intentionality while using the tools.\n\nWe mapped our findings to each phase of knowledge workers’ GenAI tool workflow. We classified knowledge workers’ critical thinking practices into 1) goal and query formation, 2) inspect response, and 3) integrate response. Our analysis is based primarily on workflow characterisations from previous work \\[ [29](https://dl.acm.org/dl.acm.org#Bib0029), [46](https://dl.acm.org/dl.acm.org#Bib0046), [130](https://dl.acm.org/dl.acm.org#Bib0130)\\], though more general frameworks for human cognitive problem solving \\[ [137](https://dl.acm.org/dl.acm.org#Bib0137)\\] and problem solving with AI \\[ [60](https://dl.acm.org/dl.acm.org#Bib0060), [89](https://dl.acm.org/dl.acm.org#Bib0089), [108](https://dl.acm.org/dl.acm.org#Bib0108)\\] are also related.\n\n#### 4.1.1 Goal and query formation.\n\nDuring goal and query formation, participants enact critical thinking through prompt optimisation to produce the responses they desire. They also enact critical thinking by “taking a step back” to consolidate their goals and queries to the tools. These phenomena correspond to the goal and query formulation phases in the _iterative goal satisfaction_ framework proposed by Drosos et al. \\[ [29](https://dl.acm.org/dl.acm.org#Bib0029)\\].\n\n_Form goal (6/319)_. Before engaging with a tool, knowledge workers reflect on their goals, needs and intents, and identify a need for assistance where the GenAI tool could be applied. For example, when P140 tried to learn the functionality of a code snippet through ChatGPT, he saw critical thinking as the need to _“analyze what my goal was and how I was going to achieve it... I had to first learn what was I going to use in order to make progress.”_ Similarly, participants defined critical thinking as setting clear goals in mind before using GenAI tools to generate images (e.g., P14) and ideas for a report (e.g., P2).\n\nFormation of intentions applies to other computational tools and is not unique to GenAI. However, as emphasised in the generative AI metacognitive framework proposed by Tankelevitch et al. \\[ [130](https://dl.acm.org/dl.acm.org#Bib0130)\\], critical thinking in the form of goal setting is particularly relevant due to its direct connection with the process of “forming queries” — users must first establish clear goals to effectively generate queries for the tool.\n\n_Form query (30/319)_. Some knowledge workers enacted critical thinking by creating or revising prompts to GenAI tools to get the desired response. With a goal in mind, knowledge workers create queries that further clarify the final deliverables for the tool. For example, when P97 tried to create an art piece for her website, _“\\[I\\] was reflective when it came to giving the correct prompts, in order to get the correct result a correct description needs to be given.”_\n\nThe process of iterating on a prompt may help clarify knowledge workers’ goals and provide an opportunity for enacting critical thinking. For instance, when a teacher (P19) generated an image with DALL-E for her presentation about hand washing at school: _“I noticed it was missing soap dispensers. So I changed my prompt to include them and tried again... By thinking about what the image really needed to show, I got a much better result from the AI for my presentation.”_\n\n#### 4.1.2 Inspect response.\n\nPrior work has identified the work of understanding and evaluating GenAI output as a key aspect of working with GenAI \\[ [29](https://dl.acm.org/dl.acm.org#Bib0029), [46](https://dl.acm.org/dl.acm.org#Bib0046), [114](https://dl.acm.org/dl.acm.org#Bib0114), [130](https://dl.acm.org/dl.acm.org#Bib0130)\\]. Participants also enacted critical thinking by assessing if a GenAI output meets certain criteria and standards, or if the information it contains is verified or verifiable. They applied multiple types of quality criteria and verification approaches.\n\n_Ensure quality through objective criteria (125/319)_. When applicable, knowledge workers evaluate the GenAI output with objective criteria (which we define as those that are straightforward to articulate and apply [4](https://dl.acm.org/dl.acm.org#fn4)), such as if the output complies with their queries, or if the generated artefact is functional (e.g., generated code compiles without errors). For example, when P278 prepared a specification document for her client with ChatGPT, _“I had to make sure each piece of text generated met the requirements of the client based on criteria \\[in the prompt\\] like colour palette, and people in photos - male/female, skin tone, etc.”_ Similarly, when asking for a content summary, knowledge workers ensure the response is _“properly taking all info into account”_ (P177) and check _“whether the AI added irrelevant content and if it changed up my main point of the letter”_ (P144). Artefacts such as program code can be tested for quality using other software tools such as compilers, or runtime environments such as browsers. For example, P308 asked Claude to write code for her web application, and had _“to make sure it runs without error and then observed how it functioned.”_\n\n_Ensure quality through subjective standards (77/319)_. Knowledge workers also evaluate GenAI output through response-specific subjective quality standards, some of which reflect what Paul and Elder \\[ [103](https://dl.acm.org/dl.acm.org#Bib0103)\\] refer to as “intellectual standards” in thinking. Some participants evaluated the real-world **feasibility** of any suggestions. For example, when P297 looked into her social service work for people with mental health disorders and learning disabilities, she had to _“really think about whether the answer the GenAI tool gave me would be easily transferrable to real life situations in social care... not every company has the budget and necessary equipment to provide this most of the times.”_ Others evaluated the internal **logic** of the AI response. For instance, when a forex and commodities trader (P10) used ChatGPT to _“generate recommendations for new resources and strategies to explore to hone my trading skills, I evaluated whether the stated ideas flowed logically.”_ Participants also evaluated the **relevance** of the AI response, to see how well it matches _“with my presentation on Kaizen methods on performance management”_ (P188) or whether it is appropriately _“in a manner that address the needs of the target job role and attract attention of the recruiter”_ (P123).\n\n_Verify information by assessing referenced sources (23/319)_. Participants were generally aware of the issues of hallucination in GenAI, and manually **verify sources** that are directly referenced in GenAI output to ensure they are real and reputable. This is especially true when users request high stakes information, such as advice for medical symptoms (e.g., P5), or the references need to be verifiable for the task to progress, e.g., in P213’s job search: _“I was looking for a full-stack role and there was no such role at the company \\[websites\\] the GenAI listed”_.\n\n_Verify information by cross-referencing external sources (114/319)_. More commonly, knowledge workers cross-referenced information in the GenAI output against reputable, external sources, to validate it. For tasks within their domain knowledge, our participants relied on their **own knowledge** to identify biases and limitations of the AI response, as noted by P133: _“the AI may suggest repertoire \\[for the concert I direct\\], but it sometimes is very American-centric. I often have to use my judgment to come up with a repertoire that fits my reality.”_ For responses involving technical and professional details, participants cross-referenced **technical or formal documentations** such as official manuals, guidelines, and reports to verify the reliability of the responses. For example, a nurse (P250) verified a ChatGPT-generated educational pamphlet for newly diagnosed diabetic patients by cross-checking with the diabetes management guidelines from her hospital. Similarly, participants verified AI responses with a more general **web search** for information accessible from online forums (e.g., Quora, YouTube, Wikipedia) and other websites. While less common, participants also shared other external sources for cross-referencing, such as responses of other GenAI tools, other task-specialised tools (e.g., language translation), and consulting human domain experts.\n\n#### 4.1.3 Integrate response.\n\nPrior work has suggested GenAI requires knowledge workers to perform “critical integration” \\[ [114](https://dl.acm.org/dl.acm.org#Bib0114)\\]: the work of editing and incorporating GenAI output into a broader workflow. Qualitatively, we observe that participants integrate GenAI output to their tasks in two distinct ways: they focus either on the _content_ — selecting and manipulating a part of the output for use — or _form_ — modifying style, wording, tone, etc.\n\n_Integrate partial response (36/319)_. GenAI excels at generating large amounts of information that appear relevant, and not all of it is useful. Participants viewed the process of selectively incorporating the relevant parts of GenAI output into their tasks as critical thinking. For example, when P188 used ChatGPT to help her summarise her past work as an auditor for her resume: _“some of the information provided did not particularly relate to my role and even to the country I was working in. So rather than copying over everything, I had to critically evaluate what would apply, the regulations mentioned - do they apply to the country I work in.”_\n\n_Modify style to be appropriate for the task (45/319)_. Finally, participants reflected not only on _what_ to incorporate from the response, but also _how_ to incorporate it. They might add a “personal touch”, or adjust the tone to align the response with their intended style. For example, when P210 used ChatGPT to revise his paper abstract, he had to rephrase the output with a scientific tone because _“often the AI writes awful stuff like “our groundbreaking and fundamental analysis shows...” that sounds too emphatic and does not fit the scientific style.”_ Participants also attempted to make the GenAI output read less “AI-generated” and more personal, as P254 noted: _“I did make sure it \\[email composed by ChatGPT\\] read properly and made sense and did sound like an email that I had composed myself and that a colleague would send.”_\n\n### 4.2 When knowledge workers perceive the enaction of critical thinking\n\n| | | | | | | | |\n| --- | --- | --- | --- | --- | --- | --- | --- |\n| Perceived Enaction of Critical Thinking (N=930) | Knowledge (N=782) | Comprehension (N=849) | Application (N=768) | Analysis (N=753) | Synthesis (N=825) | Evaluation (N=764) |\n| DV distribution Binary: True/False 5-Likert: -2/-1/0/1/2 | 551/ 379 | 236/326/191/19/10 | 333/335/139/30/12 | 227/305/201/23/12 | 219/320/184/16/14 | 267/359/156/30/13 | 177/246/221/84/36 |\n| (Pseudo) r square/conditional r square | 0.43 | 0.33 | 0.32 | 0.37 | 0.43 | 0.38 | 0.44 |\n| _**Task Factors**_ |\n| Task type: _Creation_ | 0 r | 0 r | 0 r | 0 r | 0 r | 0 r | 0 r |\n| Task type: _Advice_ | 0.12( _p_ = 0.829) | 0.04( _p_ = 0.816) | 0.00( _p_ = 0.994) | 0.06( _p_ = 0.713) | -0.03( _p_ = 0.865) | -0.04( _p_ = 0.839) | -0.18( _p_ = 0.127) |\n| Task type: _Information_ | 0.32( _p_ = 0.364) | -0.13( _p_ = 0.223) | -0.03( _p_ = 0.865) | 0.08( _p_ = 0.474) | -0.14( _p_ = 0.127) | 0.01( _p_ = 0.967) | 0.14( _p_ = 0.248) |\n| Confidence in self | **0.26\\***( _p_ = 0.026) | 0.02( _p_ = 0.713) | 0.02( _p_ = 0.779) | **0.08\\*** ( _p_ = 0.029) | 0.07( _p_ = 0.121) | 0.01( _p_ = 0.965) | **0.10\\*** ( _p_ = 0.027) |\n| Confidence in AI | **-0.69\\*\\*\\***( _p_ < 0.001) | **-0.11\\*** ( _p_ = 0.029) | **-0.13\\*** ( _p_ = 0.014) | -0.09( _p_ = 0.128) | **-0.15\\*\\*** ( _p_ = 0.003) | **-0.12\\*** ( _p_ = 0.026) | **-0.23\\*\\*\\*** ( _p_ < 0.001) |\n| Confidence in evaluation | **0.31\\*** ( _p_ = 0.046) | 0.00( _p_ = 0.994) | 0.00( _p_ = 0.97) | -0.06( _p_ = 0.364) | 0.10( _p_ = 0.06) | -0.03( _p_ = 0.795) | -0.01( _p_ = 0.967) |\n| _**User Factors**_ |\n| Gender: _Man_ | 0 r | 0 r | 0 r | 0 r | 0 r | 0 r | 0 r |\n| Gender: _Woman_ | 0.33( _p_ = 0.38) | 0.03( _p_ = 0.865) | -0.03( _p_ = 0.865) | -0.02( _p_ = 0.967) | -0.15( _p_ = 0.248) | -0.14( _p_ = 0.29) | -0.21( _p_ = 0.127) |\n| Gender: _Non-binary_ | 1.11( _p_ = 0.517) | 0.26( _p_ = 0.713) | 0.03( _p_ = 0.967) | 0.14( _p_ = 0.865) | -0.51( _p_ = 0.338) | -0.25( _p_ = 0.718) | -0.45( _p_ = 0.495) |\n| Age group: _25-34_ | 0 r | 0 r | 0 r | 0 r | 0 r | 0 r | 0 r |\n| Age group: _18-24_ | 0.14( _p_ = 0.849) | 0.08( _p_ = 0.713) | 0.06( _p_ = 0.783) | 0.04( _p_ = 0.865) | 0.01( _p_ = 0.967) | 0.06( _p_ = 0.795) | -0.01( _p_ = 0.967) |\n| Age group: _35-44_ | 0.31( _p_ = 0.59) | 0.00( _p_ = 0.994) | -0.11( _p_ = 0.589) | -0.01( _p_ = 0.967) | -0.06( _p_ = 0.841) | -0.02( _p_ = 0.967) | -0.05( _p_ = 0.865) |\n| Age group: _45-54_ | -0.28( _p_ = 0.804) | 0.18( _p_ = 0.529) | 0.24( _p_ = 0.378) | 0.25( _p_ = 0.38) | 0.23( _p_ = 0.451) | 0.17( _p_ = 0.589) | 0.24( _p_ = 0.474) |\n| Age group: _55+_ | -0.96( _p_ = 0.474) | -0.11( _p_ = 0.865) | 0.04( _p_ = 0.967) | -0.23( _p_ = 0.713) | -0.25( _p_ = 0.713) | 0.04( _p_ = 0.967) | -0.57( _p_ = 0.29) |\n| Occupation’s riskof automation: _Low_ | 0 r | 0 r | 0 r | 0 r | 0 r | 0 r | 0 r |\n| Occupation’s riskof automation: _High_ | 0.17( _p_ = 0.74) | 0.04( _p_ = 0.829) | 0.10( _p_ = 0.451) | 0.15( _p_ = 0.248) | 0.03( _p_ = 0.865) | 0.19( _p_ = 0.116) | 0.16( _p_ = 0.29) |\n| Tendency to reflect | **0.52\\*\\*\\*** ( _p_ < 0.001) | -0.01( _p_ = 0.967) | 0.06( _p_ = 0.378) | 0.05( _p_ = 0.511) | 0.01( _p_ = 0.967) | 0.06( _p_ = 0.392) | 0.05( _p_ = 0.59) |\n| Trust in GenAI | -0.01( _p_ = 0.967) | **-0.12\\*** ( _p_ = 0.029) | -0.08( _p_ = 0.223) | **-0.17\\*\\*** ( _p_ = 0.002) | **-0.12\\*** ( _p_ = 0.046) | -0.05( _p_ = 0.499) | **-0.24\\*\\*\\*** ( _p_ < 0.001) |\n\nNon-standardised coefficients of the mixed-effects regressions modeling knowledge workers’ perceived enaction of critical thinking and perceived effort in cognitive activities when using generative AI tools.\n\nSignificance: \\*p<.05; \\*\\*p<.01; \\*\\*\\*p<.001; r: reference\n\nOver 936 GenAI tool use examples, participants self-reported having enacted some critical thinking activity (see Section [4.1](https://dl.acm.org/dl.acm.org#sec-4-1)) for approximately 60% (555 out of 936) of them. Both knowledge workers’ task confidence and their tendency to reflect on work are associated with _when_ they perceive the enaction of critical thinking during GenAI tool use (see _Perceived Enaction of Critical Thinking_ in Table [4](https://dl.acm.org/dl.acm.org#tab4)). We discuss key findings for each type of factor, in turn.\n\n#### 4.2.1 Task Factors.\n\nWhile prior work suggests that knowledge workers employ task-dependent strategies for GenAI tool use \\[ [13](https://dl.acm.org/dl.acm.org#Bib0013)\\], we did not find a main effect on perceived critical thinking for task type (Creation, Advice, Information). Instead, users’ perceptions of confidence — in themselves and in AI doing the task — significantly correlated with their perceived enaction of critical thinking. In line with recent projections that more accessible GenAI tools may exacerbate the risks of technology over-reliance \\[ [29](https://dl.acm.org/dl.acm.org#Bib0029), [102](https://dl.acm.org/dl.acm.org#Bib0102), [130](https://dl.acm.org/dl.acm.org#Bib0130)\\], our results provide empirical evidence that knowledge workers’ confidence in AI doing the tasks indeed _negatively_ correlates with their enaction of critical thinking ( _β_ =-0.69, _p_ < 0.001). Nevertheless, we also found that knowledge workers’ confidence in doing the task themselves ( _β_ =0.26, _p_ = 0.026) and evaluating AI responses ( _β_ =0.31, _p_ = 0.046) both _positively_ correlate with their enaction of critical thinking. These findings suggest that a reflective approach toward the use of GenAI tools, which can lead to what prior work refers to as “pathways to non-reliance on AI” \\[ [20](https://dl.acm.org/dl.acm.org#Bib0020)\\], is more likely to occur when knowledge workers have more confidence in doing the task without AI, or in evaluating AI responses. Our qualitative analysis (see Section [4.3](https://dl.acm.org/dl.acm.org#sec-4-3)) finds that participants enacted critical thinking when trying to improve the quality and mitigate the negative consequences of AI responses.\n\n#### 4.2.2 User Factors.\n\nWe also found that knowledge workers’ overall tendency to reflect on their work had a positive effect on perceived enaction of critical thinking ( _β_ =0.52, _p_ < 0.001). This suggests that knowledge workers who already engage in critical thinking in their work are likely to continue doing so even when using GenAI tools. However, in contrast to knowledge workers’ confidence in AI doing the task at hand (i.e., _Confidence in AI_, above), which negatively correlated with their perceived enaction of critical thinking, we did not find a significant correlation between knowledge workers’ _overall trust in GenAI_ and their perceived enaction of critical thinking. A possible explanation is that users’ reliance and confidence on AI, as well as their perceived enaction of critical thinking, might vary across tasks; accordingly, the variance that would have been explained by the general user-level factor may already be well captured by the task-level confidence factors.\n\n### 4.3 Motivators and inhibitors for the perceived enaction of critical thinking\n\nWe analysed participants’ free-text responses about why they engaged in or prioritised critical thinking (or did not do so) when using GenAI tools for work. We found that enaction of critical thinking was motivated by improvement in work quality, avoidance of negative outcomes, and skill development. We found many inhibitors for the enaction of critical thinking related to awareness (e.g., reliance on AI), motivation (e.g., lack of time), and ability (e.g., barriers to improving GenAI output).\n\n#### 4.3.1 Critical thinking motivators.\n\n_Work quality (74/319)_. As shown in Section [4.1](https://dl.acm.org/dl.acm.org#sec-4-1), participants’ critical thinking actions were often performed to improve the quality of the work artefact being produced. A key motivator for critical thinking is to think of ways to improve AI responses. Participants shared several examples of when the AI response fell short of their standards, and motivated critical revision. For instance, when P92 generated content with ChatGPT for his company website: _“the output is way too cookie cutter, full of cliché \\[text\\] and boring. I have to edit it a lot to get something out of it that I could ever give to my bosses.”_ GenAI output can be too shallow and generic for participants’ tasks, motivating them to think critically about the depth and specificity of the work. As P133 noted when using ChatGPT to write an executive summary: _“the AI does not understand the niche type of work I do. I have to adapt the output to fit my needs.”_\n\n_Potential negative outcomes (116/319)_. Participants shared that their critical thinking was driven by the potential negative outcomes of their use of GenAI. They wished to avoid harm to their work, such as program code that produces wrong outcomes (e.g., P210), outdated information (e.g., P240), or faulty mathematical formulas (P155). This is especially the case when GenAI is applied in high-stakes scenarios and workplaces. For example, P267 used ChatGPT to help her write the pharmacist continuing professional development (CPD) documents, _“the entry is to be submitted for review so I would to double check to be sure otherwise I might have to face suspension.”_\n\nSocial conflict was another undesirable outcome that motivated critical thinking about GenAI output. For example, P101 reported to a younger supervisor with a different ethnic background. Thus, when preparing work presentations and emails with ChatGPT, he must _“always consider that hierarchy, age, respect for even Chinese festivals, \\[which\\] are culturally really important for them.”_\n\n_Skill development (13/319)_. Finally, knowledge workers are incentivised to improve skills and learn best practices for their work, even when assisted by GenAI tools. Participants were motivated to enact critical thinking about GenAI output as a means to learn about the task and not simply rely on AI in the long run. For example, when P154 asks ChatGPT for solutions to the issue in a code snippet, _“I make sure that I understood how it works and can do it by myself next time.”_ Likewise, P176 used ChatGPT to improve an important email draft to sound more professional, and he decided to _“read and break down all the suggested corrections to improve my email writing style”_. This helped improve his writing style, and his later emails _“required less correction.”_\n\n#### 4.3.2 Critical thinking inhibitors.\n\nIn this section, we organised the findings by highlighting the three types of critical thinking barriers introduced by the use of GenAI tools — i.e., awareness, motivation, and ability.\n\n_Awareness barriers_. Potential downstream harms of GenAI responses can motivate critical thinking (see Section [4.3.1](https://dl.acm.org/dl.acm.org#sec-4-3-1)), but only if the user is consciously aware of such harms. Our analysis finds, however, that GenAI tools create obstacles for knowledge workers to be aware of the need for critical thinking, especially when the tasks are perceived to be less important, and when users trust and rely on GenAI tools.\n\nSome participants shared examples in which they thought critical thinking was unnecessary because their **use of GenAI tool is secondary** (14/319) to their goals. P147 used _“Dall-E for indirect purposes (visual reference), \\[so\\] there’s no need to over-correct what the AI outputs.”_ Likewise, participants do not enact critical thinking when the **task is perceived to be trivial and insignificant** (55/319), such as writing social media posts (P239) and meeting minutes summary (P271).\n\nComplementing our quantitative findings, knowledge workers’ **trust and reliance on GenAI** (83/319) doing the task can discourage them from critically reflecting on their use of the tools. Users often adopt a mental model that assumes AI is competent for simple tasks. This was influenced by users’ prior experience with GenAI tools, where the AI had proven trustworthy for specific tasks, as P289 noted: _“With straightforward factual information, ChatGPT usually gives good answers.”_ For instance, P275 remarked: _“It’s a simple task \\[make a passage professional\\] and I knew ChatGPT could do it without difficulty, so I just never thought about it, as critical thinking didn’t feel relevant.”_ This mental model, however, can lead to overestimating AI capabilities. Some users, like P185, believed the information provided by GenAI tools was always truthful and of high quality, while others (e.g., P143, P236) assumed the outputs would consistently and accurately reflect referenced data sources. Complementary to the perception of AI as being competent and capable, some participants expressed self-doubt in their ability to perform tasks independently, such as verifying grammar in text (P101) or composing legal letters (P204). This self-doubt led them to accept GenAI outputs by default — a phenomenon corroborated by prior studies \\[ [117](https://dl.acm.org/dl.acm.org#Bib0117)\\].\n\nOverreliance on computing technology is not a novel phenomenon; however, GenAI tools can exacerbate the associated risks. Indeed, such reliance may be tolerable for low-stakes tasks, like grammar checking, but it can lead to significant negative outcomes in high-stakes contexts, like drafting legal documents (e.g., \\[ [118](https://dl.acm.org/dl.acm.org#Bib0118)\\]). While critical thinking may not be necessary for low-stakes tasks, it is risky for users to only apply critical thinking in high-stakes situations. Without regular practice in common and/or low-stakes scenarios, cognitive abilities can deteriorate over time \\[ [5](https://dl.acm.org/dl.acm.org#Bib0005)\\], and thus create risks if high-stakes scenarios are the only opportunities available for exercising such abilities. This phenomenon is well-documented, as in Bainbridge’s “Ironies of Automation” \\[ [7](https://dl.acm.org/dl.acm.org#Bib0007)\\], and has been recently revisited in the context of GenAI by Simkute et al. \\[ [122](https://dl.acm.org/dl.acm.org#Bib0122)\\] as the “Ironies of Generative AI”.\n\n_Motivation barriers_. Knowledge workers also discussed how prioritising critical thinking in their work might be misaligned with their overall task motivations or job objectives. For example, participants discussed a **lack of time** (44/319) for critical thinking at work. For instance, a sales development representative (P295) noted that _“\\[t\\]he reason I use AI is because in sales, I must reach a certain quota daily or risk losing my job. Ergo, I use AI to save time and don’t have much room to ponder over the result.”_ Even when time was not constrained, knowledge workers often lacked incentives to engage in critical thinking when it is perceived as **not part of their job responsibilities** (11/319). P232, who used ChatGPT to write the company’s marketing campaigns: _“verification and rewriting is handled by another part of the team. The team is able to verify, sense check and modify the content of the landing pages as they see fit.”_\n\n_Ability barriers_. Participants face obstacles to enacting critical thinking, specifically in verifying and improving GenAI output, even if they are otherwise motivated to do so. Participants report **barriers to inspect AI responses** (58/319), such as not possessing enough domain knowledge. As P290 noted: _“in cases where you don’t know the specific topic \\[e.g., translation and math problems\\], it’s hard to determine whether the AI is giving the correct answer or not.”_\n\nEven if knowledge workers identify limitations in the GenAI output, they encounter **barriers in revising queries and improving the response** (72/319). For example, P239 received negative feedback from colleagues for a document that ChatGPT helped her write, but _“I’m not sure how I could have improved the text that ChatGPT wrote.”_ Also, GenAI tools can be “stubborn” and do not follow through with users’ revised prompts, as P208 shared when asking GenAI to fix an error in his code: _“it repeatedly recommended the wrong solution despite asking for a different suggestion.”_\n\n## 5 Findings for RQ2: _When and why do knowledge workers perceive increased/decreased effort for critical thinking due to GenAI?_\n\nTo answer **RQ2**, we report a descriptive analysis of participants’ perceived effort in cognitive activities associated with critical thinking, as defined by Bloom’s taxonomy (Section [5.1](https://dl.acm.org/dl.acm.org#sec-5-1)) — i.e., recall (Knowledge), organising/translating ideas (Comprehension), problem solving (Application), breaking down a problem (Analysis), putting together ideas (Synthesis), and evaluating and quality checking (Evaluation). We complement this with an analysis of participants’ free text elaborations on why they perceived an increase or decrease in effort due to GenAI, observing three qualitative shifts in critical thinking effort (Section [5.2](https://dl.acm.org/dl.acm.org#sec-5-2)).\n\nA perceived reduction in effort when using GenAI may be due to participants 1) enacting the same “amount” of critical thinking but feeling supported by GenAI, 2) offloading the work of critical thinking to GenAI, 3) enacting “less” critical thinking overall, or 4) conflating reduction in cognitive effort in general, with reduction in critical thinking effort specifically. We address each of these interpretations in context.\n\n### 5.1 When knowledge workers perceive increased/decreased effort for critical thinking due to GenAI\n\nIn the majority of examples, knowledge workers perceive decreased effort for cognitive activities associated with critical thinking when using GenAI compared to not using one — examples that were reported as “much less effort” or “less effort” comprise 72% in Knowledge, 79% in Comprehension, 69% in Application, 72% in Analysis, 76% in Synthesis, and 55% in Evaluation dataset (See Figure [2](https://dl.acm.org/dl.acm.org#fig2)). Moreover, knowledge workers tend to perceive that GenAI reduces the effort for cognitive activities associated with critical thinking when they have **greater confidence in AI doing the tasks** and possess **higher overall trust in GenAI** (see Table [4](https://dl.acm.org/dl.acm.org#tab4)).\n\nA stacked bar chart showing the distribution of perceived effort in cognitive activities when using a GenAI tool compared to not using one. The y-axis represents the count normalized as a percentage; the x-axis lists cognitive activities defined in Bloom’s taxonomy: Knowledge, Comprehension, Application, Analysis, Synthesis, and Evaluation. The bars are segmented into five categories: Much less effort (dark blue), Less effort (light blue), About the same (gray), More effort (yellow), and Much more effort (orange). The majority of responses for each category are concentrated around \"Much less effort\" and \"Less effort\" combined (Knowledge: 72%, Comprehension: 78%, Application: 70%, Analysis: 71%, Synthesis: 76%, Evaluation: 55%), with small proportions for \"More effort\" and \"Much more effort\" combined (Knowledge: 3%, Comprehension: 5%, Application: 5%, Analysis: 4%, Synthesis: 6%, Evaluation: 16%).\n\nDistribution of perceived effort (%) in cognitive activities (based on Bloom’s taxonomy) when using a GenAI tool compared to not using one.\n\n#### 5.1.1 Task Factors.\n\nWe found that knowledge workers’ _confidence in AI_ doing the tasks _negatively_ correlated with perceived effort for five of the six cognitive activities (all except Application). The higher the participant’s _confidence in AI_, the greater is their perceived reduction in effort for Knowledge ( _β_ =-0.11, _p_ = 0.029), Comprehension ( _β_ =-0.13, _p_ = 0.014), Analysis ( _β_ =-0.15, _p_ = 0.003), Synthesis ( _β_ =-0.12, _p_ = 0.026), and Evaluation ( _β_ =-0.23, _p_ < 0.001). Moreover, knowledge workers’ _confidence in themselves_ doing the task correlates positively with perceived effort in Application ( _β_ =0.08, _p_ = 0.029) and Evaluation (( _β_ =0.10, _p_ = 0.027). We qualitatively analyse participant rationales in the next section in more detail, but one explanation for why knowledge workers’ confidence in AI and in themselves had the opposite effects on perceived effort in these cognitive activities is the following. GenAI tools can decrease knowledge workers’ cognitive load by automating a significant portion of their tasks, but as knowledge workers have more confidence in doing the task themselves, they employ more engaged practices in steering AI responses, especially when applying (Application) and evaluating (Evaluation) AI responses.\n\nThese findings, along with our quantitative findings for **RQ1**, reveal a connection between knowledge workers’ self-confidence and confidence in AI and their perceived critical thinking during GenAI tool use: 1) **a higher confidence in GenAI is associated with less critical thinking even though it is perceived as less effort to do so**, and 2) **a higher self-confidence is associated with more critical thinking even though it is perceived as more effort to do so**. We discuss this in more detail in Section [6.1.1](https://dl.acm.org/dl.acm.org#sec-6-1-1).\n\n#### 5.1.2 User Factors.\n\nIn contrast to our findings about knowledge workers’ perceived enaction of critical thinking (see Section [4.2](https://dl.acm.org/dl.acm.org#sec-4-2)), we found no significant correlation between their overall tendency to reflect and perceived effort of critical thinking for any cognitive activities. This suggests that knowledge workers who do (or do not) tend to reflect on their work do not necessarily perceive a higher or lower effort of critical thinking with GenAI. However, knowledge workers’ _overall trust in GenAI_ was negatively correlated with perceived effort for four of the six cognitive activities — i.e., higher trust in the technology is associated with less perceived effort for Knowledge ( _β_ =-0.12, _p_ = 0.029), Application ( _β_ =-0.17, _p_ = 0.002), Analysis ( _β_ =-0.12, _p_ = 0.046), and Evaluation ( _β_ =-0.24, _p_ < 0.001). Thus, knowledge workers with higher levels of trust in GenAI — generally or for specific tasks — perceive engaging in critical thinking activities to be less effortful. A possible explanation, supplemented with our qualitative analysis in RQ1 (see Section [4.3.2](https://dl.acm.org/dl.acm.org#sec-4-3-2)), is that trust and reliance on GenAI inhibit the enaction of critical thinking, i.e., users underinvest in critical thinking when using GenAI.\n\n### 5.2 Why knowledge workers perceive increased/decreased effort for critical thinking due to GenAI\n\nTo understand _why_ participants perceived an increase or decrease in the effort of critical thinking due to GenAI, we analysed the free-text responses in which they were asked to elaborate, mapping the responses onto the six cognitive activities.\n\nWe found that GenAI tools shift the effort of critical thinking in three distinct ways: for Knowledge and Comprehension, the effort shifts from information gathering to information verification; for Application, effort shifts from problem-solving to AI response integration; and for Analysis, Synthesis, and Evaluation, effort shifts from task execution to task stewardship.\n\n#### 5.2.1 Knowledge & Comprehension: From information gathering to information verification.\n\nEfforts invested in Knowledge (e.g., retrieving relevant information) and Comprehension (understanding that information) often go hand in hand when using GenAI tools. In general, participants perceived less effort in retrieving and curating task-relevant information, because GenAI automates the process. However, they perceived more effort in verifying the information in the AI response.\n\nParticipants perceived less effort to **fetch task-specific information at scale, and in real-time** (111/319). For instance, P232 shared that her market research results through ChatGPT _“are immediate and at a sufficient level of detail for me to get to grips with the basics of the industries. I would otherwise have to read a lot of press reports and subscribe to multiple newsletters.”_\n\nGenAI tools are perceived to **organise and present information in a readable format** (87/319). For example, P86 compared his experience in searching in a web browser with that in ChatGPT: _“ Research using Google is time-consuming; even clicking on a couple of websites takes more time than asking a single question to an LLM. Also, the LLM produces organized answers... the tools and techniques were categorized by type, and a dotted list was produced for each.”_ Participants find it less effort to re-structure and summarise information in GenAI tools. E.g., P137 tried to update protocol documents to comply with a new standard: _“ I did not have to check the templates one by one... Questions I had related to the procedures were answered by the GenAI, and it helped me to know better this new standard.”_\n\nHowever, many participants shared examples when they perceived more effort in information retrieval because the **AI response can be wrong and needs verification** (56/319). For example, when a lawyer (P147) used ChatGPT to find relevant laws for a legal case, he noticed _“AI tends to make up information to agree with whatever points you are trying to make, so it takes valuable time to manually verify.”_\n\n#### 5.2.2 Application: From problem-solving to response integration.\n\nGenAI can contextually apply knowledge to users’ specific questions and examples, reducing perceived effort for Application overall. However, users must instead spend effort integrating GenAI output, in form and content (as mentioned in Section [4.1.3](https://dl.acm.org/dl.acm.org#sec-4-1-3)).\n\nParticipants perceived less effort in problem-solving and question answering because GenAI tools **provide personalised solutions to their problems** (77/319). For example, P154 compared his experience in reviewing code with and without ChatGPT: _“trying to understand how something works or understanding the problem is the main challenge. People have to “google” a lot. Find the correct information and then try to find people facing similar problems. That takes a lot of effort. GPT simply answers those very fast and easily and mostly correctly.”_\n\nWith in-context learning, GenAI can also **apply users’ examples to new context** (9/319). For example, participants used GenAI tools to generate text, guided with examples: _“company has a set out list of possible scenarios and how we can address them, all I have to do is feed it to the AI, and it would generate a set response based on the data given”_ (P268).\n\nDespite the ability for contextual tailoring, participants still reported an increased effort in having to **apply the responses** (19/319) to their tasks and to meet specific needs. For example, when P51 wrote a promotional blog post for their product launch, _“the AI-generated content required substantial editing to align with specific marketing guidelines and tone preferences. This editing process could be time-consuming, particularly when ensuring that technical details were accurate and comprehensible to our target audience.”_ Additional application effort is incurred when knowledge workers integrate AI-generated content with content from other sources, or misjudge the extent to which GenAI output will be contextualised to their scenario. As P36 noted _“the extra effort in determining that the code generated matched my existing code, and making subsequent alterations to make it fit was more effort than just doing it myself in the end.”_\n\n#### 5.2.3 Analysis, Synthesis, and Evaluation: From task execution to task stewardship.\n\nParticipants perceived these activities, overall, to require less effort due to GenAI tools. Specifically, GenAI helps knowledge workers scaffold complicated tasks and information; it helps knowledge workers automate artefact creation; and it helps form feedback cycles that knowledge workers otherwise do not have access to. Nevertheless, knowledge workers perceived increased effort spent on AI stewardship — translating intentions into queries, steering AI responses, and assessing if the AI response meets their quality standards for work, while retaining accountability for the work.\n\n_Analysis_. Participants reported reduced effort when GenAI tools helped to **scaffold complicated tasks and information** (48/319). For instance, P203 used ChatGPT to write a complex Slack message to an unfamiliar colleague, and _“GenAI broke down the problem.”_ This helped her think Analytically, to derive criteria such as to _“make sure the message structure is to the point and understandable to someone who doesn’t have the same background knowledge”_ as well as _“ensure that I am not missing elements or being confusing with examples.”_\n\nHowever, GenAI tools also require users to **articulate their needs and translate intentions into a query** (45/319), which was perceived to increase Analysis effort. As mentioned in Section [4.1.1](https://dl.acm.org/dl.acm.org#sec-4-1-1), revising queries is a critical thinking activity specific to GenAI use. P24 described several phases of image generation prompting, saying _“Image generation requires more effort for everything except the actual image generation. I have to think of what I want to be drawn, then on how the AI wants it described, then correct it when it makes wacky outputs.”_\n\n_Synthesis_. Participants perceived less effort when GenAI **automates the creation process** (129/319), such as drafting documents, responding to emails, or generating code.\n\nHowever, participants noted that the reduced effort in Synthesis could lead to less critical engagement with the task. For instance, P131, when generating advising campaigns for her business, remarked having _“to read what ChatGPT generates and make sure that it’s what I want, but not to \\[let it\\] think the whole idea.”_ Moreover, participants perceived it to be more effort to constantly **steer AI responses** (48/319), which incurs additional Synthetic thinking effort due to the cost of developing explicit steering prompts. For example, P110 tried to use Copilot to learn a subject more deeply, but realised: _“its answers are prone to several \\[diversions\\] along the way. I need to constantly make sure the AI is following along the correct ‘thought process’, as inconsistencies evolve and amplify as I keep interacting with the AI.”_\n\n_Evaluation_. Finally, critical thinking is perceived to be less effort because GenAI tools **provide personalised feedback loops for tasks** (40/319) that users otherwise do not have access to. For example, to edit text P313 said he previously _“would often go through multiple rounds of checks by others \\[humans\\] for feedback”_, but with GenAI could do so _“on my own time”_ by asking the _“AI to do alternate versions, and compare what I like and don’t”_.\n\nIn certain cases where GenAI is perceived to have a strength relative to the user’s own capability (e.g., in spelling or grammar in a non-native language), **GenAI responses are perceived to make few mistakes** (19/319). Thus, participants perceived a reduced effort needed for Evaluation, as P239 noted: _“I can be confident that everything is spelt correctly, I don’t need to second guess myself... I can get the reassurance I need without having to bother another person to check it for me.”_\n\nThose cases notwithstanding, as noted in Section [4.1.2](https://dl.acm.org/dl.acm.org#sec-4-1-2), participants needed to **evaluate AI-generated content** (42/319) through several objective and subjective criteria, and reported increased effort in doing so.\n\n## 6 Discussion\n\n### 6.1 Implications for Designing GenAI Tools That Support Critical Thinking\n\n#### 6.1.1 Self-Confidence and Task Confidence.\n\nTask confidence appears to significantly influence knowledge workers’ perceived enaction of critical thinking and the effort they invest in it. Specifically, a user’s confidence in GenAI is predictive of the extent to which critical thinking is exercised in GenAI-assisted tasks. Both our quantitative and qualitative results suggest that higher confidence in GenAI is associated with less critical thinking, as GenAI tools appear to reduce the perceived effort required for critical thinking tasks among knowledge workers. Conversely, with the important caveat that users’ self-confidence is a subjective measure of their knowledge, experiences, and abilities on the tasks \\[ [20](https://dl.acm.org/dl.acm.org#Bib0020), [59](https://dl.acm.org/dl.acm.org#Bib0059), [85](https://dl.acm.org/dl.acm.org#Bib0085)\\], higher self-confidence is associated with more critical thinking, even though workers who are confident in their own skills tend to perceive greater effort in these tasks, particularly when evaluating and applying AI responses.\n\nOur analysis does not establish causation. However, based on our evidence, it is possible that fostering workers’ domain expertise and associated self-confidence may result in improved critical thinking when using GenAI. Task confidence significantly influences how users engage with AI tools, particularly in the context of human-AI “collaboration” (notwithstanding objections to that term \\[ [113](https://dl.acm.org/dl.acm.org#Bib0113)\\]). Previous frameworks have categorised human-AI collaborations by how often the user or the AI initiates an action \\[ [95](https://dl.acm.org/dl.acm.org#Bib0095)\\], and which entity takes on a “supervisory” role \\[ [88](https://dl.acm.org/dl.acm.org#Bib0088)\\]. Our findings shed light on this issue in the context of GenAI-assisted knowledge work. High task confidence is associated with users’ ability to delegate tasks effectively, fostering better stewardship while maintaining accountability. Conversely, lower self-confidence may lead users to rely more on AI, potentially diminishing their critical engagement and independent problem-solving skills. This reliance on AI can be seen as a form of cognitive offloading \\[ [8](https://dl.acm.org/dl.acm.org#Bib0008)\\], where users depend on AI to perform tasks they feel less confident in handling themselves.\n\nConfidence in AI is associated with reduced critical thinking effort, while self-confidence is associated with increased critical thinking effort. This duality indicates that design strategies should focus on balancing these aspects. The aims are both to improve the quality of AI-assisted tasks and also to empower users to develop their skills and maintain a balanced “relationship” with AI. To address task confidence recalibration, AI tools could incorporate feedback mechanisms that help users gauge the reliability of AI outputs, when to trust the AI and when to apply their critical thinking skills. This aligns with the goals of explainable AI \\[ [33](https://dl.acm.org/dl.acm.org#Bib0033)\\]. Moreover, the user should remain responsible and accountable for the outcome. AI tools must support users in actively and critically customising and refining AI-generated content. Tools may incorporate explicit controls for users to regulate the extent of AI assistance, depending on their confidence levels and the task’s complexity.\n\n#### 6.1.2 Awareness, Motivation, and Execution of Critical Thinking.\n\nOur study identifies key motivators for and inhibitors of critical thinking among knowledge workers using GenAI. The design implications are clear: critical thinking interventions for GenAI tools should aim to enhance and leverage motivators while mitigating and avoiding inhibitors.\n\nOne design approach is to enhance _awareness_ of critical thinking opportunities. Our findings indicate that knowledge workers tend to forgo critical thinking for tasks perceived as unimportant or secondary, while engaging in it when aiming to improve task quality or avoid negative outcomes. This suggests a need for both proactive and reactive critical thinking interventions. Proactive systems take the initiative \\[ [52](https://dl.acm.org/dl.acm.org#Bib0052)\\] to interrupt the user to highlight the need and opportunity for critical thinking in situations where it is likely to be overlooked; a reactive approach would allow the user to explicitly request critical thinking assistance when it is consciously needed.\n\nAnother approach is to increase the _motivation_ to think critically. Our study reveals that knowledge workers often neglect critical thinking when they perceive it as outside their job scope, but engage in it when aiming to improve their professional skills. Thus, critical thinking interventions for GenAI tools could be positioned as contributing to long-term skill development and professional growth, as opposed to an extraneous “co-auditing” \\[ [46](https://dl.acm.org/dl.acm.org#Bib0046)\\] task that is only relevant on a task-by-task basis.\n\nFinally, design could aim to enhance the _ability_ to execute critical thinking. We find that knowledge workers often refrain from critical thinking when they lack the skills to inspect, improve, and guide AI-generated responses. GenAI tools could incorporate features that facilitate user learning, such as providing explanations of AI reasoning, suggesting areas for user refinement, or offering guided critiques. The tool could help develop specific critical thinking skills, such as analysing arguments \\[ [72](https://dl.acm.org/dl.acm.org#Bib0072)\\], or cross-referencing facts against authoritative sources. This would align with the motivation-enhancing approach of positioning AI as a partner in skill development.\n\n### 6.2 Shifts in Critical Thinking Due to Generative AI\n\nCritical thinking in knowledge work involves a range of cognitive activities, such as analysis, synthesis, and evaluation. We observed that the use of GenAI tools shifts the knowledge workers’ perceived critical thinking effort in three ways. Specifically, for recall and comprehension, the focus shifts from information gathering to information verification. For application, the emphasis shifts from problem-solving to AI response integration. Lastly, for analysis, synthesis, and evaluation, effort shifts from task execution to task stewardship.\n\nThe use of GenAI in knowledge work creates new cognitive tasks for knowledge workers. The task of response integration is a prime example. Knowledge workers must assess AI-generated content to determine its relevance and applicability to their specific tasks, often modifying the style and tone to align with the intended purpose and audience.\n\nConversely, some cognitive tasks become less necessary due to GenAI. For instance, information gathering has been significantly reduced. GenAI tools automate the process of fetching and curating task-relevant information, making it less effortful for knowledge workers. As a result, the cognitive load associated with searching for and compiling information has decreased.\n\nSome cognitive tasks remain, but have evolved in their nature due to GenAI. One such is information verification; cross-referencing AI-generated outputs with external sources and their own expertise to ensure accuracy and reliability. Workers have always needed to verify the information they work with, but as a tool, GenAI has its own particular strengths and failure modes when it comes to correctness, accuracy, and bias.\n\nWith GenAI, knowledge workers also shift from task execution to oversight, requiring them to guide and monitor AI to produce high-quality outputs — a role we describe as “stewardship”. It is not that execution has disappeared altogether, nor is having high-level oversight on a task an entirely new cognitive role, but there is a shift from the former to the latter. Unlike in human-human collaboration, in a human-AI “collaboration”, the responsibility and accountability for the work still resides with the human user despite the labour of material production being delegated to the GenAI tool, which makes stewardship strike us as a more appropriate metaphor for what the human user is doing, than teammate, collaborator, or supervisor.\n\nIn light of these changes, training knowledge workers to think critically when working with GenAI should focus on developing skills in information verification, response integration, and task stewardship. Training programs should emphasise the importance of cross-referencing AI outputs, assessing the relevance and applicability of AI-generated content, and continuously refining and guiding AI processes. Additionally, a focus on maintaining foundational skills in information gathering and problem-solving would help workers avoid becoming overreliant on AI \\[ [102](https://dl.acm.org/dl.acm.org#Bib0102)\\].\n\n### 6.3 Limitations\n\nOur study has limitations that warrant consideration and offer avenues for future research. Firstly, we observed that participants occasionally conflated reduced effort in _using_ GenAI with reduced effort in _critical thinking_ with GenAI. This misconception may stem from the infrequent contemplation of critical thinking in their daily tasks (regardless of whether they use GenAI), potentially leading to inaccurate self-reporting. This conflation often occurred when participants were satisfied with AI-generated responses, suggesting that when AI produces expected outcomes, users may engage in less critical evaluation. Future studies could employ alternative measures of critical thinking, such as think-aloud protocols or task-based assessments, to better differentiate between effort reduction and critical thinking processes.\n\nSecondly, we assess users’ subjective task confidence following prior work on AI-assisted decision-making \\[ [20](https://dl.acm.org/dl.acm.org#Bib0020), [59](https://dl.acm.org/dl.acm.org#Bib0059), [85](https://dl.acm.org/dl.acm.org#Bib0085)\\]. Still, one’s subjective self-confidence may not always be well-calibrated with respect to objective expertise on tasks \\[ [39](https://dl.acm.org/dl.acm.org#Bib0039), [130](https://dl.acm.org/dl.acm.org#Bib0130)\\]. Future work should explore this subjective/objective distinction in the context of critical thinking with GenAI in knowledge work.\n\nThirdly, our survey was conducted exclusively in English, with participants required to be fluent English speakers. This approach ensured consistency in data collection and feasibility of analysis by our English-speaking research team, but has no representation of non-English speaking populations or multilingual contexts. Future research could explore cross-linguistic and cross-cultural perspectives on GenAI usage and critical thinking.\n\nFourthly, our sample was biased towards younger, more technologically skilled participants who regularly use GenAI tools at work at least once per week. This demographic skew may not fully represent the broader population of knowledge workers, potentially overlooking the experiences and perceptions of older or less tech-oriented professionals.\n\nLastly, GenAI tools are constantly evolving, and the ways in which knowledge workers interact with these technologies are likely to change over time. We adopted the task taxonomy due to Brachman et al. \\[ [13](https://dl.acm.org/dl.acm.org#Bib0013)\\] to capture relatively stable and coarse-grained characteristics of tasks without overcomplicating our explanatory models. Future work on different goals can expand our measures with more detailed categorisation and/or task-specific measurements (e.g., task difficulty and skill). To that end, our study provides a valuable baseline for understanding critical thinking in the context of current GenAI tools. In future work, longitudinal studies tracking changes in AI usage patterns and their impact on critical thinking processes would be beneficial. Additionally, developers of GenAI tools can deploy telemetry, within-tool surveys, or experience sampling to their users, to gain more insight into how specific tools can evolve to better support critical thinking in different tasks.\n\n## 7 Conclusion\n\nWe surveyed 319 knowledge workers who use GenAI tools (e.g., ChatGPT, Copilot) at work at least once per week, to model how they enact critical thinking when using GenAI tools, and how GenAI affects their perceived effort of thinking critically. Analysing 936 real-world GenAI tool use examples our participants shared, we find that knowledge workers engage in critical thinking primarily to ensure the quality of their work, e.g. by verifying outputs against external sources. Moreover, while GenAI can improve worker efficiency, it can inhibit critical engagement with work and can potentially lead to long-term overreliance on the tool and diminished skill for independent problem-solving. Higher confidence in GenAI’s ability to perform a task is related to less critical thinking effort. When using GenAI tools, the effort invested in critical thinking shifts from information gathering to information verification; from problem-solving to AI response integration; and from task execution to task stewardship. Knowledge workers face new challenges in critical thinking as they incorporate GenAI into their knowledge workflows. To that end, our work suggests that GenAI tools need to be designed to support knowledge workers’ critical thinking by addressing their awareness, motivation, and ability barriers.\n\n## Acknowledgments\n\nWe thank members of the Tools for Thought group at Microsoft Research ( [https://aka.ms/toolsforthought](https://aka.ms/toolsforthought)) and the Calc Intelligence group at Microsoft Research ( [https://aka.ms/calcintel](https://aka.ms/calcintel)) for their guidance and discussions throughout our study. We thank our participants for their time, and our reviewers for their helpful feedback.\n\n## A Appendix\n\n### A.1 Survey Questions\n\n#### A.1.1 Task Questions.\n\n1.\n\nPlease share one more specific real-world example of the way you used GenAI tool while doing work. Please tell us: 1) what you were trying to achieve, 2) in what GenAI tool, and 3) how you used the GenAI tool, including any prompts (it may help to look at your GenAI tool chat history, or if you cannot recall the exact prompts you used, please include a rough equivalent). \\[Free response\\]\n\n2.\n\nFor the specific example you share, what best describes this task?\n\n(a)\n\nGenerate something (e.g., text, Python code, or image) to be used directly.\n\n(b)\n\nGenerate something (e.g., text, Python code, or image) to be used with some modification.\n\n(c)\n\nGenerate an idea to be used indirectly (e.g., use a chatbot to generate product ideas to help you think, but you won’t use the text in a document).\n\n(d)\n\nSeek a fact or piece of information (e.g., find specific instructions for a tool, or search my document for relevant passages).\n\n(e)\n\nLearn about a new topic more broadly (e.g., how can I get a job as a software engineer).\n\n(f)\n\nGenerate a shorter version of a piece of content that describes the important elements (e.g., summarise text from external websites).\n\n(g)\n\nDiscover a new insight about information or data (e.g., analyse a spreadsheet or CSV file for business insights).\n\n(h)\n\nGenerate a better version (e.g., re-write text that was too long or complex).\n\n(i)\n\nGet guidance about how to make a decision (e.g., try to figure out the ideal amount of time a project should take).\n\n(j)\n\nCheck whether an artefact satisfies a set of rules, constraints, quality checks, or formatting requirements (e.g., document checking to ensure all required elements are included).\n\n(k)\n\nOther: \\[Free response\\]\n\n3.\n\nDid GenAI make your work easier or harder? When you used a GenAI tool for this task, did you have to put in more effort or less effort for the following activities you may have performed during the task, compared to when you did not use GenAI? (1: Much less effort; 5: Much more effort; N/A: this activity is not relevant to the task):\n\n(a)\n\nRecall: Recognizing or remembering facts, terms, basic concepts, or answers\n\n(b)\n\nOrganising/translating ideas: Organizing, summarising, translating, generalising, giving descriptions, and stating the main ideas\n\n(c)\n\nProblem solving: Using acquired knowledge to solve problems in new situations\n\n(d)\n\nBreaking down a problem: Examining and breaking information into component parts, determining how the parts relate to one another, identifying motives or causes, making inferences, and finding evidence to support generalisations\n\n(e)\n\nPutting together ideas: Building a structure or pattern from diverse elements; putting parts together to form a whole or bringing pieces of information together to form a new meaning\n\n(f)\n\nEvaluating and quality checking: Presenting and defending opinions by making judgments about information, the validity of ideas, or quality of work based on a set of criteria\n\n4.\n\nIf you selected “more effort” or “much more effort” for any of the activities above, please explain why those activities require more effort with GenAI, compared to when you did not use GenAI. \\[Free response\\]\n\n5.\n\nIf you selected “less effort” or “much less effort” for any of the activities above, please explain why those activities require less effort with GenAI, compared to when you did not use GenAI. \\[Free response\\]\n\n6.\n\nHave you ever done any reflective/critical thinking (e.g., reflect on your use and the outputs you got from LLM tools) when doing this task with GenAI tool? \\[Yes/No\\]\n\n7.\n\n_(If selected Yes in Q6)_\n\n(a)\n\nWhat type of reflective/critical thinking tactic(s) did you do to for this task in GenAI? (select all that apply)\n\n(i)\n\nReflecting on facts or basic concepts, and cross-check AI output with other sources. (Example: After the AI generates a summary of a historical event, you verify the dates and key figures by looking them up on trusted websites or in textbooks.)\n\n(ii)\n\nReflecting on organisation, summarization, and generalisation. Consider whether the AI output is well structured and formatted, whether it is too long/short, etc. (Example: You receive a report from the AI and check if the sections are clearly divided, headings are properly used, and the summary accurately reflects the main points without missing any critical information.)\n\n(iii)\n\nReflecting on how knowledge is applied, such as considering whether AI correctly understood and applied any high-level concepts in your work, and reflecting on your own application of knowledge. (Example: When the AI writes a technical explanation, you review it to ensure that it correctly applies industry-specific terminology and concepts, such as proper use of scientific methods or legal principles.)\n\n(iv)\n\nReflecting on individual elements and their relationship. Thinking about whether the AI output flows logically, whether different claims are coherent with each other, etc. (Example: The AI creates a persuasive essay, and you evaluate whether each argument builds logically on the previous one and whether there are any contradictions or gaps in the reasoning.)\n\n(v)\n\nReflecting on how ideas are combined to form new meaning. (Example: The AI proposes a new business strategy by combining market analysis, customer feedback, and competitor data. You assess whether these elements are integrated in a way that offers a novel and feasible approach.)\n\n(vi)\n\nReflecting on the quality of the work, such as making sure the work meets objective standards and expectations in your workplace, and also deciding what quality standards matter and when to apply them.(Example: You review an AI-generated project proposal to ensure it meets your company’s standards for clarity, thoroughness, and professionalism, and aligns with the objectives of the task.)\n\n(vii)\n\nOther: \\[Free response\\]\n\n(b)\n\nPlease share one real-world example when you applied the critical thinking tactic(s) to this task, and explain why you did critical thinking. \\[Free response\\]\n\n(c)\n\nWhen applying this critical thinking tactic during your use of GenAI tool, have you ever encountered any challenges and obstacles? \\[Free response\\]\n\n(d)\n\nHow did you learn to apply critical/reflective thinking when using GenAI? (select all that apply)\n\n(i)\n\nInformally, at school or university (e.g., learnt from peers, or picked it up over time)\n\n(ii)\n\nThrough formal training at school or university (e.g., took a course)\n\n(iii)\n\nInformally, at my workplace (e.g., learnt from colleagues, or picked it up over time)\n\n(iv)\n\nThrough formal training after school or university (e.g., took a professional development seminar)\n\n(v)\n\nOther: \\[Free response\\]\n\n8.\n\n_(If selected No in Q6)_\n\n(a)\n\nWhat prevented you from applying critical thinking strategies when doing this task with GenAI? (select all that apply)\n\n(i)\n\nNot enough time in my schedule\n\n(ii)\n\nNot prioritised by management\n\n(iii)\n\nNot sure how to verify information\n\n(iv)\n\nNot sure how to improve AI suggestions quality\n\n(v)\n\nIt didn’t occur to me\n\n(vi)\n\nThe task doesn’t require critical thinking\n\n(vii)\n\nOther: \\[Free response\\]\n\n(b)\n\nPlease tell us why you chose the answer(s) above: \\[Free response\\]\n\n9.\n\nWhy do you use GenAI for this task? (select all that apply)\n\n(a)\n\nIt helps me save time\n\n(b)\n\nIt helps me do the work better\n\n(c)\n\nIt helps me make progress when I am stuck\n\n(d)\n\nIt helps me be more creative and get more ideas\n\n(e)\n\nIt helps me do things that I don’t have the expertise to do myself\n\n(f)\n\nOther reason: \\[Free response\\]\n\n10.\n\nWould you like GenAI to automate this task entirely? \\[Yes/No\\]\n\n11.\n\nYour confidence in doing the task with and without GenAI (1: Not at all confident; 5: Extremely confident):\n\n(a)\n\nHow confident are you in your ability to do this task without GenAI?\n\n(b)\n\nHow confident are you in the ability of GenAI to do this task?\n\n(c)\n\nHow confident are you, in the course of your normal work (e.g., accounting for time and resource demands of your task), in evaluating the output that AI produces for this task?\n\n#### A.1.2 User Questions.\n\n1.\n\nWhat GenAI tools do you use in your work? (check all that apply)\n\n(a)\n\nChatGPT\n\n(b)\n\nGemini website\n\n(c)\n\nGemini in Google products such as Gmail, Google Slides\n\n(d)\n\nCopilot website (formally known as Bing Chat)\n\n(e)\n\nMicrosoft 365 Copilot (embedded with Office apps such as Word)\n\n(f)\n\nClaude.ai\n\n(g)\n\nDeepAI AI Chat\n\n(h)\n\nPi.ai\n\n(i)\n\nPerplexity.ai\n\n(j)\n\nDall-E\n\n(k)\n\nStable Diffusion\n\n(l)\n\nMidjourney\n\n(m)\n\nOther: \\[Free response\\]\n\n2.\n\nWhat is your age range?\n\n(a)\n\n18-24\n\n(b)\n\n25-34\n\n(c)\n\n35-44\n\n(d)\n\n45-54\n\n(e)\n\n55 or over\n\n(f)\n\nPrefer not to say\n\n3.\n\nWhat is your gender identity?\n\n(a)\n\nMan\n\n(b)\n\nWoman\n\n(c)\n\nNon-binary/gender diverse\n\n(d)\n\nPrefer not to say\n\n4.\n\nWhat is currently your primary country of residence? \\[Free response\\]\n\n5.\n\nWhat is your job title? \\[Free response\\]\n\n6.\n\nWhich of these best describes your work?\n\n(a)\n\nMilitary\n\n(b)\n\nTransportation and Material Moving\n\n(c)\n\nProduction\n\n(d)\n\nInstallation, Maintenance, and Repair\n\n(e)\n\nConstruction and Extraction\n\n(f)\n\nFarming, Fishing, and Forestry\n\n(g)\n\nOffice and Administrative Support\n\n(h)\n\nSales and Related\n\n(i)\n\nPersonal Care and Service\n\n(j)\n\nBuilding and Grounds Cleaning and Maintenance\n\n(k)\n\nFood Preparation and Serving Related\n\n(l)\n\nProtective Service\n\n(m)\n\nHealthcare Support\n\n(n)\n\nHealthcare Practitioners and Technical\n\n(o)\n\nArts, Design, Entertainment, Sports, and Media\n\n(p)\n\nEducational Instruction and Library\n\n(q)\n\nLegal\n\n(r)\n\nCommunity and Social Service\n\n(s)\n\nLife, Physical, and Social Science\n\n(t)\n\nArchitecture and Engineering\n\n(u)\n\nComputer and Mathematical\n\n(v)\n\nBusiness and Financial Operations\n\n(w)\n\nManagement\n\n(x)\n\nOther: \\[Free response\\]\n\n7.\n\nTo what extent do you agree with the following statements, regarding your daily work? (1: Strongly disagree; 5: Strongly agree)\n\n(a)\n\nI sometimes question the way others (e.g., your colleagues) do something and try to think of a better way.\n\n(b)\n\nI like to think over what I have been doing and consider alternative ways of doing it.\n\n(c)\n\nI often reflect on my actions to see whether I could have improved on what I did.\n\n(d)\n\nI often re-appraise my experience so I can learn from it and improve for my next performance.\n\n8.\n\nFor the below listed items, please read each statement carefully. Using the 5-point scale ranging from 1 (Strongly disagree) to 5 (Strongly agree), select the answer that most accurately describes your feelings.\n\n(a)\n\nGenerally, I trust GenAI.\n\n(b)\n\nGenAI helps me solve many problems.\n\n(c)\n\nI think it’s a good idea to rely on GenAI for help.\n\n(d)\n\nI don’t trust the information I get from GenAI.\n\n(e)\n\nGenAI is reliable.\n\n(f)\n\nI rely on GenAI.\n\n| | |\n| --- | --- |\n| **RQ1: How do knowledge workers perceive the enaction of critical thinking when using GenAI?** |\n| **Goal and query formation** | **Critical thinking motivators** |\n| Form goal | Work quality |\n| Form query | Potential negative outcomes |\n| Skill development |\n| **Inspect response** |\n| Ensure quality through objective criteria | **Critical thinking inhibitors** |\n| Ensure quality through subjective standards | Awareness barriers |\n| Verify information by assessing referenced sources | _\\- use of GenAI tool is secondary_ |\n| Verify information by cross-referencing external sources | _\\- task is perceived to be trivial and insignificant_ |\n| _\\- trust and reliance on GenAI_ |\n| **Integrate response** | Motivation barriers |\n| Integrate partial response | _\\- lack of time_ |\n| Modify style to be appropriate for the task | _\\- not part of their job responsibilities_ |\n| Ability barriers |\n| _\\- barriers to inspect AI responses_ |\n| _\\- barriers in revising queries and improving the response_ |\n| **RQ2: Why do knowledge workers perceive increased/decreased effort for critical thinking due to GenAI?** |\n| **Knowledge & Comprehension** | **Analysis, Synthesis, and Evaluation** |\n| Fetch task-specific information at scale, in real-time | Scaffold complicated tasks and information |\n| Organise and present information in a readable format | Automate the creation process |\n| AI response can be wrong and needs verification | Provide personalised feedback loops for tasks |\n| GenAI responses are perceived to make few mistakes and easy to review |\n| **Application** | Users need to articulate the need and translate intentions into a query |\n| Provide personalised solutions to their problems | Users need to steer AI responses |\n| Apply users’ examples to new context | Users need to evaluate AI-generated content |\n| Users need to apply the responses to their tasks |\n\nCodebook for the qualitative analysis.\n\n## Footnotes\n\n1\n\nWhile there is no broad consensus on how to define this now-common term, for clarity we adopt this definition, a rationale for which is given in \\[ [115](https://dl.acm.org/dl.acm.org#Bib0115)\\].\n\n2\n\n[https://prolific.co/](https://prolific.co/)\n\n3\n\nA list of 23 occupation categories listed as “Major Group” in [https://www.onetcenter.org/taxonomy/2019/structure.html](https://www.onetcenter.org/taxonomy/2019/structure.html)\n\n4\n\nWe acknowledge that this is a necessary oversimplification, and there are degrees of subjectivity in every criterion.\n\n## Supplemental Material\n\nVTT File - pn7679-talk-video-caption.vtt\n\npresentation\n\n- [Download](https://dl.acm.org/doi/suppl/10.1145/3706598.3713778/suppl_file/pn7679-talk-video-caption.vtt)\n- 11.88 KB\n\nMP4 File - pn7679-talk-video.mp4\n\npresentation\n\n- [Download](https://dl.acm.org/doi/suppl/10.1145/3706598.3713778/suppl_file/pn7679-talk-video.mp4)\n- 176.81 MB\n\n## References\n\n\\[1\\]\n\nMuhammad Abbas, Farooq Ahmed Jam, and Tariq Iqbal Khan. 2024. Is it harmful or helpful? Examining the causes and consequences of generative AI usage among university students. _International Journal of Educational Technology in Higher Education_ 21, 1 (2024), 10.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Is+it+harmful+or+helpful%3F+Examining+the+causes+and+consequences+of+generative+AI+usage+among+university+students&author=Muhammad+Abbas&author=Farooq%C2%A0Ahmed+Jam&author=Tariq%C2%A0Iqbal+Khan&publication_year=2024&pages=10)\n\n\\[2\\]\n\nSophie Abel, Kirsty Kitto, Simon Knight, and Simon Buckingham Shum. 2018. Designing personalised, automated feedback to develop students’ research writing skills. In _ASCILITE 2018 Conference Proceedings_. University of Technology Sydney.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Designing+personalised%2C+automated+feedback+to+develop+students%E2%80%99+research+writing+skills&author=Sophie+Abel&author=Kirsty+Kitto&author=Simon+Knight&author=Simon%C2%A0Buckingham+Shum&publication_year=2018)\n\n\\[3\\]\n\nSatu Alaoutinen and Kari Smolander. 2010. Student self-assessment in a programming course using bloom’s revised taxonomy. In _Proceedings of the fifteenth annual conference on Innovation and technology in computer science education_. ACM, Bilkent Ankara Turkey, 155–159.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/1822090.1822135)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Student+self-assessment+in+a+programming+course+using+bloom%E2%80%99s+revised+taxonomy&author=Satu+Alaoutinen&author=Kari+Smolander&publication_year=2010&pages=155-159&doi=10.1145%2F1822090.1822135)\n\n\\[4\\]\n\nRiku Arakawa and Hiromu Yakura. 2024. Coaching Copilot: Blended Form of an LLM-Powered Chatbot and a Human Coach to Effectively Support Self-Reflection for Leadership Growth. In _Proceedings of the 6th ACM Conference on Conversational User Interfaces_ (Luxembourg, Luxembourg) ( _CUI ’24_). Association for Computing Machinery, New York, NY, USA, Article 2, 14 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3640794.3665549)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Coaching+Copilot%3A+Blended+Form+of+an+LLM-Powered+Chatbot+and+a+Human+Coach+to+Effectively+Support+Self-Reflection+for+Leadership+Growth&author=Riku+Arakawa&author=Hiromu+Yakura&publication_year=2024&doi=10.1145%2F3640794.3665549)\n\n\\[5\\]\n\nWinfred Arthur Jr, Winston Bennett Jr, Pamela L Stanush, and Theresa L McNelly. 1998. Factors that influence skill decay and retention: A quantitative review and analysis. _Human performance_ 11, 1 (1998), 57–101.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Factors+that+influence+skill+decay+and+retention%3A+A+quantitative+review+and+analysis&author=Winfred+Arthur%C2%A0Jr&author=Winston+Bennett%C2%A0Jr&author=Pamela%C2%A0L+Stanush&author=Theresa%C2%A0L+McNelly&publication_year=1998&pages=57-101)\n\n\\[6\\]\n\nFlorian M Artinger, Gerd Gigerenzer, and Perke Jacobs. 2022. Satisficing: Integrating two traditions. _Journal of Economic Literature_ 60, 2 (2022), 598–635.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Satisficing%3A+Integrating+two+traditions&author=Florian%C2%A0M+Artinger&author=Gerd+Gigerenzer&author=Perke+Jacobs&publication_year=2022&pages=598-635)\n\n\\[7\\]\n\nLisanne Bainbridge. 1983. Ironies of automation. In _Analysis, design and evaluation of man–machine systems_. Elsevier, 129–135.\n\n[Crossref](https://doi.org/10.1016/B978-0-08-029348-6.50026-9)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Ironies+of+automation&author=Lisanne+Bainbridge&publication_year=1983&pages=129-135&doi=10.1016%2FB978-0-08-029348-6.50026-9)\n\n\\[8\\]\n\nNathaniel Barr, Gordon Pennycook, Jennifer A Stolz, and Jonathan A Fugelsang. 2015. The brain in your pocket: Evidence that Smartphones are used to supplant thinking. _Computers in Human Behavior_ 48 (2015), 473–480.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+brain+in+your+pocket%3A+Evidence+that+Smartphones+are+used+to+supplant+thinking&author=Nathaniel+Barr&author=Gordon+Pennycook&author=Jennifer%C2%A0A+Stolz&author=Jonathan%C2%A0A+Fugelsang&publication_year=2015&pages=473-480)\n\n\\[9\\]\n\nYoav Benjamini and Yosef Hochberg. 1995. Controlling the false discovery rate: a practical and powerful approach to multiple testing. _Journal of the Royal statistical society: series B (Methodological)_ 57, 1 (1995), 289–300.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Controlling+the+false+discovery+rate%3A+a+practical+and+powerful+approach+to+multiple+testing&author=Yoav+Benjamini&author=Yosef+Hochberg&publication_year=1995&pages=289-300)\n\n\\[10\\]\n\nJeffrey R Binder and Rutvik H Desai. 2011. The neurobiology of semantic memory. _Trends in cognitive sciences_ 15, 11 (2011), 527–536.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+neurobiology+of+semantic+memory&author=Jeffrey%C2%A0R+Binder&author=Rutvik%C2%A0H+Desai&publication_year=2011&pages=527-536)\n\n\\[11\\]\n\nJeffrey R Binder, Rutvik H Desai, William W Graves, and Lisa L Conant. 2009. Where is the semantic system? A critical review and meta-analysis of 120 functional neuroimaging studies. _Cerebral cortex_ 19, 12 (2009), 2767–2796.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Where+is+the+semantic+system%3F+A+critical+review+and+meta-analysis+of+120+functional+neuroimaging+studies&author=Jeffrey%C2%A0R+Binder&author=Rutvik%C2%A0H+Desai&author=William%C2%A0W+Graves&author=Lisa%C2%A0L+Conant&publication_year=2009&pages=2767-2796)\n\n\\[12\\]\n\nBenjamin S Bloom, Max D Engelhart, Edward J Furst, Walquer H Hill, David R Krathwohl, et al. 1956. _Taxonomy of educational objetives: the classification of educational goals: handbook I: cognitive domain_. Technical Report. New York, US: D. Mckay.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Taxonomy+of+educational+objetives%3A+the+classification+of+educational+goals%3A+handbook+I%3A+cognitive+domain&author=Benjamin%C2%A0S+Bloom&author=Max%C2%A0D+Engelhart&author=Edward%C2%A0J+Furst&author=Walquer%C2%A0H+Hill&author=David%C2%A0R+Krathwohl&publication_year=1956)\n\n\\[13\\]\n\nMichelle Brachman, Amina El-Ashry, Casey Dugan, and Werner Geyer. 2024. How Knowledge Workers Use and Want to Use LLMs in an Enterprise Context. In _Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems_( _CHI EA ’24_). Association for Computing Machinery, New York, NY, USA, 1–8.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613905.3650841)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=How+Knowledge+Workers+Use+and+Want+to+Use+LLMs+in+an+Enterprise+Context&author=Michelle+Brachman&author=Amina+El-Ashry&author=Casey+Dugan&author=Werner+Geyer&publication_year=2024&pages=1-8&doi=10.1145%2F3613905.3650841)\n\n\\[14\\]\n\nArthur Brookes and Peter Grundy. 1990. _Writing for Study Purposes: A Teacher’s Guide to Developing Individual Writing Skills_. Cambridge University Press, 40 West 20th St.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Writing+for+Study+Purposes%3A+A+Teacher%E2%80%99s+Guide+to+Developing+Individual+Writing+Skills&author=Arthur+Brookes&author=Peter+Grundy&publication_year=1990)\n\n\\[15\\]\n\nAnn L Brown and Jeanne D Day. 1983. Macrorules for summarizing texts: The development of expertise. _Journal of verbal learning and verbal behavior_ 22, 1 (1983), 1–14.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Macrorules+for+summarizing+texts%3A+The+development+of+expertise&author=Ann%C2%A0L+Brown&author=Jeanne%C2%A0D+Day&publication_year=1983&pages=1-14)\n\n\\[16\\]\n\nAnn L Brown, Jeanne D Day, and Roberta S Jones. 1983. The development of plans for summarizing texts. _Child development_ (1983), 968–979.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+development+of+plans+for+summarizing+texts&author=Ann%C2%A0L+Brown&author=Jeanne%C2%A0D+Day&author=Roberta%C2%A0S+Jones&publication_year=1983&pages=968-979)\n\n\\[17\\]\n\nZana Buçinca, Maja Barbara Malaya, and Krzysztof Z. Gajos. 2021. To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decision-making. _Proc. ACM Hum.-Comput. Interact._ 5, CSCW1, Article 188 (apr 2021), 21 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3449287)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=To+Trust+or+to+Think%3A+Cognitive+Forcing+Functions+Can+Reduce+Overreliance+on+AI+in+AI-assisted+Decision-making&author=Zana+Bu%C3%A7inca&author=Maja%C2%A0Barbara+Malaya&author=Krzysztof%C2%A0Z.+Gajos&publication_year=2021&doi=10.1145%2F3449287)\n\n\\[18\\]\n\nOğuz \"Oz\" Buruk. 2023. Academic Writing with GPT-3.5: Reflections on Practices, Efficacy and Transparency. _arXiv preprint arXiv: [https://arXiv.org/abs/2304.11079](https://arXiv.org/abs/2304.11079)_ (2023).\n\n[Crossref](https://doi.org/10.48550/arXiv.2304.11079)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Academic+Writing+with+GPT-3.5%3A+Reflections+on+Practices%2C+Efficacy+and+Transparency&author=O%C4%9Fuz%C2%A0%22Oz%22+Buruk&publication_year=2023&doi=10.48550%2FarXiv.2304.11079)\n\n\\[19\\]\n\nMichael Castelluccio. 2022. IS DIGITAL AMNESIA REAL? _Strategic Finance_ 104, 3 (2022), 57–58.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=IS+DIGITAL+AMNESIA+REAL%3F&author=Michael+Castelluccio&publication_year=2022&pages=57-58)\n\n\\[20\\]\n\nValerie Chen, Q. Vera Liao, Jennifer Wortman Vaughan, and Gagan Bansal. 2023. Understanding the Role of Human Intuition on Reliance in Human-AI Decision-Making with Explanations. _Proceedings of the ACM on Human-Computer Interaction_ 7, CSCW2 (Sept. 2023), 1–32.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3610219)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Understanding+the+Role+of+Human+Intuition+on+Reliance+in+Human-AI+Decision-Making+with+Explanations&author=Valerie+Chen&author=Q.%C2%A0Vera+Liao&author=Jennifer+Wortman%C2%A0Vaughan&author=Gagan+Bansal&publication_year=2023&pages=1-32&doi=10.1145%2F3610219)\n\n\\[21\\]\n\nOoi Yan Chiew, An Qi Lai, and Wen Xin Liew. 2020. _Digital technology overuse as a predictor of digital amnesia and productivity_. Ph. D. Dissertation. UTAR.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Digital+technology+overuse+as+a+predictor+of+digital+amnesia+and+productivity&author=Ooi%C2%A0Yan+Chiew&author=An%C2%A0Qi+Lai&author=Wen%C2%A0Xin+Liew&publication_year=2020)\n\n\\[22\\]\n\nLeah Chong, Guanglu Zhang, Kosa Goucher-Lambert, Kenneth Kotovsky, and Jonathan Cagan. 2022. Human confidence in artificial intelligence and in themselves: The evolution and impact of confidence on adoption of AI advice. _Computers in Human Behavior_ 127 (Feb. 2022), 107018.\n\n[Digital Library](https://dl.acm.org/doi/10.1016/j.chb.2021.107018)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Human+confidence+in+artificial+intelligence+and+in+themselves%3A+The+evolution+and+impact+of+confidence+on+adoption+of+AI+advice&author=Leah+Chong&author=Guanglu+Zhang&author=Kosa+Goucher-Lambert&author=Kenneth+Kotovsky&author=Jonathan+Cagan&publication_year=2022&pages=107018&doi=10.1016%2Fj.chb.2021.107018)\n\n\\[23\\]\n\nJuliet Corbin and Anselm Strauss. 2015. _Basics of qualitative research_. Vol. 14. sage.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Basics+of+qualitative+research&author=Juliet+Corbin&author=Anselm+Strauss&publication_year=2015)\n\n\\[24\\]\n\nValdemar Danry, Pat Pataranutaporn, Yaoli Mao, and Pattie Maes. 2023. Don’t Just Tell Me, Ask Me: AI Systems that Intelligently Frame Explanations as Questions Improve Human Logical Discernment Accuracy over Causal AI explanations. In _Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems_ (Hamburg, Germany) ( _CHI ’23_). Association for Computing Machinery, New York, NY, USA, Article 352, 13 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3544548.3580672)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Don%E2%80%99t+Just+Tell+Me%2C+Ask+Me%3A+AI+Systems+that+Intelligently+Frame+Explanations+as+Questions+Improve+Human+Logical+Discernment+Accuracy+over+Causal+AI+explanations&author=Valdemar+Danry&author=Pat+Pataranutaporn&author=Yaoli+Mao&author=Pattie+Maes&publication_year=2023&doi=10.1145%2F3544548.3580672)\n\n\\[25\\]\n\nMartin Davies. 2011. Concept mapping, mind mapping and argument mapping: what are the differences and do they matter? _Higher education_ 62 (2011), 279–301.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Concept+mapping%2C+mind+mapping+and+argument+mapping%3A+what+are+the+differences+and+do+they+matter%3F&author=Martin+Davies&publication_year=2011&pages=279-301)\n\n\\[26\\]\n\nJohn Dewey. 1910. _How We Think_. D.C. Heath & Co., Publishers, Boston.\n\n[Crossref](https://doi.org/10.1037/10903-000)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=How+We+Think&author=John+Dewey&publication_year=1910&doi=10.1037%2F10903-000)\n\n\\[27\\]\n\nAmir Dirin, Ari Alamäki, and Jyrki Suomala. 2019. Digital amnesia and personal dependency in smart devices: A challenge for AI. _Proceedings of Fake Intelligence Online Summit 2019_ (2019).\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Digital+amnesia+and+personal+dependency+in+smart+devices%3A+A+challenge+for+AI&author=Amir+Dirin&author=Ari+Alam%C3%A4ki&author=Jyrki+Suomala&publication_year=2019)\n\n\\[28\\]\n\nAnil R Doshi and Oliver P Hauser. 2024. Generative AI enhances individual creativity but reduces the collective diversity of novel content. _Science Advances_ 10, 28 (2024), eadn5290.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Generative+AI+enhances+individual+creativity+but+reduces+the+collective+diversity+of+novel+content&author=Anil%C2%A0R+Doshi&author=Oliver%C2%A0P+Hauser&publication_year=2024&pages=eadn5290)\n\n\\[29\\]\n\nIan Drosos, Advait Sarkar, Xiaotong Xu, Carina Negreanu, Sean Rintel, and Lev Tankelevitch. 2024. \"It’s like a rubber duck that talks back\": Understanding Generative AI-Assisted Data Analysis Workflows through a Participatory Prompting Study. In _Proceedings of the 3rd Annual Meeting of the Symposium on Human-Computer Interaction for Work_. ACM, Newcastle upon Tyne United Kingdom, 1–21.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3663384.3663389)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=%22It%E2%80%99s+like+a+rubber+duck+that+talks+back%22%3A+Understanding+Generative+AI-Assisted+Data+Analysis+Workflows+through+a+Participatory+Prompting+Study&author=Ian+Drosos&author=Advait+Sarkar&author=Xiaotong+Xu&author=Carina+Negreanu&author=Sean+Rintel&author=Lev+Tankelevitch&publication_year=2024&pages=1-21&doi=10.1145%2F3663384.3663389)\n\n\\[30\\]\n\nPeter F. Drucker. 1959. _Landmarks of Tomorrow_. Harper.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Landmarks+of+Tomorrow&author=Peter%C2%A0F.+Drucker&publication_year=1959)\n\n\\[31\\]\n\nWantong Du, Zhiying Zhu, Xinhui Xu, Haoyuan Che, and Shi Chen. 2024. CareerSim: Gamification Design Leveraging LLMs For Career Development Reflection. In _Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems_( _CHI EA ’24_). Association for Computing Machinery, New York, NY, USA, Article 71, 7 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613905.3650928)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=CareerSim%3A+Gamification+Design+Leveraging+LLMs+For+Career+Development+Reflection&author=Wantong+Du&author=Zhiying+Zhu&author=Xinhui+Xu&author=Haoyuan+Che&author=Shi+Chen&publication_year=2024&doi=10.1145%2F3613905.3650928)\n\n\\[32\\]\n\nChristopher P Dwyer, Michael J Hogan, and Ian Stewart. 2014. An integrated critical thinking framework for the 21st century. _Thinking skills and Creativity_ 12 (2014), 43–52.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=An+integrated+critical+thinking+framework+for+the+21st+century&author=Christopher%C2%A0P+Dwyer&author=Michael%C2%A0J+Hogan&author=Ian+Stewart&publication_year=2014&pages=43-52)\n\n\\[33\\]\n\nUpol Ehsan, Philipp Wintersberger, Q Vera Liao, Elizabeth Anne Watkins, Carina Manger, Hal Daumé III, Andreas Riener, and Mark O Riedl. 2022. Human-Centered Explainable AI (HCXAI): beyond opening the black-box of AI. In _CHI conference on human factors in computing systems extended abstracts_. 1–7.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3491101.3503727)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Human-Centered+Explainable+AI+%28HCXAI%29%3A+beyond+opening+the+black-box+of+AI&author=Upol+Ehsan&author=Philipp+Wintersberger&author=Q%C2%A0Vera+Liao&author=Elizabeth%C2%A0Anne+Watkins&author=Carina+Manger&author=Hal+Daum%C3%A9%C2%A0III&author=Andreas+Riener&author=Mark%C2%A0O+Riedl&publication_year=2022&pages=1-7&doi=10.1145%2F3491101.3503727)\n\n\\[34\\]\n\nRobert H Ennis. 1993. Critical thinking assessment. _Theory into practice_ 32, 3 (1993), 179–186.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Critical+thinking+assessment&author=Robert%C2%A0H+Ennis&publication_year=1993&pages=179-186)\n\n\\[35\\]\n\nNoreen C Facione, Peter A. Facione, and Carol A. Sanchez. 1994. Critical Thinking Disposition as a Measure of Competent Clinical Judgment: The Development of the California Critical Thinking Disposition Inventory. _Journal of Nursing Education_ 33, 8 (10 1994), 345–350. [https://ezp.lib.cam.ac.uk/login?url=https://www.proquest.com/scholarly-journals/critical-thinking-disposition-as-measure/docview/1026710544/se-2](https://ezp.lib.cam.ac.uk/login?url=https://www.proquest.com/scholarly-journals/critical-thinking-disposition-as-measure/docview/1026710544/se-2) Copyright - Copyright SLACK INCORPORATED Oct 1994; Last updated - 2023-02-22; CODEN - JNUEAW.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Critical+Thinking+Disposition+as+a+Measure+of+Competent+Clinical+Judgment%3A+The+Development+of+the+California+Critical+Thinking+Disposition+Inventory&author=Noreen%C2%A0C+Facione&author=Peter%C2%A0A.+Facione&author=Carol%C2%A0A.+Sanchez&publication_year=1994&pages=345-350)\n\n\\[36\\]\n\nPeter Facione. 1990. Critical thinking: A statement of expert consensus for purposes of educational assessment and instruction (The Delphi Report). (1990).\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Critical+thinking%3A+A+statement+of+expert+consensus+for+purposes+of+educational+assessment+and+instruction+%28The+Delphi+Report%29&author=Peter+Facione&publication_year=1990)\n\n\\[37\\]\n\nPeter A Facione et al. 2011. Critical thinking: What it is and why it counts. _Insight assessment_ 1, 1 (2011), 1–23.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Critical+thinking%3A+What+it+is+and+why+it+counts&author=Peter%C2%A0A+Facione&publication_year=2011&pages=1-23)\n\n\\[38\\]\n\nPeter A Facione, Carol A Sanchez, Noreen C Facione, and Joanne Gainen. 1995. The disposition toward critical thinking. _The Journal of General Education_ 44, 1 (1995), 1–25.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+disposition+toward+critical+thinking&author=Peter%C2%A0A+Facione&author=Carol%C2%A0A+Sanchez&author=Noreen%C2%A0C+Facione&author=Joanne+Gainen&publication_year=1995&pages=1-25)\n\n\\[39\\]\n\nDaniela Fernandes, Steeven Villa, Salla Nicholls, Otso Haavisto, Daniel Buschek, Albrecht Schmidt, Thomas Kosch, Chenxinran Shen, and Robin Welsch. 2024. AI Makes You Smarter, But None The Wiser: The Disconnect Between Performance and Metacognition. arXiv: [https://arXiv.org/abs/2409.16708](https://arXiv.org/abs/2409.16708).\n\n[Crossref](https://doi.org/10.48550/arXiv.2409.16708)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=AI+Makes+You+Smarter%2C+But+None+The+Wiser%3A+The+Disconnect+Between+Performance+and+Metacognition&author=Daniela+Fernandes&author=Steeven+Villa&author=Salla+Nicholls&author=Otso+Haavisto&author=Daniel+Buschek&author=Albrecht+Schmidt&author=Thomas+Kosch&author=Chenxinran+Shen&author=Robin+Welsch&publication_year=2024&doi=10.48550%2FarXiv.2409.16708)\n\n\\[40\\]\n\nMary Forehand. 2010. Bloom’s taxonomy. _Emerging perspectives on learning, teaching, and technology_ 41, 4 (2010), 47–56.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Bloom%E2%80%99s+taxonomy&author=Mary+Forehand&publication_year=2010&pages=47-56)\n\n\\[41\\]\n\nRuth Garner and Joseph L McCaleb. 1985. Effects of text manipulations on quality of written summaries. _Contemporary Educational Psychology_ 10, 2 (1985), 139–149.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Effects+of+text+manipulations+on+quality+of+written+summaries&author=Ruth+Garner&author=Joseph%C2%A0L+McCaleb&publication_year=1985&pages=139-149)\n\n\\[42\\]\n\nBhaskar Ghosh, Karthik Narain, Lan Guan, and Jim Wilson. 2023. AI for everyone. [https://www.accenture.com/us-en/insights/technology/generative-ai](https://www.accenture.com/us-en/insights/technology/generative-ai)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=AI+for+everyone&author=Bhaskar+Ghosh&author=Karthik+Narain&author=Lan+Guan&author=Jim+Wilson&publication_year=2023)\n\n\\[43\\]\n\nElla Glikson and Anita Williams Woolley. 2020. Human Trust in Artificial Intelligence: Review of Empirical Research. _Academy of Management Annals_ 14, 2 (July 2020), 627–660.\n\n[Crossref](https://doi.org/10.5465/annals.2018.0057)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Human+Trust+in+Artificial+Intelligence%3A+Review+of+Empirical+Research&author=Ella+Glikson&author=Anita%C2%A0Williams+Woolley&publication_year=2020&pages=627-660&doi=10.5465%2Fannals.2018.0057)\n\n\\[44\\]\n\nKatrin Glinka and Claudia Müller-Birn. 2023. Critical-Reflective Human-AI Collaboration: Exploring Computational Tools for Art Historical Image Retrieval. _Proc. ACM Hum.-Comput. Interact._ 7, CSCW2, Article 263 (oct 2023), 33 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3610054)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Critical-Reflective+Human-AI+Collaboration%3A+Exploring+Computational+Tools+for+Art+Historical+Image+Retrieval&author=Katrin+Glinka&author=Claudia+M%C3%BCller-Birn&publication_year=2023&doi=10.1145%2F3610054)\n\n\\[45\\]\n\nAndreas Göldi, Thiemo Wambsganss, Seyed Parsa Neshaei, and Roman Rietsche. 2024. Intelligent Support Engages Writers Through Relevant Cognitive Processes. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 1047, 12 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642549)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Intelligent+Support+Engages+Writers+Through+Relevant+Cognitive+Processes&author=Andreas+G%C3%B6ldi&author=Thiemo+Wambsganss&author=Seyed%C2%A0Parsa+Neshaei&author=Roman+Rietsche&publication_year=2024&doi=10.1145%2F3613904.3642549)\n\n\\[46\\]\n\nAndrew D. Gordon, Carina Negreanu, José Cambronero, Rasika Chakravarthy, Ian Drosos, Hao Fang, Bhaskar Mitra, Hannah Richardson, Advait Sarkar, Stephanie Simmons, Jack Williams, and Ben Zorn. 2023. Co-audit: tools to help humans double-check AI-generated content. [http://arxiv.org/abs/2310.01297](http://arxiv.org/abs/2310.01297) arXiv: [https://arXiv.org/abs/2310.01297 \\[cs\\]](https://arXiv.org/abs/2310.01297).\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Co-audit%3A+tools+to+help+humans+double-check+AI-generated+content&author=Andrew%C2%A0D.+Gordon&author=Carina+Negreanu&author=Jos%C3%A9+Cambronero&author=Rasika+Chakravarthy&author=Ian+Drosos&author=Hao+Fang&author=Bhaskar+Mitra&author=Hannah+Richardson&author=Advait+Sarkar&author=Stephanie+Simmons&author=Jack+Williams&author=Ben+Zorn&publication_year=2023)\n\n\\[47\\]\n\nChris Greenwood and Matthew Quinn. 2017. Digital amnesia and the future tourist. _Journal of Tourism Futures_ 3, 1 (2017), 73–76.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Digital+amnesia+and+the+future+tourist&author=Chris+Greenwood&author=Matthew+Quinn&publication_year=2017&pages=73-76)\n\n\\[48\\]\n\nGalen Harrison, Kevin Bryson, Ahmad Emmanuel Balla Bamba, Luca Dovichi, Aleksander Herrmann Binion, Arthur Borem, and Blase Ur. 2024. JupyterLab in Retrograde: Contextual Notifications That Highlight Fairness and Bias Issues for Data Scientists. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 475, 19 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642755)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=JupyterLab+in+Retrograde%3A+Contextual+Notifications+That+Highlight+Fairness+and+Bias+Issues+for+Data+Scientists&author=Galen+Harrison&author=Kevin+Bryson&author=Ahmad+Emmanuel%C2%A0Balla+Bamba&author=Luca+Dovichi&author=Aleksander%C2%A0Herrmann+Binion&author=Arthur+Borem&author=Blase+Ur&publication_year=2024&doi=10.1145%2F3613904.3642755)\n\n\\[49\\]\n\nDavid J. Hauser and Norbert Schwarz. 2015. It’s a Trap! Instructional Manipulation Checks Prompt Systematic Thinking on “Tricky” Tasks. _Sage Open_ 5, 2 (2015), 2158244015584617. arXiv:\n\n[Crossref](https://doi.org/10.1177/2158244015584617)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=It%E2%80%99s+a+Trap%21+Instructional+Manipulation+Checks+Prompt+Systematic+Thinking+on+%E2%80%9CTricky%E2%80%9D+Tasks&author=David%C2%A0J.+Hauser&author=Norbert+Schwarz&publication_year=2015&pages=2158244015584617&doi=10.1177%2F2158244015584617)\n\n\\[50\\]\n\nAdrian Holzer, Sten Govaerts, Samuel Bendahan, and Denis Gillet. 2015. Towards Mobile Blended Interaction Fostering Critical Thinking. In _Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct_ (Copenhagen, Denmark) ( _MobileHCI ’15_). Association for Computing Machinery, New York, NY, USA, 735–742.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/2786567.2793695)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Towards+Mobile+Blended+Interaction+Fostering+Critical+Thinking&author=Adrian+Holzer&author=Sten+Govaerts&author=Samuel+Bendahan&author=Denis+Gillet&publication_year=2015&pages=735-742&doi=10.1145%2F2786567.2793695)\n\n\\[51\\]\n\nAdrian Holzer, Nava Tintarev, Samuel Bendahan, Bruno Kocher, Shane Greenup, and Denis Gillet. 2018. Digitally Scaffolding Debate in the Classroom. In _Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems_ (Montreal QC, Canada) ( _CHI EA ’18_). Association for Computing Machinery, New York, NY, USA, 1–6.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3170427.3188499)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Digitally+Scaffolding+Debate+in+the+Classroom&author=Adrian+Holzer&author=Nava+Tintarev&author=Samuel+Bendahan&author=Bruno+Kocher&author=Shane+Greenup&author=Denis+Gillet&publication_year=2018&pages=1-6&doi=10.1145%2F3170427.3188499)\n\n\\[52\\]\n\nEric Horvitz. 1999. Principles of mixed-initiative user interfaces. In _Proceedings of the SIGCHI conference on Human Factors in Computing Systems_. 159–166.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/302979.303030)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Principles+of+mixed-initiative+user+interfaces&author=Eric+Horvitz&publication_year=1999&pages=159-166&doi=10.1145%2F302979.303030)\n\n\\[53\\]\n\nC.W. Howell. 2023. So I followed @GaryMarcus’s suggestion and had my undergrad class use ChatGPT for a critical assignment... _[https://twitter.com/cwhowell123/status/1662501821133254656](https://twitter.com/cwhowell123/status/1662501821133254656)_. Retrieved July 10, 2023.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=So+I+followed+%40GaryMarcus%E2%80%99s+suggestion+and+had+my+undergrad+class+use+ChatGPT+for+a+critical+assignment...&author=C.W.+Howell&publication_year=2023)\n\n\\[54\\]\n\nWilliam Huitt. 2011. Bloom et al.’s taxonomy of the cognitive domain. _Educational psychology interactive_ 22 (2011), 1–4.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Bloom+et+al.%E2%80%99s+taxonomy+of+the+cognitive+domain&author=William+Huitt&publication_year=2011&pages=1-4)\n\n\\[55\\]\n\nJovan Jeromela and Owen Conlan. 2023. Voicing Suggestions and Enabling Reflection: Results of an Expert Discussion on Proactive Assistants for Time Management. In _Proceedings of the 5th International Conference on Conversational User Interfaces_ (Eindhoven, Netherlands) ( _CUI ’23_). Association for Computing Machinery, New York, NY, USA, Article 48, 6 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3571884.3604317)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Voicing+Suggestions+and+Enabling+Reflection%3A+Results+of+an+Expert+Discussion+on+Proactive+Assistants+for+Time+Management&author=Jovan+Jeromela&author=Owen+Conlan&publication_year=2023&doi=10.1145%2F3571884.3604317)\n\n\\[56\\]\n\nSarah A. Jessup, Tamera R. Schneider, Gene M. Alarcon, Tyler J. Ryan, and August Capiola. 2019. The Measurement of the Propensity to Trust Automation. In _Virtual, Augmented and Mixed Reality. Applications and Case Studies_, Jessie Y.C. Chen and Gino Fragomeni (Eds.). Vol. 11575. Springer International Publishing, Cham, 476–489. Series Title: Lecture Notes in Computer Science.\n\n[Digital Library](https://dl.acm.org/doi/10.1007/978-3-030-21565-1_32)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+Measurement+of+the+Propensity+to+Trust+Automation&author=Sarah%C2%A0A.+Jessup&author=Tamera%C2%A0R.+Schneider&author=Gene%C2%A0M.+Alarcon&author=Tyler%C2%A0J.+Ryan&author=August+Capiola&publication_year=2019&pages=476-489&doi=10.1007%2F978-3-030-21565-1_32)\n\n\\[57\\]\n\nJun Li Jeung and Janet Yi-Ching Huang. 2024. Unlocking Memories with AI: Exploring the Role of AI-Generated Cues in Personal Reminiscing. In _Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems_( _CHI EA ’24_). Association for Computing Machinery, New York, NY, USA, Article 356, 6 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613905.3650979)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Unlocking+Memories+with+AI%3A+Exploring+the+Role+of+AI-Generated+Cues+in+Personal+Reminiscing&author=Jun%C2%A0Li+Jeung&author=Janet+Yi-Ching+Huang&publication_year=2024&doi=10.1145%2F3613905.3650979)\n\n\\[58\\]\n\nHong Jiao and Robert W Lissitz. 2020. _Application of Artificial Intelligence to Assessment_. IAP.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Application+of+Artificial+Intelligence+to+Assessment&author=Hong+Jiao&author=Robert%C2%A0W+Lissitz&publication_year=2020)\n\n\\[59\\]\n\nHeather Johnston, Rebecca F. Wells, Elizabeth M. Shanks, Timothy Boey, and Bryony N. Parsons. 2024. Student perspectives on the use of generative artificial intelligence technologies in higher education. _International Journal for Educational Integrity_ 20, 1 (Feb. 2024), 2.\n\n[Crossref](https://doi.org/10.1007/s40979-024-00149-4)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Student+perspectives+on+the+use+of+generative+artificial+intelligence+technologies+in+higher+education&author=Heather+Johnston&author=Rebecca%C2%A0F.+Wells&author=Elizabeth%C2%A0M.+Shanks&author=Timothy+Boey&author=Bryony%C2%A0N.+Parsons&publication_year=2024&pages=2&doi=10.1007%2Fs40979-024-00149-4)\n\n\\[60\\]\n\nSrecko Joksimovic, Dirk Ifenthaler, Rebecca Marrone, Maarten De Laat, and George Siemens. 2023. Opportunities of artificial intelligence for supporting complex problem-solving: Findings from a scoping review. _Computers and Education: Artificial Intelligence_ 4 (2023), 100138.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Opportunities+of+artificial+intelligence+for+supporting+complex+problem-solving%3A+Findings+from+a+scoping+review&author=Srecko+Joksimovic&author=Dirk+Ifenthaler&author=Rebecca+Marrone&author=Maarten+De%C2%A0Laat&author=George+Siemens&publication_year=2023&pages=100138)\n\n\\[61\\]\n\nSol Kang and William Odom. 2024. On the Design of Quologue: Uncovering Opportunities and Challenges with Generative AI as a Resource for Creating a Self-Morphing E-book Metadata Archive. In _Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems_( _CHI EA ’24_). Association for Computing Machinery, New York, NY, USA, Article 255, 16 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613905.3650909)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=On+the+Design+of+Quologue%3A+Uncovering+Opportunities+and+Challenges+with+Generative+AI+as+a+Resource+for+Creating+a+Self-Morphing+E-book+Metadata+Archive&author=Sol+Kang&author=William+Odom&publication_year=2024&doi=10.1145%2F3613905.3650909)\n\n\\[62\\]\n\nJeffrey D Karpicke and Janell R Blunt. 2011. Retrieval practice produces more learning than elaborative studying with concept mapping. _Science_ 331, 6018 (2011), 772–775.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Retrieval+practice+produces+more+learning+than+elaborative+studying+with+concept+mapping&author=Jeffrey%C2%A0D+Karpicke&author=Janell%C2%A0R+Blunt&publication_year=2011&pages=772-775)\n\n\\[63\\]\n\nRonald T Kellogg. 2008. Training writing skills: A cognitive developmental perspective. _Journal of Writing Research_ 1, 1 (2008), 1–26.\n\n[Crossref](https://doi.org/10.17239/jowr-2008.01.01.1)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Training+writing+skills%3A+A+cognitive+developmental+perspective&author=Ronald%C2%A0T+Kellogg&publication_year=2008&pages=1-26&doi=10.17239%2Fjowr-2008.01.01.1)\n\n\\[64\\]\n\nRonald T Kellogg and Bascom A Raulerson. 2007. Improving the writing skills of college students. _Psychonomic Bulletin & Review_ 14, 2 (2007), 237–242.\n\n[Crossref](https://doi.org/10.3758/BF03194058)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Improving+the+writing+skills+of+college+students&author=Ronald%C2%A0T+Kellogg&author=Bascom%C2%A0A+Raulerson&publication_year=2007&pages=237-242&doi=10.3758%2FBF03194058)\n\n\\[65\\]\n\nDavid Kember, Doris YP Leung, Alice Jones, Alice Yuen Loke, Jan McKay, Kit Sinclair, Harrison Tse, Celia Webb, Frances Kam Yuet Wong, Marian Wong, et al. 2000. Development of a questionnaire to measure the level of reflective thinking. _Assessment & evaluation in higher education_ 25, 4 (2000), 381–395.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Development+of+a+questionnaire+to+measure+the+level+of+reflective+thinking&author=David+Kember&author=Doris%C2%A0YP+Leung&author=Alice+Jones&author=Alice%C2%A0Yuen+Loke&author=Jan+McKay&author=Kit+Sinclair&author=Harrison+Tse&author=Celia+Webb&author=Frances%C2%A0Kam+Yuet%C2%A0Wong&author=Marian+Wong&publication_year=2000&pages=381-395)\n\n\\[66\\]\n\nDavid Kember, Jan McKay, Kit Sinclair, and Frances Kam Yuet Wong. 2008. A four-category scheme for coding and assessing the level of reflection in written work. _Assessment & evaluation in higher education_ 33, 4 (2008), 369–379.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=A+four-category+scheme+for+coding+and+assessing+the+level+of+reflection+in+written+work&author=David+Kember&author=Jan+McKay&author=Kit+Sinclair&author=Frances+Kam%C2%A0Yuet+Wong&publication_year=2008&pages=369-379)\n\n\\[67\\]\n\nAlison Kidd. 1994. The marks are on the knowledge worker. In _Proceedings of the SIGCHI conference on Human factors in computing systems_. 186–191.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/191666.191740)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+marks+are+on+the+knowledge+worker&author=Alison+Kidd&publication_year=1994&pages=186-191&doi=10.1145%2F191666.191740)\n\n\\[68\\]\n\nMarkus Kiefer and Friedemann Pulvermüller. 2012. Conceptual representations in mind and brain: Theoretical developments, current evidence and future directions. _cortex_ 48, 7 (2012), 805–825.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Conceptual+representations+in+mind+and+brain%3A+Theoretical+developments%2C+current+evidence+and+future+directions&author=Markus+Kiefer&author=Friedemann+Pulverm%C3%BCller&publication_year=2012&pages=805-825)\n\n\\[69\\]\n\nMinyeong Kim, Jiwook Lee, Youngji Koh, Chanhee Lee, Uichin Lee, and Auk Kim. 2024. Interrupting for Microlearning: Understanding Perceptions and Interruptibility of Proactive Conversational Microlearning Services. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 570, 21 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642778)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Interrupting+for+Microlearning%3A+Understanding+Perceptions+and+Interruptibility+of+Proactive+Conversational+Microlearning+Services&author=Minyeong+Kim&author=Jiwook+Lee&author=Youngji+Koh&author=Chanhee+Lee&author=Uichin+Lee&author=Auk+Kim&publication_year=2024&doi=10.1145%2F3613904.3642778)\n\n\\[70\\]\n\nPatricia M King. 1997. The reflective judgment model: Transforming assumptions about knowing. _College student development and academic life: psychological, intellectual, social, and moral issues_ 4 (1997), 141.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+reflective+judgment+model%3A+Transforming+assumptions+about+knowing&author=Patricia%C2%A0M+King&publication_year=1997&pages=141)\n\n\\[71\\]\n\nAlexandra Kitson, Petr Slovak, and Alissa N. Antle. 2024. Supporting Cognitive Reappraisal With Digital Technology: A Content Analysis and Scoping Review of Challenges, Interventions, and Future Directions. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 694, 17 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642488)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Supporting+Cognitive+Reappraisal+With+Digital+Technology%3A+A+Content+Analysis+and+Scoping+Review+of+Challenges%2C+Interventions%2C+and+Future+Directions&author=Alexandra+Kitson&author=Petr+Slovak&author=Alissa%C2%A0N.+Antle&publication_year=2024&doi=10.1145%2F3613904.3642488)\n\n\\[72\\]\n\nCharles W Kneupper. 1978. Teaching argument: An introduction to the Toulmin model. _College Composition and Communication_ 29, 3 (1978), 237–241.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Teaching+argument%3A+An+introduction+to+the+Toulmin+model&author=Charles%C2%A0W+Kneupper&publication_year=1978&pages=237-241)\n\n\\[73\\]\n\nAleksander Kobylarek, Kamil Błaszczyński, Luba Ślósarz, and Martyna Madej. 2022. Critical Thinking Questionnaire (CThQ)–construction and application of critical thinking test tool. _Andragogy Adult Education and Social Marketing_ 2, 2 (2022), 1–1.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Critical+Thinking+Questionnaire+%28CThQ%29%E2%80%93construction+and+application+of+critical+thinking+test+tool&author=Aleksander+Kobylarek&author=Kamil+B%C5%82aszczy%C5%84ski&author=Luba+%C5%9Al%C3%B3sarz&author=Martyna+Madej&publication_year=2022&pages=1-1)\n\n\\[74\\]\n\nDeanna Kuhn. 1993. Connecting scientific and informal reasoning. _Merrill-Palmer Quarterly (1982-)_ (1993), 74–103.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Connecting+scientific+and+informal+reasoning&author=Deanna+Kuhn&publication_year=1993&pages=74-103)\n\n\\[75\\]\n\nSoonho Kwon, Dong Whi Yoo, and Younah Kang. 2024. Spiritual AI: Exploring the Possibilities of a Human-AI Interaction Beyond Productive Goals. In _Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems_( _CHI EA ’24_). Association for Computing Machinery, New York, NY, USA, Article 299, 8 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613905.3650743)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Spiritual+AI%3A+Exploring+the+Possibilities+of+a+Human-AI+Interaction+Beyond+Productive+Goals&author=Soonho+Kwon&author=Dong%C2%A0Whi+Yoo&author=Younah+Kang&publication_year=2024&doi=10.1145%2F3613905.3650743)\n\n\\[76\\]\n\nAlain Lacroux and Christelle Martin-Lacroux. 2022. Should I Trust the Artificial Intelligence to Recruit? Recruiters’ Perceptions and Behavior When Faced With Algorithm-Based Recommendation Systems During Resume Screening. _Frontiers in Psychology_ 13 (July 2022). Publisher: Frontiers.\n\n[Crossref](https://doi.org/10.3389/fpsyg.2022.895997)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Should+I+Trust+the+Artificial+Intelligence+to+Recruit%3F+Recruiters%E2%80%99+Perceptions+and+Behavior+When+Faced+With+Algorithm-Based+Recommendation+Systems+During+Resume+Screening&author=Alain+Lacroux&author=Christelle+Martin-Lacroux&publication_year=2022&doi=10.3389%2Ffpsyg.2022.895997)\n\n\\[77\\]\n\nGeorge Lakoff and Mark Johnson. 2008. _Metaphors we live by_. University of Chicago press.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Metaphors+we+live+by&author=George+Lakoff&author=Mark+Johnson&publication_year=2008)\n\n\\[78\\]\n\nSunok Lee, Dasom Choi, Minha Lee, Jonghak Choi, and Sangsu Lee. 2023. Fostering Youth’s Critical Thinking Competency About AI through Exhibition. In _Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems_ (Hamburg, Germany) ( _CHI ’23_). Association for Computing Machinery, New York, NY, USA, Article 451, 22 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3544548.3581159)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Fostering+Youth%E2%80%99s+Critical+Thinking+Competency+About+AI+through+Exhibition&author=Sunok+Lee&author=Dasom+Choi&author=Minha+Lee&author=Jonghak+Choi&author=Sangsu+Lee&publication_year=2023&doi=10.1145%2F3544548.3581159)\n\n\\[79\\]\n\nYoung-Ju Lee. 2020. The Long-Term Effect of Automated Writing Evaluation Feedback on Writing Development. _English Teaching_ 75, 1 (2020), 67–92.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+Long-Term+Effect+of+Automated+Writing+Evaluation+Feedback+on+Writing+Development&author=Young-Ju+Lee&publication_year=2020&pages=67-92)\n\n\\[80\\]\n\nZhuoyang Li, Minhui Liang, Ray Lc, and Yuhan Luo. 2024. StayFocused: Examining the Effects of Reflective Prompts and Chatbot Support on Compulsive Smartphone Use. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 247, 19 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642479)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=StayFocused%3A+Examining+the+Effects+of+Reflective+Prompts+and+Chatbot+Support+on+Compulsive+Smartphone+Use&author=Zhuoyang+Li&author=Minhui+Liang&author=Ray+Lc&author=Yuhan+Luo&publication_year=2024&doi=10.1145%2F3613904.3642479)\n\n\\[81\\]\n\nZhuoyang Li, Minhui Liang, Hai Trung Le, Ray Lc, and Yuhan Luo. 2023. Exploring Design Opportunities for Reflective Conversational Agents to Reduce Compulsive Smartphone Use. In _Proceedings of the 5th International Conference on Conversational User Interfaces_ (Eindhoven, Netherlands) ( _CUI ’23_). Association for Computing Machinery, New York, NY, USA, Article 37, 6 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3571884.3604305)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Exploring+Design+Opportunities+for+Reflective+Conversational+Agents+to+Reduce+Compulsive+Smartphone+Use&author=Zhuoyang+Li&author=Minhui+Liang&author=Hai%C2%A0Trung+Le&author=Ray+Lc&author=Yuhan+Luo&publication_year=2023&doi=10.1145%2F3571884.3604305)\n\n\\[82\\]\n\nJingxian Liao, Mrinalini Singh, and Hao-Chuan Wang. 2023. DeepThinkingMap: Collaborative Video Reflection System with Graph-based Summarizing and Commenting. In _Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing_ (Minneapolis, MN, USA) ( _CSCW ’23 Companion_). Association for Computing Machinery, New York, NY, USA, 369–371.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3584931.3607501)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=DeepThinkingMap%3A+Collaborative+Video+Reflection+System+with+Graph-based+Summarizing+and+Commenting&author=Jingxian+Liao&author=Mrinalini+Singh&author=Hao-Chuan+Wang&publication_year=2023&pages=369-371&doi=10.1145%2F3584931.3607501)\n\n\\[83\\]\n\nZhuoran Lu and Ming Yin. 2021. Human Reliance on Machine Learning Models When Performance Feedback is Limited: Heuristics and Risks. In _Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems_. ACM, Yokohama Japan, 1–16.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3411764.3445562)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Human+Reliance+on+Machine+Learning+Models+When+Performance+Feedback+is+Limited%3A+Heuristics+and+Risks&author=Zhuoran+Lu&author=Ming+Yin&publication_year=2021&pages=1-16&doi=10.1145%2F3411764.3445562)\n\n\\[84\\]\n\nTiago Lubiana, Rafael Lopes, Pedro Medeiros, Juan Carlo Silva, Andre Nicolau Aquime Goncalves, Vinicius Maracaja-Coutinho, and Helder I Nakaya. 2023. Ten Quick Tips for Harnessing the Power of ChatGPT/GPT-4 in Computational Biology. _arXiv preprint arXiv: [https://arXiv.org/abs/2303.16429](https://arXiv.org/abs/2303.16429)_ (2023).\n\n[Crossref](https://doi.org/10.48550/arXiv.2303.16429)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Ten+Quick+Tips+for+Harnessing+the+Power+of+ChatGPT%2FGPT-4+in+Computational+Biology&author=Tiago+Lubiana&author=Rafael+Lopes&author=Pedro+Medeiros&author=Juan%C2%A0Carlo+Silva&author=Andre+Nicolau%C2%A0Aquime+Goncalves&author=Vinicius+Maracaja-Coutinho&author=Helder%C2%A0I+Nakaya&publication_year=2023&doi=10.48550%2FarXiv.2303.16429)\n\n\\[85\\]\n\nShuai Ma, Xinru Wang, Ying Lei, Chuhan Shi, Ming Yin, and Xiaojuan Ma. 2024. \"Are You Really Sure?\" Understanding the Effects of Human Self-Confidence Calibration in AI-Assisted Decision Making. [http://arxiv.org/abs/2403.09552](http://arxiv.org/abs/2403.09552) arXiv: [https://arXiv.org/abs/2403.09552 \\[cs\\]](https://arXiv.org/abs/2403.09552).\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=%22Are+You+Really+Sure%3F%22+Understanding+the+Effects+of+Human+Self-Confidence+Calibration+in+AI-Assisted+Decision+Making&author=Shuai+Ma&author=Xinru+Wang&author=Ying+Lei&author=Chuhan+Shi&author=Ming+Yin&author=Xiaojuan+Ma&publication_year=2024)\n\n\\[86\\]\n\nJill Burstein McCaffrey, Brian Riordan, and Daniel. 2020. Expanding Automated Writing Evaluation. In _Handbook of Automated Scoring_. Chapman and Hall/CRC.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Expanding+Automated+Writing+Evaluation&author=Jill%C2%A0Burstein+McCaffrey&author=Brian+Riordan&author=Daniel&publication_year=2020)\n\n\\[87\\]\n\nNora McDonald, Sarita Schoenebeck, and Andrea Forte. 2019. Reliability and Inter-rater Reliability in Qualitative Research: Norms and Guidelines for CSCW and HCI Practice. _Proc. ACM Hum.-Comput. Interact._ 3, CSCW, Article 72 (nov 2019), 23 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3359174)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Reliability+and+Inter-rater+Reliability+in+Qualitative+Research%3A+Norms+and+Guidelines+for+CSCW+and+HCI+Practice&author=Nora+McDonald&author=Sarita+Schoenebeck&author=Andrea+Forte&publication_year=2019&doi=10.1145%2F3359174)\n\n\\[88\\]\n\nNathan J McNeese, Beau G Schelble, Lorenzo Barberis Canonico, and Mustafa Demir. 2021. Who/what is my teammate? Team composition considerations in human–AI teaming. _IEEE Transactions on Human-Machine Systems_ 51, 4 (2021), 288–299.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Who%2Fwhat+is+my+teammate%3F+Team+composition+considerations+in+human%E2%80%93AI+teaming&author=Nathan%C2%A0J+McNeese&author=Beau%C2%A0G+Schelble&author=Lorenzo%C2%A0Barberis+Canonico&author=Mustafa+Demir&publication_year=2021&pages=288-299)\n\n\\[89\\]\n\nLucas Memmert and Eva Bittner. 2022. Complex problem solving through human-AI collaboration: literature review on research contexts. (2022).\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Complex+problem+solving+through+human-AI+collaboration%3A+literature+review+on+research+contexts&author=Lucas+Memmert&author=Eva+Bittner&publication_year=2022)\n\n\\[90\\]\n\nLotte Meteyard, Sara Rodriguez Cuadrado, Bahador Bahrami, and Gabriella Vigliocco. 2012. Coming of age: A review of embodiment and the neuroscience of semantics. _Cortex_ 48, 7 (2012), 788–804.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Coming+of+age%3A+A+review+of+embodiment+and+the+neuroscience+of+semantics&author=Lotte+Meteyard&author=Sara%C2%A0Rodriguez+Cuadrado&author=Bahador+Bahrami&author=Gabriella+Vigliocco&publication_year=2012&pages=788-804)\n\n\\[91\\]\n\nJosh Aaron Miller, Kutub Gandhi, Matthew Alexander Whitby, Mehmet Kosa, Seth Cooper, Elisa D. Mekler, and Ioanna Iacovides. 2024. A Design Framework for Reflective Play. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 519, 21 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642455)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=A+Design+Framework+for+Reflective+Play&author=Josh%C2%A0Aaron+Miller&author=Kutub+Gandhi&author=Matthew%C2%A0Alexander+Whitby&author=Mehmet+Kosa&author=Seth+Cooper&author=Elisa%C2%A0D.+Mekler&author=Ioanna+Iacovides&publication_year=2024&doi=10.1145%2F3613904.3642455)\n\n\\[92\\]\n\nRichard L Miller and William Wozniak. 2001. Counter-attitudinal advocacy: Effort vs. self-generation of arguments. _Current Research in Social Psychology_ 6, 4 (2001), 46–55.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Counter-attitudinal+advocacy%3A+Effort+vs.+self-generation+of+arguments&author=Richard%C2%A0L+Miller&author=William+Wozniak&publication_year=2001&pages=46-55)\n\n\\[93\\]\n\nC Donald Morris, Barry S Stein, and John D Bransford. 1979. Prerequisites for the utilization of knowledge in the recall of prose passages. _Journal of Experimental Psychology: Human Learning and Memory_ 5, 3 (1979), 253.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Prerequisites+for+the+utilization+of+knowledge+in+the+recall+of+prose+passages.&author=C%C2%A0Donald+Morris&author=Barry%C2%A0S+Stein&author=John%C2%A0D+Bransford&publication_year=1979&pages=253)\n\n\\[94\\]\n\nAnwesha Mukherjee, Vagner Figueredo De Santana, and Alexis Baria. 2023. ImpactBot: Chatbot Leveraging Language Models to Automate Feedback and Promote Critical Thinking Around Impact Statements. In _Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems_ (Hamburg, Germany) ( _CHI EA ’23_). Association for Computing Machinery, New York, NY, USA, Article 388, 8 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3544549.3573844)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=ImpactBot%3A+Chatbot+Leveraging+Language+Models+to+Automate+Feedback+and+Promote+Critical+Thinking+Around+Impact+Statements&author=Anwesha+Mukherjee&author=Vagner+Figueredo%C2%A0De+Santana&author=Alexis+Baria&publication_year=2023&doi=10.1145%2F3544549.3573844)\n\n\\[95\\]\n\nMichael Muller and Justin Weisz. 2022. Extending a human-ai collaboration framework with dynamism and sociality. In _Proceedings of the 1st Annual Meeting of the Symposium on Human-Computer Interaction for Work_. 1–12.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3533406.3533407)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Extending+a+human-ai+collaboration+framework+with+dynamism+and+sociality&author=Michael+Muller&author=Justin+Weisz&publication_year=2022&pages=1-12&doi=10.1145%2F3533406.3533407)\n\n\\[96\\]\n\nJennifer Wilson Mulnix. 2012. Thinking critically about critical thinking. _Educational Philosophy and theory_ 44, 5 (2012), 464–479.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Thinking+critically+about+critical+thinking&author=Jennifer%C2%A0Wilson+Mulnix&publication_year=2012&pages=464-479)\n\n\\[97\\]\n\nSubigya Nepal, Arvind Pillai, William Campbell, Talie Massachi, Eunsol Soul Choi, Xuhai Xu, Joanna Kuc, Jeremy F Huckins, Jason Holden, Colin Depp, Nicholas Jacobson, Mary P Czerwinski, Eric Granholm, and Andrew Campbell. 2024. Contextual AI Journaling: Integrating LLM and Time Series Behavioral Sensing Technology to Promote Self-Reflection and Well-being using the MindScape App. In _Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems_( _CHI EA ’24_). Association for Computing Machinery, New York, NY, USA, Article 86, 8 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613905.3650767)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Contextual+AI+Journaling%3A+Integrating+LLM+and+Time+Series+Behavioral+Sensing+Technology+to+Promote+Self-Reflection+and+Well-being+using+the+MindScape+App&author=Subigya+Nepal&author=Arvind+Pillai&author=William+Campbell&author=Talie+Massachi&author=Eunsol%C2%A0Soul+Choi&author=Xuhai+Xu&author=Joanna+Kuc&author=Jeremy%C2%A0F+Huckins&author=Jason+Holden&author=Colin+Depp&author=Nicholas+Jacobson&author=Mary%C2%A0P+Czerwinski&publication_year=2024&doi=10.1145%2F3613905.3650767)\n\n\\[98\\]\n\nQuoc Dinh Nguyen, Nicolas Fernandez, Thierry Karsenti, and Bernard Charlin. 2014. What is reflection? A conceptual analysis of major definitions and a proposal of a five-component model. _Medical education_ 48, 12 (2014), 1176–1189.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=What+is+reflection%3F+A+conceptual+analysis+of+major+definitions+and+a+proposal+of+a+five-component+model&author=Quoc%C2%A0Dinh+Nguyen&author=Nicolas+Fernandez&author=Thierry+Karsenti&author=Bernard+Charlin&publication_year=2014&pages=1176-1189)\n\n\\[99\\]\n\nOda Elise Nordberg and Frode Guribye. 2023. Conversations with the News: Co-speculation into Conversational Interactions with News Content. In _Proceedings of the 5th International Conference on Conversational User Interfaces_ (Eindhoven, Netherlands) ( _CUI ’23_). Association for Computing Machinery, New York, NY, USA, Article 32, 11 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3571884.3597123)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Conversations+with+the+News%3A+Co-speculation+into+Conversational+Interactions+with+News+Content&author=Oda%C2%A0Elise+Nordberg&author=Frode+Guribye&publication_year=2023&doi=10.1145%2F3571884.3597123)\n\n\\[100\\]\n\nShakked Noy and Whitney Zhang. 2023. _Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence_. Technical Report. Working Paper.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Experimental+Evidence+on+the+Productivity+Effects+of+Generative+Artificial+Intelligence&author=Shakked+Noy&author=Whitney+Zhang&publication_year=2023)\n\n\\[101\\]\n\nLorena Parra G. and Ximena Calero S.2019. Automated Writing Evaluation Tools in the Improvement of the Writing Skill. _International Journal of Instruction_ 12, 2 (2019), 209–226.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Automated+Writing+Evaluation+Tools+in+the+Improvement+of+the+Writing+Skill&author=Lorena+Parra%C2%A0G.&author=Ximena+Calero%C2%A0S.&publication_year=2019&pages=209-226)\n\n\\[102\\]\n\nSamir Passi and Mihaela Vorvoreanu. 2022. Overreliance on AI literature review. _Microsoft Research_ (2022).\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Overreliance+on+AI+literature+review&author=Samir+Passi&author=Mihaela+Vorvoreanu&publication_year=2022)\n\n\\[103\\]\n\nRichard Paul and Linda Elder. 2020. _The miniature guide to critical thinking concepts and tools (8th edition ed.)_. Rowman & Littlefield, Lanham, Md. OCLC: on1132213785.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+miniature+guide+to+critical+thinking+concepts+and+tools+%288th+edition+ed.%29&author=Richard+Paul&author=Linda+Elder&publication_year=2020)\n\n\\[104\\]\n\nRichard W Paul, Linda Elder, and Ted Bartell. 1997. California teacher preparation for instruction in critical thinking: Research findings and policy recommendations. (1997).\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=California+teacher+preparation+for+instruction+in+critical+thinking%3A+Research+findings+and+policy+recommendations.&author=Richard%C2%A0W+Paul&author=Linda+Elder&author=Ted+Bartell&publication_year=1997)\n\n\\[105\\]\n\nSheila A. Paul. 2014. Assessment of critical thinking: A Delphi study. _Nurse Education Today_ 34, 11 (2014), 1357–1360.\n\n[Crossref](https://doi.org/10.1016/j.nedt.2014.03.008)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Assessment+of+critical+thinking%3A+A+Delphi+study&author=Sheila%C2%A0A.+Paul&publication_year=2014&pages=1357-1360&doi=10.1016%2Fj.nedt.2014.03.008)\n\n\\[106\\]\n\nNikolaos Pellas. 2023. The Effects of Generative AI Platforms on Undergraduates’ Narrative Intelligence and Writing Self-Efficacy. _Education Sciences_ 13, 11 (2023), 1155.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+Effects+of+Generative+AI+Platforms+on+Undergraduates%E2%80%99+Narrative+Intelligence+and+Writing+Self-Efficacy&author=Nikolaos+Pellas&publication_year=2023&pages=1155)\n\n\\[107\\]\n\nJames Prather, Brent N Reeves, Juho Leinonen, Stephen MacNeil, Arisoa S Randrianasolo, Brett A Becker, Bailey Kimmel, Jared Wright, and Ben Briggs. 2024. The Widening Gap: The Benefits and Harms of Generative AI for Novice Programmers. In _Proceedings of the 2024 ACM Conference on International Computing Education Research-Volume 1_. 469–486.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3632620.3671116)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+Widening+Gap%3A+The+Benefits+and+Harms+of+Generative+AI+for+Novice+Programmers&author=James+Prather&author=Brent%C2%A0N+Reeves&author=Juho+Leinonen&author=Stephen+MacNeil&author=Arisoa%C2%A0S+Randrianasolo&author=Brett%C2%A0A+Becker&author=Bailey+Kimmel&author=Jared+Wright&author=Ben+Briggs&publication_year=2024&pages=469-486&doi=10.1145%2F3632620.3671116)\n\n\\[108\\]\n\nSebastian Raisch and Kateryna Fomina. 2023. Combining human and artificial intelligence: Hybrid problem-solving in organizations. _Academy of Management Review_ ja (2023), amr–2021.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Combining+human+and+artificial+intelligence%3A+Hybrid+problem-solving+in+organizations&author=Sebastian+Raisch&author=Kateryna+Fomina&publication_year=2023&pages=amr%E2%80%932021)\n\n\\[109\\]\n\nLeon Reicherts, Gun Woo Park, and Yvonne Rogers. 2022. Extending Chatbots to Probe Users: Enhancing Complex Decision-Making Through Probing Conversations. In _Proceedings of the 4th Conference on Conversational User Interfaces_ (, Glasgow, United Kingdom,) ( _CUI ’22_). Association for Computing Machinery, New York, NY, USA, Article 2, 10 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3543829.3543832)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Extending+Chatbots+to+Probe+Users%3A+Enhancing+Complex+Decision-Making+Through+Probing+Conversations&author=Leon+Reicherts&author=Gun%C2%A0Woo+Park&author=Yvonne+Rogers&publication_year=2022&doi=10.1145%2F3543829.3543832)\n\n\\[110\\]\n\nLiam Richards Maldonado, Azza Abouzied, and Nancy W. Gleason. 2023. ReaderQuizzer: Augmenting Research Papers with Just-In-Time Learning Questions to Facilitate Deeper Understanding. In _Companion Publication of the 2023 Conference on Computer Supported Cooperative Work and Social Computing_ (Minneapolis, MN, USA) ( _CSCW ’23 Companion_). Association for Computing Machinery, New York, NY, USA, 391–394.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3584931.3607494)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=ReaderQuizzer%3A+Augmenting+Research+Papers+with+Just-In-Time+Learning+Questions+to+Facilitate+Deeper+Understanding&author=Liam+Richards%C2%A0Maldonado&author=Azza+Abouzied&author=Nancy%C2%A0W.+Gleason&publication_year=2023&pages=391-394&doi=10.1145%2F3584931.3607494)\n\n\\[111\\]\n\nS James Robert, S Kadhiravan, and Dean McKay. 2024. The development and validation of digital amnesia scale. _Current Psychology_ (2024), 1–10.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+development+and+validation+of+digital+amnesia+scale&author=S%C2%A0James+Robert&author=S+Kadhiravan&author=Dean+McKay&publication_year=2024&pages=1-10)\n\n\\[112\\]\n\nChristoph Saffer. 2023. Boosting Productivity using GPT-4: Writing Articles and Coding efficiently. _[https://medium.com/@ChristophSaffer/boosting-productivity-using-gpt-4-writing-articles-and-coding-efficiently-ab0ddb955c2c](https://medium.com/@ChristophSaffer/boosting-productivity-using-gpt-4-writing-articles-and-coding-efficiently-ab0ddb955c2c)_. Retrieved July 10, 2023.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Boosting+Productivity+using+GPT-4%3A+Writing+Articles+and+Coding+efficiently&author=Christoph+Saffer&publication_year=2023)\n\n\\[113\\]\n\nAdvait Sarkar. 2023. Enough With “Human-AI Collaboration”. In _Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems_ (Hamburg, Germany) ( _CHI EA ’23_). Association for Computing Machinery, New York, NY, USA, Article 415, 8 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3544549.3582735)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Enough+With+%E2%80%9CHuman-AI+Collaboration%E2%80%9D&author=Advait+Sarkar&publication_year=2023&doi=10.1145%2F3544549.3582735)\n\n\\[114\\]\n\nAdvait Sarkar. 2023. Exploring Perspectives on the Impact of Artificial Intelligence on the Creativity of Knowledge Work: Beyond Mechanised Plagiarism and Stochastic Parrots. In _Proceedings of the 2nd Annual Meeting of the Symposium on Human-Computer Interaction for Work_ (Oldenburg, Germany) ( _CHIWORK ’23_). Association for Computing Machinery, New York, NY, USA, Article 13, 17 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3596671.3597650)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Exploring+Perspectives+on+the+Impact+of+Artificial+Intelligence+on+the+Creativity+of+Knowledge+Work%3A+Beyond+Mechanised+Plagiarism+and+Stochastic+Parrots&author=Advait+Sarkar&publication_year=2023&doi=10.1145%2F3596671.3597650)\n\n\\[115\\]\n\nAdvait Sarkar. 2023. Will Code Remain a Relevant User Interface for End-User Programming with Generative AI Models?. In _Proceedings of the 2023 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software_ (Cascais, Portugal) ( _Onward! 2023_). Association for Computing Machinery, New York, NY, USA, 153–167.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3622758.3622882)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Will+Code+Remain+a+Relevant+User+Interface+for+End-User+Programming+with+Generative+AI+Models%3F&author=Advait+Sarkar&publication_year=2023&pages=153-167&doi=10.1145%2F3622758.3622882)\n\n\\[116\\]\n\nAdvait Sarkar. 2024. AI Should Challenge, Not Obey. _Commun. ACM_ 67, 10 (Sept. 2024), 18–21.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3649404)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=AI+Should+Challenge%2C+Not+Obey&author=Advait+Sarkar&publication_year=2024&pages=18-21&doi=10.1145%2F3649404)\n\n\\[117\\]\n\nAdvait Sarkar. 2024. Intention Is All You Need. _Proceedings of the 35th Annual Conference of the Psychology of Programming Interest Group (PPIG 2024)_ (2024).\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Intention+Is+All+You+Need&author=Advait+Sarkar&publication_year=2024)\n\n\\[118\\]\n\nAdvait Sarkar. 2024. Large Language Models Cannot Explain Themselves. In _ACM CHI 2024 Workshop on Human-Centered Explainable AI (HCXAI)_.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Large+Language+Models+Cannot+Explain+Themselves&author=Advait+Sarkar&publication_year=2024)\n\n\\[119\\]\n\nAdvait Sarkar, Xiaotong (Tone) Xu, Neil Toronto, Ian Drosos, and Christian Poelitz. 2024. When Copilot Becomes Autopilot: Generative AI’s Critical Risk to Knowledge Work and a Critical Solution. In _Proceedings of the Annual Conference of the European Spreadsheet Risks Interest Group (EuSpRIG 2024)_.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=When+Copilot+Becomes+Autopilot%3A+Generative+AI%E2%80%99s+Critical+Risk+to+Knowledge+Work+and+a+Critical+Solution&author=Advait+Sarkar&author=Xiaotong%C2%A0%28Tone%29+Xu&author=Neil+Toronto&author=Ian+Drosos&author=Christian+Poelitz&publication_year=2024)\n\n\\[120\\]\n\nUlrike Schultze. 2000. A confessional account of an ethnography about knowledge work. _MIS quarterly_ (2000), 3–41.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=A+confessional+account+of+an+ethnography+about+knowledge+work&author=Ulrike+Schultze&publication_year=2000&pages=3-41)\n\n\\[121\\]\n\nCarol Sherrard. 1986. Summary writing: A topographical study. _Written Communication_ 3, 3 (1986), 324–343.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Summary+writing%3A+A+topographical+study&author=Carol+Sherrard&publication_year=1986&pages=324-343)\n\n\\[122\\]\n\nAuste Simkute, Lev Tankelevitch, Viktor Kewenig, Ava Elizabeth Scott, Abigail Sellen, and Sean Rintel. 2024. Ironies of Generative AI: Understanding and Mitigating Productivity Loss in Human-AI Interaction. _International Journal of Human–Computer Interaction_ (2024), 1–22.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Ironies+of+Generative+AI%3A+Understanding+and+Mitigating+Productivity+Loss+in+Human-AI+Interaction&author=Auste+Simkute&author=Lev+Tankelevitch&author=Viktor+Kewenig&author=Ava%C2%A0Elizabeth+Scott&author=Abigail+Sellen&author=Sean+Rintel&publication_year=2024&pages=1-22)\n\n\\[123\\]\n\nJared Spataro. 2023. Introducing Microsoft 365 Copilot – your copilot for work. _[https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/](https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/)_. Retrieved July 10, 2023.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Introducing+Microsoft+365+Copilot+%E2%80%93+your+copilot+for+work&author=Jared+Spataro&publication_year=2023)\n\n\\[124\\]\n\nArie S Spirgel and Peter F Delaney. 2016. Does writing summaries improve memory for text? _Educational Psychology Review_ 28 (2016), 171–196.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Does+writing+summaries+improve+memory+for+text%3F&author=Arie%C2%A0S+Spirgel&author=Peter%C2%A0F+Delaney&publication_year=2016&pages=171-196)\n\n\\[125\\]\n\nTom Stafford, Herman Elgueta, and Harriet Cameron. 2014. Students’ engagement with a collaborative wiki tool predicts enhanced written exam performance. _Research in Learning Technology_ 22 (2014).\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Students%E2%80%99+engagement+with+a+collaborative+wiki+tool+predicts+enhanced+written+exam+performance&author=Tom+Stafford&author=Herman+Elgueta&author=Harriet+Cameron&publication_year=2014)\n\n\\[126\\]\n\nNa Sun, Chien Wen (Tina) Yuan, Mary Beth Rosson, Yu Wu, and Jack M. Carroll. 2017. Critical Thinking in Collaboration: Talk Less, Perceive More. In _Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems_ (Denver, Colorado, USA) ( _CHI EA ’17_). Association for Computing Machinery, New York, NY, USA, 2944–2950.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3027063.3053250)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Critical+Thinking+in+Collaboration%3A+Talk+Less%2C+Perceive+More&author=Na+Sun&author=Chien+Wen%C2%A0%28Tina%29+Yuan&author=Mary%C2%A0Beth+Rosson&author=Yu+Wu&author=Jack%C2%A0M.+Carroll&publication_year=2017&pages=2944-2950&doi=10.1145%2F3027063.3053250)\n\n\\[127\\]\n\nShakti Swaminathan et al. 2020. Digital amnesia: The smart phone and the modern Indian student. _Journal of Humanities and Social Sciences Studies_ 2, 3 (2020), 23–31.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Digital+amnesia%3A+The+smart+phone+and+the+modern+Indian+student&author=Shakti+Swaminathan&publication_year=2020&pages=23-31)\n\n\\[128\\]\n\nElham Tajik and Fatemeh Tajik. 2023. A comprehensive Examination of the potential application of Chat GPT in Higher Education Institutions. (2023).\n\n[Crossref](https://doi.org/10.36227/techrxiv.22589497.v1)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=A+comprehensive+Examination+of+the+potential+application+of+Chat+GPT+in+Higher+Education+Institutions&author=Elham+Tajik&author=Fatemeh+Tajik&publication_year=2023&doi=10.36227%2Ftechrxiv.22589497.v1)\n\n\\[129\\]\n\nHaoheng Tang and Mrinalini Singha. 2024. A Mystery for You: A fact-checking game enhanced by large language models (LLMs) and a tangible interface. In _Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems_( _CHI EA ’24_). Association for Computing Machinery, New York, NY, USA, Article 631, 5 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613905.3648110)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=A+Mystery+for+You%3A+A+fact-checking+game+enhanced+by+large+language+models+%28LLMs%29+and+a+tangible+interface&author=Haoheng+Tang&author=Mrinalini+Singha&publication_year=2024&doi=10.1145%2F3613905.3648110)\n\n\\[130\\]\n\nLev Tankelevitch, Viktor Kewenig, Auste Simkute, Ava Elizabeth Scott, Advait Sarkar, Abigail Sellen, and Sean Rintel. 2024. The Metacognitive Demands and Opportunities of Generative AI. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 680, 24 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642902)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+Metacognitive+Demands+and+Opportunities+of+Generative+AI&author=Lev+Tankelevitch&author=Viktor+Kewenig&author=Auste+Simkute&author=Ava%C2%A0Elizabeth+Scott&author=Advait+Sarkar&author=Abigail+Sellen&author=Sean+Rintel&publication_year=2024&doi=10.1145%2F3613904.3642902)\n\n\\[131\\]\n\nThitaree Tanprasert, Sidney S Fels, Luanne Sinnamon, and Dongwook Yoon. 2024. Debate Chatbots to Facilitate Critical Thinking on YouTube: Social Identity and Conversational Style Make A Difference. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 805, 24 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642513)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Debate+Chatbots+to+Facilitate+Critical+Thinking+on+YouTube%3A+Social+Identity+and+Conversational+Style+Make+A+Difference&author=Thitaree+Tanprasert&author=Sidney%C2%A0S+Fels&author=Luanne+Sinnamon&author=Dongwook+Yoon&publication_year=2024&doi=10.1145%2F3613904.3642513)\n\n\\[132\\]\n\nJordi Tost, Marcel Gohsen, Britta Schulte, Fidel Thomet, Mattis Kuhn, Johannes Kiesel, Benno Stein, and Eva Hornecker. 2024. Futuring Machines: An Interactive Framework for Participative Futuring Through Human-AI Collaborative Speculative Fiction Writing. In _Proceedings of the 6th ACM Conference on Conversational User Interfaces_ (Luxembourg, Luxembourg) ( _CUI ’24_). Association for Computing Machinery, New York, NY, USA, Article 42, 7 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3640794.3665904)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Futuring+Machines%3A+An+Interactive+Framework+for+Participative+Futuring+Through+Human-AI+Collaborative+Speculative+Fiction+Writing&author=Jordi+Tost&author=Marcel+Gohsen&author=Britta+Schulte&author=Fidel+Thomet&author=Mattis+Kuhn&author=Johannes+Kiesel&author=Benno+Stein&author=Eva+Hornecker&publication_year=2024&doi=10.1145%2F3640794.3665904)\n\n\\[133\\]\n\nChun-Yen Tsai, Chih-Neng Lin, Wen-Ling Shih, and Pai-Lu Wu. 2015. The effect of online argumentation upon students’ pseudoscientific beliefs. _Computers & Education_ 80 (2015), 187–197.\n\n[Digital Library](https://dl.acm.org/doi/10.1016/j.compedu.2014.08.018)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+effect+of+online+argumentation+upon+students%E2%80%99+pseudoscientific+beliefs&author=Chun-Yen+Tsai&author=Chih-Neng+Lin&author=Wen-Ling+Shih&author=Pai-Lu+Wu&publication_year=2015&pages=187-197&doi=10.1016%2Fj.compedu.2014.08.018)\n\n\\[134\\]\n\nDavid Wade-Stein and Eileen Kintsch. 2004. Summary Street: Interactive computer support for writing. _Cognition and instruction_ 22, 3 (2004), 333–362.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Summary+Street%3A+Interactive+computer+support+for+writing&author=David+Wade-Stein&author=Eileen+Kintsch&publication_year=2004&pages=333-362)\n\n\\[135\\]\n\nThiemo Wambsganss, Christina Niklaus, Matthias Cetto, Matthias Söllner, Siegfried Handschuh, and Jan Marco Leimeister. 2021. ArgueTutor: An Adaptive Dialog-Based Learning System for Argumentation Skills. In _Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems_. ACM.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3411764.3445781)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=ArgueTutor%3A+An+Adaptive+Dialog-Based+Learning+System+for+Argumentation+Skills&author=Thiemo+Wambsganss&author=Christina+Niklaus&author=Matthias+Cetto&author=Matthias+S%C3%B6llner&author=Siegfried+Handschuh&author=Jan%C2%A0Marco+Leimeister&publication_year=2021&doi=10.1145%2F3411764.3445781)\n\n\\[136\\]\n\nGe Wang, Jun Zhao, Konrad Kollnig, Adrien Zier, Blanche Duron, Zhilin Zhang, Max Van Kleek, and Nigel Shadbolt. 2024. KOALA Hero Toolkit: A New Approach to Inform Families of Mobile Datafication Risks. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 226, 18 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642283)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=KOALA+Hero+Toolkit%3A+A+New+Approach+to+Inform+Families+of+Mobile+Datafication+Risks&author=Ge+Wang&author=Jun+Zhao&author=Konrad+Kollnig&author=Adrien+Zier&author=Blanche+Duron&author=Zhilin+Zhang&author=Max+Van%C2%A0Kleek&author=Nigel+Shadbolt&publication_year=2024&doi=10.1145%2F3613904.3642283)\n\n\\[137\\]\n\nYingxu Wang and Vincent Chiew. 2010. On the cognitive process of human problem solving. _Cognitive systems research_ 11, 1 (2010), 81–92.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=On+the+cognitive+process+of+human+problem+solving&author=Yingxu+Wang&author=Vincent+Chiew&publication_year=2010&pages=81-92)\n\n\\[138\\]\n\nDaniel T. Willingham. 2008. Critical Thinking: Why Is It So Hard to Teach? _Arts Education Policy Review_ 109, 4 (2008), 21–32. arXiv:\n\n[Crossref](https://doi.org/10.3200/AEPR.109.4.21-32)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Critical+Thinking%3A+Why+Is+It+So+Hard+to+Teach%3F&author=Daniel%C2%A0T.+Willingham&publication_year=2008&pages=21-32&doi=10.3200%2FAEPR.109.4.21-32)\n\n\\[139\\]\n\nDonna Wilson and Marcus Conyers. 2016. _Teaching students to drive their brains: Metacognitive strategies, activities, and lesson ideas_. Ascd.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Teaching+students+to+drive+their+brains%3A+Metacognitive+strategies%2C+activities%2C+and+lesson+ideas&author=Donna+Wilson&author=Marcus+Conyers&publication_year=2016)\n\n\\[140\\]\n\nPeter N Winograd. 1984. Strategic difficulties in summarizing texts. _Reading research quarterly_ (1984), 404–425.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Strategic+difficulties+in+summarizing+texts&author=Peter%C2%A0N+Winograd&publication_year=1984&pages=404-425)\n\n\\[141\\]\n\nShunYi Yeo, Gionnieve Lim, Jie Gao, Weiyu Zhang, and Simon Tangi Perrault. 2024. Help Me Reflect: Leveraging Self-Reflection Interface Nudges to Enhance Deliberativeness on Online Deliberation Platforms. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 806, 32 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642530)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Help+Me+Reflect%3A+Leveraging+Self-Reflection+Interface+Nudges+to+Enhance+Deliberativeness+on+Online+Deliberation+Platforms&author=ShunYi+Yeo&author=Gionnieve+Lim&author=Jie+Gao&author=Weiyu+Zhang&author=Simon%C2%A0Tangi+Perrault&publication_year=2024&doi=10.1145%2F3613904.3642530)\n\n\\[142\\]\n\nKangyu Yuan, Hehai Lin, Shilei Cao, Zhenhui Peng, Qingyu Guo, and Xiaojuan Ma. 2023. CriTrainer: An Adaptive Training Tool for Critical Paper Reading. In _Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology_ (San Francisco, CA, USA) ( _UIST ’23_). Association for Computing Machinery, New York, NY, USA, Article 44, 17 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3586183.3606816)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=CriTrainer%3A+An+Adaptive+Training+Tool+for+Critical+Paper+Reading&author=Kangyu+Yuan&author=Hehai+Lin&author=Shilei+Cao&author=Zhenhui+Peng&author=Qingyu+Guo&author=Xiaojuan+Ma&publication_year=2023&doi=10.1145%2F3586183.3606816)\n\n\\[143\\]\n\nLiudmila Zavolokina, Kilian Sprenkamp, Zoya Katashinskaya, Daniel Gordon Jones, and Gerhard Schwabe. 2024. Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool. In _Proceedings of the CHI Conference on Human Factors in Computing Systems_ (Honolulu, HI, USA) ( _CHI ’24_). Association for Computing Machinery, New York, NY, USA, Article 491, 24 pages.\n\n[Digital Library](https://dl.acm.org/doi/10.1145/3613904.3642805)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Think+Fast%2C+Think+Slow%2C+Think+Critical%3A+Designing+an+Automated+Propaganda+Detection+Tool&author=Liudmila+Zavolokina&author=Kilian+Sprenkamp&author=Zoya+Katashinskaya&author=Daniel%C2%A0Gordon+Jones&author=Gerhard+Schwabe&publication_year=2024&doi=10.1145%2F3613904.3642805)\n\n\\[144\\]\n\nOlaf Zawacki-Richter, Victoria I Marín, Melissa Bond, and Franziska Gouverneur. 2019. Systematic review of research on artificial intelligence applications in higher education–where are the educators? _International Journal of Educational Technology in Higher Education_ 16, 1 (2019), 39.\n\n[Crossref](https://doi.org/10.1186/s41239-019-0171-0)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Systematic+review+of+research+on+artificial+intelligence+applications+in+higher+education%E2%80%93where+are+the+educators%3F&author=Olaf+Zawacki-Richter&author=Victoria%C2%A0I+Mar%C3%ADn&author=Melissa+Bond&author=Franziska+Gouverneur&publication_year=2019&pages=39&doi=10.1186%2Fs41239-019-0171-0)\n\n\\[145\\]\n\nEsperanza Zuriguel-Pérez, Anna Falcó-Pegueroles, Juan Roldán-Merino, Sandra Agustino-Rodriguez, Maria del Carmen Gómez-Martín, and Maria Teresa Lluch-Canut. 2017. Development and psychometric properties of the nursing critical thinking in clinical practice questionnaire. _Worldviews on Evidence-Based Nursing_ 14, 4 (2017), 257–264.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Development+and+psychometric+properties+of+the+nursing+critical+thinking+in+clinical+practice+questionnaire&author=Esperanza+Zuriguel-P%C3%A9rez&author=Anna+Falc%C3%B3-Pegueroles&author=Juan+Rold%C3%A1n-Merino&author=Sandra+Agustino-Rodriguez&author=Maria+del%C2%A0Carmen+G%C3%B3mez-Mart%C3%ADn&author=Maria%C2%A0Teresa+Lluch-Canut&publication_year=2017&pages=257-264)\n\n\\[146\\]\n\nEsperanza Zuriguel-Pérez, María-Teresa Lluch-Canut, Montserrat Puig-Llobet, Luis Basco-Prado, Adrià Almazor-Sirvent, Ainoa Biurrun-Garrido, Mariela Patricia Aguayo-González, Olga Mestres-Soler, and Juan Roldán-Merino. 2022. The nursing critical thinking in clinical practice questionnaire for nursing students: A psychometric evaluation study. _Nurse Education in Practice_ 65 (2022), 103498.\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+nursing+critical+thinking+in+clinical+practice+questionnaire+for+nursing+students%3A+A+psychometric+evaluation+study&author=Esperanza+Zuriguel-P%C3%A9rez&author=Mar%C3%ADa-Teresa+Lluch-Canut&author=Montserrat+Puig-Llobet&author=Luis+Basco-Prado&author=Adri%C3%A0+Almazor-Sirvent&author=Ainoa+Biurrun-Garrido&author=Mariela%C2%A0Patricia+Aguayo-Gonz%C3%A1lez&author=Olga+Mestres-Soler&author=Juan+Rold%C3%A1n-Merino&publication_year=2022&pages=103498)\n\n## Cited By\n\n[View all](https://dl.acm.org/action/ajaxShowCitedBy?doi=10.1145/3706598.3713778)\n\n- Korsah GAdjei JMensah JArthur LAriff AAwuah RTshukudu ECraig MMann S(2025)The Impact of Artificial Intelligence on Higher Education: Perspectives and Insights from Computer Science Faculty and Students in GhanaProceedings of the ACM Global on Computing Education Conference 2025 Vol 110.1145/3736181.3747154(85-91)Online publication date: 21-Oct-2025\n[https://dl.acm.org/doi/10.1145/3736181.3747154](https://dl.acm.org/doi/10.1145/3736181.3747154)\n\n- Chaker R(2025)\nIntegrating Distributed Cognition and Culturally Responsive Pedagogy Frameworks for\nAI\nin Early Childhood Preservice Teacher Training: Toward a Culturally Responsive Educational\nAI\n(\nCREAI\n)\nAI in Early Education10.1002/9781394352821.ch01(1-20)Online publication date: 16-Oct-2025\n[https://doi.org/10.1002/9781394352821.ch01](https://doi.org/10.1002/9781394352821.ch01)\n\n- Zepf SColley M(2025)Human Authenticity and Flourishing in an AI-Driven World: Edmund's Journey and the Call for MindfulnessProceedings of the 27th International Conference on Multimodal Interaction10.1145/3716553.3750736(693-698)Online publication date: 13-Oct-2025\n[https://dl.acm.org/doi/10.1145/3716553.3750736](https://dl.acm.org/doi/10.1145/3716553.3750736)\n\n- [Show More Cited By](javascript:void(0))\n\n## Index Terms\n\n1. The Impact of Generative AI on Critical Thinking: Self-Reported Reductions in Cognitive Effort and Confidence Effects From a Survey of Knowledge Workers\n\n1. [Human-centered computing](https://dl.acm.org/topic/ccs2012/10003120?ContentGroupKey=10.1145%2F3706598&expand=all)\n\n\n\n 1. [Human computer interaction (HCI)](https://dl.acm.org/topic/ccs2012/10003120.10003121?ContentGroupKey=10.1145%2F3706598&expand=all)\n\n\n\n 1. [Empirical studies in HCI](https://dl.acm.org/topic/ccs2012/10003120.10003121.10011748?ContentGroupKey=10.1145%2F3706598&expand=all)\n\n## Recommendations\n\n- [**Mathematical Critical Thinking and Creative Thinking Skills: How Does Their Relationship Influence Mathematical Achievement?**](https://dl.acm.org/doi/10.1145/3348400.3348408)\n\nICMSTTL 2019: Proceedings of the 2019 International Conference on Mathematics, Science and Technology Teaching and Learning\n\n\n\n\n\nThis paper examines the correlation of mathematical critical thinking and creative\nthinking skills towards students' mathematical achievements. A total of 115 eighth\ngrade students from three schools in Sleman Regency were involved as the subject of\n...\n\n\n\n\n\n[Read More](https://dl.acm.org/doi/10.1145/3348400.3348408)\n\n- [**Cultivating independent thinkers: The triad of artificial intelligence, Bloom’s taxonomy and critical thinking in assessment pedagogy**](https://dl.acm.org/doi/10.1007/s10639-025-13476-x)\n\nAbstract\n\nAmalgamating generative artificial intelligence (Gen AI), Bloom’s taxonomy and critical\nthinking present a promising avenue to revolutionize assessment pedagogy and foster\nhigher-order cognitive skills needed for learning autonomy in the domain of ...\n\n\n\n\n\n[Read More](https://dl.acm.org/doi/10.1007/s10639-025-13476-x)\n\n- [**The impact of smart learning technologies on students’ cognitive competence: enhancing critical thinking**](https://dl.acm.org/doi/10.1007/s10639-024-13250-5)\n\nAbstract\n\nThe research investigates the impact of smart learning technologies (SLTs) on students’\ncritical thinking (CT). It pays special attention to the increased digitalisation\nof education and the need to develop key cognitive skills in students in the ...\n\n\n\n\n\n[Read More](https://dl.acm.org/doi/10.1007/s10639-024-13250-5)\n\n\n## Comments\n\n### Information\n\n#### Published In\n\nCHI '25: Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems\n\nApril 2025\n\n23705 pages\n\nISBN:9798400713941\n\nDOI:10.1145/3706598\n\n- **Editors:**\n- [Naomi Yamashita](https://dl.acm.org/profile/99661567625)\nKyoto University / NTT,\n\n- [Vanessa Evers](https://dl.acm.org/profile/81100133286)\nUniversity of Twente / Nanyang Technological University,\n\n- [Koji Yatani](https://dl.acm.org/profile/81100158260)\nThe University of Tokyo,\n\n- [Xianghua (Sharon) Ding](https://dl.acm.org/profile/99661566428)\nUniversity of Glasgow,\n\n- [Bongshin Lee](https://dl.acm.org/profile/99661567600)\nYonsei University,\n\n- [Marshini Chetty](https://dl.acm.org/profile/99661569005)\nUniversity of Chicago,\n\n- [Phoebe Toups-Dugas](https://dl.acm.org/profile/99661640401)\nMonash University\n\n\nCopyright © 2025 Copyright held by the owner/author(s).\n\nThis work is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/).\n\n#### Sponsors\n\n- [SIGCHI: ACM Special Interest Group on Computer-Human Interaction](https://dl.acm.org/sig/sigchi)\n\n#### Publisher\n\nAssociation for Computing Machinery\n\nNew York, NY, United States\n\n#### Publication History\n\n**Published**: 25 April 2025\n\n#### Check for updates\n\n#### Author Tags\n\n1. [Critical thinking](https://dl.acm.org/keyword/Critical+thinking?expand=all)\n2. [Generative AI tools](https://dl.acm.org/keyword/Generative+AI+tools?expand=all)\n3. [Knowledge worker](https://dl.acm.org/keyword/Knowledge+worker?expand=all)\n4. [Bloom’s taxonomy](https://dl.acm.org/keyword/Bloom%E2%80%99s+taxonomy?expand=all)\n5. [Survey](https://dl.acm.org/keyword/Survey?expand=all)\n\n#### Qualifiers\n\n- Research-article\n\n#### Conference\n\nCHI '25\n\nSponsor:\n\n- [SIGCHI](https://dl.acm.org/sig/sigchi)\n\n[CHI 2025: CHI Conference on Human Factors in Computing Systems](https://chi2025.acm.org/)\n\nApril 26 - May 1, 2025\n\nYokohama, Japan\n\n#### Acceptance Rates\n\nOverall Acceptance Rate 6,199 of 26,314 submissions, 24%\n\n#### Upcoming Conference\n\nCHI '26\n\n- **Sponsor:**\n- [sigchi](https://dl.acm.org/sig/sigchi)\n\n[ACM CHI Conference on Human Factors in Computing Systems](https://dl.acm.org/conference/chi)\n\nApril 13 - 17, 2026\n\nBarcelona ,\nSpain\n\n### Contributors\n\n#### Other Metrics\n\n[View Article Metrics](https://dl.acm.org/dl.acm.org#tab-metrics-inner)\n\n### Bibliometrics\n\n#### Article Metrics\n\n- 67\n\nTotal Citations\n[View Citations](https://dl.acm.org/dl.acm.org#tab-citations)\n- 28,754\n\nTotal Downloads\n\n\n- Downloads (Last 12 months)28,754\n- Downloads (Last 6 weeks)8,229\n\nReflects downloads up to 13 Oct 2025\n\n#### Other Metrics\n\n[View Author Metrics](https://dl.acm.org/dl.acm.org#tab-contributors)\n\n### Citations\n\n## Cited By\n\n[View all](https://dl.acm.org/action/ajaxShowCitedBy?doi=10.1145/3706598.3713778)\n\n- Korsah GAdjei JMensah JArthur LAriff AAwuah RTshukudu ECraig MMann S(2025)The Impact of Artificial Intelligence on Higher Education: Perspectives and Insights from Computer Science Faculty and Students in GhanaProceedings of the ACM Global on Computing Education Conference 2025 Vol 110.1145/3736181.3747154(85-91)Online publication date: 21-Oct-2025\n[https://dl.acm.org/doi/10.1145/3736181.3747154](https://dl.acm.org/doi/10.1145/3736181.3747154)\n\n- Chaker R(2025)\nIntegrating Distributed Cognition and Culturally Responsive Pedagogy Frameworks for\nAI\nin Early Childhood Preservice Teacher Training: Toward a Culturally Responsive Educational\nAI\n(\nCREAI\n)\nAI in Early Education10.1002/9781394352821.ch01(1-20)Online publication date: 16-Oct-2025\n[https://doi.org/10.1002/9781394352821.ch01](https://doi.org/10.1002/9781394352821.ch01)\n\n- Zepf SColley M(2025)Human Authenticity and Flourishing in an AI-Driven World: Edmund's Journey and the Call for MindfulnessProceedings of the 27th International Conference on Multimodal Interaction10.1145/3716553.3750736(693-698)Online publication date: 13-Oct-2025\n[https://dl.acm.org/doi/10.1145/3716553.3750736](https://dl.acm.org/doi/10.1145/3716553.3750736)\n\n- Giakatos DTashiro MFontugne R(2025)Pythia: Facilitating Access to Internet Data Using LLMs and IYP2025 IEEE 50th Conference on Local Computer Networks (LCN)10.1109/LCN65610.2025.11146364(1-7)Online publication date: 13-Oct-2025\n[https://doi.org/10.1109/LCN65610.2025.11146364](https://doi.org/10.1109/LCN65610.2025.11146364)\n\n- Gerlich M(2025)Outsourcing Judgment: Hidden Anxieties and the Rise of Cognitive Offloading in the Age of AITechnology and Society - Boon or Bane?10.1007/978-3-032-07163-7\\_3(44-58)Online publication date: 8-Oct-2025\n[https://doi.org/10.1007/978-3-032-07163-7\\_3](https://doi.org/10.1007/978-3-032-07163-7_3)\n\n- Schulze Heuling DJakobi ASchaal GGerlich M(2025)Generative KI und (politik)wissenschaftliches Schreiben: Herausforderung für die Lehre und darüber hinausPolitische Vierteljahresschrift10.1007/s11615-025-00631-9Online publication date: 7-Oct-2025\n[https://doi.org/10.1007/s11615-025-00631-9](https://doi.org/10.1007/s11615-025-00631-9)\n\n- Rickmann JTröster V(2025)Safeguarding Medical Decision Quality in the Age of AI – A Practice Report from Medical Risk and Claims Assessment in a Life Insurance CompanyZeitschrift für die gesamte Versicherungswissenschaft10.3790/zverswiss.2025.1469701(1-12)Online publication date: 6-Oct-2025\n[https://doi.org/10.3790/zverswiss.2025.1469701](https://doi.org/10.3790/zverswiss.2025.1469701)\n\n- Tahri Sqalli M(2025)Eyes on the Code: Mapping Critical Thinking Through Eye-Tracking for Student-LLM Coding InteractionsProceedings of the 16th Biannual Conference of the Italian SIGCHI Chapter10.1145/3750069.3750397(1-13)Online publication date: 6-Oct-2025\n[https://dl.acm.org/doi/10.1145/3750069.3750397](https://dl.acm.org/doi/10.1145/3750069.3750397)\n\n- Williams RWilliams R(2025)Social Stratification Engines and the Ideology of ReplacementDisabling Intelligences10.1007/978-3-032-02665-1\\_4(73-106)Online publication date: 1-Oct-2025\n[https://doi.org/10.1007/978-3-032-02665-1\\_4](https://doi.org/10.1007/978-3-032-02665-1_4)\n\n- Urquieta JHorne J(2025)The Philosophical Challenges of AI: Initial ConsiderationsArtificial Intelligence – COMIA 202510.1007/978-3-031-97907-1\\_24(302-312)Online publication date: 1-Oct-2025\n[https://doi.org/10.1007/978-3-031-97907-1\\_24](https://doi.org/10.1007/978-3-031-97907-1_24)\n\n- [Show More Cited By](javascript:void(0))\n\n### View options\n\n#### PDF\n\nView or Download as a PDF file.\n\n[PDF](https://dl.acm.org/doi/pdf/10.1145/3706598.3713778)\n\n#### eReader\n\nView online with eReader.\n\n[eReader](https://dl.acm.org/doi/epdf/10.1145/3706598.3713778)\n\n#### Login options\n\nCheck if you have access through your login credentials or your institution to get full access on this article.\n\n[Sign in](https://dl.acm.org/action/showLogin?redirectUri=%2Fdoi%2F10.1145%2F3706598.3713778)\n\n#### Full Access\n\n[Get this Publication](https://dl.acm.org/action/publisherEcommerceHelper?doi=10.1145/3706598.3713778&redirectUri=https://dl.acm.org/doi/10.1145/3706598.3713778)\n\n### Share\n\n#### Share this Publication link\n\nCopy Link\n\nCopied!\n\nCopying failed.\n\n#### Share on social media\n\n[X](https://dl.acm.org/dl.acm.org) [LinkedIn](https://dl.acm.org/dl.acm.org) [Reddit](https://dl.acm.org/dl.acm.org) [Facebook](https://dl.acm.org/dl.acm.org) [email](https://dl.acm.org/dl.acm.org)\n\n#### Affiliations\n\nHao-Ping (Hank)Lee\n\nCarnegie Mellon University, Pittsburgh, Pennsylvania, USA [haopingl@cs.cmu.edu](mailto:haopingl@cs.cmu.edu)\n\n[https://orcid.org/0000-0002-8063-1034](https://orcid.org/0000-0002-8063-1034)\n\n[View Profile](https://dl.acm.org/profile/99661040773)\n\nAdvaitSarkar\n\nMicrosoft Research, Cambridge, United Kingdom [advait@microsoft.com](mailto:advait@microsoft.com)\n\n[https://orcid.org/0000-0002-5401-3478](https://orcid.org/0000-0002-5401-3478)\n\n[View Profile](https://dl.acm.org/profile/99659349360)\n\nLevTankelevitch\n\nMicrosoft Research, Cambridge, United Kingdom [levt@microsoft.com](mailto:levt@microsoft.com)\n\n[https://orcid.org/0000-0003-1286-5194](https://orcid.org/0000-0003-1286-5194)\n\n[View Profile](https://dl.acm.org/profile/99660779127)\n\nIanDrosos\n\nMicrosoft Research, Cambridge, United Kingdom [t-iandrosos@microsoft.com](mailto:t-iandrosos@microsoft.com)\n\n[https://orcid.org/0000-0003-3475-2609](https://orcid.org/0000-0003-3475-2609)\n\n[View Profile](https://dl.acm.org/profile/99659285356)\n\nSeanRintel\n\nMicrosoft Research, Cambridge, United Kingdom [serintel@microsoft.com](mailto:serintel@microsoft.com)\n\n[https://orcid.org/0000-0003-0840-0546](https://orcid.org/0000-0003-0840-0546)\n\n[View Profile](https://dl.acm.org/profile/81556330456)\n\nRichardBanks\n\nMicrosoft Research Cambridge, Cambridge, United Kingdom [rbanks@microsoft.com](mailto:rbanks@microsoft.com)\n\n[https://orcid.org/0009-0004-5239-2701](https://orcid.org/0009-0004-5239-2701)\n\n[View Profile](https://dl.acm.org/profile/99661563585)\n\nNicholasWilson\n\nMicrosoft Research, Cambridge, United Kingdom [niwilson@microsoft.com](mailto:niwilson@microsoft.com)\n\n[https://orcid.org/0000-0001-8566-9720](https://orcid.org/0000-0001-8566-9720)\n\n[View Profile](https://dl.acm.org/profile/99661569167)\n\n[View full text](https://dl.acm.org/doi/full/10.1145/3706598.3713778) \\| [Download PDF](https://dl.acm.org/doi/pdf/10.1145/3706598.3713778?download=true)\n\n[View Table of Contents](https://dl.acm.org/doi/proceedings/10.1145/3706598)\n\nYour Search Results Download Request\n\nWe are preparing your search results for download ...\n\nWe will inform you here when the file is ready.\n\n[Download now!](https://dl.acm.org/dl.acm.org)\n\nYour Search Results Download Request\n\nYour file of search results citations is now ready.\n\n[Download now!](https://dl.acm.org/dl.acm.org)\n\nYour Search Results Download Request\n\nYour search export query has expired. Please try again."}
{"title": "Effects of generative artificial intelligence (GenAI) patient ...", "content": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#main-content)\n\n**Official websites use .gov**\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n**Secure .gov websites use HTTPS**\nA **lock** (\n\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC\n\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nBMC Nurs\n\n. 2025 Jul 17;24:934. doi: [10.1186/s12912-025-03492-0](https://doi.org/10.1186/s12912-025-03492-0)\n\n# Effects of generative artificial intelligence (GenAI) patient simulation on perceived clinical competency among global nursing undergraduates: a cross-over randomised controlled trial\n\n[Tai Chun John Fung](https://pubmed.ncbi.nlm.nih.gov/?term=%22Fung%20TCJ%22%5BAuthor%5D)\n\n### Tai Chun John Fung\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\nFind articles by [Tai Chun John Fung](https://pubmed.ncbi.nlm.nih.gov/?term=%22Fung%20TCJ%22%5BAuthor%5D)\n\n1,✉, [Siu Ling Chan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Chan%20SL%22%5BAuthor%5D)\n\n### Siu Ling Chan\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\nFind articles by [Siu Ling Chan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Chan%20SL%22%5BAuthor%5D)\n\n1, [Choi Fung Mabel Lam](https://pubmed.ncbi.nlm.nih.gov/?term=%22Lam%20CFM%22%5BAuthor%5D)\n\n### Choi Fung Mabel Lam\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\nFind articles by [Choi Fung Mabel Lam](https://pubmed.ncbi.nlm.nih.gov/?term=%22Lam%20CFM%22%5BAuthor%5D)\n\n1, [Chung Yan Lam](https://pubmed.ncbi.nlm.nih.gov/?term=%22Lam%20CY%22%5BAuthor%5D)\n\n### Chung Yan Lam\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\nFind articles by [Chung Yan Lam](https://pubmed.ncbi.nlm.nih.gov/?term=%22Lam%20CY%22%5BAuthor%5D)\n\n1, [Christopher Chi Wai Cheng](https://pubmed.ncbi.nlm.nih.gov/?term=%22Cheng%20CCW%22%5BAuthor%5D)\n\n### Christopher Chi Wai Cheng\n\n3The Chinese University of Hong Kong, Hong Kong, Hong Kong SAR\n\nFind articles by [Christopher Chi Wai Cheng](https://pubmed.ncbi.nlm.nih.gov/?term=%22Cheng%20CCW%22%5BAuthor%5D)\n\n3, [Man Hin Lai](https://pubmed.ncbi.nlm.nih.gov/?term=%22Lai%20MH%22%5BAuthor%5D)\n\n### Man Hin Lai\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\nFind articles by [Man Hin Lai](https://pubmed.ncbi.nlm.nih.gov/?term=%22Lai%20MH%22%5BAuthor%5D)\n\n1, [Cheuk Chun Joseph Ho](https://pubmed.ncbi.nlm.nih.gov/?term=%22Ho%20CCJ%22%5BAuthor%5D)\n\n### Cheuk Chun Joseph Ho\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\nFind articles by [Cheuk Chun Joseph Ho](https://pubmed.ncbi.nlm.nih.gov/?term=%22Ho%20CCJ%22%5BAuthor%5D)\n\n1, [Siu Lun Au](https://pubmed.ncbi.nlm.nih.gov/?term=%22Au%20SL%22%5BAuthor%5D)\n\n### Siu Lun Au\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\nFind articles by [Siu Lun Au](https://pubmed.ncbi.nlm.nih.gov/?term=%22Au%20SL%22%5BAuthor%5D)\n\n1, [Lok Yi Mak](https://pubmed.ncbi.nlm.nih.gov/?term=%22Mak%20LY%22%5BAuthor%5D)\n\n### Lok Yi Mak\n\n4Hong Kong Baptist University, Hong Kong, Hong Kong SAR\n\nFind articles by [Lok Yi Mak](https://pubmed.ncbi.nlm.nih.gov/?term=%22Mak%20LY%22%5BAuthor%5D)\n\n4, [Sophia Hu](https://pubmed.ncbi.nlm.nih.gov/?term=%22Hu%20S%22%5BAuthor%5D)\n\n### Sophia Hu\n\n5National Yang Ming Chiao Tung University, Taipei, Taiwan\n\nFind articles by [Sophia Hu](https://pubmed.ncbi.nlm.nih.gov/?term=%22Hu%20S%22%5BAuthor%5D)\n\n5, [Supapak Phetrasuwan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Phetrasuwan%20S%22%5BAuthor%5D)\n\n### Supapak Phetrasuwan\n\n6Faculty of Nursing, Mahidol University, Bangkok, Thailand\n\nFind articles by [Supapak Phetrasuwan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Phetrasuwan%20S%22%5BAuthor%5D)\n\n6, [Jumpee Granger](https://pubmed.ncbi.nlm.nih.gov/?term=%22Granger%20J%22%5BAuthor%5D)\n\n### Jumpee Granger\n\n7Ramathibodi School of Nursing, Bangkok, Thailand\n\nFind articles by [Jumpee Granger](https://pubmed.ncbi.nlm.nih.gov/?term=%22Granger%20J%22%5BAuthor%5D)\n\n7, [Jung Min Yoon](https://pubmed.ncbi.nlm.nih.gov/?term=%22Yoon%20JM%22%5BAuthor%5D)\n\n### Jung Min Yoon\n\n8Ewha Womans University, Seoul, Republic of Korea\n\nFind articles by [Jung Min Yoon](https://pubmed.ncbi.nlm.nih.gov/?term=%22Yoon%20JM%22%5BAuthor%5D)\n\n8, [Gulzar Malik](https://pubmed.ncbi.nlm.nih.gov/?term=%22Malik%20G%22%5BAuthor%5D)\n\n### Gulzar Malik\n\n9School of Nursing and Midwifery, La Trobe University, Melbourne, Australia\n\nFind articles by [Gulzar Malik](https://pubmed.ncbi.nlm.nih.gov/?term=%22Malik%20G%22%5BAuthor%5D)\n\n9, [Clara Cabrera Moreno](https://pubmed.ncbi.nlm.nih.gov/?term=%22Moreno%20CC%22%5BAuthor%5D)\n\n### Clara Cabrera Moreno\n\n10University of Navarra, Pamplona, Spain\n\nFind articles by [Clara Cabrera Moreno](https://pubmed.ncbi.nlm.nih.gov/?term=%22Moreno%20CC%22%5BAuthor%5D)\n\n10, [Man Hei Patrick Kwok](https://pubmed.ncbi.nlm.nih.gov/?term=%22Kwok%20MHP%22%5BAuthor%5D)\n\n### Man Hei Patrick Kwok\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\n2School of Health Sciences, Saint Francis University, Hong Kong, Hong Kong SAR\n\nFind articles by [Man Hei Patrick Kwok](https://pubmed.ncbi.nlm.nih.gov/?term=%22Kwok%20MHP%22%5BAuthor%5D)\n\n1,2, [Chia-Chin Lin](https://pubmed.ncbi.nlm.nih.gov/?term=%22Lin%20CC%22%5BAuthor%5D)\n\n### Chia-Chin Lin\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\nFind articles by [Chia-Chin Lin](https://pubmed.ncbi.nlm.nih.gov/?term=%22Lin%20CC%22%5BAuthor%5D)\n\n1,✉\n\n- Author information\n- Article notes\n- Copyright and License information\n\n1School of Nursing, Faculty of Medicine, University of Hong Kong, Hong Kong, Hong Kong SAR\n\n2School of Health Sciences, Saint Francis University, Hong Kong, Hong Kong SAR\n\n3The Chinese University of Hong Kong, Hong Kong, Hong Kong SAR\n\n4Hong Kong Baptist University, Hong Kong, Hong Kong SAR\n\n5National Yang Ming Chiao Tung University, Taipei, Taiwan\n\n6Faculty of Nursing, Mahidol University, Bangkok, Thailand\n\n7Ramathibodi School of Nursing, Bangkok, Thailand\n\n8Ewha Womans University, Seoul, Republic of Korea\n\n9School of Nursing and Midwifery, La Trobe University, Melbourne, Australia\n\n10University of Navarra, Pamplona, Spain\n\n✉\n\nCorresponding author.\n\nReceived 2025 Mar 18; Accepted 2025 Jun 26; Collection date 2025.\n\n© The Author(s) 2025\n\n**Open Access** This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit [http://creativecommons.org/licenses/by-nc-nd/4.0/](https://creativecommons.org/licenses/by-nc-nd/4.0/).\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC12272990  PMID: [40676632](https://pubmed.ncbi.nlm.nih.gov/40676632/)\n\n## Abstract\n\n### Background\n\nThis study compared scenario-based generative artificial intelligence (GenAI) patient simulation with immersive 360° virtual reality (VR) simulation in terms of perceived clinical competence, cultural awareness, AI readiness, and simulation effectiveness among nursing students.\n\n### Methods\n\nThis cross-over randomised controlled study design was conducted from June 2024 to August 2024. Forty-four undergraduate nursing students from years 1–3 were randomised to receive either GenAI patient simulation (Group B) or 360° VR simulation (Group A) with a one-week washout period. Five self-reported questionnaires were used to measure clinical competency: the Clinical Competence Questionnaire (CCQ), Cultural Awareness Scale (CAS), Medical Artificial Intelligence Readiness Scale for Medical Students (MAIRS-MS), Simulation Effectiveness Tool – Modified Questionnaire (SET-M), and a demographic questionnaire.\n\n### Results\n\nBoth interventions significantly improved clinical competence, cultural awareness, and AI readiness. When administered first, GenAI patient simulation demonstrated greater initial effects on clinical competence and AI readiness compared to the 360° VR simulation, though both groups achieved similar improvements by study completion. At T1, Group B (receiving GenAI) demonstrated significantly larger improvements in CCQ total score \\[47.68 (95% CI: 36.68, 58.68), _p_ < 0.001\\] compared to Group A (receiving 360° VR) \\[24.95 (95% CI: 13.96, 35.95), _p_ < 0.001\\], with significant between-group difference \\[16.59 (95% CI: 2.77, 30.41), _p_ = 0.020\\]. At T2 (post-crossover), both groups maintained significant improvements. For MAIRS-MS (measured at baseline and following each group’s GenAI exposure), Group B showed improvement from baseline to T1 \\[30.18 (95% CI: 23.35, 37.01), _p_ < 0.001\\] while Group A showed improvement from baseline to T2 \\[16.64 (95% CI: 9.80, 23.47), _p_ < 0.001\\], with significant between-group difference \\[12.09 (95% CI: 4.43, 19.75), _p_ = 0.003\\]. Both groups experienced changes in CAS scores, though between-group differences were not statistically significant. For SET-M, most participants (75%) felt debriefing contributed to their learning, and 68.2% reported increased confidence in nursing assessment skills.\n\n### Conclusions\n\nThe findings provide preliminary evidence of its effectiveness in enhancing perceived clinical outcomes among nursing students. Both 360° VR simulation and GenAI patient simulation may serve as effective teaching tools; however, GenAI patient simulation appeared to demonstrate a greater initial effect on clinical competence and AI readiness, although both interventions proved effective across all measured domains.\n\n### Clinical trial registration/number\n\nNot applicable.\n\n**Keywords:** Generative artificial intelligence, Patient simulation, Clinical reasoning, 360-degree virtual reality, Clinical competence, Medical language, Nursing education, Randomised controlled trial\n\n## Introduction\n\nThe integration of artificial intelligence (AI) into healthcare has prompted a growing emphasis in the literature on the necessity of AI readiness among nursing students and professionals. AI readiness encompasses the knowledge, skills, and attitudes required for the practical application of AI in healthcare, including preventive measures, diagnostics, treatment, and comprehensive care delivery \\[ [1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR1)\\]. However, the potential for AI to perpetuate biases and adversely affect patient care has been noted, emphasizing the need for rigorous training and oversight \\[ [2](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR2)\\]. To mitigate these risks, nursing curricula should proactively foster AI readiness through targeted education on AI fundamentals, its strengths and limitations, and ethical considerations. The literature supports curricular innovations, such as dedicated coursework and simulation-based learning with GenAI, to build foundational AI readiness and reduce biases in healthcare \\[ [3](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR3), [4](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR4)\\]. Further research is needed to systematically evaluate various pedagogical approaches utilizing AI and their long-term effects.\n\n## Background\n\nThe increasing integration of artificial intelligence (AI) into healthcare has underscored the necessity for nursing students and professionals to develop AI readiness \\[ [5](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR5)\\]. This readiness is crucial, as AI technologies, including virtual reality (VR) and conversational agents, are becoming increasingly integral to nursing education, thereby enhancing learning experiences by providing immersive and interactive environments \\[ [6](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR6)\\]. Notably, 360° VR videos simulate health and social care scenarios that are typically inaccessible in traditional educational settings, thereby significantly improving communication skills and self-efficacy in AI-enabled simulations. However, concerns exist regarding AI’s perceived human-like qualities, which could impact the authenticity of these simulations \\[ [7](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR7), [8](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR8)\\].\n\nBuilding on this foundation, pilot studies have demonstrated that integrating 360° VR simulation with structured debriefing through learning management systems (LMS) can enhance students’ clinical competence and confidence in decision-making \\[ [9](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR9), [10](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR10)\\]. This approach not only fosters a deeper understanding of clinical scenarios but also prepares students for the complexities of AI-driven healthcare environments. The emergence of Generative AI (GenAI) patient simulation represents a novel trend in nursing education, necessitating targeted education on AI fundamentals, its strengths, limitations, and ethical considerations \\[ [11](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR11)\\].\n\nThe literature further emphasizes the importance of stakeholder engagement and a comprehensive understanding of AI’s clinical role \\[ [12](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR12)\\]. This includes integrating coursework that addresses AI biases, ensuring that future nurses are equipped to navigate the ethical and practical challenges posed by AI technologies \\[ [13](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR13)\\]. Nursing practice requires providing care to patients from diverse cultural backgrounds. However, there are concerns that unintentional biases inherent in AI systems may influence learners’ cultural awareness when caring for clients \\[ [14](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR14)\\]. While text-to-text GenAI tools like ChatGPT offer educational benefits, caution is advised due to potential risks, including AI hallucination, misinformation, and cultural sensitivity issues \\[ [15](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR15)\\]. These findings advocate for urgent curricular reform to prepare nurses for AI practice, highlighting the need for a balanced approach that leverages AI’s potential while mitigating its risks \\[ [16](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR16), [17](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR17)\\].\n\nSimulation-based GenAI learning has been shown to enhance AI readiness and reinforce core nursing concepts \\[ [18](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR18)\\]. Students exposed to GenAI-generated cases exhibit improved clinical reasoning compared to those trained through traditional methods \\[ [19](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR19)\\]. This suggests that GenAI can play a pivotal role in preparing nursing students for real-world clinical challenges. However, further research is imperative to optimize the integration of GenAI into nursing education while ensuring that training remains bias-free.\n\nIn summary, the adoption of AI in nursing education is accelerating, necessitating improved competency among students and faculty. Current literature supports curricular innovations such as dedicated coursework and GenAI simulations to build AI readiness and mitigate biases. Future research should systematically evaluate various AI pedagogical approaches and their long-term impacts, ensuring that nursing education evolves in tandem with technological advancements in healthcare.\n\n## Research question\n\nDoes participation in generative artificial intelligence (GenAI) patient simulation, compared to immersive 360° virtual reality (VR) simulation, lead to greater improvements in clinical competence, cultural awareness, and AI readiness among global undergraduate nursing students?\n\n## Methods\n\n### Study design\n\nThis was a cross-over randomised controlled study with two intervention arms: GenAI and 360° VR simulation. The participants were allocated equally to the study arms.\n\n### Study participants\n\nForty-four undergraduate nursing students from Hong Kong, Taiwan, Thailand, Spain, South Korea, and Australia, in their first, second, and third years of study, participated. Subgroups were created, each consisting of three undergraduate nursing students from various academic years. A total of 22 participants were randomly assigned to Group A (who received the 360° VR simulation first and GenAI second), and the other 22 participants were assigned to Group B (who received GenAI first and the 360° VR simulation second). The allocation process was randomised with a 1:1 allocation ratio. This sequence was generated by an independent researcher to ensure unbiased assignment and was concealed from both the participants in the two groups and the researchers involved in the study. Moreover, all participants provided written informed consent before the study, and the voluntary nature of participation and the confidentiality of the data were strongly emphasized throughout the process. This study was approved by the Institutional Review Board of the University of Hong Kong/Hospital Authority Hong Kong West Cluster (IRB number: UW 24–396).\n\n### Data collection\n\n#### CCQ\n\nThe 47-item CCQ, originally developed by Liou, was utilized in this study to assess participants’ self-perceived clinical competency at both T0 and T1 \\[ [20](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR20)\\]. The questionnaire consists of four competency components, namely nursing professional behaviours (NP; 16 items, score range: 16–90), general performance (GP; 13 items, score range: 13–65), core nursing skills (CNS; 12 items, score range: 12–60), and advanced nursing skills (ANS; 6 items, score range: 6–30). The items are scored using a 5-point Likert scale (1 = ‘Do not have a clue’; 2 = ‘Know in theory, but not confident at all in practice’; 3 = ‘Know in theory, can perform some parts in practice independently, and need supervision to be readily available’; 4 = ‘Know in theory, competent in practice, need contactable sources of supervision’; 5 = ‘Know in theory, competent in practice without supervision’). The total score ranges from 47 to 235 \\[ [20](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR20)\\]. A higher score indicates higher perceived competence. Cronbach’s alpha for the CCQ was 0.98, with the reliability of each component ranging from 0.87 to 0.95 \\[ [21](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR21)\\].\n\n#### CAS\n\nThe CAS was designed by Rew to measure the cultural awareness of nursing students \\[ [22](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR22)\\]. The CAS is based on the pathway model and comprises 36 items, each rated on a 7-point Likert scale (1 = ‘strongly disagree’ to 7 = ‘strongly agree’) and divided into five subscales: general education experience (GEE; 13 items, score range: 13–91), cognitive awareness (CA; 9 items, score range: 9–63), research issues (RI; 4 items, score range: 4–28), behavior or comfort with interactions (BOCWI; 6 items, score range: 6–42), and patient care or clinical issues (PCOCI; 4 items, score range: 4–28). The total score ranges from 36 to 252. A higher score on each subscale indicates a greater degree of cultural awareness within that domain. The reliability was 0.91 for students and 0.82 for faculty. The subscales’ reliability values ranged from 0.66 to 0.99 for students and from 0.56 to 0.87 for faculty \\[ [22](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR22)\\].\n\n#### MAIRS-MS\n\nThe MAIRS-MS instrument, initially created by Karaca, has demonstrated its validity and applicability in broader healthcare education settings, including nursing \\[ [23](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR23), [24](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR24)\\]. It requires participants to rate their self-assessment on a 5-point Likert scale (ranging from 1 = ‘strongly disagree’ to 5 = ‘strongly agree’) on 22 statements regarding their AI readiness \\[ [25](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR25)\\]. The MAIRS-MS is subdivided into four factors: cognition (8 items, score range: 8–40), ability (8 items, score range: 8–40), vision (3 items, score range: 3–15), and ethics (3 items, score range: 3–15). Total score ranges from 22 to 110. Higher scores on the total scale or any subscale reflect greater readiness for the integration of artificial intelligence in medical education and practice. Two exemplary items are ‘I can explain how AI systems are trained’ (cognition) and ‘I can explain the limitations of AI technology’ (vision) \\[ [25](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR25)\\]. The internal consistency of the overall scale was acceptable (Cronbach’s alpha = 0.88), and the Cronbach’s alphas for the individual factors were 0.83 (cognition), 0.77 (ability), 0.72 (vision), and 0.63 (ethics) \\[ [26](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR26)\\].\n\n#### SET-M\n\nThe participants’ confidence was measured using the SET-M at T1 only. The modified version of this instrument was published in 2015, with a total of 19 items and a 3-point response scale (ranging from 1 = ‘do not agree’ to 3 = ‘strongly agree’) \\[ [27](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR27)\\]. The items are divided into four domains: pre-briefing (2 items, score range: 2–6), learning (6 items, score range: 6–18), confidence (6 items, score range: 6–18), and debriefing (5 items, score range: 5–15). Total score ranges from 19 to 57. A higher score on the total scale or any subscale indicates a more positive perception of the effectiveness of simulation-based learning. Cronbach’s alpha for the overall SET-M was 0.94, with the reliability of each domain ranging from 0.83 to 0.91 \\[ [27](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR27)\\].\n\n#### Demographic questionnaire\n\nA questionnaire was used to collect the participants’ demographic data, including gender, year of study, and previous clinical experience, such as Temporary Undergraduate Nursing Students (TUNS). TUNS are nursing students who work part-time in healthcare settings while completing their nursing education. Specifically, they are typically students in their 4th or 5th year of a nursing degree program.\n\nBoth A and B completed a three-day simulation intervention, with a one-week washout interval implemented between intervention phases. This washout period—during which no study interventions were administered—was designed to minimize carryover effects and allow any residual learning effects from the first intervention to dissipate before the second intervention began, consistent with prior educational research \\[ [28](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR28)\\]. To further reduce carryover effects, different clinical scenarios were used at each time point: participants experienced the acute pneumonia case during the first intervention phase (T1) and the acute appendicitis case during the second intervention phase (T2), regardless of which simulation modality they received. Five questionnaire tools were used to collect data: the Clinical Competence Questionnaire (CCQ), the Cultural Awareness Scale (CAS), the Medical Artificial Intelligence Readiness Scale for Medical Students (MAIRS-MS), the Simulation Effectiveness Tool – Modified (SET-M), and a demographic questionnaire. The questionnaires were administered to the participants at three time points – pre-intervention (baseline \\[T0\\]), time 1 (T1), and time 2 (cross-over session) (T2).\n\n### Intervention details\n\nThe participants engaged in two distinct clinical scenarios in person: an acute pneumonia case at T1 and an acute appendicitis case at T2. At both T1 and T2, 35They participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debrThey participated in the same structured debriefing protocol utilizing the 3D debriefing model \\[ [29](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR29)\\], using the same set of debrief questions and facilitated by trained staff to ensure consistency across all sites. However, the type of simulation differed between the groups: one group experienced the GenAI patient simulation while the other group participated in the 360 VR simulation. Each intervention lasted 60 min, followed by a 60-minute, face-to-face debriefing session. After the first round, the groups crossed over so that all students experienced both types of simulation. This design enabled a fair comparison of educational outcomes while ensuring that all students received equal exposure to both simulation modalities and clinical scenarios.\n\n### Description of the two clinical case interventions\n\n#### 360° VR simulation - case 1: acute pneumonia\n\nThe intervention for Case 1 with 360° VR simulation, focusing on a 25-year-old patient named Peter, who had been diagnosed with acute pneumonia. The session was structured as follows:\n\nPre-briefing: Introduction to learning objectives and orientation to the LMS platform for interactive video engagement.\n\nCase Background: Overview of Peter’s clinical presentation and relevant history.\n\nActivity 1: Students watched the initial video segment, identified and timestamped health problems, and engaged in cultural discussions about stress coping and nursing practices.\n\nActivity 2: The following video segment focused on physical assessment, with students identifying and timestamping assessment findings, discussing missed assessments, and sharing cultural perspectives on care.\n\nActivity 3: Group discussion on prioritizing three nursing diagnoses, referencing current feedback and North American Nursing Diagnosis Association International (NANDA-I) \\[ [30](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR31)\\].\n\nActivity 4: The final video segment involved group discussion on nursing interventions and patient education, focusing on evidence-based practices for airway clearance, gas exchange, hyperthermia, nutrition, and fluid balance. Written summaries and rationales were provided for each nursing diagnosis.\n\n#### Generative AI patient Simulation- case: acute pneumonia\n\nThe content and case scenario were identical to Group A, but students interacted with an AI-simulated patient. They asked questions related to history-taking and physical assessment, then formulated nursing diagnoses based on the AI’s responses. Clinical reasoning was required to determine appropriate nursing diagnoses and interventions, with all activities mirroring the VR simulation structure (pre-briefing, case background, assessment, diagnosis, and intervention planning). The interaction was dynamic and student-led, guided by their inquiries and the AI’s generated responses.\n\n#### 360° VR simulation - case 2: _acute appendicitis_\n\nThe intervention for Case 2 with 360° VR simulation centered on a 38-year-old patient, Ken Chan, admitted for acute appendicitis and post-emergency appendectomy. The session was structured as follows:\n\nPre-briefing: Explanation of learning objectives (nursing assessment, prioritization of nursing diagnoses, cultural differences in care) and orientation to the LMS platform.\n\nCase Background: Introduction to Ken’s clinical scenario, including his admission for acute lower abdominal pain, vomiting, and subsequent emergency surgery. Relevant history included high job stress, smoking, alcohol use, and initial signs of liver cirrhosis.\n\nActivity 1: Students watched the initial video segment, identified and timestamped health problems, and participated in cultural discussions about health-seeking behaviors, healthcare systems, and pain management.\n\nActivity 2: The following video segment focused on physical assessment, with students identifying and timestamping assessment findings (e.g., wound assessment, pain level, vital signs, substance use), discussing missed assessments, and sharing cultural perspectives on pain assessment and wound healing.\n\nActivity 3: Group discussion to identify and prioritize three nursing diagnoses (e.g., acute pain, risk for deficient fluid volume, risk for ineffective breathing patterns), referencing expert feedback and NANDA-I guidelines.\n\nActivity 4: The final video segment involved group discussion on nursing interventions and patient education, emphasizing evidence-based care for pain, fluid balance, infection prevention, nutrition, and liver function. Cultural sharing included discussion of clinical practices, anti-smoking and alcohol cessation policies, and relevant health apps.\n\n#### Generative AI patient simulation- case 2: _acute appendicitis_\n\nThe same content for the acute appendicitis case was used, but students interacted with an AI patient. They conducted history-taking and physical assessments by asking the AI questions, then formulated nursing diagnoses and planned interventions based on the AI’s responses. The process followed the same structure as the VR simulation (pre-briefing, case background, assessment, diagnosis, and intervention planning), but the interaction was dynamic and student-driven, with clinical reasoning applied to each AI-generated response. No results or outcomes are reported, as per instructions.\n\nNote: In both cases, the only difference between Group A and Group B is the mode of simulation (360° VR video vs. Generative AI patient interaction); the clinical content, learning objectives, and session structure remain consistent across groups.\n\n### Components of GenAI patient simulation\n\nThe proposed GenAI Patient Simulation system for nursing education integrates several key components to enhance the learning experience. The core educational innovation lies in our pedagogical framework rather than the specific AI technology. The GenAI system utilizes a specialized Large Language Model (LLM) developed through collaboration with 0xmd Inc. (Hong Kong). This LLM was purpose-built through proprietary development and trained on a comprehensive corpus comprising medical datasets, real-world clinical data, academic research papers, and peer-reviewed literature to ensure high domain-specific accuracy and robust clinical reasoning capabilities. While the specific model is proprietary, our complete educational framework is reproducible through: (1) detailed clinical case protocols with specific patient presentations and assessment criteria, (2) structured NANDA-I-based evaluation rubrics, (3) comprehensive debriefing protocols using the 3D model, and (4) scoring algorithms. Researchers can implement this pedagogical approach using any conversational AI platform by following our documented framework, ensuring educational reproducibility regardless of the underlying AI technology.\n\nUnlike generic LLMs, it is optimized explicitly for medical and healthcare applications. The School of Nursing at the University of Hong Kong collaborated with the company to adapt and fine-tune the model for nursing education, incorporating clinical simulation cases, structured diagnostic frameworks, and pedagogical methodologies. This co-development enables realistic, culturally relevant, and educationally aligned patient interactions within the simulation system, supporting its use as an innovative tool for enhancing clinical reasoning and decision-making skills in nursing education.\n\nThe system facilitates structured learning through an interactive dialogue interface where students systematically engage with AI patients. Students are guided to conduct comprehensive history-taking using open-ended questions, allowing them to gather essential patient information while developing their communication skills. The interface prompts students to perform virtual physical assessments by requesting specific examinations, enabling them to practice clinical assessment techniques in a risk-free environment. Based on the information gathered, students are challenged to formulate differential diagnoses, encouraging critical thinking and analytical reasoning skills essential for nursing practice. Furthermore, the system requires students to propose evidence-based interventions with clear rationales, fostering the development of clinical decision-making abilities grounded in current best practices.\n\nThe AI patient component responds consistently with programmed clinical presentations, providing realistic answers that accurately reflect the patient’s cultural background, symptom severity, and emotional state, all of which are appropriate to the specific medical condition. This consistency ensures that all students encounter standardized scenarios while maintaining the authenticity of patient interactions. The system categorizes nursing diagnoses into distinct domains such as physiological, psychosocial, and cultural, further classifying them into actual, potential, and wellness diagnoses to provide a structured approach to patient care assessment. Maslow’s hierarchy of needs was explicitly used to train the AI system to recognize and prioritize patient care objectives, enabling the AI to evaluate student responses, generate contextually relevant debriefing feedback, and assign scores based on how well students address care priorities, such as managing physiological needs before addressing psychosocial concerns. Additionally, the system employs a standardized scale to assess the severity and complexity of disease conditions, considering factors like symptom acuity, potential for rapid deterioration, and intervention urgency, which aids students in identifying critical nursing diagnoses. Finally, the system establishes care priorities through a scoring mechanism that evaluates each diagnosis based on its impact on patient safety, potential complications, and overall outcomes, ensuring informed clinical decision-making.\n\n### Implementation of constructive feedback through GenAI debriefing\n\nThe implementation of constructive feedback through GenAI debriefing in the proposed system is designed to facilitate asynchronous learning by providing students with personalized, post simulation expert feedback. This process involves reflective practice where students analyze their responses, actions, and the outcomes of their clinical decisions. GenAI evaluates the rationale behind each nursing diagnosis, assessing the alignment with established grading frameworks to highlight areas of strength and improvement, thereby deepening students’ understanding of prioritization. Additionally, it scrutinizes the actions taken during simulations, offering feedback on the appropriateness of interventions to enhance clinical judgment and critical thinking. Finally, GenAI assesses the results of these actions, providing insights into the effectiveness of interventions based on chosen diagnoses, reinforcing evidence-based practice. This debriefing not only offers expert feedback on the correct prioritization of nursing diagnoses but also generates a score based on the accuracy of assessments and choices, ensuring a comprehensive learning experience.\n\n### Implementation of 360° VR simulation\n\nThe 360° VR content was captured using the Insta360 Pro 2 camera system, which provides high-resolution 360-degree video recording capabilities suitable for creating immersive educational content. The raw 360° footage was processed and stitched using the manufacturer’s software to create seamless panoramic videos. These processed videos were then uploaded and hosted on the institution’s LMS, ensuring consistent delivery across all participating sites. The use of standardized hardware and processing workflows facilitated replication across the six international locations while maintaining consistency in video quality and immersive experience. The 360° VR simulation employed in this study was developed in-house by the research team at the University of Hong Kong. This system is designed for ease of replication in diverse educational settings, requiring only standard 360-degree cameras for content creation and compatible playback devices (e.g., computers, tablets, or VR headsets) for delivery. Educators can readily adapt this approach by producing customized 360° video scenarios that align with specific learning objectives relevant to their curriculum.\n\nFor this study, students assigned to the 360° VR simulation group viewed immersive video scenarios via a screen interface. The video content was identical to that used in the GenAI group, ensuring consistency across experimental conditions. The immersive nature of the 360° VR experience facilitated active decision-making and interactive engagement, as students could freely navigate the environment by scrolling within the video using a mouse to observe the complete 360-degree perspective.\n\nThe 360° VR videos were hosted on the institution’s LMS \\[ [31](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR32)\\], which supported interactive features, including timestamped commenting. Students were provided with a structured question guide to direct their observations and reflections as they engaged with the scenarios. This allowed students to annotate specific moments within the video by placing timestamped comments, thereby capturing their insights and questions in real-time.\n\nFollowing the simulation, a faculty-led debriefing session was conducted. During this session, students reviewed and discussed each other’s timestamped comments, fostering vicarious peer learning and reflective practice. The LMS platform’s structured debriefing feature provided educators with a systematic framework to guide the discussion, ensuring that feedback was timely, relevant, and closely aligned with the learning objectives of the simulation.\n\nThe high degree of realism afforded by the 360° VR scenarios enhanced the authenticity of the learning experience, supporting the educational aims of the intervention. The described implementation is readily transferable to other research and educational contexts, provided that the necessary technical infrastructure is available. This framework enables other researchers and educators to replicate the intervention, customize content, and systematically evaluate student engagement and learning outcomes using immersive 360° VR technology.\n\n### Implementation of debriefing in both groups\n\nBoth the 360 VR and GenAI patient simulation groups participated in structured debriefing sessions following their simulation experiences. For both groups, accredited simulation educators and six core faculty members experienced in simulation-based education conducted debriefings using the 3D Model, which encompasses three phases: Defusing (emotional release), Discovering (performance analysis), and Deepening (application of learning). All facilitators underwent comprehensive training in the 3D debriefing framework to ensure consistency and quality across sessions.\n\nIn the GenAI patient simulation group, participants received additional, individualized constructive feedback generated through GenAI-driven debriefing. This AI-powered feedback provided tailored insights and recommendations based on each learner’s performance, further enriching the reflective learning process.\n\nBy combining facilitator-led debriefing with GenAI-generated feedback (for the GenAI group), both groups benefited from a robust, evidence-based approach that supports reflective learning, clinical decision-making, and emotional engagement, fully aligned with best practices in simulation-based education.\n\n### Data analysis\n\nTable [1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#Tab1) shows the descriptive statistics, including means and standard deviations, were used to summarise the participants’ demographics and scores on the CCQ, CAS, MAIRS-MS, and SET-M. The baseline characteristics of the intervention and control groups were compared using chi-square tests or Fisher’s exact tests for categorical data and independent t-tests for continuous data.\n\n#### Table 1.\n\nBaseline characteristic of the participants ( _n_ = 44)\n\n| Participants, No (%) |\n| --- |\n| Characteristic | All( _N_ = 44) | A group( _N_ = 22) | B group( _N_ = 22) | _P_ value |\n| --- | --- | --- | --- | --- |\n| Age, mean (SD) | 21.0 (1.24) | 21.1 (1.27) | 20.9 (1.23) | 0.632 |\n| Sex | 0.216 |\n| Male | 7 (38.3) | 5 (22.7) | 2 (9.1) |\n| Female | 37 (61.7) | 17 (77.3) | 20 (90.9) |\n| Year of study | 0.627 |\n| Year 1 | 2 (4.5) | 1 (4.5) | 1 (4.5) |\n| Year 2 | 15 (34.1) | 6 (27.3) | 9 (40.9) |\n| Year 3 | 27 (61.4) | 15 (68.2) | 12 (54.5) |\n| Do you have any TUNS experience? | 0.262 |\n| Yes | 9 (20.5) | 3 (13.6) | 6 (27.3) |\n| No | 35 (79.5) | 19 (86.4) | 16 (72.7) |\n| Have you attended any clinical practicum? | 1.000 |\n| Yes | 28 (73.6) | 14 (73.6) | 14 (73.6) |\n| No | 8 (36.4) | 8 (36.4) | 8 (36.4) |\n| Do you have any GenAI training before? | 0.240 |\n| Yes | 8 (18.2) | 6 (27.3) | 2 (9.1) |\n| No | 36 (81.8) | 16 (72.7) | 20 (90.9) |\n| CCQ Total Score, mean (SD) | 154.16 (32.82) | 157.23 (31.38) | 151.09 (34.66) | 0.542 |\n| Nursing Professional Behaviors, mean (SD) | 52.25 (13.99) | 52.82 (13.97) | 51.68 (14.33) | 0.791 |\n| General Performance, mean (SD) | 46.50 (6.40) | 46.68 (5.97) | 46.32 (6.94) | 0.853 |\n| Core Nursing Skills, mean (SD) | 37.91 (11.20) | 39.18 (11.23) | 36.64 (11.28) | 0.457 |\n| Advanced Nursing Skills, mean (SD) | 17.50 (5.50) | 18.55 (4.90) | 16.45 (5.97) | 0.211 |\n| CAS Total Score, mean (SD) | 189.43 (40.15) | 190.91 (42.38) | 187.95 (38.74) | 0.810 |\n| General Educational Experience | 74.75 (16.69) | 74.00 (17.46) | 75.50 (16.27) | 0.770 |\n| Cognitive Awareness | 38.86 (8.42) | 38.05 (8.38) | 39.68 (8.58) | 0.526 |\n| Research Issue | 20.77 (5.17) | 20.41 (5.32) | 21.14 (5.10) | 0.646 |\n| Behaviors or Comfort with Interactions | 25.73 (8.71) | 27.36 (9.08) | 24.09 (8.19) | 0.216 |\n| Patient Care or Clinical Issues | 29.32 (7.69) | 31.09 (7.76) | 27.55 (7.38) | 0.128 |\n| MAISMS Total Score, mean (SD) | 60.27 (14.45) | 61.00 (17.41) | 59.55 (11.10) | 0.743 |\n| Cognition | 22.30 (6.11) | 22.77 (7.08) | 21.82 (5.09) | 0.610 |\n| Ability | 21.77 (5.85) | 21.86 (6.65) | 21.68 (5.07) | 0.919 |\n| Vision | 8.05 (2.40) | 8.27 (2.68) | 7.82 (2.13) | 0.536 |\n| Ethics | 8.16 (2.78) | 8.09 (2.78) | 8.23 (2.84) | 0.873 |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/Tab1/)\n\nA linear mixed-model analysis was conducted to analyse the CCQ, CAS, and MAIRS-MS scores. This model treated the participants as a random effect and included time, group, randomisation sequence order, and the time–group interaction as fixed effects \\[ [32](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR36)\\]. Linear contrasts were used to assess both between-group differences and within-group changes over time. All of the statistical analyses were performed using IBM SPSS version 29.0 (IBM Corp., Armonk, NY, USA). Two-sided tests were used throughout, with a significance level of _p_ < 0.05.\n\n## Results\n\n### Descriptive results\n\nIn total, 44 participants were included in the study, divided equally into two groups: Group A ( _n_ = 22) and Group B ( _n_ = 22). The mean age of participants was 21.0 ± 1.24 years, with no significant difference between groups ( _P_ = 0.632). Most participants were female (84.1%), and the distribution of sex did not differ significantly between groups ( _P_ = 0.216). Regarding the year of study, most participants were in Year 2 (34.1%), with no significant difference between groups ( _P_ = 0.627).\n\nParticipants with prior TUNS experience comprised 20.5%, while those without accounted for 79.5%, with no significant difference between groups ( _P_ = 0.262). Similarly, the majority (73.6%) had attended clinical practicum, and this characteristic was evenly distributed across groups ( _P_ = 1.000). Only a minority (18.2%) had experience with GenAI training, with no significant difference between groups ( _P_ = 0.240).\n\nBaseline scores for CCQ Total Score, Nursing Professional Behaviors, General Performance, Core Nursing Skills, and Advanced Nursing Skills were comparable between groups, with P values ranging from 0.211 to 0.853, indicating no significant differences. The CAS Total Score also showed no significant difference between groups ( _P_ = 0.810). These findings suggest that demographic and baseline clinical characteristics were well-balanced across the two groups ( _P_ > 0.05).\n\n### Effect of the interventions on SET-M\n\nTable [2](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#Tab2) shows the responses of the participants to the SET-M. Most of the participants (75%, _n_ = 33) strongly agreed that debriefing contributed to their learning. Regarding confidence subscale, over half proportion of participants (68.2%, _n_ = 30) strongly agreed that they are more confident of their nursing assessment skills. Additionally, most participants (72.7%, _n_ = 32) strongly agreed that they were confident in using evidence-based practice to provide nursing care.\n\n#### Table 2.\n\nSimulation effectiveness Tool-Modified (SET‐M) responses\n\n| Simulation Effectiveness Tool-Modified (SET‐M) responsesAll respondents ( _N_ = 44) |\n| --- |\n| Survey questions: | Strongly Agree | Somewhat Agree | Do Not Agree |\n| --- | --- | --- | --- |\n| Prebriefing subscale |\n| Prebriefing increased my confidence. | 52.3% (23) | 47.7% (21) | 0% (0) |\n| Prebriefing was beneficial to my learning. | 65.9% (29) | 34.1% (15) | 0% (0) |\n| Learning subscale |\n| I am better prepared to respond to changes in my patient’s condition. | 70.5% (31) | 29.5% (13) | 0% (0) |\n| I developed a better understanding of the pathophysiology. | 68.2% (30) | 31.8% (14) | 0% (0) |\n| I am more confident of my nursing assessment skills. | 68.2% (30) | 31.8% (14) | 0% (0) |\n| I felt empowered to make clinical decisions. | 77.3% (34) | 22.7% (10) | 0% (0) |\n| I developed a better understanding of medications. | 65.9% (29) | 31.8% (14) | 2.3% (1) |\n| I had the opportunity to practice my clinical decision making skills. | 70.5% (31) | 29.5% (13) | 0% (0) |\n| Confidence subscale |\n| I am more confident in my ability to prioritize care and interventions | 68.2% (30) | 31.8% (14) | 0% (0) |\n| I am more confident in communicating with my patient. | 72.7% (32) | 27.3% (12) | 0% (0) |\n| I am more confident in my ability to teach patients about their illness and interventions. | 70.5% (31) | 29.5% (13) | 0% (0) |\n| I am more confident in my ability to report information to health care team. | 68.2% (30) | 31.8% (14) | 0% (0) |\n| I am more confident in providing interventions that foster patient safety. | 75.0% (33) | 25.0% (11) | 0% (0) |\n| I am more confident in using evidence-based practice to provide nursing care. | 72.7% (32) | 27.3% (12) | 0% (0) |\n| Debriefing subscale |\n| Debriefing contributed to my learning. | 75.0% (33) | 25.0% (11) | 0% (0) |\n| Debriefing allowed me to verbalize my feelings before focusing on the scenario. | 68.2% (30) | 31.8% (14) | 0% (0) |\n| Debriefing was valuable in helping me improve my clinical judgment. | 68.2% (30) | 31.8% (14) | 0% (0) |\n| Debriefing provided opportunities to self-reflect on my performance during simulation. | 68.2% (30) | 31.8% (14) | 0% (0) |\n| Debriefing was a constructive evaluation of the simulation. | 75.0% (33) | 25.0% (11) | 0% (0) |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/Tab2/)\n\n### Effects of the interventions on CCQ\n\nBoth groups demonstrated significant within-group improvements in perceived clinical competence at T1 and T2. Group B (GenAI first) showed significantly greater improvement in CCQ total score at T1 compared to Group A, with a between-group difference of 16.59 points (95% CI: 2.77, 30.41, _p_ = 0.020). By T2, both groups maintained significant improvements from baseline, suggesting sustained educational benefits across the crossover design.\n\n### Effects of the interventions on CAS\n\nBoth groups demonstrated improvements in cultural awareness. Group B showed consistent significant gains at both time points \\[T1: 27.59 (95% CI: 9.54, 45.64), _p_ = 0.003; T2: 20.91 (95% CI: 2.86, 38.96), _p_ = 0.024\\], while Group A showed significant improvement at T1 \\[18.27 (95% CI: 0.22, 36.32), _p_ = 0.047\\] with marginal significance at T2. No significant between-group differences were detected for total scores or individual subscales, indicating both interventions effectively enhanced culturalawareness.\n\n### Effects of the interventions on MAIRS-MS\n\nThe MAIRS-MS was administered at baseline (T0) and following each group’s GenAI simulation exposure, as this instrument specifically measures nursing students’ AI readiness after exposure to AI technology. Given the cross-over design, Group A received MAIRS-MS at T0 and T2 (following their GenAI exposure at T2), while Group B received MAIRS-MS at T0 and T1 (following their GenAI exposure at T1). No MAIRS-MS measurement was conducted following the 360° VR simulation, as this tool is designed to assess AI readiness specifically after exposure to AI intervention.\n\nTable [3](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#Tab3) presents the results of mixed-effects tests on the interventions’ effects on the MAIRS-MS. For the MAIRS-MS Total Score, Group A exhibited significant changes from baseline (T0) to post-GenAI exposure (T2) with an increase of 16.64 (95% CI \\[9.80, 23.47\\], _p_ < 0.001). In comparison, Group B showed significant changes from baseline (T0) to post-GenAI exposure (T1) with an increase of 30.18 (95% CI \\[23.35, 37.01\\], _p_ < 0.001). A significant between-group difference was noted (12.09, 95% CI \\[4.43, 19.75\\], _p_ = 0.003), with Group B demonstrating greater improvement in AI readiness. Significant between-group differences were also observed in the Cognition and Ability subscales. Overall, both groups showed significant improvements in AI readiness following their respective GenAI exposures.\n\n#### Table 3.\n\nMixed effects analysis for the interventional effects ( _n_ = 44)\n\n| Measure | Group A( _n_ = 22)Within-Group Change (95% CI) | _P_ Value | Group B( _n_ = 22)Within-Group Change (95% CI) | _P_ Value | Between-Group DifferenceMean (95% CI) | _P_ Value |\n| --- | --- | --- | --- | --- | --- | --- |\n| CCQ-Total |\n| T1 | 24.95 (13.96, 35.95) | < 0.001\\* | 47.68 (36.68, 58.68) | < 0.001\\* | 16.59 (2.77, 30.41) | 0.020\\* |\n| T2 | 31.09 (20.09, 42.09) | < 0.001\\* | 39.64 (28.64, 50.64) | < 0.001\\* | 2.41 (-11.41, 16.23) | 0.727 |\n| CCQ-NP |\n| T1 | 8.82 (3.70, 13.94) | < 0.001\\* | 11.86 (6.74, 16.98) | < 0.001\\* | 1.91 (-5.64, 9.45) | 0.612 |\n| T2 | 12.50 (7.38, 17.62) | < 0.001\\* | 13.59 (8.47, 18.71) | < 0.001\\* | -0.05 (-7.59, 7.50) | 0.990 |\n| CCQ-GP |\n| T1 | 3.36 (0.45, 6.28) | 0.024\\* | 9.41 (6.49, 12.33) | < 0.001\\* | 5.68 (2.72, 8.64) | < 0.001\\* |\n| T2 | 3.73 (0.81, 6.65) | 0.013\\* | 6.77 (3.85, 9.69) | < 0.001\\* | 2.68 (-0.28, 5.64) | 0.075 |\n| CCQ-CNS |\n| T1 | 9.23 (5.06, 13.40) | < 0.001\\* | 18.14 (13.96, 22.31) | < 0.001\\* | 6.36 (2.08, 10.65) | 0.005\\* |\n| T2 | 9.36 (5.19, 13.54) | < 0.001\\* | 13.82 (9.65, 17.99) | < 0.001\\* | 1.91 (-2.38, 6.20) | 0.374 |\n| CCQ-ANS |\n| T1 | 3.55 (1.31, 5.78) | 0.002\\* | 8.27 (6.04, 10.51) | < 0.001\\* | 2.64 (-0.39, 5.66) | 0.086 |\n| T2 | 5.50 (3.27, 7.73) | < 0.001\\* | 5.45 (3.22, 7.69) | < 0.001\\* | -2.14 (-5.16, 0.89) | 0.162 |\n| CAS-Total |\n| T1 | 18.27 (0.22, 36.32) | 0.047\\* | 27.59 (9.54, 45.64) | 0.003\\* | 6.36 (-15.08, 27.80) | 0.552 |\n| T2 | 15.32 (-2.73, 33.37) | 0.095 | 20.91 (2.86, 38.96) | 0.024\\* | 2.64 (-18.80, 24.08) | 0.805 |\n| CAS-GEE |\n| T1 | 3.95 (-3.92, 11.83) | 0.321 | 5.41 (-2.46, 13.28) | 0.175 | 2.95 (-6.70, 12.61) | 0.540 |\n| T2 | 3.32 (-4.55, 11.19) | 0.404 | 2.50 (-5.37, 10.37) | 0.529 | 0.68 (-8.97, 10.34) | 0.887 |\n| CAS-CA |\n| T1 | 4.77 (1.02, 8.53) | 0.013\\* | 6.09 (2.33, 9.85) | 0.002\\* | 2.95 (-1.01, 6.92) | 0.140 |\n| T2 | 4.23 (0.47, 7.98) | 0.028\\* | 6.05 (2.29, 9.80) | 0.002\\* | 3.45 (-0.51, 7.42) | 0.086 |\n| CAS-RI |\n| T1 | 2.68 (-0.08, 5.44) | 0.057 | 2.05 (-0.72, 4.81) | 0.145 | 0.09 (-3.17, 3.36) | 0.955 |\n| T2 | 0.64 (-2.13, 3.40) | 0.648 | 1.50 (-1.26, 4.26) | 0.283 | 1.59 (-1.67, 4.86) | 0.331 |\n| CAS-BOCWI |\n| T1 | 2.86 (-1.16, 6.89) | 0.161 | 5.59 (1.57, 9.62) | 0.007\\* | -0.55 (-5.43, 4.34) | 0.823 |\n| T2 | 2.68 (-1.34, 6.71) | 0.189 | 4.00 (-0.03, 8.03) | 0.051 | -1.95 (-6.84, 2.93) | 0.424 |\n| CAS-PCOCI |\n| T1 | 4.00 (0.55, 7.45) | 0.023\\* | 8.45 (5.01, 11.90) | < 0.001\\* | 0.91 (-3.00, 4.82) | 0.641 |\n| T2 | 4.45 (1.01, 7.90) | 0.012\\* | 6.86 (3.42, 10.31) | < 0.001\\* | -1.14 (-5.04, 2.77) | 0.560 |\n| MAIRS-MS-Total |\n| (T2 for Group A, T1 for group B) | 16.64 (9.80, 23.47) | < 0.001\\* | 30.18 (23.35, 37.01) | < 0.001\\* | 12.09 (4.43, 19.75) | 0.003\\* |\n| MAIRS-MS-Cognition |\n| (T2 for Group A, T1 for group B) | 4.50 (1.46, 7.54) | 0.005\\* | 11.59 (8.55, 14.63) | < 0.001\\* | 6.14 (2.89, 9.38) | < 0.001\\* |\n| MAIRS-MS-Ability |\n| (T2 for Group A, T1 for group B) | 6.00 (2.25, 9.75) | 0.002\\* | 10.36 (6.62, 14.11) | < 0.001\\* | 4.18 (0.13, 8.23) | 0.043\\* |\n| MAIRS-MS-Vision |\n| (T2 for Group A, T1 for group B) | 3.23 (1.79, 4.66) | < 0.001\\* | 4.55 (3.11, 5.98) | < 0.001\\* | 0.86 (-0.60, 2.33) | 0.241 |\n| MAIRS-MS-Ethics |\n| (T2 for Group A, T1 for group B) | 2.91 (1.63, 4.19) | < 0.001\\* | 3.68 (2.40, 4.96) | < 0.001\\* | 0.91 (-0.53, 2.35) | 0.209 |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/Tab3/)\n\nNote:\n\n• TUNS: Temporary Undergraduate Nursing Student\n\n• CCQ: Clinical Competence Questionnaire\n\n• NP: Nursing professional behaviors\n\n• GP: General Performance\n\n• CNS: Core Nursing Skills\n\n• ANS: Advanced Nursing Skills\n\n• CAS: Cultural Awareness Scale\n\n• GEE: General Educational Experience\n\n• CA: Cognitive Awareness\n\n• RI: Research Issues\n\n• BOCWI: Behavior or Comfort with Interactions\n\n• PCOCI: Patient Care or Clinical Issues\n\n\\* _p_ < 0.05 indicates statistical significance\n\n## Discussion\n\nThis study examined the impact of two innovative interventions – GenAI and 360° VR simulation – on the perceived clinical competence, cultural awareness, and AI readiness of nursing students in two distinct groups. Group A received the 360° VR Simulation first, followed by GenAI, while Group B experienced these interventions in the reverse order. Both groups demonstrated significant improvements in perceived clinical competence, with Group B initially showing advantages in general performance and core nursing skills, possibly due to the adaptive and interactive nature of GenAI simulation. Regarding cultural awareness, Group B made earlier gains in educational experience and cognitive awareness, although Group A eventually matched these improvements. Notably, both groups exhibited substantial progress in AI readiness across all subscales.\n\nAdditionally, a majority of students reported positive experiences with debriefing, contributing to increased confidence in their nursing skills. Both 360° VR simulation and GenAI patient simulation appear to be promising pedagogical strategies for enhancing certain clinical outcomes among the nursing students in this study. However, GenAI showed a trend toward a more pronounced impact in this cohort, possibly due to higher initial engagement, although further research is needed to confirm these findings. Specifically, when GenAI patient simulation is provided first, it yields greater outcomes; subsequently, utilising 360° VR can enhance these results.\n\n### Clinical competence\n\nThe study’s results indicate that the intervention enhanced perceived clinical competence in both groups, with Group B demonstrating a more pronounced initial improvement at T1, particularly in the General Practice (GP) and Clinical Nursing Skills (CNS) components of the Clinical Competence Questionnaire (CCQ). However, by T2, Group A had begun to catch up, suggesting that while their progress was initially slower, they eventually reached comparable levels of competence, which may indicate that the intervention had a more gradual impact on some participants but was ultimately effective for both groups over time. The customisation enabled by GenAI interventions, which catered to individual learners’ needs, preferences, and learning styles, likely facilitated targeted feedback, adaptive challenges, and content alignment with specific clinical roles and responsibilities. Our findings demonstrated that a tailored, personalised learning approach—developed and implemented in our study—effectively fosters essential clinical competencies among nursing students. This aligns with existing literature, which also supports the effectiveness of personalised learning in enhancing clinical competence across both generalist and specialist nursing practice \\[ [33](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR33)\\]. Moreover, GenAI interventions specifically targeted cognitive skills such as problem-solving, critical thinking, decision-making, and clinical reasoning, which are crucial for effective practice in healthcare settings. Engaging participants in higher-order thinking tasks and complex scenarios relevant to their practice areas potentially enhanced the development of these cognitive skills more effectively than traditional interventions.\n\nA notable feature of GenAI is its ability to deliver real-time feedback, debriefing, performance monitoring, and adaptive learning pathways tailored to learners’ responses and progress. This immediate feedback loop enables participants to pinpoint areas for improvement, adjust their strategies, and track their progress over time, thereby fostering an environment conducive to continuous learning and skill refinement. The personalised feedback and adaptive nature of GenAI likely contributed to the improved performance outcomes observed in the GP and CNS assessments of the CCQ. By leveraging advanced AI technologies, including deep learning and natural language processing, GenAI creates dynamic, responsive, and intelligent learning environments that optimize educational experiences, customize content delivery, and support individualized learning pathways focused on the specific competencies required for diverse nursing specialties.\n\n### Cultural awareness\n\nThe interventions aimed at enhancing cultural awareness, as measured by the Cultural Awareness Scale (CAS), demonstrated significant improvements in both groups, particularly in the dimensions of Cognitive Awareness and Patient Care or Clinical Issues. Group B exhibited more substantial enhancements at both time points compared to Group A, indicating a potentially more effective intervention for this group. Nonetheless, both groups experienced significant gains in several core areas of cultural awareness.\n\nThe notable advancements in Cognitive Awareness and patient care, as well as clinical issues, underscore the efficacy of these interventions in improving participants’ understanding of cultural issues and their practical application in clinical settings. This is further substantiated by evidence in the literature that cultural awareness is increasingly recognized as vital for delivering high-quality and patient-centered care \\[ [34](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR34), [35](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#CR35)\\]. The balanced representation of students from various countries in both groups facilitated an increase in cultural awareness through both patient simulations. These simulations were designed to interact according to distinct cultural beliefs and express cultural requirements, allowing students to engage in and gain insights from culturally nuanced exchanges, thereby enhancing their comprehension of cultural diversity within healthcare environments. The improvements in these areas suggest that the intervention successfully addressed key components of cultural awareness, potentially leading to better patient outcomes and more culturally sensitive care practices.\n\nHowever, the absence of significant changes in the areas of Behavior or Comfort with Interactions and Research Issues across both groups highlights a critical gap in the interventions. These components of cultural awareness, which involve interpersonal dynamics and behavior in diverse settings, may necessitate more teaching sessions, such as role-playing, simulations, or real-world applications, to cultivate practical skills in navigating cultural interactions. The absence of significant changes in the Behavior or Comfort with Interactions and Research Issues subscales may reflect several methodological considerations. First, our interventions were primarily designed to enhance clinical reasoning and decision-making rather than interpersonal cultural interaction skills. Second, the intervention duration (60 min per simulation) and short study timeframe may have been insufficient to impact these behavioral dimensions of cultural awareness. Additionally, these subscales may require measurement approaches specifically designed to detect changes following educational interventions. Future research should investigate whether interventions specifically targeting interpersonal cultural skills, with appropriate measurement tools and extended follow-up periods, might be more effective for addressing these domains of cultural awareness.\n\nThe findings indicate that interventions focusing on cultural awareness may enhance healthcare professionals’ cognitive understanding and clinical application of cultural awareness. Such improvements are essential for fostering culturally sensitive healthcare environments, particularly in increasingly diverse patient populations. However, to achieve broader cultural awareness, future training programs should incorporate more specific elements related to research issues and intercultural interactions, areas that were not significantly addressed in this study.\n\n### AI readiness\n\nThe findings indicate that GenAI patient simulation was effective in enhancing AI readiness for both groups, with both demonstrating significant improvements from their respective baselines after exposure to GenAI. Group B showed a larger improvement \\[30.18 (95% CI: 23.35, 37.01), _p_ < 0.001\\] compared to Group A \\[16.64 (95% CI: 9.80, 23.47), _p_ < 0.001\\], with a significant between-group difference \\[12.09 (95% CI: 4.43, 19.75), _p_ = 0.003\\]. Notably, Group B was assessed at T1 immediately following their first GenAI exposure, while Group A was assessed at T2 following their GenAI exposure after experiencing a 360° VR simulation first.\n\nThe significant improvements observed across all subscales of the MAIRS-MS suggest that GenAI patient simulation was highly effective in increasing nursing students’ readiness to engage with and utilize AI in their practice. The larger improvement in Group B may reflect the immediate impact of GenAI simulation when experienced as the first intervention, before any potential carry-over effects from prior simulation exposure. This sequence effect suggests that initial exposure to GenAI simulation may optimize learning gains in AI readiness, particularly when students encounter AI technology without prior simulation experience in the study context.\n\nThe results indicate that GenAI patient simulation successfully addressed key aspects of AI readiness, including cognitive understanding of AI concepts, the ability to interact with AI systems, and vision for AI integration in healthcare. While our study measured ethical readiness as part of the MAIRS-MS instrument, further analysis of specific ethical considerations would strengthen future research in this domain. The substantial increases in scores, particularly in the Cognition and Ability subscales, highlight that participants gained both theoretical knowledge about AI and practical skills in working with AI technologies through direct interaction with the GenAI patient simulation system. This comprehensive improvement across all dimensions of AI readiness is crucial for preparing nursing students to implement AI in healthcare settings successfully.\n\n### Perceived simulation effectiveness (SET-M)\n\nThe analysis of the SET-M responses indicates that a majority of the participants perceived debriefing as highly beneficial to their learning, with 75% expressing strong agreement. Furthermore, a large majority of the participants reported increased confidence in their nursing assessment skills (68.2%). These findings underscore the importance of perceived competence and confidence in clinical training, suggesting that structured peer interactions may enhance learning experiences and foster a supportive educational environment.\n\n### Implications of nursing educational practice\n\nThe integration of GenAI patient simulation and immersive 360° VR may offer innovative approaches to developing clinical competence, cultural awareness, and AI readiness among undergraduate nursing students. Both modalities provide realistic and interactive environments that enhance experiential learning and clinical decision-making, thereby addressing the limitations of traditional didactic methods. GenAI enables adaptive, personalized feedback and real-time debriefing, supporting individualized learning trajectories and fostering critical thinking. These innovations may help equip future nurses with relevant skills and confidence; further research is needed to determine their impact on patient care and safety.\n\n### Implications of the findings\n\nThe findings suggest that both GenAI patient simulation and 360° VR simulation may improve participants’ perceived clinical competence, cultural awareness, and AI readiness, with GenAI showing a greater effect in some measured domains. The positive student feedback on debriefing and increased confidence in assessment skills highlight the pedagogical value of simulation-based education. These results provide preliminary support for incorporating advanced simulation technologies into nursing curricula to enhance readiness for AI-integrated healthcare; however, further large-scale studies are warranted to confirm this finding.\n\n### Future directions\n\nFuture research should investigate longitudinal follow-up at 3, 6, and 12 months after GenAI and 360° VR simulation to assess the impact on clinical competence. Qualitative investigations into student experiences can deepen understanding of the mechanisms driving observed improvements. Expanding outcome measures to include patient care outcomes and the transferability of skills to real-world settings will further inform the development of the curriculum. Objective assessments and culturally responsive models should be incorporated to address the limitations of self-report tools and better capture diversity in learning needs. Additionally, future studies should consider larger sample sizes ( _n_ ≥ 100) per group, more diverse samples to enable subgroup analyses by country and context, enhancing the generalizability of findings.\n\n### Strengths and limitations\n\nA key strength of this study lies in its innovative cross-over design, which enabled rigorous comparison of GenAI and 360° VR simulation across six universities in six countries, drawing on a diverse cohort of nursing students from three different academic years. While the total sample size ( _n_ = 44) is modest, several factors justify its adequacy. The study achieved a 0% dropout rate, ensuring complete data from all participants. Additionally, the inclusion of students from varied cultural and educational backgrounds enhances the international diversity and relevance of the findings. Moreover, the observed large effect size supports the statistical power of the analyses, as larger effects can be reliably detected with fewer participants, aligning with best practices for sample size justification in resource-constrained or specialized settings. However, limitations must be acknowledged. The small sample, when disaggregated by university, country, and cohort year, restricts the ability to conduct subgroup analyses and may limit the generalizability of the findings. All measures assess perceived competence rather than actual clinical performance through self-report questionnaires. Self-reported competence may not correlate with objective clinical abilities, and future research should incorporate objective assessments alongside self-report tools to provide a comprehensive evaluation of clinical competence. Although participants’ English proficiency was not formally assessed, administering the surveys in English is justified, as all participating universities officially adopt English as the medium of instruction. All surveys were administered in English, which served as the common language of instruction across participating institutions. However, because no formal assessment of English proficiency was conducted, there is a possibility that language barriers may have influenced participants’ understanding of survey items and the accuracy of their responses, particularly for cultural awareness measures. Future studies should consider formally assessing language proficiency or providing validated translations to ensure linguistic differences do not compromise data validity. The absence of significant changes in the Behavior or Comfort with Interactions and Research Issues subscales may reflect several methodological factors.\n\n## Conclusion\n\nThe results provide preliminary evidence for the effectiveness of this cutting-edge approach in improving perceived clinical competence, cultural awareness, and AI readiness, with statistically significant improvements observed, particularly within Group B. Both 360° VR simulation and GenAI patient simulation may serve as effective pedagogical strategies for enhancing the clinical outcomes of nursing students. However, GenAI may exhibit a more significant impact, as its initial implementation appeared to engage students more effectively in the learning process, thereby potentially facilitating enhanced educational outcomes. Specifically, when GenAI patient simulation was first introduced, it may have produced superior results; the subsequent use of 360° VR may have further amplified these benefits.\n\nBoth groups demonstrated significant improvements across all assessed domains, underscoring the potential efficacy of the intervention in clinical training. The favourable feedback regarding the SET-M suggests that the participating students not only recognised the benefits of these GenAI simulations but also valued the function of GenAI debriefing, which may have enriched their educational experiences and facilitated their professional development.\n\nThe integration of GenAI into patient simulations may facilitate dynamic and adaptive learning environments, enabling learners to engage with realistic scenarios that reflect the complexities of actual clinical encounters. Through real-time feedback and GenAI debriefing, this technology may improve diagnostic accuracy and support critical skills such as decision-making and cultural awareness, which are essential elements in today’s diverse healthcare landscape.\n\nTo fully capitalize on these promising results, future research should focus on identifying the specific components of our GenAI intervention that drive these positive outcomes. By doing so, we may enhance educational strategies in clinical training, ensuring that healthcare professionals are not only technically proficient but also culturally aware and prepared for the challenges of contemporary medical practice. This exploration may be crucial in advancing healthcare education through innovative simulation methodologies.\n\n## Acknowledgements\n\nWe are grateful for the nursing students participating in the study.\n\n## Author contributions\n\nCRediT authorship contribution statement John Fung Tai Chun: Conceptualization, Methodology, Supervision, Writing- original draft and review & editing. Siu Ling Chan: Conceptualization, Methodology, Writing- review & editing. Choi Fung Lam: Methodology, Project administration, Writing- review & editing. Chung Yan Lam: Methodology, Project administration, Writing- review & editing. Christopher Chi Wai Cheng: Methodology, Formal analysis, Writing- review & editing. Man Hin Lai: Methodology, Formal analysis, Project administration, Data Curation, Visualization, Writing- review & editing. Cheuk Chun Joseph Ho: Project administration, Writing- review & editing. Au Siu Lun: Project administration, Writing- review & editing. Mak Lok Yi: Project administration, Writing- review & editing. Sophia Hu: Project administration, Writing- review & editing. Supapak Phetrasuwan: Project administration, Writing- review & editing. Jumpee Granger: Project administration, Writing- review & editing. Jung Min Yoon: Project administration, Writing- review & editing. Gulzar Mailk: Project administration, Writing- review & editing. Clara Cabrera Moreno: Project administration, Writing- review & editing. Patrick Kwok Man Hei: Project administration, Writing- review & editing. Chia-Chin Lin: Project administration, Writing- review & editing.\n\n## Funding\n\nThe study was funded by the HKU Teaching Development Grant (Grant no 966). The funders did not have a role in study design, data collection, analysis, reporting or the decision to submit for publication.\n\n## Data availability\n\nThe datasets used and analyzed during the present study are available from the corresponding author on reasonable request.\n\n## Declarations\n\n### Ethics approval and consent to participate\n\nThis study was performed in line with the principles of the Declaration of Helsinki. Ethical approval for this study was obtained from the Institutional Review Board of the University of Hong Kong/Hospital Authority Hong Kong West Cluster (IRB number: UW 24–396). Participants were assured of data confidentiality and voluntariness of participation in and withdrawal from the study, and personal written informed consent was obtained from each of them.\n\n### Consent for publication\n\nNot applicable.\n\n### Competing interests\n\nThe authors declare no competing interests.\n\n## Footnotes\n\n**Publisher’s note**\n\nSpringer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\n\n## Contributor Information\n\nTai Chun John Fung, Email: bigjohn@hku.hk.\n\nChia-Chin Lin, Email: cclin@hku.hk.\n\n## References\n\n- 1.Laupichler MC, Hadizadeh DR, Wintergerst MW, Emde VD, Paech L, Dick D, E. A., Raupach T. Effect of a flipped classroom course to foster medical students’ AI literacy with a focus on medical imaging: A single group pre-and post-test study. BMC Med Educ. 2022;22(1):803.\n\\[ [DOI](https://doi.org/10.1186/s12909-022-03866-x)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC9672614/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/36397110/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Laupichler%20MC,%20Hadizadeh%20DR,%20Wintergerst%20MW,%20Emde%20VD,%20Paech%20L,%20Dick%20D,%20E.%20A.,%20Raupach%20T.%20Effect%20of%20a%20flipped%20classroom%20course%20to%20foster%20medical%20students%E2%80%99%20AI%20literacy%20with%20a%20focus%20on%20medical%20imaging:%20A%20single%20group%20pre-and%20post-test%20study.%20BMC%20Med%20Educ.%202022;22(1):803.)\\]\n- 2.Cross JL, Choma MA, Onofrey JA. (2024). Bias in medical AI: implications for clinical decision-making. PLOS Digit Health. 3(11): e0000651. \\[ [DOI](https://doi.org/10.1371/journal.pdig.0000651)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC11542778/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/39509461/)\\]\n- 3.Agarwal R, Bjarnadottir M, Rhue L, Dugas M, Crowley K, Clark J, Gao G. Addressing algorithmic bias and the perpetuation of health inequities: an AI bias aware framework. Health Policy Technol. 2023;12(1):100702. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Agarwal%20R,%20Bjarnadottir%20M,%20Rhue%20L,%20Dugas%20M,%20Crowley%20K,%20Clark%20J,%20Gao%20G.%20Addressing%20algorithmic%20bias%20and%20the%20perpetuation%20of%20health%20inequities:%20an%20AI%20bias%20aware%20framework.%20Health%20Policy%20Technol.%202023;12(1):100702.)\\]\n- 4.Parikh RB, Teeple S, Navathe AS. Addressing bias in artificial intelligence in health care. JAMA. 2019;322(24):2377–8.\n\\[ [DOI](https://doi.org/10.1001/jama.2019.18058)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/31755905/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Parikh%20RB,%20Teeple%20S,%20Navathe%20AS.%20Addressing%20bias%20in%20artificial%20intelligence%20in%20health%20care.%20JAMA.%202019;322(24):2377%E2%80%938.)\\]\n- 5.Franco D’, Mathew M, Mishra V, Surapaneni KM. Twelve tips for addressing ethical concerns in the implementation of artificial intelligence in medical education. Med Educ Online. 2024;29(1):2330250.\n\\[ [DOI](https://doi.org/10.1080/10872981.2024.2330250)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10993743/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38566608/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Franco%20D%E2%80%99,%20Mathew%20M,%20Mishra%20V,%20Surapaneni%20KM.%20Twelve%20tips%20for%20addressing%20ethical%20concerns%20in%20the%20implementation%20of%20artificial%20intelligence%20in%20medical%20education.%20Med%20Educ%20Online.%202024;29(1):2330250.)\\]\n- 6.Gazzelloni A, Sguanci M, Piredda M, Calandrella C, Tieri G, Piga S, De Marinis MG. Evaluation of the effectiveness of the 360-degree video compared to standard video for nursing students. Preliminary data of a randomized controlled trial. Sci Talks. 2023;6:100201. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Gazzelloni%20A,%20Sguanci%20M,%20Piredda%20M,%20Calandrella%20C,%20Tieri%20G,%20Piga%20S,%20De%20Marinis%20MG.%20Evaluation%20of%20the%20effectiveness%20of%20the%20360-degree%20video%20compared%20to%20standard%20video%20for%20nursing%20students.%20Preliminary%20data%20of%20a%20randomized%20controlled%20trial.%20Sci%20Talks.%202023;6:100201.)\\]\n- 7.Pieterse AD, Hierck BP, de Jong PG, Ginn TF, Hamoen EC, Reinders ME. User experiences of medical students with 360-degree virtual reality applications to prepare them for the clerkships. Virtual Reality. 2023;27(2):1381–9. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Pieterse%20AD,%20Hierck%20BP,%20de%20Jong%20PG,%20Ginn%20TF,%20Hamoen%20EC,%20Reinders%20ME.%20User%20experiences%20of%20medical%20students%20with%20360-degree%20virtual%20reality%20applications%20to%20prepare%20them%20for%20the%20clerkships.%20Virtual%20Reality.%202023;27(2):1381%E2%80%939.)\\]\n- 8.Liaw SY, Tan JZ, Lim S, Zhou W, Yap J, Ratan R, Chua WL. Artificial intelligence in virtual reality simulation for interprofessional communication training: mixed method study. Nurse Educ Today. 2023;122:105718.\n\\[ [DOI](https://doi.org/10.1016/j.nedt.2023.105718)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/36669304/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Liaw%20SY,%20Tan%20JZ,%20Lim%20S,%20Zhou%20W,%20Yap%20J,%20Ratan%20R,%20Chua%20WL.%20Artificial%20intelligence%20in%20virtual%20reality%20simulation%20for%20interprofessional%20communication%20training:%20mixed%20method%20study.%20Nurse%20Educ%20Today.%202023;122:105718.)\\]\n- 9.Alammary MA, Halliday L, Konstantinidis ST. 360-degree virtual reality utilising head-mounted devices in undergraduate nursing and midwifery education: A scoping review. Virtual Worlds. 2023;2(4):396–421. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Alammary%20MA,%20Halliday%20L,%20Konstantinidis%20ST.%20360-degree%20virtual%20reality%20utilising%20head-mounted%20devices%20in%20undergraduate%20nursing%20and%20midwifery%20education:%20A%20scoping%20review.%20Virtual%20Worlds.%202023;2(4):396%E2%80%93421.)\\]\n- 10.Lee E, Baek G. Development and effects of a virtual reality simulation nursing education program combined with clinical practice based on an information processing model. CIN: Computers Inf Nurs. 2023;41(12):1016–25. \\[ [DOI](https://doi.org/10.1097/CIN.0000000000001051)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37647622/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Lee%20E,%20Baek%20G.%20Development%20and%20effects%20of%20a%20virtual%20reality%20simulation%20nursing%20education%20program%20combined%20with%20clinical%20practice%20based%20on%20an%20information%20processing%20model.%20CIN:%20Computers%20Inf%20Nurs.%202023;41(12):1016%E2%80%9325.)\\]\n- 11.Furey P, Town A, Sumera K, Webster CA. (2024). Approaches for integrating generative artificial intelligence in emergency healthcare education within higher education: a scoping review.\n- 12.Seibert K, Domhoff D, Bruch D, Schulte-Althoff M, Fürstenau D, Biessmann F, Wolf-Ostermann K. (2021). Application scenarios for artificial intelligence in nursing care: rapid review. J Med Internet Res. 23(11): e26522. \\[ [DOI](https://doi.org/10.2196/26522)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC8669587/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/34847057/)\\]\n- 13.Porter A, Foronda C. Enhancing artificial intelligence literacy in nursing education to combat embedded biases. Nurs Educ Perspect. 2024;45(2):131–2.\n\\[ [DOI](https://doi.org/10.1097/01.NEP.0000000000001245)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38373100/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Porter%20A,%20Foronda%20C.%20Enhancing%20artificial%20intelligence%20literacy%20in%20nursing%20education%20to%20combat%20embedded%20biases.%20Nurs%20Educ%20Perspect.%202024;45(2):131%E2%80%932.)\\]\n- 14.Lewis AA. Unpacking cultural Bias in AI Language learning tools: an analysis of impacts and strategies for inclusion in diverse educational settings. Int J Res Innov Social Sci. 2025;9(1):1878–92. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Lewis%20AA.%20Unpacking%20cultural%20Bias%20in%20AI%20Language%20learning%20tools:%20an%20analysis%20of%20impacts%20and%20strategies%20for%20inclusion%20in%20diverse%20educational%20settings.%20Int%20J%20Res%20Innov%20Social%20Sci.%202025;9(1):1878%E2%80%9392.)\\]\n- 15.Currie GM, Hawk KE, Rohren EM. Generative artificial intelligence biases, limitations and risks in nuclear medicine: an argument for appropriate use framework and recommendations. Seminars in nuclear medicine. WB Saunders. 2024. \\[ [DOI](https://doi.org/10.1053/j.semnuclmed.2024.05.005)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38851934/)\\]\n- 16.Buchanan C, Howitt ML, Wilson R, Booth RG, Risling T, Bamford M. (2021). Predicted influences of artificial intelligence on nursing education: scoping review. JMIR Nurs. 4(1): e23933. \\[ [DOI](https://doi.org/10.2196/23933)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC8328269/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/34345794/)\\]\n- 17.Nazar M, Alam MM, Yafi E, Su’ud MM. A systematic review of human–computer interaction and explainable artificial intelligence in healthcare with artificial intelligence techniques. IEEE Access. 2021;9:153316–48. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Nazar%20M,%20Alam%20MM,%20Yafi%20E,%20Su%E2%80%99ud%20MM.%20A%20systematic%20review%20of%20human%E2%80%93computer%20interaction%20and%20explainable%20artificial%20intelligence%20in%20healthcare%20with%20artificial%20intelligence%20techniques.%20IEEE%20Access.%202021;9:153316%E2%80%9348.)\\]\n- 18.Mirchi N, Bissonnette V, Yilmaz R, Ledwos N, Winkler-Schwartz A, Del Maestro RF. (2020). The virtual operative assistant: an explainable artificial intelligence tool for simulation-based training in surgery and medicine. PLoS ONE. 15(2): e0229596. \\[ [DOI](https://doi.org/10.1371/journal.pone.0229596)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC7046231/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/32106247/)\\]\n- 19.Krive J, Isola M, Chang L, Patel T, Anderson M, Sreedhar R. Grounded in reality: artificial intelligence in medical education. JAMIA Open. 2023;6(2):ooad037.\n\\[ [DOI](https://doi.org/10.1093/jamiaopen/ooad037)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10234762/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37273962/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Krive%20J,%20Isola%20M,%20Chang%20L,%20Patel%20T,%20Anderson%20M,%20Sreedhar%20R.%20Grounded%20in%20reality:%20artificial%20intelligence%20in%20medical%20education.%20JAMIA%20Open.%202023;6(2):ooad037.)\\]\n- 20.Liou SR, Cheng CY. Developing and validating the clinical competence questionnaire: A self-assessment instrument for upcoming baccalaureate nursing graduates. J Nurs Educ Pract. 2014;4(2):56. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Liou%20SR,%20Cheng%20CY.%20Developing%20and%20validating%20the%20clinical%20competence%20questionnaire:%20A%20self-assessment%20instrument%20for%20upcoming%20baccalaureate%20nursing%20graduates.%20J%20Nurs%20Educ%20Pract.%202014;4(2):56.)\\]\n- 21.Gu YH, Xiong L, Bai JB, Hu J, Tan XD. Chinese version of the clinical learning environment comparison survey: assessment of reliability and validity. Nurse Educ Today. 2018;71:121–8. 10.1016/j.nedt.2018.09.026.\n\\[ [DOI](https://doi.org/10.1016/j.nedt.2018.09.026)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/30286369/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Gu%20YH,%20Xiong%20L,%20Bai%20JB,%20Hu%20J,%20Tan%20XD.%20Chinese%20version%20of%20the%20clinical%20learning%20environment%20comparison%20survey:%20assessment%20of%20reliability%20and%20validity.%20Nurse%20Educ%20Today.%202018;71:121%E2%80%938.%2010.1016/j.nedt.2018.09.026.)\\]\n- 22.Rew L, Becker H, Cookston J, Khosropour S, Martinez S. Measuring cultural awareness in nursing students. J Nurs Educ. 2003;42(6):249–57.\n\\[ [DOI](https://doi.org/10.3928/0148-4834-20030601-07)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/12814215/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Rew%20L,%20Becker%20H,%20Cookston%20J,%20Khosropour%20S,%20Martinez%20S.%20Measuring%20cultural%20awareness%20in%20nursing%20students.%20J%20Nurs%20Educ.%202003;42(6):249%E2%80%9357.)\\]\n- 23.Yalcinkaya T, Ergin E, Yucel SC. Exploring nursing students’ attitudes and readiness for artificial intelligence: A Cross-Sectional study. Teach Learn Nurs. 2024;19(4):e722–8. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Yalcinkaya%20T,%20Ergin%20E,%20Yucel%20SC.%20Exploring%20nursing%20students%E2%80%99%20attitudes%20and%20readiness%20for%20artificial%20intelligence:%20A%20Cross-Sectional%20study.%20Teach%20Learn%20Nurs.%202024;19(4):e722%E2%80%938.)\\]\n- 24.Eminoğlu A, Çelikkanat Ş. Assessment of the relationship between executive nurses’ leadership self-efficacy and medical artificial intelligence readiness. Int J Med Informatics. 2024;184:105386. \\[ [DOI](https://doi.org/10.1016/j.ijmedinf.2024.105386)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38387197/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Emino%C4%9Flu%20A,%20%C3%87elikkanat%20%C5%9E.%20Assessment%20of%20the%20relationship%20between%20executive%20nurses%E2%80%99%20leadership%20self-efficacy%20and%20medical%20artificial%20intelligence%20readiness.%20Int%20J%20Med%20Informatics.%202024;184:105386.)\\]\n- 25.Karaca O, Çalışkan SA, Demir K. Medical artificial intelligence readiness scale for medical students (MAIRS-MS)–development, validity and reliability study. BMC Med Educ. 2021;21:1–9.\n\\[ [DOI](https://doi.org/10.1186/s12909-021-02546-6)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC7890640/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/33602196/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Karaca%20O,%20%C3%87al%C4%B1%C5%9Fkan%20SA,%20Demir%20K.%20Medical%20artificial%20intelligence%20readiness%20scale%20for%20medical%20students%20(MAIRS-MS)%E2%80%93development,%20validity%20and%20reliability%20study.%20BMC%20Med%20Educ.%202021;21:1%E2%80%939.)\\]\n- 26.Tomesko J, Cohen D, Bridenbaugh J. (2022). Using a virtual flipped classroom model to promote critical thinking in online graduate courses in the United States: a case presentation. Journal of Educational Evaluation for Health Professions. 19. \\[ [DOI](https://doi.org/10.3352/jeehp.2022.19.5)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC9008223/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/35219288/)\\]\n- 27.Leighton K, Ravert P, Mudra V, Macintosh C. Updating the simulation effectiveness tool: item modifications and Reevaluation of psychometric properties. Nurs Educ Perspect. 2015;36(5):317–23.\n\\[ [DOI](https://doi.org/10.5480/15-1671)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/26521501/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Leighton%20K,%20Ravert%20P,%20Mudra%20V,%20Macintosh%20C.%20Updating%20the%20simulation%20effectiveness%20tool:%20item%20modifications%20and%20Reevaluation%20of%20psychometric%20properties.%20Nurs%20Educ%20Perspect.%202015;36(5):317%E2%80%9323.)\\]\n- 28.Kassis, N., Weber, J. R., Adams, W., Burke, L., Laubham, M. P., Pelka, M.,… Lopez,J. J. (2022). Immersive educational curriculum on intracoronary optical coherence tomography image analysis among naïve readers. BMC Medical Education, 22(1), 719. \\[ [DOI](https://doi.org/10.1186/s12909-022-03704-0)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC9554992/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/36224563/)\\]\n- 29.Zigmont JJ, Kappus LJ, Sudikoff SN. (2011, April). The 3D model of debriefing: defusing, discovering, and deepening. In Seminars in perinatology. 35(2):52-59. \\[ [DOI](https://doi.org/10.1053/j.semperi.2011.01.003)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/21440811/)\\]\n- 30.Herdman TH, Kamitsuru S, Lopes CT, editors. NANDA-I international nursing diagnoses: definitions & classification, 2024–2026. 13th ed. Thieme. 2024.\n- 31.Lam PPY, Cabalen MB, Peng S, Wong HMG, Botelho MG. (2025). Potentiating the learning outcomes in paediatric dentistry via clinical vicarious learning dialogue videos: A mixed study. Eur J Dent Educ. \\[ [DOI](https://doi.org/10.1111/eje.13093)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/40263697/)\\]\n- 32.Saunders WB, Jiang J, Nguyen T. (2007). Linear and generalized linear mixed models and their applications. New York: Springer\n- 33.Zhang P, Kamel Boulos MN. Generative AI in medicine and healthcare: promises, opportunities and challenges. Future Internet. 2023;15(9):286. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Zhang%20P,%20Kamel%20Boulos%20MN.%20Generative%20AI%20in%20medicine%20and%20healthcare:%20promises,%20opportunities%20and%20challenges.%20Future%20Internet.%202023;15(9):286.)\\]\n- 34.Rony MKK, Parvin MR, Ferdousi S. (2024). Advancing nursing practice with artificial intelligence: enhancing preparedness for the future. Nurs Open. 11(1). \\[ [DOI](https://doi.org/10.1002/nop2.2070)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10733565/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38268252/)\\]\n- 35.Ličen S, Karnjuš I, Prosen M. Measuring cultural awareness among Slovene nursing student: A cross-sectional study. J Transcult Nurs. 2021;32(1):77–85.\n\\[ [DOI](https://doi.org/10.1177/1043659620941585)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/32666907/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Li%C4%8Den%20S,%20Karnju%C5%A1%20I,%20Prosen%20M.%20Measuring%20cultural%20awareness%20among%20Slovene%20nursing%20student:%20A%20cross-sectional%20study.%20J%20Transcult%20Nurs.%202021;32(1):77%E2%80%9385.)\\]\n\n## Associated Data\n\n_This section collects any data citations, data availability statements, or supplementary materials included in this article._\n\n### Data Availability Statement\n\nThe datasets used and analyzed during the present study are available from the corresponding author on reasonable request.\n\n## ACTIONS\n\n- [View on publisher site](https://doi.org/10.1186/s12912-025-03492-0)\n- [PDF (1.2 MB)](https://pmc.ncbi.nlm.nih.gov/pdf/12912_2025_Article_3492.pdf)\n- Cite\n- Collections\n- Permalink\n\n\n## PERMALINK\n\n\n\nCopy\n\n\n## RESOURCES\n\n### Similar articles\n\n### Cited by other articles\n\n### Links to NCBI Databases\n\nBack to Top"}
{"title": "(PDF) Impact of Generative AI on Critical Thinking Skills in ...", "content": "- [Home](https://www.researchgate.net/directory/publications)\n- [Philosophical Logic](https://www.researchgate.net/topic/Philosophical-Logic/publications)\n- [Philosophy](https://www.researchgate.net/topic/Philosophy/publications)\n- [Critical Thinking](https://www.researchgate.net/topic/Critical-Thinking/publications)\n\nArticlePDF Available\n\n# Impact of Generative AI on Critical Thinking Skills in Undergraduates: A Systematic Review\n\n- December 2024\n- [Journal of Desk Research Review and Analysis](https://www.researchgate.net/journal/Journal-of-Desk-Research-Review-and-Analysis-3030-7015) 2(1):199-215\n\nDOI: [10.4038/jdrra.v2i1.55](https://doi.org/10.4038/jdrra.v2i1.55)\n\n- License\n- [CC BY-SA 4.0](https://www.researchgate.net/deref/https%3A%2F%2Fcreativecommons.org%2Flicenses%2Fby-sa%2F4.0%2F)\n\nAuthors:\n\n[P. P. Premkumar](https://www.researchgate.net/scientific-contributions/P-P-Premkumar-2295909331)\n\n[P. P. Premkumar](https://www.researchgate.net/scientific-contributions/P-P-Premkumar-2295909331)\n\n- This person is not on ResearchGate, or hasn't claimed this research yet.\n\n\n[Kaushalya Yatigammana](https://www.researchgate.net/profile/Kaushalya-Yatigammana)\n\n- [University of Kelaniya](https://www.researchgate.net/institution/University_of_Kelaniya)\n\n[Kannangara Sampath](https://www.researchgate.net/profile/Kannangara-Sampath)\n\n- [International College of Business and Technology](https://www.researchgate.net/institution/International-College-of-Business-and-Technology)\n\n[Download full-text PDF](https://www.researchgate.net/publication/388476744_Impact_of_Generative_AI_on_Critical_Thinking_Skills_in_Undergraduates_A_Systematic_Review/fulltext/679a05e14c479b26c9bf8930/Impact-of-Generative-AI-on-Critical-Thinking-Skills-in-Undergraduates-A-Systematic-Review.pdf)\n\n[Read full-text](https://www.researchgate.net/publication/388476744_Impact_of_Generative_AI_on_Critical_Thinking_Skills_in_Undergraduates_A_Systematic_Review#read)\n\n[Download citation](https://www.researchgate.net/publication/388476744_Impact_of_Generative_AI_on_Critical_Thinking_Skills_in_Undergraduates_A_Systematic_Review/citation/download)\n\nCopy link Link copied\n\n[Read full-text](https://www.researchgate.net/publication/388476744_Impact_of_Generative_AI_on_Critical_Thinking_Skills_in_Undergraduates_A_Systematic_Review#read) [Download citation](https://www.researchgate.net/publication/388476744_Impact_of_Generative_AI_on_Critical_Thinking_Skills_in_Undergraduates_A_Systematic_Review/citation/download)\nCopy link Link copied\n\n## Abstract\n\nDespite widespread acknowledgement of the significance of critical thinking skills for success in today's job market, higher education institutions face challenges in effectively nurturing these skills in students. Educational policies, reports, and employer demands emphasise the importance of critical thinking, yet a gap remains between its recognised value and the actual proficiency levels among university students. This study employs a systematic literature review approach to address a research question, \"What is the impact of Generative AI on the critical thinking skills of undergraduates?\" About half of the thirty selected papers suggest that Generative AI benefits undergraduate critical thinking, but limitations in study design prevent generalisation. Other inconclusive studies highlight the need for further research to address research gaps.\n\n**Discover the world's research**\n\n- 25+ million members\n- 160+ million publication pages\n- 2.3+ billion citations\n\n[Join for free](https://www.researchgate.net/signup.SignUp.html)\n\nAvailable via license: [CC BY-SA 4.0](https://www.researchgate.net/deref/https%3A%2F%2Fcreativecommons.org%2Flicenses%2Fby-sa%2F4.0%2F)\n\nContent may be subject to copyright.\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n199\n\nIMPACT OF GENERATIVE AI ON CRITICAL THINKING SKILLS IN\n\nUNDERGRADUATES: A SYSTEMATIC REVIEW\n\nPP Premkumar1 and MRKN Yatigammana2 and S Kannangara3\n\nAbstract\n\nDespite widespread acknowledgement of the significance of critical thinking skills for success in today's\n\njob market, higher education institutions face challenges in effectively nurturing these skills in students.\n\nEducational policies, reports, and employer demands emphasise the importance of critical thinking, yet\n\na gap remains between its recognised value and the actual proficiency levels among university students.\n\nThis study employs a systematic literature review approach to address a research question, \"What is the\n\nimpact of Generative AI on the critical thinking skills of undergraduates?\" About half of the thirty\n\nselected papers suggest that Generative AI benefits undergraduate critical thinking, but limitations in\n\nstudy design prevent generalisation. Other inconclusive studies highlight the need for further research\n\nto address research gaps.\n\nKeywords: Critical thinking, Generative AI, Higher education\n\n1Postgraduate student, Faculty of Graduate Studies, University of Kelaniya, Sri Lanka\n\nEmail: prabu@icbtcampus.edu.lkhttps://orcid.org/0009-0005-1950-190X\n\n2Professor, Faculty of Commerce & Management Studies, University of Kelaniya, Sri Lanka\n\nEmail: kaushalya@kln.ac.lkhttps://orcid.org/0000-0002-8057-8632\n\n3Executive Director CEO & Executive Dean, ICBT, Sri Lanka\n\nEmail: sampathk@icbtcampus.edu.lkhttps://orcid.org/0009-0009-9247-8426\n\nThe Journal of Desk Research Review and Analysis © 2024 by The Library,\n\nUniversity of Kelaniya, Sri Lanka, is licensed under CC BY-SA 4.0\n\nReceived date: 09.07.2024\n\nAccepted date: 22.10.2024\n\nDOI: https://doi.org/10.4038/jdrra.v2i1.55\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n200\n\nIntroduction\n\nCritical thinking is vital in higher education, influencing students' academic, professional, personal, and\n\nsocio-political growth. Despite extensive research, there is no universally accepted definition, though it\n\nis ecognised as a key academic skill that encourages students to question and reflect on knowledge\n\n(Moore, 2011;Davies,2015). Research over the past four decades, particularly in Western contexts,\n\nhighlights the increasing demand for critical thinking skills to meet the needs of a complex,\n\ntechnological society and the globalised economy (Moore, 2011). Philosophical perspectives emphasise\n\nargumentation, while psychological approaches focus on cognitive skills. Educational programs have\n\nbeen developed to cultivate logic, reasoning, and argumentation skills (Paul, 2011).\n\nFrom a cognitive standpoint, critical thinking involves skills, attitudes, and knowledge, encompassing\n\nabilities like evaluation, synthesis, analysis, interpretation, inference, and explanation (Sternberg &\n\nHalpern, 2020). Critical thinkers excel in communication and teamwork, aiding in problem-solving.\n\nPaul and Elder (2006) define critical thinking as the skill of evaluating and improving thought processes,\n\nessential for professional success and active democratic participation.\n\nTeaching critical thinking is vital in its contribution to a rational, civilised community, its value across\n\nprofessions, and its role as a lifelong skill (Wass, 2012). Higher education aims to develop critical\n\nthinking, a key concern for educators worldwide. Critical thinking enables graduates to participate\n\nactively in society, tackle global issues, and foster democracy (Stanford Encyclopedia of Philosophy,\n\n2018). However, teaching critical thinking techniques alone is insufficient; students must learn to apply\n\nthese skills in real-world situations. Instructors initially support learning through scaffolding but later\n\nadopt a facilitator role as students grow more independent. Critical thinking is a learned skill that must\n\nbe taught, as it is not innate, emphasising the need for education to help students form independent\n\nopinions and judgments (Fahim & Masouleh, 2012).\n\nThe Dearing Report (1997) and the Hunt Report (2011) emphasise the importance of undergraduates\n\nacquiring skills such as \"learning to learn,\" \"critical analysis,\" and \"independent thought,\" highlighting\n\nthe need for these skills to address future societal needs. Tomlinson (2010) notes that technological\n\nadvancements and new knowledge requirements have shifted employer expectations, making life skills\n\nand critical thinking essential for graduates.\n\nEmployees who adapt to changing conditions and technological advancements are crucial in today's\n\ndynamic workplace. Critical thinking skills enable graduates to think creatively, learn quickly, and solve\n\nproblems. According to the World Economic Forum (2023), \"critical thinking and problem-solving\"\n\nare among the most essential skills for future employment.\n\nCritical thinking and problem-solving are crucial skills in every job, as they involve analysing\n\nsituations, identifying key issues, evaluating data, and making informed decisions. According to a\n\nNACE report (2021), these are the most sought-after skills among recent graduates. However, national\n\nassessments in the United Kingdom (UK) and the United States (US) indicate that university students'\n\ncritical thinking abilities are not improving (Arum & Roksa, 2011; Huber & Kuncel, 2016). A survey\n\nfound that only 39% of US employers believe graduates are well-prepared in critical thinking,\n\nhighlighting a mismatch between workforce demands and educational outcomes (Y Fin Le Y. et al.,\n\n2021).\n\nDespite the importance of critical thinking skills for undergraduates, some barriers hinder their\n\ndevelopment, as demonstrated by a study on South African undergraduates. (Eze. et al., 2022). The\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n201\n\nmain obstacles include lecturers' lack of proficiency, societal norms that discourage challenging\n\nauthority, students' unfamiliarity and reluctance, and an education system focused on memorisation.\n\nAdditional factors include confirmation biases, language proficiency, and an overreliance on lectures\n\nand teachers. In summary, critical thinking in higher education is vital, but it faces significant challenges\n\ndue to various educational and societal factors (Utami et al.,2021).\n\nGenerative AI and Critical Thinking in Higher Education\n\nGenerative Artificial Intelligence (GenAI) is a typeof artificial intelligence that can generate content in\n\nthe form of text, image, audio, video, animation, and code (Chan & Hu, 2023). GenAI technologies like\n\nChatGPT are revolutionising higher education by reshaping traditional teaching methods and enhancing\n\nlearning experiences. GenAI, which uses machine learning and neural networks to generate content,\n\nhas seen rapid adoption, exemplified by ChatGPT's massive user base shortly after its release in\n\nNovember 2022 (Lim et al., 2023). GenAI offers personalised tutoring, automated grading, language\n\ntranslation, and interactive learning(Chan & Hu, 2023). However, it also raises concerns about\n\nacademic integrity, privacy, and the potential for students to rely too heavily on GenAI, undermining\n\ntheir critical thinking skills (Tamrat, 2022).\n\nIntegrating GenAI in higher education presents opportunities and challenges for fostering critical\n\nthinking. While AI tools can enhance problem-solving and creativity, they may also lead to a decline in\n\nhigher-order cognitive skills if over-relied upon (Bhosale, 2023). However, the impact of GenAI on\n\ncritical thinking remains a topic of debate. Critics argue that excessive dependence on GenAI may\n\nreduce students' motivation to conduct independent research and analysis(Farrokhnia et al.,2023).\n\nTherefore, it is crucial to integrate GenAI thoughtfully into educational systems to encourage inquiry,\n\ndiscussion, and critical evaluation rather than passive learning. This balance is essential to ensure that\n\nGenAI is a complement to, rather than a replacement for, traditional educational methods.\n\nThe impact of GenAI on undergraduate students' critical thinking remains underexplored, with\n\nsignificant gaps in empirical research, theoretical frameworks, and practical applications (Wang, 2024).\n\nAdditionally, there is a need for more comprehensive studies on students’ and teachers’ perceptions of\n\nGenAI across various demographics and educational contexts (Chan & Lee, 2023). With the\n\nunprecedented interest in GenAI, it is essential to explore students' experiences and perceptions to\n\nunderstand how these technologies can be integrated into higher education to enhance critical thinking\n\nskills.\n\nThis literature review maps prior research on the influence generated by GenAI on undergraduate\n\nstudents' critical thinking. The result of this Systematic Literature Review is to map out possibilities for\n\nfurther research on the impact of GenAI on the development of critical thinking abilities among\n\nundergraduates.\n\nMethodology\n\nSystematic Literature Review\n\nSystematic literature reviews aim to examine a specific research question comprehensively. Unlike\n\nstandard literature reviews, which offer a general overview, systematic reviews are highly focused and\n\ninvolve a more structured and transparent process. This process includes clearly defined protocols,\n\nmeticulous planning, and a detailed search strategy(Lame, 2019).\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n202\n\nThese reviews offer in-depth insights, making them exceptionally valuable to practitioners and\n\nresearchers despite being more time-consuming and detailed than standard literature reviews. The focus,\n\ntransparency, and comprehensive nature of systematic reviews ensure their reliability and relevance in\n\nresearch.\n\nThe steps in a systematic literature review typically involve(Lame, 2019):\n\n1.Defining the research question\n\n2.Developing a protocol\n\n3.Conducting a comprehensive literature search\n\n4.Selecting studies\n\n5.Extracting data\n\n6.Assessing study quality\n\n7.Synthesising data\n\n8.Interpreting and reporting results\n\n9.Drawing conclusions and making recommendations\n\n10.\n\nResearch Question\n\nThe following question is addressed in the systematic Review\n\n●What is the impact of Generative AI on the critical thinking skills of undergraduates?\n\nLiterature Review Source\n\nThe literature sources that were used in this research are from several trusted and recognised quality\n\npublishers, such as:\n\n●Emerald Insight (http://emeraldinsight.com)\n\n●IEEE Explore (http:// ieeexplore.ieee.org)\n\n●Taylor & Francis Online (http://tandfonline.com)\n\n●Digital Scholarship (http://digital-scholarship.org)\n\n●Sage Publications (https://us.sagepub.com)\n\n●Elsevier(https://www.elsevier.com)\n\n●SpringerOpen(https://www.springeropen.com)\n\n●ACM Digital Library (https://dl.acm.org)\n\n●arXiv(https://arxiv.org/)\n\n●Wiley Online (https://onlinelibrary.wiley.com)\n\nThe references were obtained from several sources of literature. These references were sorted using\n\ninclusion and exclusion criteria, which we will explain in subsequent sections.\n\nStudy Selection\n\nStudy selection is used to sort the references from various online publishing sources. Over a thousand\n\narticles were initially identified, and after sorting, 30 references were identified as relevant to the\n\nresearch. Two criteria were applied to the literature selection process to establish clear boundaries, as\n\noutlined in Table 1.\n\nTable 1: Inclusion and Exclusion Criteria\n\nInclusion Criteria\n\n●Papers published in English.\n\n●Complete papers.\n\n●Papers are available in electronic format.\n\n●Papers published in Journals.\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n203\n\n●Papers related to the search string terms.\n\n●Papers published after November 2022\n\n●References that discuss the impact of GenAI in higher education\n\nExclusion Criteria\n\n●References that discuss the general impact of GenAI in education\n\n●References which are published before November 2022\n\n●Documents classified as tutorials, posters, panels, lectures,\n\n●Round tables, theses, dissertations, book chapters and technical reports.\n\n●Duplicate papers.\n\n●Papers that cannot be located.\n\nInitially, a search was conducted using the keywords \"Generative AI\" and \"Higher Education.\" This\n\nsearch was subsequently refined by including \"Critical Thinking\" alongside the initial keywords.\n\nResearch papers were searched using Google Scholar, Connected Papers, Research Rabbit,\n\nResearchGate, and Semantic Scholar. Due to this filtering process, 68 journal articles were identified.\n\nFrom these, 30 articles were selected for Review following additional filtration focused on research\n\nquestions. The selected papers were then critically examined to address the research questions.\n\nResults and Discussion\n\nFrequently Studied Educational Contexts\n\nFrom the selected studies on the impact of GenAI on the critical thinking skills of undergraduates,\n\napproximately five studies (Berg & Plessis, 2023; Javaid et al., 2023; Farrokhnia et al., 2023; Lu et al.,\n\n2024; and Hsiao-Ping Hsu, 2023) focused on the field of education. Additionally, four studies (Jia &\n\nTu, 2024; Shanto et al., 2024; Zaphir et al., 2024; and Fiialka et al., 2023) included undergraduates from\n\nvarious disciplines. Three studies (Yilmaz, 2023; Styve et al., 2024; and Elsayed, 2023) specifically\n\ninvestigated the development of critical thinking skills among computing students, particularly in\n\nprogramming. Two studies (Wang, 2024; and Hutson, 2024) examined the influence of GenAI in\n\nEnglish language studies. Furthermore, there is one study each in the fields of business (Essien et al.,\n\n2024), social science (Taiye et al., 2024), applied science (Walter, 2024), and mathematics (Barana et\n\nal., 2023), all exploring the effects of GenAI on the critical thinking abilities of undergraduates.\n\nResearch Methods Employed for Analysis\n\nIn the systematic literature review on the impact of Generative AI on the critical thinking skills of\n\nundergraduates, various research methods were identified, with a dominant approach being the quasi-\n\nexperimental study design. This method involved control and experimental groups, where the\n\nexperimental groups utilised GenAI tools, while the control groups engaged in traditional methods that\n\nrequired critical thinking skills. This design was prevalent in the selected papers, including studies by\n\nEssien et al. (2024), Shanto et al. (2024), Barana et al. (2023), Lu etal. (2024), and Yilmaz (2023) as it\n\nallowed for a comparative analysis of the effects of GenAI on students' cognitive abilities. Additionally,\n\nqualitative methodologies were employed, notably through exploratory case studies and\n\nphenomenological research, which included document analysis to gain in-depth insights into\n\nparticipants' experiences and perceptions as well as thing ethnography in the studies of Berg and Plessis\n\n(2023), Wang (2024), Michel-Villarreal et al.(2023), (Elsayed,2023), Lancaster (2023), Walter (2024),\n\nand Zaphir et al. (2024). Online surveys were also used in studies such as Smolensky et al. (2023),\n\nStyve, Virkki, & Naeem (2024), and Fiialka etal. (2023) to gather quantitative data, providing a broader\n\nunderstanding of the trends and patterns in the data. Furthermore, structural equation modelling was\n\nemployed (Jia & Tu, 2024) to examine the relationships between variables, offering a comprehensive\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n204\n\nview of the factors influencing critical thinking skills. Also, mixed-method approaches, combining both\n\nquantitative and qualitative methods, were utilised in the studies of Ruiz-Rojas et al. (2024), Leiker et\n\nal. (2023), and Hsiao-Ping Hsu (2023) to provide a holistic understanding of the impact of GenAI on\n\nundergraduates' critical thinking skills, integrating diverse data sources for richer analysis and\n\ninterpretation. In addition, there are a number of studies such as Sallam (2023), George et al. (2023),\n\nLim et al. (2023), Kasneci et al. (2023), Farrokhnia etal. (2023), Thiga (2024), Rudolph, Tan, and Tan\n\n(2023), Javaid et al. (2023), Dai et al. (2023), and Hutson (2024) employed literature review or desk-\n\nbased analysis. Also, a few unique approaches, such as Taiye et al. (2024) used Soft Systems\n\nMethodology, and Tenakwaha et al. (2023) applied Competency Based Analysis.\n\nThePotential of GenAI in Enhancing Cognitive Abilities\n\nGenAI can be used to develop students' critical thinking in the form of data generation (Berg & Plessis,\n\n2023). However, contrary to the study of Smolansky et al. (2023), academics assume Artificial\n\nIntelligence (AI) will be used to encourage critical thinking. However, students' reactions are mixed, in\n\npart due to concerns about a loss of creativity. Kasneci et al. (2023) contend that excessive dependence\n\non ChatGPT might detrimentally affect students' abilities to think critically and solve problems.\n\nUsing its ability to produce human-like writing on a broad range of subjects, ChatGPT has become a\n\npotent conversational AI agent (George et al., 2023). However, some worry that relying on it too much\n\ncan result in problems like plagiarism, a lack of critical thinking skills, and the dissemination of false\n\ninformation (Sallam, 2023). To give students feedback on their work and encourage them to think more\n\ncarefully about the course material, Javaid et al. (2023) suggested employing ChatGPT as a teaching\n\nassistant. They discovered that posing challenging queries and highlighting errors in students' logic\n\ncould assist them in developing their critical analysis abilities. ChatGPT was conceived by Dai et al.\n\n(2023) as a student-driven invention with immense potential to empower students and improve their\n\neducational resources and experiences. Due to its sophisticated conversational abilities, ChatGPT can\n\noffer formative feedback on essays and transform it into a tutoring system, fostering critical thinking\n\nand stimulating student debates (Farrokhnia et al.,2023). According to Michel-Villarreal et al. (2023),\n\neducators can use simulations or virtual personas driven by ChatGPT, facilitating student involvement\n\nin role-playing scenarios, decision-making activities, or historical recreations. These immersive\n\nencounters can potentially boost student motivation, critical thinking, and creativity.\n\nInfluence of GenAI on Critical Thinking\n\nThe study by Thiga (2024) explores the impact of GenAI on developing critical thinking skills, noting\n\nthat information overload can hinder critical analysis, and the attention economy affects critical thinking\n\nby capturing scarce attention resources. The methodology involved a literature review, surveys, and\n\ninterviews with educators and students to understand their experiences with GenAI and analyse\n\nqualitative data to identify patterns and themes. Observations in educational settings assessed the effects\n\nof GenAI tools on learning outcomes. Key findings of Thiga (2024) indicate that GenAI can enhance\n\ncritical thinking by providing personalised learning experiences and promoting creativity. Integrating\n\nGenAI tools improves student engagement, motivation, problem-solving, and analytical thinking skills.\n\nThe study suggests that GenAI in education helps students develop adaptability and resilience.\n\nThe study of Jia and Tu (2024) investigates AI's impact on critical thinking awareness in college\n\nstudents, focusing on AI capabilities, general self-efficacy, and learning motivation. The objectives are\n\nto explore how AI fosters critical thinking by enhancing self-efficacy and motivation, examine causal\n\nrelationships between these factors, understand AI's role in education, and provide theoretical and\n\npractical insights. The methodology includes a literature review, hypothesis development, data\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n205\n\ncollection through surveys, questionnaire design and validation, and statistical analysis using structural\n\nequation modelling. Key findings indicate that AI indirectly enhances critical thinking awareness by\n\nboosting self-efficacy and motivation. General self-efficacy significantly influences learning\n\nmotivation and critical thinking, while learning motivation strongly correlates with critical thinking\n\nskills. However, AI's direct impact on critical thinking is not significant.\n\nThe study conducted by Wang (2024) examines how native and non-native English-speaking college\n\nstudents engage with ChatGPT in their writing processes, focusing on their perceptions, experiences,\n\nand ethical dilemmas. Employing a phenomenological approach, the research reveals that students use\n\nAI tools for convenience and enhancing their critical thinking skills. Students reported both cognitive\n\nand emotional benefits from using ChatGPT, showing a critical engagement with AI suggestions and\n\nreflecting on their writing practices. The study also underscores the challenges of maintaining an\n\nauthentic voice while incorporating AI, highlighting the importance of critical AI literacy (Wang,2024).\n\nHowever, the research's limitations include a small sample size, a brief duration, a specific context,\n\nvarying proficiency levels, and the constraints of a phenomenological design, which may not fully\n\ncapture the diversity of student experiences.\n\nGenAI can contribute to education by generating intricate scenarios for students to analyse and assess\n\nusing Bloom's taxonomy (JISC 2023). Additionally, engaging with GenAI text generators can prompt\n\nstudents to devise innovative solutions, stimulating the highest cognitive skill level (creating) within\n\nBloom's taxonomy (Rudolph et al., 2023). According to the findings of Shanto et al. (2024), students,\n\non average, expressed that AI significantly assisted in idea generation and critical analysis compared to\n\nworking independently. This study evaluates students' responses using Lee's model (Lee, 2000, as cited\n\nin Shanto et al.,2024) of thinking levels. However, the limitations of Shanto et al. (2024) study include\n\nthe small sample size, the controlled experimental setting, potential AI reliability issues, and the risk of\n\nover-reliance on ChatGPT, which could hinder original thought and creativity. On the contrary, the\n\nresearch on the impact of GenAI text generators on critical thinking skills in UK business schools\n\ndemonstrates that AI-based text generators enhance only the lower levels of Bloom's taxonomy (Essien\n\netal.,2024). Additionally, it tackles concerns regarding reliability, accuracy, and ethical implications\n\nassociated with the educational use of AI text generators.\n\nGenAI and Critical Thinking in Different Educational Contexts\n\nIn a study on fostering critical thinking in solving mathematical problems (Barana et al.,2023), students\n\nprimarily used ChatGPT to aid in problem-solving by exploring different solutions and testing their\n\nvalidity. ChatGPT facilitated critical thinking, particularly when students evaluated the AI's proposed\n\nsolutions or used the tool to verify their answers. This has both scientific and practical implications.\n\nThe results indicate that AI did not replace human involvement but complemented the students,\n\nreinforcing their active participation in problem-solving.\n\nThe study by Lu et al. (2024) assessed the impact of GenAI-assisted training on 215 Chinese preservice\n\nteachers' self-efficacy and higher-order thinking skills. One group received AI-assisted training using a\n\npretest-post-test design, while a control group used traditional methods. The AI group significantly\n\noutperformed the control group in self-efficacy and higher-order thinking. Interviews with 25\n\nparticipants highlighted positive perceptions, demonstrating AI's effectiveness in teacher development.\n\nThe study by Yilmaz (2023) investigates the impact of ChatGPT on students' computational thinking\n\nskills, programming self-efficacy, and motivation. Conducted in a flipped classroom setting with hands-\n\non coding, the experimental group used ChatGPT for programming homework. Analysis of covariance\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n206\n\n(ANCOVA) analysis compared the computational thinking skills of the experimental and control\n\ngroups. Key findings reveal that the experimental group demonstrated higher computational thinking\n\nskills, self-efficacy, and motivation. ChatGPT enhanced students' creativity, algorithmic thinking,\n\ncooperativity, and problem-solving abilities. Additionally, the experimental group had significantly\n\nhigher post-test scores in computer programming self-efficacy. Limitations of the study include the\n\nshort five-week duration, the small sample size of 45 students affecting generalizability, and the reliance\n\non Unified Modeling diagrams, limiting the variety of programming tasks.\n\nThe study of Berg and Plessis (2023) investigates the role of ChatGPT in teacher education, focusing\n\non lesson planning, critical thinking, and openness. It examines how GenAI tools like ChatGPT can\n\nassist teachers by providing specific materials and support mechanisms, such as lesson plans, enhancing\n\nteachers' critical thinking by encouraging diverse approaches. The qualitative methodology employed\n\nan exploratory case study design and phenomenological research with document analysis, ensuring data\n\ntrustworthiness through credibility, transferability, dependability, and confirmability. Key findings\n\nhighlight that ChatGPT makes lesson plans accessible to all teachers, promoting equity across\n\ngeographical, social, and cultural backgrounds. However, the study emphasises the need for caution\n\nand critically evaluating AI tools for limitations and biases (Berg & Plessis,2023).\n\nTaiye et al. (2024) investigated using GenAI chatbots to enhance academic writing and critical thinking,\n\nfocusing on ethical challenges and stakeholder perspectives. It aims to develop CHAT4ISP-AI, a tool\n\nto improve academic writing skills. Utilising Soft Systems Methodology (SSM), the research involved\n\niterative enhancements through stakeholder feedback, incorporating diverse perspectives from\n\ndevelopers, IT (Information Technology) support, teachers, and students. SSM employed structured\n\nqualitative data and adaptive stakeholder engagement to refine the tool. Key findings reveal varied\n\nexpectations and concerns among stakeholders, with students engaging more in idea generation,\n\nsummarising sources, and checking grammar, while teachers have mixed reactions regarding academic\n\nintegrity (Taiye et al.,2024). The CHAT4ISP-AI tool shows promise but requires further development\n\nand ethical considerations. Limitations include a focused scope on first-year Social Sciences students,\n\nthe initial proof-of-concept stage of the tool, divergent stakeholder objectives, and operational\n\nchallenges related to time and funding for further development.\n\nTenakwaha et al. (2023) assess ChatGPT's competence in answering university-level questions across\n\ndisciplines like Accounting, Social Work, Law, Management, and Education. It highlights ChatGPT's\n\nlanguage proficiency, reasoning ability, and response structuring but also identifies its limitations in\n\nproducing sophisticated, contextually relevant arguments. The study emphasises the importance of\n\nhuman oversight in ensuring the accuracy and feasibility of AI-generated content. A multidisciplinary\n\nteam from five Australian universities evaluated ChatGPT's responses, noting that while clear and\n\nreadable, they often lacked depth and engagement. Despite its strengths, ChatGPT's responses were\n\nsometimes basic, lacking in critical analysis and specific examples (Tenakwaha et al., 2023). The study\n\nsuggests using ChatGPT to stimulate deeper thinking rather than as a complete solution for academic\n\nwriting, underscoring the necessity of human intelligence in reviewing AI output. Limitations included\n\na lack of detailed analysis, correct references, and cohesive idea flow, necessitating user verification of\n\nChatGPT's information.\n\nIn the article \"Rethinking Plagiarism in the Era of Generative AI,\" Hutson (2024) explores how GenAI\n\ncan enhance students' critical thinking skills in English composition courses. He argues that GenAI\n\ntools can encourage originality by helping students generate unique ideas and content, fostering creative\n\nthinking. Additionally, GenAI provides instant feedback on students' work, aiding in the refinement of\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n207\n\narguments and improving reasoning skills. The article also highlights how GenAI facilitates research\n\nby assisting in the gathering and analysing information, which enables students to develop well-\n\ninformed perspectives.\n\nThe research findings from the study on incorporating GenAI tools into introductory programming\n\ncourses (Styve et al., 2024) indicate an improvement in students' critical thinking practices. After\n\nengaging with AI-based programming assignments, students demonstrated a more remarkable ability\n\nto critically evaluate AI-generated solutions, reflecting on their appropriateness and reliability.\n\nStrategies of Integration of GenAI in Critical Thinking of Undergraduates\n\nWalter's paper (2024) discusses the importance of AI literacy, prompt engineering, and critical thinking\n\nin modern education, employing a two-step methodology. Conceptual discussions and informal\n\nconversations with students and lecturers at the Swiss University of Applied Sciences, combined with\n\nthe author's teaching experience, explored AI's role in education. Real-life case studies identified the\n\nneed for further clarifications and best practices, while a narrative literature review addressed open\n\nquestions and offered practical suggestions for higher education. Key findings revealed a lack of\n\ncomprehensive AI training for students and highlighted AI's potential to support special needs\n\ninterventions. Practical suggestions emphasise AI literacy and prompt engineering to enhance\n\neducational experiences and promote critical thinking. However, the paper's conceptual focus and case\n\nstudy from a single Swiss university may limit its generalizability. Additionally, it relies on informal\n\ndiscussions, which might not fully capture the diverse challenges and opportunities in various\n\neducational settings.\n\nZaphir et al. (2024) introduce the MAGE framework (Mapping, AI vulnerability testing, Grading,\n\nEvaluation) to evaluate the quality of critical thinking in GenAI like ChatGPT4. The framework\n\nassesses the vulnerability of assessment tasks to AI, emphasising the importance of critical thinking\n\nskills that AI can mimic but not fully perform. The methodology involves mapping cognitive skills,\n\ntesting AI vulnerability with different question versions, grading AI responses, and evaluating results.\n\nA case study demonstrates the framework's application, showing how various assessment tasks can be\n\nevaluated for AI vulnerability. Key findings of Zaphir etal.’s (2024) paper highlight the limitations of\n\nChatGPT4 in emulating critical thinking, suggesting that educators redesign assessments to focus on\n\nmore profound comprehension and analytical skills. The study emphasises the importance of authentic\n\nlearning to deter AI-driven shortcuts.\n\nIntegrating AI text generators into education poses distinct challenges, underscoring the intricacy of\n\nincorporating them into existing teaching methodologies (Lancaster, 2023). Another challenge pertains\n\nto the accuracy of AI-generated content, with nonsensical responses being common, indicating\n\noccasional failures in grasping context accurately and raising concerns about its precision. Ensuring the\n\nreliability of AI tools necessitates robust fact-checking procedures and continuous review mechanisms\n\n(Leiker et al., 2023).\n\nThe paper by Ruiz-Rojas et al. (2024) explores the impact of GenAI tools on critical thinking and\n\ncollaboration among university students, aiming to identify suitable tools, evaluate their effects, and\n\ndevelop effective pedagogical strategies. Using a mixed methods approach, including quantitative\n\nsurveys and qualitative thematic analysis, the study assessed 121 students selected through purposive\n\nsampling. Key findings show high familiarity with AI tools, with 87% of respondents aware of them\n\nand 38% using them occasionally. Additionally, 64% believe these tools significantly enhance critical\n\nthinking. Despite this, there is a need for continuous training and technical support. Limitations include\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n208\n\nlimited sample size, a focus on quantitative data, which may not capture the full depth of experiences,\n\na lack of longitudinal data to assess long-term impacts, and ethical concerns related to AI biases and\n\ndata privacy.\n\nHsiao-Ping Hsu (2023) generated a short research paper with the support of ChatGPT 4.0 using prompt\n\nengineering techniques, and the study found that GenAI can assist in research and education by\n\ngenerating ideas and designs. However, it is crucial for scholars to evaluate its outputs to uphold\n\nacademic integrity critically. While GenAI offers efficiency and accessibility, it challenges traditional\n\nknowledge, scholarship, and teaching concepts. More emphasis should be placed on developing critical\n\nthinking skills to responsibly use GenAI, ensuring it complements rather than detracts from the essence\n\nof education and scholarly work.\n\nExisting literature highlights the potential integration of GenAI into education while also underscoring\n\nthe risks associated with excessive reliance on AI. By understanding the constraints of AI models such\n\nas ChatGPT and designing questions, educators can encourage active participation in the learning\n\njourney, fostering the growth of critical thinking and problem-solving abilities among students\n\n(Elsayed,2023).\n\nNevertheless, it is essential to recognise that merging human intellectual capacity with the potential of\n\nGenAI transcends the limits of human capability, accelerating the generation of innovative ideas and\n\nfostering a more meaningful and effective educational process (Fiialka. et al.,2023).\n\nSummary of Key Findings\n\nTable 2 summarises significant research works reviewed in this paper, including method, conclusion,\n\nkey findings, and drawbacks.\n\nTable 2: Summary of key findings\n\nAuthor\n\nMethod\n\nConclusion\n\nKey Findings\n\nDrawbacks\n\nThiga\n\n(2024)\n\nLiterature\n\nReview\n\nGenAI can\n\nenhance critical\n\nthinking\n\nIntegrating AI tools improves\n\nstudent engagement,\n\nmotivation, problem-solving\n\nabilities, and analytical\n\nthinking skills.\n\nThe methodology was\n\nnot strong enough for a\n\nconclusive result.\n\nNot focused on a\n\nspecific GenAI\n\napplication\n\nJia et al.\n\n(2024).\n\nStructured\n\nequation\n\nmodelling\n\nAI indirectly\n\nenhances critical\n\nthinking\n\nawareness\n\nGeneral self-efficacy\n\nsignificantly influences both\n\nlearning motivation and\n\ncritical thinking, while\n\nlearning motivation strongly\n\ncorrelates with critical\n\nthinking skills. However, AI's\n\ndirect impact on critical\n\nthinking is not significant.\n\nGenetic factors were not\n\ntested.\n\nThe proposed path\n\nmodel was only\n\nmarginally accepted.\n\nThe reinforcement\n\nlearning theory was not\n\nutilised fully.\n\nWang\n\n(2024)\n\nPhenomenol\n\nogical\n\nStudents use AI\n\ntools for\n\nconvenience and\n\nStudents reported both\n\ncognitive and emotional\n\nbenefits from using ChatGPT,\n\nSample size.\n\nShort duration of the\n\nstudy.\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n209\n\nresearch\n\ndesign\n\nto enhance their\n\ncritical thinking\n\nskills.\n\nshowing a critical engagement\n\nwith AI suggestions and\n\nreflecting on their writing\n\npractices.\n\nSadat\n\nShanto et\n\nal. (2024)\n\nQuasi-\n\nexperimenta\n\nl design\n\nAI significantly\n\nassisted in idea\n\ngeneration and\n\ncritical analysis\n\nFramework 'AI-CRITIQUE'\n\nenhances critical thinking\n\nusing ChatGPT in education\n\nSmall sample size.\n\nThe framework was\n\nonly tested in a\n\ncontrolled and\n\nexperimental\n\nenvironment and not in\n\nreal-life situations.\n\nEssien et\n\nal.\n\n(2024).\n\nQuasi-\n\nexperimenta\n\nl design\n\nAI-based text\n\ngenerators\n\nenhance only the\n\nlower levels of\n\nBloom's\n\ntaxonomy\n\nSignificant improvements in\n\nlower levels of Bloom's\n\ntaxonomy\n\nBloom's Taxonomy\n\nmay not capture the\n\nbreadth of skills to\n\nevaluate a detailed\n\nassessment.\n\nBarana et\n\nal.\n\n(2023).\n\nQuasi-\n\nexperimenta\n\nl design\n\nChatGPT\n\nfacilitated critical\n\nthinking,\n\nAI did not replace human\n\ninvolvement but\n\ncomplemented the students,\n\nreinforcing their active\n\nparticipation in the problem-\n\nsolving process.\n\nIt was only tested for a\n\nsingle discipline.\n\nLu et al.\n\n(2024)\n\nQuasi-\n\nexperimenta\n\nl design\n\nThe AI group\n\nsignificantly\n\noutperformed the\n\ncontrol group in\n\nself-efficacy and\n\nhigher-order\n\nthinking.\n\nThis study produced a\n\npractical teachers’\n\nprofessional development\n\nmethod for preservice\n\nteachers with generative AI.\n\nOnly teachers of\n\nMathematics, Science\n\nand Computer Science\n\nwere considered.\n\nYilmaz et\n\nal. (2023)\n\nQuasi-\n\nexperimenta\n\nl design\n\nChatGPT\n\nenhanced students'\n\ncreativity,\n\nalgorithmic\n\nthinking,\n\ncooperativity, and\n\nproblem-solving\n\nabilities.\n\nThe experimental group\n\ndemonstrated higher\n\ncomputational thinking skills,\n\nself-efficacy, and motivation.\n\nSmall sample size.\n\nShort study duration.\n\nBerg et\n\nal.\n\n(2023).\n\nExploratory\n\nCase Study:\n\nThe study\n\nemphasises the\n\nneed for caution,\n\ncritically\n\nevaluating AI\n\ntools for\n\nlimitations and\n\nbiases\n\nChatGPT makes lesson plans\n\naccessible to all teachers,\n\npromoting equity across\n\ngeographical, social, and\n\ncultural backgrounds.\n\nOnly one lesson of one\n\nmodule for a specific\n\nlevel was reviewed.\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n210\n\nTaiye et\n\nal.\n\n(2024).\n\nSoft System\n\nMethodolog\n\ny\n\nVaried\n\nexpectations and\n\nconcerns among\n\nstakeholders\n\nStudents engaging more in\n\nidea generation, summarising\n\nsources, and checking\n\ngrammar, while teachers have\n\nmixed reactions regarding\n\nacademic integrity\n\nLimited scope. only the\n\nfirst-year social science\n\nstudents were\n\nconsidered\n\nTenakwa\n\nh et al.\n\n(2023)\n\nCompetence\n\n-based\n\nanalysis of\n\nChatGPT's\n\ntask\n\nresponse\n\nChatGPT's\n\nresponses were\n\nsometimes\n\nprimary, lacking\n\nin critical analysis\n\nand specific\n\nexamples\n\nInstead of viewing ChatGPT\n\nas a solution to all academic\n\nwriting challenges, it should\n\nbe seen as a tool to generate\n\nideas that spark further, more\n\nin-depth thinking.\n\nHuman intelligence must\n\nreview the output for\n\naccuracy, consistency, and\n\npracticality for research-\n\noriented tasks.\n\nStudents' perspectives\n\non the motivation of\n\nChatGPT were not\n\nconsidered.\n\nThe longitudinal\n\napproach was not\n\nconsidered.\n\nLimited disciplines\n\nconsidered\n\nHutson\n\n(2024)\n\nDesk\n\nResearch\n\nGenAI tools can\n\nencourage\n\noriginality by\n\nhelping students\n\ngenerate unique\n\nideas and content,\n\nfostering creative\n\nthinking.\n\nGenAI provides instant\n\nfeedback on students' work,\n\naiding in the refinement of\n\narguments and improving\n\nreasoning skills.\n\nGenAI facilitates research by\n\nassisting in gathering and\n\nanalysing information,\n\nenabling students to develop\n\nwell-informed perspectives.\n\nThe methodology was\n\nnot strong enough.\n\nRuiz-\n\nRojas et\n\nal. (2024)\n\nMixed\n\nmethod\n\nGenAI tools\n\nsignificantly\n\nimpact the critical\n\nthinking of higher\n\neducation\n\nstudents.\n\nIncorporating didactic and\n\npedagogical approaches and\n\ngenerative AI tools has\n\nenhanced the depth and\n\nreflectiveness of critical\n\nthinking.\n\nLimited sample size.\n\nLack of longitudinal\n\ndata.\n\nStyve et\n\nal.\n\n(2024).\n\nSurvey-\n\nbased, Pre\n\nand Post-test\n\nGenAI improves\n\nstudents' critical\n\nthinking practices.\n\nStudents demonstrated a\n\ngreater ability to critically\n\nevaluate AI-generated\n\nsolutions, reflecting on their\n\nappropriateness and\n\nreliability.\n\nHigher-order thinking\n\nwas not evaluated.\n\nThe introductory course\n\nwill not represent all\n\nlevels of coding.\n\nThe results are based on\n\nstudents’ self-reported\n\nopinions and practices.\n\nLong-term effects and\n\nchanges in critical\n\nthinking practices were\n\nnot considered. The\n\nfocus was on specific AI\n\ntools only.\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n211\n\nWalter,\n\nY.\n\n(2024).\n\nCase study\n\nAI literacy and\n\nprompt\n\nengineering to\n\nenhance\n\neducational\n\nexperiences and\n\npromote critical\n\nthinking\n\nChallenges in educator\n\ntraining, ethical\n\nconsiderations, and resource\n\naccessibility.\n\nA single university was\n\nconsidered.\n\nInformal discussion\n\nmay need to be revised.\n\nZaphir et\n\nal.\n\n(2024)\n\nEvaluate the\n\nMASE\n\nframework\n\nusing case\n\nstudies\n\nThere are\n\nlimitations of\n\nChatGPT4 in\n\nemulating critical\n\nthinking,\n\nEducators redesign\n\nassessments to focus on\n\ndeeper comprehension and\n\nanalytical skills. The study\n\nemphasises the importance of\n\nauthentic learning to deter AI-\n\ndriven shortcuts.\n\nNot all aspects of\n\ncritical thinking were\n\nconsidered in the\n\nproposed framework.\n\nHsiao-\n\nPing Hsu\n\n(2023).\n\nIterative\n\nthree-stage\n\nmanuscript\n\ngeneration\n\nprocess with\n\nChatGPT\n\nGenAI offers\n\ninsights and\n\nsupport in\n\ndeveloping\n\nresearch ideas and\n\ndesigns, academic\n\nwriting, and\n\nEnglish\n\ncomposition.\n\nThe need to balance the\n\ngrowing capabilities of GenAI\n\nwith preserving traditional\n\nacademic and educational\n\nvalues is crucial.\n\nLack of a guiding map\n\nproviding the expected\n\nmajor and minor\n\nheading required for\n\neach chapter.\n\nConclusions and Recommendations\n\nAlthough the broader impact of GenAI in education has been thoroughly explored (Lim et al., 2023),\n\nthere has been a noticeable oversight in examining critical thinking within higher education settings\n\n(QAA, 2023). The findings of about fifty percent of the reviewed papers concludethat GenAI positively\n\nimpacts the critical thinking of undergraduates. This literature study indicates that incorporating GenAI\n\ntools like ChatGPT into higher education can significantly enhance students' critical thinking skills\n\nwhen used thoughtfully. Studies show structured engagement with ChatGPT helps students move from\n\nbasic recall to more advanced reasoning and critical analysis (Shanto et al., 2024). However, these\n\nfindings cannot be generalised due to the sample size, research design, and study context. A significant\n\nnumber of papers have no conclusive evidence of the impact of GenAI on undergraduates' critical\n\nthinking skills. The study of Essien et al. (2024) found that the most notable improvements in critical\n\nthinking occurred at the lower levels of Bloom's Taxonomy, such as remembering, understanding and\n\napplying, suggesting that AI text generators have a foundational impact on student learning. However,\n\nthere is a lack of solid evidence from the literature showing the positive effects of GenAI on higher-\n\norder thinking skills like analysing, evaluation, and creating.\n\nAdditionally, concerns about over-reliance on these tools have been raised, which may inhibit creativity\n\nand original thought (Taiye et al.,2024). While students often see GenAI as helpful for personalised\n\nlearning and writing assistance, they also voice concerns about its accuracy and ethical implications,\n\nwhich could affect the development of their critical thinking skills (Chan & Hu, 2023). Thus, while\n\nGenAI has the potential to support critical thinking, its effective use requires thoughtful implementation\n\nand continuous evaluation to mitigate potential risks (Berg & Plessis,2023; Taiye et al.,2024).\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n212\n\nThe selected studies also emphasise AI literacy and prompt engineering, which are key to developing\n\ncritical thinking skills in education. Teaching students and teachers techniques like zero-shot and few-\n\nshot prompting encourages greater engagement with AI, promoting critical analysis and creative\n\nproblem-solving (Walter, 2024). Collaborative exercises using prompt engineering challenge students\n\nand enhance their understanding of AI interactions, enriching their learning experience. This approach\n\nalso increases awareness of AI's limitations and capabilities, which are essential for informed decision-\n\nmaking and reflective thinking. Integrating AI literacy and prompt engineering creates a more\n\ninteractive learning environment that fosters critical thinking (Jia & Tu, 2024).\n\nAccording to the findings of this Review, further studies are needed to address the literature, theoretical,\n\npractical, and contextual gaps to provide a more comprehensive understanding of the topic, particularly\n\nconsidering the significance of critical thinking skills in the ever-changing higher educational\n\nlandscape.\n\nRecommendations\n\nEducators should prioritise AI literacy and prompt engineering to effectively leverage GenAI in\n\nfostering critical thinking within academic activities. It is crucial to evaluate assessment tasks for\n\npotential AI vulnerabilities and to redesign them to emphasise the testing of critical and analytical skills.\n\nAdditionally, ensuring the reliability of AI tools and providing clear guidelines on acceptable GenAI\n\ntools are essential. Institutions should also develop robust policies to govern the responsible use of\n\nGenAI, thereby upholding academic integrity.\n\nGaps and Limitations\n\nThe common limitations across the numerous studies include small sample sizes, which affect the\n\ngeneralizability of findings, and short study durations that limit the understanding of long-term impacts.\n\nMany studies had a geographic or disciplinary focus, reducing the applicability of results to broader\n\ncontexts. Ethical and social implications, such as biases, data privacy, and academic integrity, were\n\nfrequently noted but not deeply explored. A reliance on quantitative data might not fully capture the\n\ndepth of participants’ experiences and perceptions. Additionally, several studies were in preliminary or\n\nconceptual stages, requiring further development and validation. There was a dependency on specific\n\nAI tools, frameworks, or methodologies, which might limit the diversity of findings. Lastly, many\n\nstudies lacked long-term data to assess the sustained impact of AI tools on educational outcomes.\n\nFuture Research\n\nThere is a pressing need for additional research on higher education institutions to assess their methods\n\nof teaching and fostering critical thinking skills, particularly in relation to students' use of GenAI-based\n\ntools. Future studies should examine the application of GenAI across different contexts to gain a deeper\n\nunderstanding of its use and the impact of contextual factors on critical thinking skills. Moreover,\n\nstudies should focus more on how GenAI can improve higher-order thinking skills.\n\nPrior studies have rarely utilised taxonomies beyond Bloom's to evaluate the critical thinking skills of\n\nstudents using GenAI. Furthermore, research should broaden to include more disciplines, allowing for\n\ncomparisons across fields to identify factors influencing its use. Additional research is needed to explore\n\nthe link between prompt engineering and critical thinking skills among higher education students. A\n\nlongitudinal approach could help track applications like ChatGPT and identify long-term users.\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n213\n\nAcknowledgement\n\nThis work was conducted without specific financial support from public, commercial, or not-for-profit\n\nfunding agencies.\n\nReference\n\nArum, R., & Roksa, J. (2011). Academically adrift: Limited learning on college campuses. University\n\nof Chicago Press.\n\nBarana, A., Marchisio, M., & Roman, F. (2023). Fostering problem-solving and critical thinking in\n\nmathematics through generative artificial intelligence.\n\nBerg, G., & Plessis, E. (2023). ChatGPT and Generative AI: Possibilities for Its Contribution to Lesson\n\nPlanning, Critical Thinking and Openness in Teacher Education. Education Sciences.\n\nBhosale, U. (2023). Responsible Use of Generative AI. Enago Academy.\n\nhttps://www.enago.com/academy/responsibleuse-of-generative-ai/\n\nChan, C. K. Y., & Hu, W. (2023). Students’ Voices on Generative AI: Perceptions, Benefits, and\n\nChallenges in Higher Education. https://doi.org/10.1186/s41239-023-00411-8\n\nChan, C. K. Y., & Lee, K. K. W. (2023). The AI generation gap: Are Gen Z students more interested in\n\nadopting generative AI such as ChatGPT in teaching and learning than their Gen X and\n\nmillennial generation teachers? Smart Learning Environments, 10(1), 60.\n\nhttps://doi.org/10.1186/s40561-023-00269-3\n\nDavies, M. (2015). A model of critical thinking in higher education. In M.B. Paulsen (ed.), Higher\n\nEducation: Handbook of Theory and Research 30. DOI 10.1007/978-3-319-12835-1\\_2\n\nDai, Y., Liu, A., & Lim, C. P. (2023). Reconceptualising ChatGPT and generative AI as a student-\n\ndriven innovation in higher education. Procedia CIRP, 119, 84–90.\n\nhttps://doi.org/10.1016/j.procir.2023.05.002 .\n\nDearing, R. (1997). Higher Education in the Learning Society. The National Committee of Enquiry into\n\nHigher Education.\n\nhttp://www.educationengland.org.uk/documents/dearing1997/dearing1997.html\n\nElsayed, S.M. (2023). Towards Mitigating ChatGPT's Negative Impact on Education: Optimising\n\nQuestion Design Through Bloom's Taxonomy. 2023 IEEE Region 10 Symposium\n\n(TENSYMP), 1-6.\n\nEssien, A., Bukoye, O. T., O’Dea, C., & Kremantzis, M. (2024). The influence of AI text generators on\n\ncritical thinking skills in UK business schools. Studies in Higher Education.\n\nhttps://doi.org/10.1080/03075079.2024.2316881\n\nEssien, A., G. Chukwukelu, and V. Essien. (2021). Opportunities and Challenges of Adopting Artiﬁcial\n\nIntelligence for Learning and Teaching in Higher Education. In: Fostering Communication and\n\nLearning with Underutilized Technologies in Higher Education. IGI Global, pp. 67–78.\n\nEze, I.F., Iwu, C.G., & Dubihlela, J. (2022). Students’ views regarding the barriers to learning critical\n\nthinking. International Journal of Research in Business and Social Science (2147- 4478).\n\nFahim, M., & Masouleh, N.S. (2012). Critical thinking in higher education: A pedagogical look. Theory\n\nand Practice in Language Studies, 2(7), 1370-1375. doi: 10.4304/tpls.2.7.1370-1375\n\nFarrokhnia, M., Banihashem, S. K., Noroozi, O., & Wals, A. (2023). A SWOT analysis of ChatGPT:\n\nImplications for educational practice and research. Innovations in Education and Teaching\n\nInternational, 0(0), 1–15\\. https://doi.org/10.1080/14703297.2023.2195846\n\nFiialka, S., Kornieva, Z., & Honcharuk, T. (2023). ChatGPT in Ukrainian Education: Problems and\n\nProspects. Int. J. Emerg. Technol. Learn., 18, 236-250.\n\nGeorge, A. S. H. George, and A. S. G. Martin, (2023). “A Review of ChatGPT AI’s Impact on Several\n\nBusiness Sectors,” Partners Universal International Innovation Journal (PUIIJ), vol. 01, no. 01,\n\npp. 9–23, doi: https://doi.org/10.5281/zenodo.7644359.\n\nHsiao-Ping Hsu. (2023). Can Generative Artificial Intelligence Write an Academic Journal Article?\n\nOpportunities, Challenges, and Implications. Irish Journal of Technology Enhanced Learning.\n\nhttps://doi.org/10.22554/ijtel.v7i2.152\n\nHuber, C. R., & Kuncel, N. R. (2016). Does College Teach Critical Thinking? A Meta-Analysis. Review\n\nof Educational Research, 86(2), 431–468\\. https://doi.org/10.3102/0034654315605917\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n214\n\nHunt, C. (2011). National Strategy for Higher Education to 2030: Report of the Strategy Group.\n\nDepartment of Education and Skills, Government Publications Office.\n\nhttp://hea.ie/assets/uploads/2017/06/National-Strategy-for-Higher-Education-2030.pdf\n\nHutson, J. (2024). Rethinking Plagiarism in the Era of Generative AI. Journal of Intelligent\n\nCommunication, 4(1), 20–31\\. https://doi.org/10.54963/jic.v4i1.220\n\nJavaid, M., Haleem, A., Singh, R. P., Khan, S., & Khan, I. H. (2023). Unlocking the opportunities\n\nthrough ChatGPT Tool towards ameliorating the education system. Bench Council\n\nTransactions on Benchmarks, Standards and Evaluations, 3(2),\n\ndoi:https://doi.org/10.3390/healthcare11060887.\n\nJia, X.-H., & Tu, J.-C. (2024). Towards a New Conceptual Model of AI-Enhanced Learning for College\n\nStudents: The Roles of Artificial Intelligence Capabilities, General Self-Efficacy, Learning\n\nMotivation, and Critical Thinking Awareness. Systems, 12(3), 74.\n\nhttps://doi.org/10.3390/systems12030074\n\nJISC. (2023). Does ChatGPT mean the End of the Essay as an Assessment Tool? \\| Jisc \\[WWW\n\nDocument\\]. Accessed April 21, 2024. URL https://www.jisc.ac.uk/news/does-chatgpt-mean-\n\nthe-end-of-the-essay-as-an-assessment-tool-10-jan-2023.\n\nKasneci, E., Seßler, K., Küchemann, S., Bannert, M., Dementieva, D., Fischer, F., Gasser, U., Groh,\n\nG., Günnemann, S., Hüllermeier, E., et al. (2023). ChatGPT for good? On opportunities and\n\nchallenges of large language models for education. Learning and Individual Differences, 103,\n\n102274.\n\nLancaster, T. (2023). “Artiﬁcial Intelligence, Text Generation Tools and ChatGPT–Does Digital\n\nWatermarking Oﬀer a Solution?” International Journal for Educational Integrity 19:10.\n\nhttps://doi.org/10.1007/s40979-023-00131-6.\n\nLame, G. (2019). Systematic Literature Reviews: An Introduction. Proceedings of the Design Society:\n\nInternational Conference on Engineering Design, 1(1), 1633–1642.\n\nhttps://doi.org/10.1017/dsi.2019.169\n\nLeiker, D., A. R. Gyllen, I. Eldesouky, and M. Cukurova. (2023). Generative AI for Learning:\n\nInvestigating the Potential of Synthetic Learning Videos. arXiv Prepr. ArXiv2304.03784.\n\nLim, W. M., A. Gunasekara, J. L. Pallant, J. I. Pallant, and E. Pechenkina. (2023). “Generative AI and\n\nthe Future of Education: Ragnarök or Reformation? A Paradoxical Perspective from\n\nManagement Educators.” The International Journal of Management Education 21 (2): 100790.\n\nhttps://doi.org/10.1016/j.ijme.2023.100790.\n\nLu, J., Zheng, R., Gong, Z., & Xu, H. (2024). Supporting Teachers' Professional Development with\n\nGenerative AI: The Effects on Higher Order Thinking and Self-Efficacy. IEEE Transactions on\n\nLearning Technologies, p. 17, 1279–1289.\n\nMichel-Villarreal, R., Vilalta-Perdomo, E.L., Salinas-Navarro, D.E., Thierry-Aguilera, R., & Gerardou,\n\nF.S. (2023). Challenges and Opportunities of Generative AI for Higher Education as Explained\n\nby ChatGPT. Education Sciences.\n\nMoore, T. J. (2011). Critical thinking and language: The challenge of generic skills and disciplinary\n\ndiscourse. London: Bloomsbury Academic. 978144111359-web more book.pdf (secured)\n\nNACE Center, “What is career readiness?” NACE Center for Career Development and Talent\n\nAcquisition, 2021. https://www.naceweb.org/career-readiness/competencies/careerreadiness-\n\ndefined/ (accessed April. 23, 2024).\n\nPaul, R. (2011). \"Reflections on the Nature of Critical Thinking, Its History, Politics, and Barriers, and\n\nIts Status Across the College/University Curriculum Part I.\" INQUIRY: Critical Thinking\n\nAcross the Disciplines 26 (3), 5–24.\n\nPaul, R., & Elder, L. (2006). The miniature guide to critical thinking: Concepts and tools. Retrieved from:\n\nhttp://criticalthinking.org/files/Concepts\\_Tools.pdf\n\nQAA. (2023). Maintaining quality and standards in the ChatGPT era: QAA advice on the opportunities and\n\nchallenges of Generative Artiﬁcial Intelligence \\[WWW Document\\]. Accessed April 21, 2024. URL\n\nhttps://www. qaa.ac.uk/docs/qaa/members/maintaining-quality-and-standards-in-the-chatgpt-\n\nera.pdf.\n\nRudolph, J., Samson Tan, & Shannon Tan. (2023). \"ChatGPT: Bullshit Spewer or the End of Traditional\n\nAssessments in Higher Education?\" Journal of Applied Learning and Teaching 6 (1): 342–363.\n\nhttps://doi.org/10.37074/jalt.2023.6.1.9.\n\nThe Journal of Desk Research Review and Analysis, Vol. 2, Issue 1, 2024, 199-215\n\n215\n\nRuiz-Rojas, L. I., Salvador-Ullauri, L., & Acosta-Vargas, P. (2024). Collaborative Working and Critical\n\nThinking: Adoption of Generative Artificial Intelligence Tools in Higher Education. Sustainability,\n\n16(5367). https://doi.org/10.3390/ su16135367\n\nSadat Shanto, S., & Ahmed, Z. (2024). Enriching the Learning Process with Generative AI: A Proposed\n\nFramework to Cultivate Critical Thinking in Higher Education using ChatGPT. Article in Tuijin\n\nJishu/Journal of Propulsion Technology, 45(1), 1001–4055.\n\nhttps://doi.org/10.52783/tjjpt.v45.i01.4680\n\nSallam, M. (2023). “ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review\n\non the Promising Perspectives and Valid Concerns,” Healthcare, vol. 11(6). p. 887.\n\ndoi:https://doi.org/10.3390/healthcare11060887.\n\nSmolansky, A., Cram, A., Raduescu, C., Zeivots, S., Huber, E., & Kizilcec, R.F. (2023). Educator and\n\nStudent Perspectives on the Impact of Generative AI on Assessments in Higher Education.\n\nProceedings of the Tenth ACM Conference on Learning @ Scale.\n\nStanford Encyclopedia of Philosophy. (2018). Critical thinking. Retrieved from\n\nhttps://plato.stanford.edu/entries/critical-thinking/#DeweThreMainExam\n\nSternberg, R. J., & Halpern, D. F. (Eds.). (2020). Critical thinking in psychology (2nd ed.). Cambridge\n\nUniversity Press. https://doi.org/10.1017/9781108684354\n\nStyve, A., Virkki, O. T., & Naeem, U. (2024). Developing critical thinking practices interwoven with\n\ngenerative AI usage in an introductory programming course. In 2024 IEEE Global Engineering\n\nEducation Conference (EDUCON) (pp. 01-08). Kos Island, Greece.\n\nhttps://doi.org/10.1109/EDUCON60312.2024.10578746\n\nTat Putjorn & Pruet Putiorn. (2023). Augmented Imagination: Exploring Generative AI from the\n\nPerspectives of Young Learners. International Conferences on Information Technologies and\n\nElectrical Engineering. https://doi.org/10.1109/icitee59582.2023.10317680\n\nTenakwah, E. S., Boadu, G., & Tenakwah, E. J. (2023). Generative AI and Higher Education Assessments:\n\nA Competency-Based Analysis. https://orcid.org/0000-0001-6338-218X\n\nThiga, M. M. (2024). Generative AI and the Development of Critical Thinking Skills. IRE Journals, 7(9),\n\n83–90.\n\nTomlinson, M. (2010). Investing in the self: Structure, agency, and identity in graduates' employability.\n\nEducation, Knowledge, and Economy, 4(2), 73–88\\. https://doi.org/10.1080/17496896.2010.499273\n\nUtami, R.T., Saleh, M., Warsono, & Hartono, R. (2021). Factors Affecting Students’ Critical Thinking\n\nDevelopment in EFL Classroom. Proceedings of the 1st Paris Van Java International Seminar on\n\nHealth, Economics, Social Science and Humanities (PVJ-ISHESSH 2020).\n\nWalter, Y. (2024). Embracing the future of Artificial Intelligence in the classroom: The relevance of AI\n\nliteracy, prompt engineering, and critical thinking in modern education. International Journal of\n\nEducational Technology in Higher Education, 21(1). https://doi.org/10.1186/s41239-024-00448-3\n\nWang, C. (2024). Exploring Students' Generative AI-Assisted Writing Processes: Perceptions and\n\nExperiences from Native and Non-native English Speakers. Technology, Knowledge, and Learning.\n\nhttps://doi.org/10.1007/s10758-024-09744-3\n\nWass, R. T. (2012). Developing critical thinkers in higher education: A Vygotskian perspective. (Doctoral\n\nThesis), University of Otago, Dunedin, New Zealand. Retrieved from\n\nhttps://ourarchive.otago.ac.nz/bitstream/handle/10523/2491/WassRobertT2012PhD.pdf?sequenc\n\ne=1&isAllowed=y.\n\nWorld Economic Forum. (2023). The-future-of-jobs-report-2023. www.weforum.org\n\nY Fin Le Y, A. le, & Finley, A. (2021). How College Contributes to Workforce Success EMPLOYER\n\nVIEWS ON WHAT MATTERS MOST How College Contributes to Workforce Success\n\nEMPLOYER VIEWS ON WHAT MATTERS MOST. Association of American Colleges and\n\nUniversities\n\nYilmaz, R., & Yilmaz, F. G. K. (2023). The effect of generative artificial intelligence (AI)-based tool use on\n\nstudents’ computational thinking skills, programming self-efficacy and motivation. Computers and\n\nEducation: Artificial Intelligence, 4, 100147. https://doi.org/10.1016/j.caeai.2023.100147\n\nZaphir, L., Lodge, J. M., Lisec, J., Mcgrath, D., & Khosravi, H. (2024). How critically can an AI think? A\n\nframework for evaluating the quality of thinking of generative artificial intelligence.\n\nhttps://doi.org/10.48550/arXiv.2406.14769\n\n... The growing complexity of digital learning environments has intensified the demand for critical thinking skills. Particularly skills related to navigating information, evaluating arguments, and making informed decisions \\[18\\], \\[27\\] have become key. In this context, GenAI is increasingly being explored for its capacity to support cognitive development through interactive, personalized, and adaptive learning experiences. ...\n\n... Although rather than replacing human reasoning, GenAI functions as a scaffold that supports and amplifies the development of cognitive autonomy, when implemented ethically and intentionally. Scholars such as Akhtar \\[18\\] and Pervaiz et al. \\[30\\] argue that when aligned with clearly defined educational objectives, GenAI can foster critical engagement and reflective thinking. All these would offer meaningful contributions to a pedagogical model grounded in intellectual rigor and digital responsibility. ...\n\n... It is supported by the results presented in section 4.1, where the Kruskal-Wallis test yielded a p-value of 0.1655, indicating no significant differences in AI knowledge among the different age groups (Figure 1). Akhtar \\[18\\] highlights that integrating GenAI in higher education requires moving beyond generational assumptions, focusing instead on equitable access and pedagogical support to ensure inclusive AI literacy. This finding suggests that instructional design and educational opportunity, rather than age, are the primary drivers of students' engagement with AI tools reinforcing the need for universal strategies to foster digital competence in higher education. ...\n\n[Evaluation of Generative AI Use to Foster Critical Thinking in Higher Education](https://www.researchgate.net/publication/394444564_Evaluation_of_Generative_AI_use_to_foster_critical_thinking_in_higher_education)\n\nArticle\n\nFull-text available\n\n- [Luis Magdiel Oiva-Córdova](https://www.researchgate.net/scientific-contributions/Luis-Magdiel-Oiva-Cordova-2321616757)\n- [Inés Alvarez-Icaza](https://www.researchgate.net/profile/Ines-Alvarez-Icaza)\n- [Carlos Enrique George-Reyes](https://www.researchgate.net/profile/Carlos-George-Reyes-2)\n\nCritical thinking is a key competency in higher education, particularly in digital environments that demand analysis, judgment, and informed decision-making. Generative Artificial Intelligence (GenAI) represents an emerging opportunity to enhance complex cognitive skills in educational settings. A quasi-experimental research design with a mixed-methods approach was employed and applied to a sample of university students aiming to address the research question: What is the impact of using GenAI tools on the development of critical thinking in university students? The educational intervention consisted of structured workshops that incorporated GenAI tools into activities aimed at developing six dimensions of critical thinking: remembering, understanding, applying, analyzing, evaluating, and creating. Results showed significant improvements in applying (p = .002), analyzing (p = .0008), and evaluating (p = .003), all associated with higher-order thinking skills. Three dimensions -remembering, understanding, and creating- showed statistically significant changes. However, students’ perception showed a notable increase in the value of GenAI use. Additionally, participants highlighted the usefulness of GenAI for generating ideas, decision making, and promoting deeper reflections. The study concludes that the intentional integration of GenAI technologies, when aligned with clear educational goals, can produce a meaningful and positive impact on the development of critical thinking in university contexts. These findings offer empirical support for designing innovative, ethically grounded learning experiences that incorporate GenAI to strengthen cognitive development in higher education.\n\n[View](https://www.researchgate.net/publication/394444564_Evaluation_of_Generative_AI_use_to_foster_critical_thinking_in_higher_education)\n\nShow abstract\n\n... In addition, Suh et al.'s experiment involved a one-time, 40-minute essay task with ten participants; our eight-week action research across three colleges (N = 92) shows that scaffolded prompts yield durable, longitudinal CT gains, overcoming the temporary improvements and mechanical trade-offs they observed. Furthermore, whereas Premkumar, et al. \\[20\\] reported mixed generative-AI benefits in undergraduates due to inconsistent intervention designs \\[21\\] our precisely designed prompt frameworks produced consistently robust gains, addressing their call for rigorous scaffold development. ...\n\n... Ruiz-Rojas, et al. \\[21\\] surveyed students who believed generative AI improved their CT, but lacked objective measures or evidence of sustained reflection \\[20\\]. Our NVivo analysis shows reflectiveawareness codes rose 73% over four cycles, proving that pairing AI prompts with teacher-led debriefs transforms momentary insight into enduring self-monitoring habits. ...\n\n... By comparing with CGCAW \\[19\\] AI-CRITIQUE \\[23\\] and other frameworks, we provide the first empirical validation of a unified GenAI-CT model that embeds Bloom's taxonomy, Vygotsky \\[5\\] ZPD, and cognitive apprenticeship within multi-cycle AI-mediated pedagogy. Unlike survey-only \\[21\\] or single-draft \\[19,24,26\\] designs, our multi-site action research offers both breadth and depth, fulfilling calls for robust intervention studies \\[20\\]. This research shows how to craft precision prompts, orchestrate dual-layer mediation, and sequence iterative cycles-a cohesive, replicable protocol for EFL contexts. ...\n\n[Generative AI–mediated scaffolds for enhanced critical thinking in EFL writing](https://www.researchgate.net/publication/392568809_Generative_AI-mediated_scaffolds_for_enhanced_critical_thinking_in_EFL_writing)\n\nArticle\n\n- Jun 2025\n\n- [Hui Hong](https://www.researchgate.net/scientific-contributions/Hui-Hong-2315778944)\n- [Poonsri Vate-U-Lan](https://www.researchgate.net/scientific-contributions/Poonsri-Vate-U-Lan-2315775010)\n- [Chantana Viriyavejakul](https://www.researchgate.net/scientific-contributions/Chantana-Viriyavejakul-2315808310)\n\nGenerative AI tools present new opportunities for enhancing critical thinking (CT) in English as a Foreign Language (EFL) writing instruction. This study investigates how the structured integration of these technologies could support the development of CT skills, particularly in vocational education contexts. An eight-week multiple-case action research design was conducted across three vocational colleges, involving 92 students engaged in iterative writing and revision cycles guided by the GenAI-CT framework. This pedagogical model draws on Bloom’s taxonomy, Vygotsky’s Zone of Proximal Development, and cognitive apprenticeship theory to scaffold learners through increasingly complex reasoning tasks. Data were collected from student essays, AI interaction logs, reflective journals, and classroom observations. Mixed-methods analysis revealed statistically significant gains across all CT dimensions (p< .001). Thematic findings indicated notable increases in analytical depth, metacognitive reflection, and evaluative judgment. Variations across cases underscored the influence of disciplinary focus and instructional mediation styles. These results demonstrate that generative AI, when embedded in intentional pedagogical structures, can foster cognitive engagement rather than superficial automation. The GenAI-CT framework offers a replicable model for integrating AI in applied language and communication instruction, supporting educators in cultivating critical thinking through technology-enhanced learning environments.\n\n[View](https://www.researchgate.net/publication/392568809_Generative_AI-mediated_scaffolds_for_enhanced_critical_thinking_in_EFL_writing)\n\nShow abstract\n\n... Research investigating the impact of classroom useage of GAI on students critical thinking is limited, both in volume and study design \\[13\\]. Students who use GAI are more likely to procrastinate and less likely to remember what they learned \\[14\\]. ...\n\n[Pilot Study on Generative AI and Critical Thinking in Higher Education Classrooms](https://www.researchgate.net/publication/395212774_Pilot_Study_on_Generative_AI_and_Critical_Thinking_in_Higher_Education_Classrooms)\n\nPreprint\n\nFull-text available\n\n- Aug 2025\n\n- [W. F. Lamberti](https://www.researchgate.net/scientific-contributions/W-F-Lamberti-2323849563)\n- [S. R. Lawrence](https://www.researchgate.net/scientific-contributions/S-R-Lawrence-2323839989)\n- [D. White](https://www.researchgate.net/scientific-contributions/D-White-2323833089)\n- [S. Abdullah](https://www.researchgate.net/scientific-contributions/S-Abdullah-2323863878)\n\nGenerative AI (GAI) tools have seen rapid adoption in educational settings, yet their role in fostering critical thinking remains underexplored. While previous studies have examined GAI as a tutor for specific lessons or as a tool for completing assignments, few have addressed how students critically evaluate the accuracy and appropriateness of GAI-generated responses. This pilot study investigates students' ability to apply structured critical thinking when assessing Generative AI outputs in introductory Computational and Data Science courses. Given that GAI tools often produce contextually flawed or factually incorrect answers, we designed learning activities that require students to analyze, critique, and revise AI-generated solutions. Our findings offer initial insights into students' ability to engage critically with GAI content and lay the groundwork for more comprehensive studies in future semesters.\n\n[View](https://www.researchgate.net/publication/395212774_Pilot_Study_on_Generative_AI_and_Critical_Thinking_in_Higher_Education_Classrooms)\n\nShow abstract\n\n... Berpikir kritis merupakan kemampuan yang sangat esensial untuk kehidupan dan berfungsi efektif dalam semua aspek kehidupan. Berpikir kritis mampu menyiapkan peserta didik berpikir pada berbagai disiplin ilmu, serta dapat dipakai untuk menyiapkan peserta didik untuk menjalani karir dan kehidupan nyatanya (Premkumar et al., 2024). Critical thinking penting bagi mahasiswa karena kemampuan ini memungkinkan mereka untuk menganalisa informasi secara mendalam, mengevaluasi berbagai perspektif dan membuat keputusan berdasarkan data yang valid . ...\n\n[Penggunaan GenAI terhadap Kemampuan Berpikir Kritis Mahasiswa PGSD](https://www.researchgate.net/publication/395010108_Penggunaan_GenAI_terhadap_Kemampuan_Berpikir_Kritis_Mahasiswa_PGSD)\n\nArticle\n\nFull-text available\n\n- Aug 2025\n\n- [Petrus Murwanto](https://www.researchgate.net/scientific-contributions/Petrus-Murwanto-2273003414)\n- [Ria Triayomi](https://www.researchgate.net/scientific-contributions/Ria-Triayomi-2156127849)\n\nKehadiran kecerdasan buatan generatif (Generative Artificial Intelligence/GenAI) dalam dunia pendidikan memunculkan dinamika baru dalam proses pembelajaran, khususnya terkait pengembangan kemampuan berpikir kritis mahasiswa. Penelitian ini bertujuan untuk mengetahui persepsi mahasiswa terhadap penggunaan GenAI dan dampaknya terhadap kemampuan berpikir kritis. Penelitian menggunakan pendekatan kuantitatif deskriptif dengan melibatkan 101 mahasiswa Program Studi Pendidikan Guru Sekolah Dasar (PGSD) Universitas Katolik Musi Charitas. Instrumen yang digunakan berupa kuesioner online yang mencakup berbagai aspek berpikir kritis dan interaksi mahasiswa dengan GenAI. Hasil penelitian menunjukkan bahwa mayoritas mahasiswa (47,52 %) mempersepsikan GenAI sebagai alat yang cukup membantu dalam mendorong berpikir kritis, namun di sisi lain juga 70, 3 % responden menyadari potensi GenAI dalam menurunkan kualitas kemampuan berpikir kritis apabila digunakan tanpa proses reflektif dan verifikasi. Terdapat kecenderungan positif (56 %) dalam praktik verifikasi informasi, namun masih ditemukan kendala berupa rendahnya literasi informasi serta ketidaktahuan terhadap sumber referensi yang kredibel (56,4 %), keterbatasan pemahaman prosedural (38,5 %) dan keterbatasan waktu (30,8 %). Oleh karena itu, diperlukan strategi integrasi GenAI secara pedagogis yang diiringi dengan peningkatan literasi digital dan penguatan keterampilan berpikir kritis mahasiswa agar teknologi ini dapat digunakan secara optimal dan bertanggung jawab dalam konteks akademik.\n\n[View](https://www.researchgate.net/publication/395010108_Penggunaan_GenAI_terhadap_Kemampuan_Berpikir_Kritis_Mahasiswa_PGSD)\n\nShow abstract\n\n... The author understands that these discussions are based on approximately half of the enrolled students granting permission to examine their work on one single assignment in one single course. This is a potential limitation to the study's broader implications, even though the population of participating students is much larger than some of the referenced studies \\[22\\] \\[23\\]. Preliminary examination of a similar GenAI approach on a second assignment in this course, with a different targeted Learning Outcome, suggests that the same pool of students apply what they have learned in the current study to their own future work in the course. ...\n\n[WIP - An Exploratory Approach to Introducing Generative AI into a Large-scale Engineering-focused General Education Course](https://www.researchgate.net/publication/394828668_WIP_-_An_Exploratory_Approach_to_Introducing_Generative_AI_into_a_Large-scale_Engineering-focused_General_Education_Course)\n\nConference Paper\n\n- Jun 2025\n\n- [Brian Kirkmeyer](https://www.researchgate.net/profile/Brian-Kirkmeyer)\n\n[View](https://www.researchgate.net/publication/394828668_WIP_-_An_Exploratory_Approach_to_Introducing_Generative_AI_into_a_Large-scale_Engineering-focused_General_Education_Course)\n\n... Due to the importance of these skills across educational, occupational, and civic contexts, they have been widely accepted and are still seen as relevant in the long journey towards modernizing education \\[80\\]. Notably, each of these skills has a meaningful interface with GenAI: critical thinking may inform humans' effective use of GenAI, and reciprocally, GenAI use may support the promotion of humans' critical thinking \\[81\\]\\[82\\]\\[83\\]; human-machine communication lies at the core of using GenAI-based applications, and interpersonal communication may be meaningfully impacted by the use of GenAI \\[84,85\\]; collaboration-wise, GenAI is often looked at as an aid to humans \\[48\\]; and creativity may play an important role in promoting the synergy between humans and GenAI \\[86\\]\\[87\\]\\[88\\]. ...\n\n[Framing and Evaluating Task-Centered Generative Artificial Intelligence Literacy for Higher Education Students](https://www.researchgate.net/publication/393220958_Framing_and_Evaluating_Task-Centered_Generative_Artificial_Intelligence_Literacy_for_Higher_Education_Students)\n\nArticle\n\nFull-text available\n\n- Jun 2025\n\n- [Arnon Hershkovitz](https://www.researchgate.net/profile/Arnon-Hershkovitz)\n- [Michal Tabach](https://www.researchgate.net/profile/Michal-Tabach)\n- [Yoram Reich](https://www.researchgate.net/profile/Yoram-Reich)\n- [Tamar Cholcman](https://www.researchgate.net/scientific-contributions/Tamar-Cholcman-2314638623)\n\nThe rise in generative artificial intelligence (GenAI) demands new forms of literacy among higher education students. This paper introduces a novel task-centered generative artificial intelligence literacy framework, which was developed collaboratively with academic and administrative staff at a large research university in Israel. The framework identifies eight skills which are informed by the six cognitive domains of Bloom’s Taxonomy. Based on this framework, we developed a measuring tool for students’ GenAI literacy and surveyed 1667 students. Findings from the empirical phase show moderate GenAI use and medium–high literacy levels, with significant variations by gender, discipline, and age. Notably, 82% of students support formal GenAI instruction, favoring integration within curricula to prepare for broader digital society participation. The study offers actionable insights for educators and policymakers aiming to integrate GenAI into higher education responsibly and effectively.\n\n[View](https://www.researchgate.net/publication/393220958_Framing_and_Evaluating_Task-Centered_Generative_Artificial_Intelligence_Literacy_for_Higher_Education_Students)\n\nShow abstract\n\n... Recent research on the impact of AI on critical thinking has typically reported positive outcomes, particularly in the use of chatbots in education. A systematic review by Premkumar, Yatigammana, and Kannangara \\[26\\] examined the impact of GenAI on the critical thinking skills of undergraduates. The study found that about half of the reviewed papers suggest that GenAI can enhance critical thinking skills. ...\n\n[The Impact of AI Use in Programming Courses on Critical Thinking Skills](https://www.researchgate.net/publication/390803419_The_Impact_of_AI_Use_in_Programming_Courses_on_Critical_Thinking_Skills)\n\nArticle\n\nFull-text available\n\n- Apr 2025\n\n- [Christian Jay St Francis Clarke](https://www.researchgate.net/scientific-contributions/Christian-Jay-St-Francis-Clarke-2310396018)\n- [Abdullah Konak](https://www.researchgate.net/profile/Abdullah-Konak)\n\n[View](https://www.researchgate.net/publication/390803419_The_Impact_of_AI_Use_in_Programming_Courses_on_Critical_Thinking_Skills)\n\n[The Impact of Using Generative Artificial Intelligence Tools (ChatGPT) on Developing Critical Thinking Skills Among University Students](https://www.researchgate.net/publication/394565638_The_Impact_of_Using_Generative_Artificial_Intelligence_Tools_ChatGPT_on_Developing_Critical_Thinking_Skills_Among_University_Students)\n\nArticle\n\nFull-text available\n\n- Aug 2025\n\n- [Sherin Hassan Mabrouk](https://www.researchgate.net/profile/Sherin-Mabrouk)\n\nThis study aims to investigate the impact of using generative artificial intelligence tools, specifically ChatGPT, on developing critical thinking skills among university students. A quasi-experimental design was employed, with participants divided into an experimental group that used ChatGPT as a learning tool to enhance critical thinking, and a control group that received traditional instruction. Critical thinking skills were measured before and after the intervention using a standardized and reliable assessment tool. The results indicated a significant improvement in the critical thinking abilities of the experimental group compared to the control group, suggesting that generative AI tools can effectively contribute to enhancing students’ analytical, evaluative, and logical reasoning skills. The study also discusses the challenges and opportunities associated with integrating this technology into educational settings. The findings recommend incorporating generative AI tools into university curricula, alongside providing adequate training for both students and instructors to maximize the benefits of this technology in fostering critical thinking skills.\n\n[View](https://www.researchgate.net/publication/394565638_The_Impact_of_Using_Generative_Artificial_Intelligence_Tools_ChatGPT_on_Developing_Critical_Thinking_Skills_Among_University_Students)\n\nShow abstract\n\n[Investigating the impact of Generative AI integration on the Sustenance of Higher-Order Thinking Skills and understanding of programming logic in Programming Education](https://www.researchgate.net/publication/394428466_Investigating_the_impact_of_Generative_AI_integration_on_the_Sustenance_of_Higher-Order_Thinking_Skills_and_understanding_of_programming_logic_in_Programming_Education)\n\nArticle\n\n- Jan 2025\n\n- [Jemimah Nathaniel](https://www.researchgate.net/profile/Jemimah-Nathaniel-2)\n- [Solomon Sunday Oyelere](https://www.researchgate.net/profile/Solomon-Oyelere)\n- [Jarkko Suhonen](https://www.researchgate.net/profile/Jarkko-Suhonen)\n- [Matti Tedre](https://www.researchgate.net/profile/Matti-Tedre)\n\nThis study investigates how integrating generative AI (GenAI) with instructional scaffolding and prompt engineering supports higher-order thinking skills (HOTS) and programming logic. A mixed-methods design was used, combining quantitative and qualitative data. The intervention followed a one-group pretest-post-test structure over seven weeks with 25-second-year computer science students with no prior C++ experience. The GenAI-Ped framework guided the design. It combines Bloom’s taxonomy, Seelf-Regulated Learning, Universal Design for Learning, and Vygotsky’s Zone of Proximal Development. Students received scaffolded support across six instructional phases, including prompt training and guided GenAI use. Quantitative results showed significant gains in problem-solving (applying constructs: t = 2.38, p = 0.013, d = 0.475), critical thinking (conditional reasoning: t = 2.53, p = 0.018, d = 0.506), creativity (applying new ideas: t = 2.28, p = 0.032, d = 0.456), and programming logic (loops: t = 2.78, p = 0.010, d = 0.555). However, smaller gains were observed in code optimization (t = 1.693, p = 0.103, d = 0.339) and evaluating solutions (t = 1.732, p = 0.096). Qualitative data, including feedback and GenAI chat logs, showed that prompt specificity and scaffolded feedback improved engagement, HOTS, and programming logic. The novelty of the study lies in its demonstration that the integration of GenAI into programming education using GenAI-Ped framework can sustain HOTS and programming logic while mitigating overreliance. These findings offer a practical model for integrating GenAI into programming education.\n\n[View](https://www.researchgate.net/publication/394428466_Investigating_the_impact_of_Generative_AI_integration_on_the_Sustenance_of_Higher-Order_Thinking_Skills_and_understanding_of_programming_logic_in_Programming_Education)\n\nShow abstract\n\n[A systematic review of generative AI in CALL published research in scholarly journals](https://www.researchgate.net/publication/394190252_A_systematic_review_of_generative_AI_in_CALL_published_research_in_scholarly_journals)\n\nArticle\n\nFull-text available\n\n- Jun 2025\n\n- [Yazdan Choubsaz](https://www.researchgate.net/profile/Yazdan-Choubsaz)\n- [S Arizavi](https://www.researchgate.net/scientific-contributions/S-Arizavi-2320720003)\n\nThis study aimed to systematically examine attitudes toward GenAI and its applications in CALL research published in top-tier CALL journals. Forty papers met the inclusion/exclusion criteria and were classified as attitudinal, empirical, and combined. Using a principled approach to coding and thematizing the data based on the research questions of the current study, major themes and trends were identified. Findings indicate an overall positive attitude to GenAI integration into CALL research, while negative voices were also detected concerning the biased nature of GenAI in relation to certain stereotypes and access inequalities. Regarding empirical research, it turned out that most were conducted in formal settings and were most effective in the writing skill, followed by speaking skills, revealing a serious gap in connection to the other language skills and subskills. The study also discusses research-related implications and then concludes with suggestions for further examination of GenAI in view of the observed limitations.\n\n[View](https://www.researchgate.net/publication/394190252_A_systematic_review_of_generative_AI_in_CALL_published_research_in_scholarly_journals)\n\nShow abstract\n\nShow more\n\n[Collaborative Working and Critical Thinking: Adoption of Generative Artificial Intelligence Tools in Higher Education](https://www.researchgate.net/publication/381696118_Collaborative_Working_and_Critical_Thinking_Adoption_of_Generative_Artificial_Intelligence_Tools_in_Higher_Education)\n\nArticle\n\nFull-text available\n\n- Jun 2024\n\n- [Lena Ruiz](https://www.researchgate.net/profile/Lena-Ruiz)\n- [Luis Salvador-Ullauri](https://www.researchgate.net/profile/Luis-Salvador-Ullauri)\n- [Patricia Acosta-Vargas](https://www.researchgate.net/profile/Patricia-Acosta-Vargas)\n\nThis study explores the impact of generative artificial intelligence tools on critical thinking and collaboration among university students, highlighting the importance of investigating these technologies due to their increasing integration into higher education and their potential to transform traditional pedagogical practices. A predominantly female sample was surveyed to assess their familiarity with and experience and perceptions of these tools. A total of 87% of the respondents had prior knowledge of generative AI tools, with 38% using them occasionally. Among the most popular tools are Canva 2024 (33%), Chat PDF (26%), and YOU.COM (24%). Additionally, 64% of the respondents believe that these tools significantly improve their critical thinking ability. Despite their high familiarity with and occasional use of these tools, the need for continuous training and technical support was identified. While generative AI tools show promising potential for enhancing collaboration and critical thinking in higher education, previous research has limitations, such as the lack of longitudinal data and the inadequacy in addressing ethical considerations and potential biases. More comprehensive research is needed to understand their long-term impact better and maximize their potential benefits.\n\n[View](https://www.researchgate.net/publication/381696118_Collaborative_Working_and_Critical_Thinking_Adoption_of_Generative_Artificial_Intelligence_Tools_in_Higher_Education)\n\nShow abstract\n\n[How critically can an AI think? A framework for evaluating the quality of thinking of generative artificial intelligence](https://www.researchgate.net/publication/381652447_How_critically_can_an_AI_think_A_framework_for_evaluating_the_quality_of_thinking_of_generative_artificial_intelligence)\n\nPreprint\n\nFull-text available\n\n- Jun 2024\n\n- [Luke Zaphir](https://www.researchgate.net/profile/Luke-Zaphir)\n- [Jason M Lodge](https://www.researchgate.net/profile/Jason-Lodge)\n- [Jacinta Lisec](https://www.researchgate.net/scientific-contributions/Jacinta-Lisec-2285142049)\n- [Hassan Khosravi](https://www.researchgate.net/profile/Hassan-Khosravi-5)\n\nGenerative AI such as those with large language models have created opportunities for innovative assessment design practices. Due to recent technological developments, there is a need to know the limits and capabilities of generative AI in terms of simulating cognitive skills. Assessing student critical thinking skills has been a feature of assessment for time immemorial, but the demands of digital assessment create unique challenges for equity, academic integrity and assessment authorship. Educators need a framework for determining their assessments vulnerability to generative AI to inform assessment design practices. This paper presents a framework that explores the capabilities of the LLM ChatGPT4 application, which is the current industry benchmark. This paper presents the Mapping of questions, AI vulnerability testing, Grading, Evaluation (MAGE) framework to methodically critique their assessments within their own disciplinary contexts. This critique will provide specific and targeted indications of their questions vulnerabilities in terms of the critical thinking skills. This can go on to form the basis of assessment design for their tasks.\n\n[View](https://www.researchgate.net/publication/381652447_How_critically_can_an_AI_think_A_framework_for_evaluating_the_quality_of_thinking_of_generative_artificial_intelligence)\n\nShow abstract\n\n[Rethinking Plagiarism in the Era of Generative AI](https://www.researchgate.net/publication/380134868_Rethinking_Plagiarism_in_the_Era_of_Generative_AI)\n\nArticle\n\nFull-text available\n\n- Apr 2024\n\n- [James Hutson](https://www.researchgate.net/profile/James-Hutson-4)\n\nThe emergence of generative artificial intelligence (AI) technologies, such as large language models (LLMs) like ChatGPT, has precipitated a paradigm shift in the realms of academic writing, plagiarism, and intellectual property. This article explores the evolving landscape of English composition courses, traditionally designed to develop critical thinking through writing. As AI becomes increasingly integrated into the academic sphere, it necessitates a reevaluation of originality in writing, the purpose of learning research and writing, and the frameworks governing intellectual property (IP) and plagiarism. The paper commences with a statistical analysis contrasting the actual use of LLMs in academic dishonesty with educator perceptions. It then examines the repercussions of AI-enabled content proliferation, referencing the limitation of three books self-published per day in September 2023 by Amazon due to a suspected influx of AI-generated material. The discourse extends to the potential of AI in accelerating research akin to the contributions of digital humanities and computational linguistics, highlighting its accessibility to the general public. The article further delves into the implications of AI on pedagogical approaches to research and writing, contemplating its impact on communication and critical thinking skills, while also considering its role in bridging the digital divide and socio-economic disparities. Finally, it proposes revisions to writing curricula, adapting to the transformative influence of AI in academic contexts.\n\n[View](https://www.researchgate.net/publication/380134868_Rethinking_Plagiarism_in_the_Era_of_Generative_AI)\n\nShow abstract\n\n[Towards a New Conceptual Model of AI-Enhanced Learning for College Students: The Roles of Artificial Intelligence Capabilities, General Self-Efficacy, Learning Motivation, and Critical Thinking Awareness](https://www.researchgate.net/publication/378502246_Towards_a_New_Conceptual_Model_of_AI-Enhanced_Learning_for_College_Students_The_Roles_of_Artificial_Intelligence_Capabilities_General_Self-Efficacy_Learning_Motivation_and_Critical_Thinking_Awareness)\n\nArticle\n\nFull-text available\n\n- Feb 2024\n\n- [Xi-Hui Jia](https://www.researchgate.net/scientific-contributions/Xi-Hui-Jia-2203917786)\n- [Jui-Che Tu](https://www.researchgate.net/profile/Jui-Che-Tu)\n\nIn the aftermath of the COVID-19 pandemic, college students have faced various challenges that could negatively impact their critical thinking abilities due to disruptions to education, increased stress and anxiety, less social interaction, and the advancement of distance learning relying more heavily on digital tools. With the increasing integration of AI technology across sectors, higher education institutions have deployed various AI capabilities for intelligent campuses and modernized teaching. However, how to fully utilize AI capabilities to promote students’ thinking awareness on learning effectiveness is still not clear, as critical thinking is an essential skill set holding significant implications for college students’ development. This research adopts the resource-based theory (RBT) to conceptualize the university as a unified entity of artificial intelligence (AI) resources. It aims to investigate whether AI capabilities can foster critical thinking awareness among students by enhancing general self-efficacy and learning motivation. In particular, it examines the causal relationships between AI capabilities, general self-efficacy, motivation and critical thinking awareness. Primary data was collected through a questionnaire administered to 637 college students. Structural equation modeling was employed to test hypotheses pertaining to causality. The results showed that AI capabilities could indirectly enhance students’ critical thinking awareness by strengthening general self-efficacy and learning motivation, but the effect on critical thinking awareness was not significant. Meanwhile, general self-efficacy significantly affected the formation of learning motivation and critical thinking awareness. This indicates that AI capabilities are able to reshape the cognitive learning process, but its direct influence on thinking awareness needs to be viewed with caution. This study explored the role of AI capabilities in education from the perspective of organizational capabilities. It not only proves how AI facilitates cognition, but also discovered the important mediating role of general self-efficacy and motivation in this process. This finding explains the inherent connections between the mechanism links. Furthermore, the study expands research on AI capabilities research from the technical level to the educational field. It provides a comprehensive and in-depth theoretical explanation theoretically, guiding the practice and application of AI in education. The study is of positive significance for understanding the need for the future development of the cultivation of critical thinking awareness talents needed for future development through AI capabilities in education.\n\n[View](https://www.researchgate.net/publication/378502246_Towards_a_New_Conceptual_Model_of_AI-Enhanced_Learning_for_College_Students_The_Roles_of_Artificial_Intelligence_Capabilities_General_Self-Efficacy_Learning_Motivation_and_Critical_Thinking_Awareness)\n\nShow abstract\n\n[Enriching the Learning Process with Generative AI: A Proposed Framework to Cultivate Critical Thinking in Higher Education using ChatGPT](https://www.researchgate.net/publication/377931524_Enriching_the_Learning_Process_with_Generative_AI_A_Proposed_Framework_to_Cultivate_Critical_Thinking_in_Higher_Education_using_ChatGPT)\n\nArticle\n\nFull-text available\n\n- Feb 2024\n\n- [Shakib Sadat Shanto](https://www.researchgate.net/profile/Shakib-Shanto)\n- [Zishan Ahmed](https://www.researchgate.net/profile/Zishan-Ahmed-5)\n- [Akinul Islam Jony](https://www.researchgate.net/scientific-contributions/Akinul-Islam-Jony-2150138757)\n\nThe emergence of large language models like ChatGPT, a Generative AI (GAI) tool has created excitement about their potential to enhance education, but also concerns about overreliance and lack of critical thinking. This study aims to develop and evaluate a conceptual framework named “AI-CRITIQUE” (AI-based Critical Reflection and Insightful Thought Unleashed for Education) for leveraging ChatGPT to promote critical thinking abilities in higher education settings. Our proposed framework provides structured guidance for focused questioning, gathering diverse perspectives, evaluating responses, synthesizing insights, and reflective learning to critically analyze and build upon AI output. An empirical study was conducted with 20 undergraduate students, who answered an open-ended question with and without ChatGPT. They utilized the proposed framework when using ChatGPT. Responses were analyzed using Lee’s model of thinking levels. A survey also assessed student perceptions. When using the framework with ChatGPT, students' average thinking level significantly increased from recall (1.35) to rationalization (2.4). Survey results showed on average students felt AI helped substantially with idea generation (4.0/5.0) and critical analysis (4.2/5.0) compared to independent work. The study provides preliminary evidence that the proposed framework can effectively leverage ChatGPT's capabilities to enhance critical thinking. While further research is needed, this offers a promising novel approach for AI integration to augment human abilities and critical thinking.\n\n[View](https://www.researchgate.net/publication/377931524_Enriching_the_Learning_Process_with_Generative_AI_A_Proposed_Framework_to_Cultivate_Critical_Thinking_in_Higher_Education_using_ChatGPT)\n\nShow abstract\n\n[Challenges and Opportunities of Generative AI for Higher Education as Explained by ChatGPT](https://www.researchgate.net/publication/373328547_Challenges_and_Opportunities_of_Generative_AI_for_Higher_Education_as_Explained_by_ChatGPT)\n\nArticle\n\nFull-text available\n\n- Aug 2023\n\n- [Rosario Michel-Villarreal](https://www.researchgate.net/profile/Rosario-Michel-Villarreal)\n- [Eliseo Vilalta-Perdomo](https://www.researchgate.net/profile/Eliseo-Vilalta-Perdomo)\n- [David Ernesto Salinas Navarro](https://www.researchgate.net/profile/David-Ernesto-Salinas-Navarro)\n- [Flor Silvestre Gerardou](https://www.researchgate.net/scientific-contributions/Flor-Silvestre-Gerardou-2259251792)\n\nChatGPT is revolutionizing the field of higher education by leveraging deep learning models to generate human-like content. However, its integration into academic settings raises concerns regarding academic integrity, plagiarism detection, and the potential impact on critical thinking skills. This article presents a study that adopts a thing ethnography approach to understand ChatGPT’s perspective on the challenges and opportunities it represents for higher education. The research explores the potential benefits and limitations of ChatGPT, as well as mitigation strategies for addressing the identified challenges. Findings emphasize the urgent need for clear policies, guidelines, and frameworks to responsibly integrate ChatGPT in higher education. It also highlights the need for empirical research to understand user experiences and perceptions. The findings provide insights that can guide future research efforts in understanding the implications of ChatGPT and similar Artificial Intelligence (AI) systems in higher education. The study concludes by highlighting the importance of thing ethnography as an innovative approach for engaging with intelligent AI systems and calls for further research to explore best practices and strategies in utilizing Generative AI for educational purposes.\n\n[View](https://www.researchgate.net/publication/373328547_Challenges_and_Opportunities_of_Generative_AI_for_Higher_Education_as_Explained_by_ChatGPT)\n\nShow abstract\n\n[Artificial intelligence, text generation tools and ChatGPT – does digital watermarking offer a solution?](https://www.researchgate.net/publication/371305657_Artificial_intelligence_text_generation_tools_and_ChatGPT_-_does_digital_watermarking_offer_a_solution)\n\nArticle\n\nFull-text available\n\n- Jun 2023\n\n- [Thomas Lancaster](https://www.researchgate.net/profile/Thomas-Lancaster-2)\n\nText generation tools, often presented as a form of generative artificial intelligence, have the potential to pose a threat to the integrity of the educational system. They can be misused to afford students marks and qualifications that they do not deserve. The emergence of recent tools, such as ChatGPT, appear to have left the educational community unprepared, despite the fact that the computer science community has been working to develop and improve such tools for years. This paper provides an introduction to text generation tools intended for a non-specialist audience, discussing the types of assessments that students can outsource, showing the type of prompts that can be used to generate text, and illustrating one possible watermarking technique that may allow generated text to be detected. A small-scale study into watermarking suggests that this technique is feasible and show technical promise but should not be relied on as a solution to widespread use of artificial intelligence based tools by students. Alternative solutions are needed, including encouraging the educational community to work with artificial intelligence rather than against it. As such, the paper concludes by discussing seven potential areas for further exploration.\n\n[View](https://www.researchgate.net/publication/371305657_Artificial_intelligence_text_generation_tools_and_ChatGPT_-_does_digital_watermarking_offer_a_solution)\n\nShow abstract\n\n[ChatGPT Utility in Health Care Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns](https://www.researchgate.net/publication/369362084_ChatGPT_Utility_in_Health_Care_Education_Research_and_Practice_Systematic_Review_on_the_Promising_Perspectives_and_Valid_Concerns)\n\nArticle\n\nFull-text available\n\n- Mar 2023\n\n- [Malik Sallam](https://www.researchgate.net/profile/Malik-Sallam)\n\nChatGPT is an artificial intelligence (AI)-based conversational large language model (LLM). The potential applications of LLMs in health care education, research, and practice could be promising if the associated valid concerns are proactively examined and addressed. The current systematic review aimed to investigate the utility of ChatGPT in health care education, research, and practice and to highlight its potential limitations. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar (published research or preprints) that examined ChatGPT in the context of health care education, research, or practice. A total of 60 records were eligible for inclusion. Benefits of ChatGPT were cited in 51/60 (85.0%) records and included: (1) improved scientific writing and enhancing research equity and versatility; (2) utility in health care research (efficient analysis of datasets, code generation, literature reviews, saving time to focus on experimental design, and drug discovery and development); (3) benefits in health care practice (streamlining the workflow, cost saving, documentation, personalized medicine, and improved health literacy); and (4) benefits in health care education including improved personalized learning and the focus on critical thinking and problem-based learning. Concerns regarding ChatGPT use were stated in 58/60 (96.7%) records including ethical, copyright, transparency, and legal issues, the risk of bias, plagiarism, lack of originality, inaccurate content with risk of hallucination, limited knowledge, incorrect citations, cybersecurity issues, and risk of infodemics. The promising applications of ChatGPT can induce paradigm shifts in health care education, research, and practice. However, the embrace of this AI chatbot should be conducted with extreme caution considering its potential limitations. As it currently stands, ChatGPT does not qualify to be listed as an author in scientific articles unless the ICMJE/COPE guidelines are revised or amended. An initiative involving all stakeholders in health care education, research, and practice is urgently needed. This will help to set a code of ethics to guide the responsible use of ChatGPT among other LLMs in health care and academia.\n\n[View](https://www.researchgate.net/publication/369362084_ChatGPT_Utility_in_Health_Care_Education_Research_and_Practice_Systematic_Review_on_the_Promising_Perspectives_and_Valid_Concerns)\n\nShow abstract\n\n[Supporting Teachers’ Professional Development With Generative AI: The Effects on Higher Order Thinking and Self-Efficacy](https://www.researchgate.net/publication/378500452_Supporting_Teachers'_Professional_Development_With_Generative_AI_The_Effects_on_Higher_Order_Thinking_and_Self-Efficacy)\n\nArticle\n\n- Jan 2024\n\n- [Jijian Lu](https://www.researchgate.net/scientific-contributions/Jijian-Lu-2156527763)\n- [Ruxin Zheng](https://www.researchgate.net/scientific-contributions/Ruxin-Zheng-2274892250)\n- [Zikun Gong](https://www.researchgate.net/scientific-contributions/Zikun-Gong-2274887338)\n- [Huifen Xu](https://www.researchgate.net/scientific-contributions/Huifen-Xu-2274873938)\n\nGenerative artificial intelligence (AI) has emerged as a noteworthy milestone and a consequential advancement in the annals of major disciplines within the domains of human science and technology. This study aims to explore the effects of generative AI-assisted preservice teaching skills training on preservice teachers’ self-efficacy and higher order thinking. The participants of this study were 215 preservice mathematics, science, and computer teachers from a university in China. First, a pretest–post-test quasi-experimental design was implemented for an experimental group (teaching skills training by generative AI) and a control group (teaching skills training by traditional methods) by investigating the teacher self-efficacy and higher order thinking of the two groups before and after the experiment. Finally, a semistructured interview comprising open-ended questions was administered to 25 preservice teachers within the experimental group to present their views on generative AI-assisted teaching. The results showed that the scores of preservice teachers in the experimental group, who used generative AI for teachers’ professional development, were considerably higher than those of the control group, both in teacher self-efficacy (\nF\n= 8.589,\np\n= 0.0084 < 0.05) and higher order thinking (\nF\n= 7.217,\np\n= 0.008 < 0.05). It revealed that generative AI can be effective in supporting teachers’ professional development. This study produced a practical teachers’ professional development method for preservice teachers with generative AI.\n\n[View](https://www.researchgate.net/publication/378500452_Supporting_Teachers'_Professional_Development_With_Generative_AI_The_Effects_on_Higher_Order_Thinking_and_Self-Efficacy)\n\nShow abstract\n\n[Generative AI and the future of education: Ragnarök or reformation? A paradoxical perspective from management educators](https://www.researchgate.net/publication/371972703_Generative_AI_and_the_future_of_education_Ragnarok_or_reformation_A_paradoxical_perspective_from_management_educators)\n\nArticle\n\n- Jul 2023\n\n- [Weng Marc Lim](https://www.researchgate.net/scientific-contributions/Weng-Marc-Lim-2231991729)\n- [Asanka Gunasekara](https://www.researchgate.net/scientific-contributions/Asanka-Gunasekara-2255024719)\n- [Jessica L. Pallant](https://www.researchgate.net/scientific-contributions/Jessica-L-Pallant-2175824716)\n- [Ekaterina Pechenkina](https://www.researchgate.net/profile/Ekaterina-Pechenkina)\n\n[View](https://www.researchgate.net/publication/371972703_Generative_AI_and_the_future_of_education_Ragnarok_or_reformation_A_paradoxical_perspective_from_management_educators)\n\nShow more\n\n**We and our partners use cookies** ✕\n\nBy using this site, you consent to the processing of your personal data, the storing of cookies on your device, and the use of similar technologies for personalization, ads, analytics, etc. For more information or to opt out, see our [Privacy Policy](https://www.researchgate.net/privacy-policy)"}
{"title": "Assessment Transformation in the Age of AI: Moving Beyond the Influence of Generative Tools", "content": "Assessment Transformation in the Age of AI: Moving Beyond the Influence of Generative Tools \\| IEEE Conference Publication \\| IEEE Xplore\n### IEEE Account\n- [Change Username/Password](https://www.ieee.org/profile/changeusrpwd/showChangeUsrPwdPage.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [Update Address](https://www.ieee.org/profile/address/getAddrInfoPage.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n### Purchase Details\n- [Payment Options](https://www.ieee.org/profile/payment/showPaymentHome.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [Order History](https://www.ieee.org/profile/vieworder/showOrderHistory.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [View Purchased Documents](https://ieeexplore.ieee.org/articleSale/purchaseHistory.jsp)\n### Profile Information\n- [Communications Preferences](https://www.ieee.org/ieee-privacyportal/app/ibp?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [Profession and Education](https://www.ieee.org/profile/profedu/getProfEduInformation.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [Technical Interests](https://www.ieee.org/profile/tips/getTipsInfo.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n### Need Help?\n- **US & Canada:** +1 800 678 4333\n- **Worldwide:** +1 732 981 0060\n- [Contact & Support](https://ieeexplore.ieee.org/xpl/contact)\n- [About IEEE _Xplore_](https://ieeexplore.ieee.org/Xplorehelp/overview-of-ieee-xplore/about-ieee-xplore)\n- [Contact Us](https://ieeexplore.ieee.org/xpl/contact)\n- [Help](https://ieeexplore.ieee.org/Xplorehelp)\n- [Accessibility](https://ieeexplore.ieee.org/Xplorehelp/overview-of-ieee-xplore/accessibility-statement)\n- [Terms of Use](https://ieeexplore.ieee.org/Xplorehelp/overview-of-ieee-xplore/terms-of-use)\n- [Nondiscrimination Policy](http://www.ieee.org/web/aboutus/whatis/policies/p9-26.html)\n- [Sitemap](https://ieeexplore.ieee.org/xpl/sitemap.jsp)\n- [Privacy & Opting Out of Cookies](http://www.ieee.org/about/help/security_privacy.html)\nA not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.\n© Copyright 2025 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions."}
{"title": "Rethinking Educational Assessment in the Age of Generative AI: Actionable Strategies to Mitigate Academic Dishonesty", "content": "[Book Chapters](https://manuelgarcia.info/publications/book-chapters) Full-Text Available\n\n# Rethinking Educational Assessment in the Age of Generative AI: Actionable Strategies to Mitigate Academic Dishonesty\n\n_Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_, 1-24, (2025)\n\ndoi [10.4018/979-8-3373-0122-8.ch001](https://doi.org/10.4018/979-8-3373-0122-8.ch001) \\| Citations: 9\n\n[Garcia, M. B.](javascript:void(0)) [iD](https://orcid.org/0000-0003-2615-422X)\n\nCorresponding Author\n\n#### Garcia, Manuel B.\n\n[mbgarcia@feutech.edu.ph](mailto:mbgarcia@feutech.edu.ph) [iD 0000-0003-2615-422X](https://orcid.org/0000-0003-2615-422X)\n\nEducational Innovation and Technology Hub, FEU Institute of Technology, Philippines\n\n[Search for more papers by this author](https://manuelgarcia.info/search?author=mbgarcia-edith)\n\n,\n\n[Rosak-Szyrocka, J.](javascript:void(0)) [iD](https://orcid.org/0000-0002-5548-6787)\n\n#### Rosak-Szyrocka, Joanna\n\n[rosakszyrocka@gmail.com](mailto:rosakszyrocka@gmail.com) [iD 0000-0002-5548-6787](https://orcid.org/0000-0002-5548-6787)\n\nFaculty of Management, Czestochowa University of Technology, Poland\n\n[Search for more papers by this author](https://manuelgarcia.info/search?author=jrosakszyrocka-cut)\n\n,\n\n[Yilmaz, R.](javascript:void(0)) [iD](https://orcid.org/0000-0002-2041-1750)\n\n#### Yilmaz, Ramazan\n\n[ryilmaz@bartin.edu.tr](mailto:ryilmaz@bartin.edu.tr) [iD 0000-0002-2041-1750](https://orcid.org/0000-0002-2041-1750)\n\nFaculty of Science, Bartin University, Turkey\n\n[Search for more papers by this author](https://manuelgarcia.info/search?author=ryilmaz-bu)\n\n,\n\n[Metwally, A. H. S.](javascript:void(0)) [iD](https://orcid.org/0000-0002-9545-5870)\n\n#### Metwally, Ahmed Hosny Saleh\n\n[ahmed.hosny@bnu.edu.cn](mailto:ahmed.hosny@bnu.edu.cn) [iD 0000-0002-9545-5870](https://orcid.org/0000-0002-9545-5870)\n\nFaculty of Education, Helwan University, Egypt\n\n[Search for more papers by this author](https://manuelgarcia.info/search?author=ahsmetwally-hu)\n\n,\n\n[Acut, D. P.](javascript:void(0)) [iD](https://orcid.org/0000-0002-9608-1292)\n\n#### Acut, Dharel P.\n\n[sirdharel.acut@gmail.com](mailto:sirdharel.acut@gmail.com) [iD 0000-0002-9608-1292](https://orcid.org/0000-0002-9608-1292)\n\nCollege of Education, Cebu Technological University, Philippines\n\n[Search for more papers by this author](https://manuelgarcia.info/search?author=dpacut-ctu)\n\n,\n\n[Ofosu-Ampong, K.](javascript:void(0)) [iD](https://orcid.org/0000-0003-0561-6376)\n\n#### Ofosu-Ampong, Kingsley\n\n[kingofosu11@gmail.com](mailto:kingofosu11@gmail.com) [iD 0000-0003-0561-6376](https://orcid.org/0000-0003-0561-6376)\n\nBusiness School, University of Ghana, South Africa\n\n[Search for more papers by this author](https://manuelgarcia.info/search?author=koampong-ug)\n\n,\n\n[Erdoğdu, F.](javascript:void(0)) [iD](https://orcid.org/0000-0003-1022-8570)\n\n#### Erdoğdu, Fatih\n\n[fatiherdogdu67@gmail.com](mailto:fatiherdogdu67@gmail.com) [iD 0000-0003-1022-8570](https://orcid.org/0000-0003-1022-8570)\n\nDepartment of Computer Technology, Zonguldak Bülent Ecevit University, Turkey\n\n[Search for more papers by this author](https://manuelgarcia.info/search?author=ferdogdu-zbeu)\n\n,\n\n[Fung, C. Y.](javascript:void(0)) [iD](https://orcid.org/0000-0002-2007-6286)\n\n#### Fung, Chorng Yuan\n\n[cfung@swinburne.edu.my](mailto:cfung@swinburne.edu.my) [iD 0000-0002-2007-6286](https://orcid.org/0000-0002-2007-6286)\n\nFaculty of Business, Design and Arts, Swinburne University of Technology, Malaysia\n\n[Search for more papers by this author](https://manuelgarcia.info/search?author=cyfung-sut)\n\n,\n\n[Bozkurt, A.](javascript:void(0)) [iD](https://orcid.org/0000-0002-4520-642X)\n\n#### Bozkurt, Aras\n\n[arasbozkurt@gmail.com](mailto:arasbozkurt@gmail.com) [iD 0000-0002-4520-642X](https://orcid.org/0000-0002-4520-642X)\n\nDepartment of Distance Education, Anadolu University, Turkey\n\n[Search for more papers by this author](https://manuelgarcia.info/search?author=abozkurt-au)\n\nThis is a post-peer-review, pre-copyedit version of an article published in the Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias book. The final authenticated version is available online at: [https://doi.org/10.4018/979-8-3373-0122-8.ch001](https://doi.org/10.4018/979-8-3373-0122-8.ch001).\n\n## Abstract\n\nAs artificial intelligence (AI) becomes increasingly integrated into educational contexts, they present new challenges to traditional assessment methods. A particularly pressing issue is academic dishonesty, which undermines learning authenticity and the credibility of educational institutions. With generative AI tools like ChatGPT making it easier for students to produce automated answers, educational assessments are at risk of measuring AI capabilities rather than students' actual knowledge. Thus, this chapter explores a range of strategies designed to adapt assessment practices in response to the influence of AI in education. These strategies offer actionable frameworks to support authentic learning and uphold academic integrity. Additionally, the chapter highlights future research directions to guide further adaptation of educational policies and practices. Given the rapid integration of AI in the education sector, this chapter provides sensible insights that reinforce the importance of integrity-focused reforms in sustaining meaningful educational outcomes in an AI-driven world.\n\nKeywords: Educational Assessment, Artificial Intelligence, Generative AI, Academic Dishonesty, Technology-Enhanced Assessment, Academic Integrity, ChatGPT\n\n## Introduction\n\nEducational assessment is fundamental to the learning process. It provides essential insights into both student progress and institutional effectiveness. Over time, assessment practices have evolved alongside shifts in educational theories and societal expectations. This evolution underscores the ongoing need to align them with the demands of higher education and professional fields. Traditionally, assessments have relied on structured, standardized methods such as written exams, essays, and graded assignments. These approaches often emphasize the retention of knowledge, critical thinking, and the ability to apply learned concepts in specific contexts. In classroom settings, educators have used techniques like oral questioning, quizzes, and written feedback to gauge student comprehension and progress. Final exams and cumulative projects serve as benchmarks to summarize students' overall performance. These culminating assessments prove a snapshot of their achievements at the end of a course or program. While these conventional methods have shaped the foundation of educational assessment, evolving educational landscapes and emerging challenges signal a need to explore more dynamic and flexible ways of measuring and fostering learning outcomes (e.g., Swiecki et al., 2022).\n\nIn the 21st century, advancements in information and communication technologies have significantly transformed assessment methods (See et al., 2022). Recent trends pave the way for technology-enhanced assessments like computer-based testing and online evaluations. Particularly, e-assessment has emerged as a powerful tool for aiding teachers in monitoring student progress and evaluating complex cognitive skills (Azevedo & Azevedo, 2019). Prior works underscored the benefits of e-assessment in higher education, highlighting its potential to boost student motivation, satisfaction, skill development, autonomy, and flexibility (Montenegro-Rueda et al., 2021). E-assessments are often facilitated through learning management systems, which provide a variety of assessment options, including calculation questions, essays, matching exercises, and true/false queries. In addition, online tools like self-test quizzes, discussion forums, and e-portfolios have been increasingly adopted for educational assessments (Gikandi et al., 2011). The importance of these resources was further amplified during the COVID-19 pandemic (Ofosu-Ampong et al., 2024) when platforms such as Moodle and Zoom became essential for conducting online assessments to maintain the continuity of student evaluation amidst unprecedented challenges (Montenegro-Rueda et al., 2021; Slack & Priestley, 2023).\n\nWhile e-assessments offer numerous benefits (Heil & Ifenthaler, 2023), the rise of emerging technologies like artificial intelligence (AI) introduces new challenges in educational assessment (Swiecki et al., 2022). One of the most pressing concerns is the increasing use of generative AI tools, which can produce sophisticated written responses, solve complex problems, and simulate human-like interactions. These AI-powered tools, such as ChatGPT, have made it easier for students to generate content that may not accurately reflect their individual understanding or learning progress. This ease of access has heightened concerns around academic dishonesty (Gruenhagen et al., 2024), which refers to any form of cheating or misrepresentation of one’s own work in an academic setting. Students may rely on AI tools to complete assessments, which undermines the authenticity of their work (Lee et al., 2024). Educational assessment methods now face the risk of becoming avenues for misuse rather than accurate measures of student knowledge. Consequently, educators are confronted with the challenge of designing assessments that not only measure genuine skills but also discourage reliance on AI-generated content. Addressing these concerns requires a rethinking of assessment strategies to uphold academic integrity in this evolving technological landscape.\n\n## Main Focus of the Chapter\n\nThe rapid advancements in generative AI have underscored the inadequacy of conventional assessment paradigms in addressing the multifaceted demands of modern education. As AI tools become increasingly sophisticated and ubiquitous, educators are compelled to reconceptualize and reengineer assessment frameworks to ensure they remain pedagogically sound, equitable, and authentically reflective of learner competencies. This chapter argues that simply modifying existing assessment methods is not enough; instead, a fundamental rethinking is imperative to align evaluative methodologies with the transformative capabilities and ethical implications of generative AI. There is an urgent need for actionable frameworks that can be operationalized across diverse educational ecosystems—including K–12 education, tertiary institutions, and professional development environments. These frameworks must account for evolving patterns of learner engagement, emergent modalities of knowledge representation, and heightened vulnerabilities to academic misconduct enabled by AI technologies.\n\nConsequently, the objective of this chapter is to furnish a praxis-oriented analysis of how assessment systems can be recalibrated in response to the generative AI landscape. It endeavors to offer empirically grounded insights and pedagogical strategies that educators and institutions can adopt to construct assessments that not only yield valid measures of student learning but also uphold academic integrity and cultivate higher-order cognitive skills. To ensure epistemic rigor and contextual relevance, this chapter employs a collaborative expert synthesis coupled with an integrative review of contemporary scholarship. This methodological orientation reflects both the cross-disciplinary expertise of the contributing authors and a critical engagement with current empirical and theoretical discourse. The resulting strategies are thus both theoretically robust and pedagogically responsive. Determining and proposing these actionable strategies seeks to empower institutions, educational leaders, and teachers to navigate the challenges posed by AI advancements (Acut et al., 2025; Gantalao et al., 2025; Mangubat et al., 2025).\n\n## Strategies in Designing Assessments\n\n### Implement Multimodal Assessment Techniques for Holistic Learning\n\nIn the era of generative AI, diversifying assessment types is crucial to ensure the authenticity of student work and minimize opportunities for academic dishonesty. Multimodal assessments go beyond traditional written tasks by incorporating oral presentations, practical demonstrations, and portfolios. Utilizing various forms of evaluation allows educators to capture a more comprehensive picture of students' abilities and learning processes (Grapin, 2023). More importantly, it reduces the likelihood of AI-generated content misrepresenting a student's actual skills. For example, in science education, students may be required to explain the steps of a scientific experiment through oral presentations. They can also perform practical demonstrations (e.g., conducting a chemistry experiment) to showcase hands-on skills that cannot be easily fabricated by AI. Asking students to create portfolios is another example, as it allows them to compile a curated collection of their work throughout the course, demonstrating their progress, critical thinking, and reflective learning. By adopting a more varied assessment strategy, educators not only foster a more equitable learning environment but also create a system that emphasizes authentic student engagement and the application of knowledge.\n\nIronically, teachers can use AI to counter the challenges posed by AI-generated content in student work (Hasanah et al., 2025). Integrating AI tools into the assessment process can add a layer of objectivity and tailored feedback to multimodal assessments. These AI capabilities in areas such as speech analysis, real-time feedback, and content evaluation can help ensure the authenticity of student work while supporting more diverse and holistic assessment methods. Table 1 presents different ways AI can be effectively integrated into multimodal assessments, highlighting practical strategies that educators can employ to maintain academic integrity while adapting to the ever-evolving technological landscape in education. This comprehensive approach not only counters the misuse of AI tools by students but also enriches the learning experience, making assessments more meaningful and aligned with 21st-century skills.\n\n| Assessment Type | Description | Benefits | Challenges | Examples of AI Integration |\n| --- | --- | --- | --- | --- |\n| Oral Presentations | Students articulate their understanding verbally, often in front of peers or through recorded video. | Develops communication skills and real-time articulation of ideas. | Requires evaluation of subjective aspects like speaking style and confidence. | AI can analyze speech clarity and tone and provide feedback on content and presentation style. |\n| Practical Demonstrations | Hands-on demonstration of skills, often in labs or simulations, showing the application of theoretical knowledge. | Validates real-world skills and problem-solving abilities. | It may require specific equipment or environments; evaluation criteria can be complex. | AI-based simulations can provide virtual environments for practice and give immediate feedback on performance. |\n| Portfolios | A curated collection of a student's work over time, reflecting progress and learning. | Encourages reflection and self-assessment and showcases a range of skills. | Time-consuming to compile and evaluate; requires clear criteria. | AI can analyze portfolio content, track progress, and suggest areas for improvement. |\n| Visual Presentations | Use of graphics, slideshows, infographics, and videos to present information. | Enhances creativity and visual communication skills. | Difficult to assess the quality of visual elements objectively. | AI can assess design aspects, clarity, and the effectiveness of visual elements used. |\n| Interactive Activities | Engaging in tasks like quizzes, simulations, or role-playing scenarios that involve active participation. | Fosters engagement, collaboration, and practical application of knowledge. | Requires proper setup; monitoring and feedback may be challenging. | AI-based platforms can provide interactive simulations, track performance, and give real-time feedback. |\n| Peer Evaluations | Students assess each other's work, providing feedback and constructive criticism. | Promotes critical thinking and self-reflection; develops evaluation skills. | It can be biased or inconsistent and requires guidance on effective feedback. | AI can guide students on how to give constructive feedback and assess the quality of peer evaluations. |\n| Self-Evaluations | Students reflect on their own work and learning processes, often using rubrics or guided questions. | Enhances self-awareness and encourages lifelong learning skills. | Requires a high level of student honesty and self-assessment skills. | AI tools can provide prompts for reflection and track self-assessment trends over time. |\n\n### Promote Higher-Order Thinking Skills Through Critical Analysis\n\nHigher-order thinking skills are fundamental for developing modern competencies (Huang et al., 2024). Key components of these skills include critical thinking, problem-solving, creative thinking, and decision-making. However, the advent of generative AI in educational settings poses a significant risk: _students may become overly dependent on these tools_. This dependency bypasses the development and application of their higher-order thinking abilities. When students rely on AI to generate content, solve problems, or provide answers, they often neglect the deep cognitive processes involved in analyzing information, synthesizing ideas, and making complex decisions. This dependency can lead to a superficial understanding of the material and an increase in academic dishonesty, as students might submit AI-generated work that does not truly reflect their knowledge or skills (Miranda et al., 2025). Excessive reliance on AI tools can contribute to mental health issues, including what some researchers refer to as \" _ChatGPT Dependency Disorder_\" (Garcia, 2024). This condition arises when students become so reliant on AI that they experience anxiety or difficulty when faced with tasks that require independent thought and problem-solving. Such dependency can ultimately undermine self-confidence, critical thinking, and creativity, which then affects both academic performance and overall mental well-being.\n\nTo counter the risk of overreliance on AI tools, it is crucial to design assessments that focus on promoting higher-order thinking. Tasks that require students to critically analyze a case study, synthesize information from multiple sources, or develop an original argument challenge them to go beyond simple knowledge recall or basic problem-solving that AI can easily replicate. For instance, instead of assigning a traditional essay, teachers can implement project-based assessments where students must address real-world problems. One practical strategy is to use a \" _Design Thinking Challenge_,\" where students are tasked with identifying a community issue, researching possible solutions, and creating a proposal or prototype that addresses the problem (Revano & Garcia, 2020). In this scenario, students might be asked to investigate local environmental concerns, such as plastic waste, and then propose an innovative recycling program tailored to their community's needs. This process requires them to conduct interviews, analyze data, think creatively, and present their findings through a combination of written reports, visual presentations, and oral pitches. By doing so, students are encouraged to use skills that AI cannot replicate—such as original problem-solving, empathy gained through interviews, and real-time adaptation during the presentation. Moreover, teachers can integrate reflective components where students must discuss their thought processes, challenges faced, and lessons learned.\n\n### Incorporate Human-Centered Interaction to Assess Real-Time Understanding\n\nAssessment methods that prioritize direct human interaction have become more crucial than ever with the rise of generative AI. These methods offer students opportunities to demonstrate their knowledge and skills in real-time, without the crutch of AI tools. By integrating elements such as interviews, oral examinations, collaborative projects, role-playing activities, and Socratic seminars into the assessment process, educators can better assess students' spontaneous understanding while fostering essential communication skills that are critical in the professional world. The Media Richness Theory (Daft & Lengel, 1986) provides a relevant lens through which to view these interactions. This theory posits that communication media vary in their capacity to convey nuanced information and facilitate understanding. Richer mediums (e.g., face-to-face interactions) allow for immediate feedback, nonverbal cues, and personal engagement, making them more effective for complex communication tasks. In the context of educational assessments, interviews, oral exams, and discussions serve as 'rich' media. They facilitate a level of depth, spontaneity, and adaptability in evaluating students' skills that AI-driven assessments, which typically operate through 'leaner' media like text-based platforms, cannot easily replicate.\n\nGenerative AI tools, while capable of evaluating factual knowledge through structured methods (e.g., multiple-choice questions), struggle to assess soft skills like communication, collaboration, and critical thinking effectively (Yilmaz & Karaoglan Yilmaz, 2023). Incorporating methods like oral exams and group work into assessments not only provides real-time insight into students' abilities but also creates an environment where they must adapt their thinking dynamically in response to questions and dialogue. Interviews and oral examinations can be structured in various ways. For example, structured interviews with predetermined questions ensure consistency and fairness, while unstructured or semi-structured interviews allow for a more adaptive, conversational approach. Both formats facilitate an interactive environment where students articulate their thoughts, defend their ideas, and engage in intellectual discourse. Unlike traditional written exams, these oral formats require students to think on their feet, respond to inquiries, and explain their reasoning processes. These approaches are more effective in terms of uncovering deeper levels of understanding and critical thinking that written responses may not fully capture. Teachers can further enhance these skills by providing opportunities for students to practice and receive constructive feedback (Garcia et al., 2024). This interaction supports the development of communication skills and ensures that assessments reflect a more comprehensive evaluation of student learning, counteracting the limitations of AI-driven methods.\n\n### Prioritize Process-Oriented Learning Over End-Product Evaluation\n\nThe emergence of generative AI in education necessitates a paradigm shift in how we assess students' learning processes and outcomes. Traditional assessment methods, which often focus solely on the final product, may be insufficient in the context of generative AI, as they fail to capture the full scope of student development. Therefore, educators must adopt a process-oriented approach that emphasizes the learning journey rather than just the result (Garcia, 2024). By shifting the focus to the steps, students take toward achieving their outcomes, teachers can reduce the risk of academic dishonesty facilitated by AI tools while fostering deeper engagement, critical thinking, and continuous improvement (Yilmaz & Karaoglan Yilmaz, 2023). Process-oriented assessment recognizes that learning is a dynamic and iterative process, and evaluating students’ progress over time provides a more comprehensive understanding of their intellectual growth and problem-solving abilities. This approach becomes particularly crucial in the age of AI, where polished end products generated by tools like ChatGPT can obscure the learner's true depth of understanding and effort (Salinas-Navarro et al., 2024). By emphasizing research logs, draft submissions, and reflective papers, educators can create assessments that value the entire learning process, not just the final product (Preiksaitis & Rose, 2023).\n\nIncorporating process-oriented assessments into the curriculum requires setting clear criteria for evaluating research logs, drafts, and reflective writings, along with guidelines for how these components will be weighted in the overall assessment framework (Cacho, 2024). Providing students with templates, examples, and training in metacognitive strategies and reflective writing can further enhance their ability to document their learning processes effectively. Timely feedback on research logs, drafts, and reflections is essential, as it helps guide students toward a deeper understanding rather than simply correcting errors. Organizing peer review sessions also fosters a collaborative learning environment where students give and receive feedback on their drafts and reflections, learning from one another’s approaches. Generative AI can support this process by offering automated feedback on draft submissions, which helps students identify areas for improvement before receiving instructor input. However, educators must use AI tools judiciously to enhance rather than replace authentic learning experiences. By emphasizing the learning process over the final product, process-oriented assessments not only promote academic integrity but also prepare students for lifelong learning (Salinas-Navarro et al., 2024).\n\n### Utilize Performance-Based Tasks to Demonstrate Practical Knowledge\n\nPerformance-based tasks offer an authentic approach to assessing students’ real-time demonstration of skills, emphasizing the application of practical knowledge over mere theoretical understanding. In the age of generative AI, traditional assessments such as written exams are increasingly vulnerable to compromise, as students can leverage AI tools to generate content. Performance-based tasks serve as a valuable alternative, requiring active, hands-on participation that is difficult to replicate using AI. Rooted in constructivist theories, these assessments align with the principle that students learn more effectively through doing rather than passively receiving information (Anderson & Johnston, 2016). By integrating tasks like lab activities, simulations, or practical demonstrations, educators can better measure a student's ability to apply theoretical knowledge in real-world scenarios. One of the key advantages of performance-based tasks is their ability to capture a student’s problem-solving process in dynamic environments (see Table 2). For instance, in lab-based assessments, students are required to apply scientific principles, conduct experiments, interpret data, and make real-time decisions based on their observations. This approach not only evaluates content knowledge but also critical thinking and adaptive learning skills (Aladini et al., 2024). Similarly, simulations in fields such as medicine or engineering place students in complex scenarios that mirror real-world challenges, demanding thoughtful navigation and decision-making (Kong et al., 2024). These tasks go beyond simply testing knowledge; they provide a window into the students' analytical and reflective abilities, which AI-generated responses cannot easily mimic (Hasanah et al., 2025).\n\n| Performance Task | Description | Key Skills Assessed | Example Fields of Application | Supporting Studies |\n| --- | --- | --- | --- | --- |\n| Lab Activities | Hands-on experiments or tasks requiring students to apply scientific methods in real-time. | Critical thinking, problem-solving, data analysis | Science, Engineering | Gomez-del Rio and Rodriguez, (2022); Kovaleva et al., (2024) |\n| Simulations | Virtual or physical scenarios that mimic real-world processes require decision-making and adaptive learning. | Decision-making, adaptability, collaboration | Medicine, Nursing, Law | Slavinska et al., (2024); Miller et al., (2024); Petil et al., (2025) |\n| Collaborative Group Work | Group-based tasks that require joint problem-solving and teamwork in dynamic environments. | Collaboration, communication, leadership | Business, Social Sciences, ICT | Riebe et al., (2016); Garcia, (2023) |\n| Creative Problem-solving Challenges | Open-ended tasks that require innovation and creative application of knowledge. | Creativity, innovation, reflective thinking | STEM Education, Design Thinking | Valderama et al., (2022); Acut et al., (2025) |\n| Portfolio Development | Compilation and presentation of students' work over time to showcase growth and achievements. | Self-assessment, reflective thinking, organizational skills | Arts, Education, Business | Ryan, (2011); Doğan et al., (2024) |\n\nIn the context of generative AI's increasing capabilities and features, performance-based tasks serve as a critical safeguard against academic dishonesty. While generative AI can assist students in generating written responses or solving complex problems (Acut et al., 2024), it cannot physically perform tasks or replicate real-time decision-making processes. By requiring students to actively demonstrate their skills in real time, educators ensure that assessments reflect each student's true abilities rather than the output of an AI model. The integration of performance-based assessments is, therefore, increasingly recognized as a best practice in educational settings. In science education, for example, performance assessments have been shown to enhance scientific inquiry skills and deepen students' understanding of content (Acut, 2022). Similarly, in professional fields such as nursing and law, performance-based tasks (e.g., simulations and practical exercises) effectively mirror the complexities of real-world practice and decision-making (Slavinska et al., 2024). As educators rethink assessment strategies in the age of generative AI, performance-based tasks emerge as a reliable approach to measure authentic student skills. These assessments offer a more holistic evaluation of student capabilities, better preparing them for the demands of professional environments in an AI-driven world.\n\n### Initiate Capstone Projects for Real-World Problem Solving\n\nCapstone projects offer a comprehensive and multifaceted approach to assessing student learning (Tenhunen et al., 2023). This academic experience requires extensive research, planning, and execution over an extended period (Table 3). These projects culminate in a final presentation or defense, where students synthesize the knowledge and skills acquired throughout their academic journey (Acut, 2022). In the era of generative AI, capstone projects stand out as one of the most rigorous forms of assessment because they demand creativity, critical thinking, problem-solving, and deep subject matter expertise—skills that are not easily automated or replicated by AI systems. Unlike traditional assessments focused on memorization or short-term knowledge retention, capstone projects span several months, offering students the opportunity to explore a topic in great depth (Kim et al., 2019). This process inherently fosters higher-order thinking as students identify real-world problems, design research methodologies, collect and analyze data, and propose evidence-based solutions (Stephenson et al., 2020). The reflective nature of these projects ensures that students not only gain a deeper understanding of the subject matter but also develop the ability to apply their learning in meaningful ways.\n\n| Capstone Project Type | Key Components | Skills Assessed | Assessment Method | Example Fields |\n| --- | --- | --- | --- | --- |\n| Research-based Project | Literature review, data collection, analysis | Critical thinking, research skills | Written reports, defense | Social Sciences, STEM |\n| Design/Engineering Project | Prototype development, testing | Problem-solving, technical skills | Prototype, presentation | Engineering, ICT |\n| Service-Learning Project | Community engagement, solution implementation | Collaboration, leadership | Project report, oral defense | Education, Public Health |\n| Entrepreneurship Project | Business plan, market analysis, product development | Innovation, strategic thinking | Business proposal, pitch | Business, Economics |\n| Artistic/Creative Project | Concept creation, artifact production | Creativity, technical expertise | Portfolio, exhibition | Fine Arts, Media Studies |\n| Interdisciplinary Project | Integration of multiple fields, comprehensive analysis | Systems thinking, adaptability | Multi-format deliverables | Sustainability, Policy Studies |\n| Technology Integration Project | Software/hardware development, user testing | Programming, usability design | Software demo, documentation | ICT, Education Technology |\n\nA key benefit of capstone projects is the promotion of student autonomy and self-directed learning. Since students typically choose their topics based on personal or professional interests, they are more motivated to engage deeply with the material. Landfried et al., (2023) found that capstone projects can enhance student engagement and ownership of learning, resulting in improved academic outcomes and higher satisfaction. Additionally, these projects often require collaboration with industry professionals, community partners, or interdisciplinary teams, providing students with valuable real-world experience (Badir et al., 2023). Capstone projects also help students develop key skills that are highly sought after in today’s job market, including project management, research, communication, and teamwork. By guiding students through the process of project conception, development, and execution, educators help them refine these transferable skills, which are essential for success in diverse professional contexts (Darling-Hammond et al., 2019). Finally, the formal presentation or defense at the project’s culmination further enhances students' ability to articulate their ideas persuasively.\n\nFrom an assessment perspective, capstone projects provide educators with the opportunity to evaluate a broad range of competencies, from research proficiency to practical application. They often require the integration of multiple forms of assessment, including written reports, oral presentations, and project artifacts, offering a holistic view of student learning (Acut, 2022). The defense component adds an additional layer of rigor, as students must not only present their findings but also respond to questions and critiques, demonstrating their ability to defend their work and think critically on their feet. Previous studies have highlighted the effectiveness of capstone projects in fostering critical skills. For instance, Cheng et al., (2019) found that these projects facilitate deeper learning and the development of essential competencies such as problem-solving and independent work. Similarly, Stephenson et al., (2020) emphasized how capstone experiences integrate theoretical knowledge with practical application, preparing students for professional life. In the age of AI, where skills like creativity, adaptability, and problem-solving are increasingly valuable and less susceptible to automation, capstone projects stand out as a robust method of ensuring students are well-equipped for the future.\n\n### Facilitate Value-Based Discussions to Foster Reflective Thinking\n\nValue-based discussions are a dialogic approach that emphasizes active listening, respect, empathy, and the exploration of the ethical, cultural, and social implications of a subject. In the context of generative AI, incorporating value-based discussions into assessments can serve as a powerful tool for preventing academic dishonesty. These discussions require students to engage with the subject matter, critically reflect on their values, and consider the broader implications of their actions, making it difficult for them to rely solely on AI-generated responses. When students are asked to reflect on ethical considerations or societal impacts, they are compelled to express their individual perspectives and reasoning. Generative AI can enhance value-based discussions by providing a starting point for exploration. For example, AI can generate prompts that urge students to analyze various ethical scenarios or cultural biases embedded in AI's outputs (Ofosu-Ampong et al., 2023; Walter, 2024). However, educators must be cautious in how they use AI in this context. The questions posed by AI should not simply reflect dominant viewpoints or specific agendas; instead, they should provoke genuine thought and debate. Teachers play a crucial role in scrutinizing these AI-generated prompts to ensure they are free of bias and encourage students to examine underlying beliefs critically (Adams, 2021). By actively engaging in these reflective discussions, students learn to articulate their thoughts, question the narratives presented to them, and make informed decisions—skills that reduce their dependence on AI for answers.\n\nAdditionally, value-based discussions can highlight the limitations of AI and the importance of human judgment. When students discuss ethical dilemmas, cultural norms, or social justice issues, they are not just responding to information; they are interpreting and negotiating meaning based on their values and experiences (Martínez-Requejo et al., 2025). This level of critical engagement is something that AI cannot authentically reproduce. As a moderator, AI can facilitate a more inclusive environment by filtering out hate speech and fostering respectful exchanges (Kiritchenko et al., 2021). However, educators must define the parameters of discourse (Bozkurt et al., 2024), ensuring that diverse perspectives are included without overly aggressive content filtering that might incorrectly categorize unconventional viewpoints as negative. By promoting transparency about AI's role in discussions and guiding students in balancing free speech with constructive communication (Xiao et al., 2025), educators can create a learning environment where students develop critical thinking skills, ethical reasoning, and a deeper understanding of complex issues—all of which make academic dishonesty less likely.\n\n### Conduct Continuous Assessments for Ongoing Learning and Feedback\n\nContinuous assessment is an ongoing process of evaluating students’ learning progress throughout a program or course. This approach employs a variety of assessment methods—such as gamified quizzes, project work, peer reviews, presentations, and assignments—rather than relying solely on final exams. By providing regular and timely feedback, continuous assessments help students improve their learning performance and outcomes while also serving as a valuable tool for combating academic dishonesty, especially in the context of AI's growing influence.\n\n| Activity | Description |\n| --- | --- |\n| After each lecture | Short online quizzes featuring a mix of multiple-choice and open-ended questions to test students' analysis and interpretation of sociological events. |\n| Weekly | One-page reflection essay analyzing sociological facts, motivations, and outcomes in society. |\n| Mid-term project | Research proposal outlining a sociological effect and its significance, incorporating an appropriate methodological approach to explain or unravel new knowledge. |\n| Class participation | Deploying robust and engaging gamification mechanisms to reward students for asking thoughtful questions and engaging in meaningful discussions. |\n| Final project work | Research paper on a specific sociological problem in a context that requires critical analysis and synthesis of evidence to examine students' thought processes and original arguments. |\n\nThe introduction of AI in education has raised concerns regarding its potential impact on the integrity of continuous assessments. However, adopting a diversified and dynamic approach can significantly reduce the likelihood of AI-generated submissions compromising academic integrity (Gruenhagen et al., 2024; Taneja et al., 2025). Teachers can combat dishonesty by incorporating creative tasks, essays, and open-ended questions that demand originality and critical thinking—tasks that AI tools cannot easily replicate. Moving beyond multiple-choice questions to assessments that emphasize application over memorization (see Table 4) helps ensure that students are evaluated on their ability to analyze, synthesize, and apply knowledge. This variety in assessment types makes it harder for students to rely solely on AI to produce responses, as the tasks require a demonstration of personal insight, reasoning, and problem-solving.\n\n| Activity | Description |\n| --- | --- |\n| Daily coding challenge | Conduct short coding exercises to practice specific programming concepts learned in each class session. |\n| Weekly programming assignment | Crafting code through problem-solving, focusing on the thought process behind the code, and understanding how to adapt solutions to new scenarios. |\n| Mid-term project | Task students with designing and developing a simple mobile app that addresses societal challenges, such as waste management or climate change. |\n| Peer code review | Facilitate collaborative learning sessions where students review each other's work, identify errors, and suggest improvements for efficiency and code readability. |\n| Final project work | Combine multiple-choice questions on specific concepts with open-ended coding problems to assess understanding comprehensively. |\n\nThe proposed continuous assessment framework for Information Systems (see Table 5) illustrates how incorporating real-world scenarios and project-based learning can diminish the impact of AI-generated content. By engaging students in problem-solving that reflects real-world complexities, educators encourage critical analysis and the application of knowledge, both of which are difficult for AI to replicate. Additionally, continuous assessments foster an environment where students receive feedback at regular intervals, allowing them to identify and address weaknesses in their understanding before being tempted to resort to dishonest means. By prioritizing ongoing engagement and the development of higher-order thinking skills, continuous assessments serve as a robust strategy to maintain academic integrity in an AI-enhanced educational landscape (Ofosu-Ampong et al., 2023; Xiao et al., 2025).\n\n### Customize Assessment Criteria to Encourage the Synthesis of Knowledge\n\nRecalibrating assessment frameworks to prioritize epistemic synthesis and the pragmatic application of disciplinary knowledge is pivotal for cultivating higher-order cognitive engagement and robust critical thinking among learners. Conventional evaluative mechanisms tend to focus on surface-level learning—primarily rote memorization and basic factual recall (Diaz et al., 2025)—which insufficiently capture a learner’s conceptual depth or capacity for transference to authentic contexts. By refocusing assessment criteria toward indicators that demand interdisciplinary reasoning, intellectual engagement, and applied problem-solving, educators can more effectively equip students with the competencies required for navigating complexity in academic inquiry.\n\n**Application-Based Assessments**: These challenge students to operationalize theoretical constructs within novel and contextually relevant scenarios. In computing education, for instance, such assessments may entail the end-to-end development of functional software artifacts (see Garcia, 2025 for detailed examples). To foreground applied cognition, instructors can recalibrate their grading rubrics to include the following evaluative dimensions:\n\n- **Operational Validity**: Does the artifact meet all functional specifications and demonstrate reliability across use cases?\n- **Code Robustness and Elegance**: Is the source code optimized, syntactically coherent, and aligned with industry-standard conventions for maintainability?\n- **Algorithmic Reasoning**: How effectively does the student diagnose edge cases and deploy debugging methodologies?\n- **Innovative Problem Formulation**: Does the project exhibit originality in conceptualization or deploy non-traditional heuristics?\n\n**Synthesis-Based Assessments**: These tasks involve the convergence of disparate conceptual frameworks to produce integrated, innovative outcomes—fostering meta-cognitive reasoning and design thinking. Within an AI-driven programming curriculum (Garcia, 2025), a synthesis-centric task might involve the architectural design and implementation of a multi-component web platform. Expert-level criteria for such assessments include:\n\n- **Technological Integration**: To what extent does the student fluently orchestrate multiple programming paradigms, libraries, or third-party APIs?\n- **Systemic Cohesion**: Is the final deliverable an architecturally coherent system with seamless interaction between components?\n- **Cognitive Complexity**: Does the project incorporate advanced functionalities, such as asynchronous data flows, machine learning modules, or secure authentication systems?\n- **Creative Fluency**: How distinctive is the student’s approach in terms of user experience, design aesthetics, and conceptual novelty?\n\n**Implementing Customized Assessment Criteria**: For rigorous implementation of these advanced assessment modalities, pedagogical strategies such as Project-Based Learning (PBL) and scenario-based case studies should be deployed. These should be scaffolded by analytically robust rubrics, which articulate clear evaluative benchmarks:\n\n- **Conceptual Transference**: How adeptly does the learner transpose theoretical insights to resolve real-world, ill-structured problems?\n- **Cross-Platform Synergy**: Does the student demonstrate sophistication in synthesizing diverse technologies to create functional and aesthetically cohesive systems?\n- **Metacognitive Reflexivity**: Is the learner able to critically evaluate their development process, articulating challenges encountered and strategies for adaptive learning?\n- **Collaborative Dynamics**: In team-based contexts, how does the student engage in distributed cognition, co-construction of knowledge, and equitable task allocation?\n\nBy providing well-defined criteria through rubrics, educators guide students toward deeper learning and create an environment that values originality, critical thinking, and practical application—key factors in reducing academic dishonesty.\n\n### Facilitate Peer Review Activities to Enhance Scrutiny and Understanding\n\nOrganizing peer assessment activities where students evaluate each other’s work introduces an additional layer of scrutiny, contributing to a more comprehensive and equitable evaluation process. In this approach, students not only receive feedback from their instructors but also engage with their peers' perspectives, often accounting for a small portion of the overall assessment marks. This added layer enhances the credibility of the assessment, as students actively participate in the evaluation process, fostering a deeper understanding of academic standards and criteria. One of the primary benefits of peer assessment lies in its ability to develop critical thinking skills (Topping et al., 2025). By evaluating their classmates' work, students are required to thoughtfully and objectively apply evaluative criteria, analyzing and judging the quality based on established standards. This process not only cultivates an analytical mindset but also helps students identify strengths and weaknesses in their own work. The practice of scrutinizing peers' submissions allows them to gain insight into different approaches and solutions, which, in turn, enhances their own learning and ability to produce quality work. Additionally, peer assessment fosters a sense of responsibility and accountability. Knowing that their work will be reviewed by classmates often motivates students to invest more effort into producing higher-quality submissions. This sense of accountability extends to the role of evaluator, where students learn to provide fair, constructive, and respectful feedback, grasping the ethical and professional standards expected in both academic and professional settings.\n\nTo implement effective peer assessment activities, it is crucial to provide students with clear guidelines and criteria for evaluation. Utilizing rubrics and checklists ensures that the peer assessments are consistent, objective, and focused on key learning outcomes. Training sessions or workshops on how to give and receive constructive feedback can further prepare students to participate effectively in the peer review process. By organizing structured peer assessment activities, educators create a learning environment where students engage actively with the material, develop critical thinking skills, and gain a deeper understanding of the standards that underpin academic evaluation. This approach not only adds a layer of scrutiny to the assessment process but also enhances students' ability to self-assess and reflect on their learning.\n\n## Future Directions and Research Needs\n\nAs generative AI continues to evolve, so too must our strategies for educational assessment. The rapid advancements in AI capabilities present both opportunities and challenges, particularly concerning academic integrity. To effectively address these challenges, future research must focus on developing innovative assessment methods, ethical guidelines, and policies that adapt to this changing technological landscape. This section outlines key areas for future research to ensure that assessments remain effective, fair, and authentic.\n\n### Exploring the Impact of Generative AI on Learning Outcomes\n\nAs generative AI becomes increasingly integrated into educational environments (Hulus, 2025; Olugbade, 2025), its influence on pedagogical processes and cognitive development warrants sustained, critical inquiry. Although preliminary investigations have documented short-term gains—such as increased accessibility and adaptive feedback—there remains a paucity of longitudinal evidence regarding its impact on core educational constructs, including epistemic engagement, durable knowledge retention, and the cultivation of higher-order cognitive faculties (Garcia et al., 2025). Moreover, the continuous interplay between learners and AI systems introduces new dynamics in metacognitive regulation and problem representation. To address these complexities, future research should pursue the following trajectories:\n\n- Conduct studies comparing traditional and AI-integrated assessment frameworks to evaluate their efficacy in fostering deep learning and transferable competencies.\n- Investigate the extent to which AI-mediated evaluations influence students’ capacity for integrative thinking, adaptive reasoning, and creative problem-solving.\n- Analyze shifts in students’ epistemological beliefs and self-regulated learning behaviors in response to sustained interactions with generative AI tools.\n\n### Development of Ethical Guidelines for AI Use in Assessments\n\nThe integration of AI into assessment ecosystems introduces a spectrum of ethical and sociotechnical challenges that extend beyond algorithmic functionality. Critical issues such as algorithmic opacity, surveillance risk, data sovereignty, and the erosion of authorship authenticity must be addressed through normative frameworks that prioritize justice, accountability, and inclusivity. The lack of cohesive institutional protocols leaves educational stakeholders vulnerable to unintended harm and systemic inequities. Therefore, establishing a comprehensive set of ethical parameters is essential for ensuring responsible AI deployment in evaluative contexts. Future research should be oriented toward the following imperatives:\n\n- Develop and evaluate transparent governance models to ensure responsible AI use in assessment, emphasizing student data protection and informed consent.\n- Design audit mechanisms for identifying and mitigating algorithmic bias, particularly across diverse sociocultural and linguistic student populations.\n- Examine the role of ethics-based policy frameworks in shaping institutional practices that promote fairness, trust, and transparency in AI-supported evaluation systems.\n\n### AI as an Assessment Tool\n\nDespite presenting epistemological and logistical challenges, generative AI holds substantial promise as an augmentative mechanism within the assessment continuum. When integrated judiciously, AI can facilitate scalable feedback systems, automate routine evaluation tasks, and support differentiated instruction across diverse learning profiles. However, uncritical reliance on algorithmic assessment risks undermining the interpretive and relational dimensions of human evaluation. To optimize AI’s role in assessment, it is essential to interrogate its pedagogical affordances while preserving the educator’s epistemic authority. The following research directions are essential for realizing AI's constructive potential:\n\n- Evaluate the pedagogical value of AI-generated feedback in supporting formative assessment and enhancing students' metacognitive awareness.\n- Determine best practices for calibrating AI-human hybrid assessment models to ensure reliability, validity, and student engagement.\n- Explore subject-specific implementations of AI-driven assessments that allow for personalization without compromising academic rigor or learner autonomy.\n\n### Development of Anti-Cheating Technologies\n\nThe advent of generative AI has introduced novel vectors for academic misconduct, significantly complicating the verification of student-authored work. Existing academic integrity frameworks and detection mechanisms are often ill-equipped to distinguish between authentic and algorithmically generated submissions. As such, the development of intelligent, adaptive countermeasures is imperative for sustaining trust in assessment validity. These mechanisms must be rooted in both technical rigor and ethical defensibility, capable of evolving alongside adversarial AI capabilities. Future research must address the following critical areas:\n\n- Advance the design of AI-enabled forensics capable of identifying linguistic, syntactic, and semantic markers indicative of non-human authorship.\n- Conduct empirical evaluative studies on the efficacy and limitations of existing academic integrity tools in detecting generative AI outputs.\n- Facilitate interdisciplinary collaboration to co-develop context-aware anti-cheating frameworks that integrate machine learning, educational theory, and ethical oversight.\n\n### Policy and Institutional Adaptation\n\nThe increasing ubiquity of AI in pedagogical and assessment practices necessitates a systemic reconfiguration of institutional policies and governance models. Static, pre-digital frameworks are ill-suited to address the evolving nature of algorithmically mediated learning environments. Institutional stakeholders must, therefore, engage in anticipatory policymaking that foregrounds educational equity, assessment fidelity, and technological accountability. To ensure that assessment practices remain aligned with educational goals and ethical standards in an AI-augmented context, the following research avenues are proposed:\n\n- Formulate institution-wide AI governance policies that codify principles of academic integrity, transparency, and responsible innovation in assessment.\n- Investigate adaptive models of assessment that integrate AI while centering on learning outcomes, disciplinary standards, and student well-being.\n- Develop strategic frameworks that align institutional assessment policies with national and international standards for ethical AI deployment in education.\n\n## Conclusion\n\nIn confronting the complexities introduced by advanced AI technologies, educational assessment must undergo a thoughtful transformation. The strategies outlined in this chapter offer actionable frameworks to support authentic learning and uphold academic integrity. Each of these approaches offers unique ways to assess students’ deeper cognitive and practical skills, reducing the reliance on outputs that may be artificially generated. The implications of these evolving strategies reach beyond the academic world. By incorporating integrity-centered assessment practices, educators influence the cultivation of critical thinking and ethical awareness in students—skills essential for navigating an AI-driven society. Implementing these methods prepares students not only for academic success but also for responsible participation in a technology-infused world. Looking forward, commitment to these integrity-based reforms will shape the resilience of educational institutions in preserving the values of genuine scholarship. Through adaptable, ethics-focused assessment models, educators can nurture learning environments that emphasize personal accountability and true intellectual development.\n\n## Key Terms and Definitions\n\n**Educational Assessment**: The systematic process of evaluating student learning, skills, and performance through various tools and methods to measure educational outcomes.\n\n**Academic Dishonesty**: The act of cheating, plagiarism, or misrepresenting one’s own work in an academic setting to gain an unfair advantage.\n\n**Artificial Intelligence**: A field of computer science focused on creating systems capable of performing tasks that typically require human intelligence.\n\n**Generative AI**: A type of artificial intelligence that can generate new content, such as text, images, or audio, based on the data it has been trained on.\n\n**Technology-Enhanced Assessment**: The use of digital tools, such as e-assessments and online platforms, to support and improve the process of evaluating student learning.\n\n[Related Research **The Manifesto for Teaching and Learning in a Time of Generative AI: A Critical Collective Stance to Better Navigate the Future** \\\nOpen Praxis\\\nRead Paper](https://manuelgarcia.info/publication/10.55982/openpraxis.16.4.777)\n\n## References\n\n01. Acut, D. (2022). Developing SIPCaR projects utilizing modern technologies: Its impact to students’ engagement, R&D skills, and learning outcomes. _LUMAT: International Journal on Math, Science and Technology Education_, 10(1), 294–318. [https://doi.org/10.31129/LUMAT.10.1.1667](https://doi.org/10.31129/LUMAT.10.1.1667)\n02. Acut, D. P., Gamusa, E. V., Pernaa, J., Yuenyong, C., Pantaleon, A. T., Espina, R. C., Sim, M. J. C., & Garcia, M. B. (2025). AI Shaming Among Teacher Education Students: A Reflection on Acceptance and Identity in the Age of Generative Tools. In _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_. IGI Global. [https://doi.org/10.4018/979-8-3373-0122-8.ch005](https://doi.org/10.4018/979-8-3373-0122-8.ch005)\n03. Acut, D. P., Lobo, J. T., & Garcia, M. B. (2025). Determinants of Teachers' Intentions to Integrate Education for Sustainable Development (ESD) Into Physical Education and Health Curricula. In M. B. Garcia (Ed.), _Global Innovations in Physical Education and Health_ (pp. 439-472). IGI Global. [https://doi.org/10.4018/979-8-3693-3952-7.ch016](https://doi.org/10.4018/979-8-3693-3952-7.ch016)\n04. Acut, D. P., Malabago, N. K., Malicoban, E. V., Galamiton, N. S., & Garcia, M. B. (2024). “ChatGPT 4.0 Ghosted Us While Conducting Literature Search:” Modeling the Chatbot’s Generated Non-Existent References Using Regression Analysis. _Internet Reference Services Quarterly_, 1-26. [https://doi.org/10.1080/10875301.2024.2426793](https://doi.org/10.1080/10875301.2024.2426793)\n05. Adams, R. (2021). Can Artificial Intelligence be Decolonized? _Interdisciplinary Science Reviews_, 46(1-2), 176-197. [https://doi.org/10.1080/03080188.2020.1840225](https://doi.org/10.1080/03080188.2020.1840225)\n06. Aladini, A., Bayat, S., & Abdellatif, M. S. (2024). Performance-Based Assessment in Virtual Versus Non-Virtual Classes: Impacts on Academic Resilience, Motivation, Teacher Support, and Personal Best Goals. _Asian-Pacific Journal of Second and Foreign Language Education_, 9(1), 1-27. [https://doi.org/10.1186/s40862-023-00230-4](https://doi.org/10.1186/s40862-023-00230-4)\n07. Anderson, A., & Johnston, B. (2016). Student Learning and Information Literacy. In A. Anderson & B. Johnston (Eds.), _From Information Literacy to Social Epistemology_ (pp. 67-79). Chandos Publishing. [https://doi.org/10.1016/B978-0-08-100545-3.00005-3](https://doi.org/10.1016/B978-0-08-100545-3.00005-3)\n08. Azevedo, A., & Azevedo, J. (Eds.). (2019). _Handbook of Research on E-Assessment in Higher Education_. IGI Global. [https://doi.org/10.4018/978-1-5225-5936-8](https://doi.org/10.4018/978-1-5225-5936-8).\n09. Badir, A., O’Neill, R., Kinzli, K.-D., Komisar, S., & Kim, J.-Y. (2023). Fostering Project-Based Learning through Industry Engagement in Capstone Design Projects. _Education Sciences_, 13(4), 1-14. [https://doi.org/10.3390/educsci13040361](https://doi.org/10.3390/educsci13040361)\n10. Bozkurt, A., Xiao, J., Farrow, R., Bai, J. Y. H., Nerantzi, C., Moore, S., Dron, J., Stracke, C. M., Singh, L., Crompton, H., Koutropoulos, A., Terentev, E., Pazurek, A., Nichols, M., Sidorkin, A. M., Costello, E., Watson, S., Mulligan, D., Honeychurch, S., Hodges, C. B., Sharples, M., Swindell, A., Frumin, I., Tlili, A., Slagter van Tryon, P. J., Bond, M., Bali, M., Leng, J., Zhang, K., Cukurova, M., Chiu, T. K. F., Lee, K., Hrastinski, S., Garcia, M. B., Sharma, R. C., Alexander, B., Zawacki-Richter, O., Huijser, H., Jandrić, P., Zheng, C., Shea, P., Duart, J. M., Themeli, C., Vorochkov, A., Sani-Bozkurt, S., Moore, R., & Asino, T. I. (2024). The Manifesto for Teaching and Learning in a Time of Generative AI: A Critical Collective Stance to Better Navigate the Future. _Open Praxis_, 16(4), 487-513. [https://doi.org/10.55982/openpraxis.16.4.777](https://doi.org/10.55982/openpraxis.16.4.777)\n11. Cacho, R. (2024). Integrating Generative AI in University Teaching and Learning: A Model for Balanced Guidelines. _Online Learning_, 28(3), 1-28. [https://doi.org/10.24059/olj.v28i3.4508](https://doi.org/10.24059/olj.v28i3.4508)\n12. Cheng, L. T. W., Armatas, C. A., & Wang, J. W. (2019). The Impact of Diversity, Prior Academic Achievement and Goal Orientation on Learning Performance in Group Capstone Projects. _Higher Education Research & Development_, 39(5), 913-925. [https://doi.org/10.1080/07294360.2019.1699028](https://doi.org/10.1080/07294360.2019.1699028)\n13. Daft, R. L., & Lengel, R. H. (1986). Organizational Information Requirements, Media Richness and Structural Design. _Management Science_, 32(5), 554-571. [https://doi.org/10.1287/mnsc.32.5.554](https://doi.org/10.1287/mnsc.32.5.554)\n14. Darling-Hammond, L., Flook, L., Cook-Harvey, C., Barron, B., & Osher, D. (2019). Implications for Educational Practice of the Science of Learning and Development. _Applied Developmental Science_, 24(2), 97-140. [https://doi.org/10.1080/10888691.2018.1537791](https://doi.org/10.1080/10888691.2018.1537791)\n15. Diaz, F. C. B., Trinidad, I., Agustin, M. J., Panganiban, T. P., & Garcia, M. B. (2025). Mindfulness For Health and Well-Being: An Innovative Physical Education Course in the University of the Philippines Diliman. In _Global Innovations in Physical Education and Health_. IGI Global. [https://doi.org/10.4018/979-8-3693-3952-7.ch006](https://doi.org/10.4018/979-8-3693-3952-7.ch006)\n16. Doğan, Y., Yıldırım, N. T., & Batdı, V. (2024). Effectiveness of Portfolio Assessment in Primary Education: A Multi-Complementary Research Approach. _Evaluation and Program Planning_, 106, 1-12. [https://doi.org/10.1016/j.evalprogplan.2024.102461](https://doi.org/10.1016/j.evalprogplan.2024.102461)\n17. Gantalao, L. C., Calzada, J. G. D., Capuyan, D. L., Lumantas, B. C., Acut, D. P., & Garcia, M. B. (2025). Equipping the Next Generation of Technicians: Navigating School Infrastructure and Technical Knowledge in the Age of AI Integration. In _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_. IGI Global. [https://doi.org/10.4018/979-8-3373-0122-8.ch009](https://doi.org/10.4018/979-8-3373-0122-8.ch009)\n18. Garcia, M. B. (2023). Facilitating Group Learning Using an Apprenticeship Model: Which Master is More Effective in Programming Instruction? _Journal of Educational Computing Research_, 61(6), 1207-1231. [https://doi.org/10.1177/07356331231170382](https://doi.org/10.1177/07356331231170382)\n19. Garcia, M. B. (2024). Addressing the Mental Health Implications of ChatGPT Dependency: The Need for Comprehensive Policy Development. _Asian Journal of Psychiatry_, 98\\. [https://doi.org/10.1016/j.ajp.2024.104140](https://doi.org/10.1016/j.ajp.2024.104140)\n20. Garcia, M. B. (2024). The Paradox of Artificial Creativity: Challenges and Opportunities of Generative AI Artistry. _Creativity Research Journal_, 1-14. [https://doi.org/10.1080/10400419.2024.2354622](https://doi.org/10.1080/10400419.2024.2354622)\n21. Garcia, M. B. (2025). Teaching and Learning Computer Programming Using ChatGPT: A Rapid Review of Literature Amid the Rise of Generative AI Technologies. _Education and Information Technologies_, 1-25. [https://doi.org/10.1007/s10639-025-13452-5](https://doi.org/10.1007/s10639-025-13452-5)\n22. Garcia, M. B., Arif, Y. M., Khlaif, Z. N., Zhu, M., de Almeida, R. P. P., de Almeida, R. S., & Masters, K. (2024). Effective Integration of Artificial Intelligence in Medical Education: Practical Tips and Actionable Insights. In _Transformative Approaches to Patient Literacy and Healthcare Innovation_ (pp. 1-19). IGI Global. [https://doi.org/10.4018/979-8-3693-3661-8.ch001](https://doi.org/10.4018/979-8-3693-3661-8.ch001)\n23. Garcia, M. B., Goi, C. L., Shively, K., Maher, D., Rosak-Szyrocka, J., Happonen, A., Bozkurt, A., & Damaševičius, R. (2025). Understanding Student Engagement in AI-Powered Online Learning Platforms: A Narrative Review of Key Theories and Models. In A. R. Gierhart (Ed.), _Cases on Enhancing P-16 Student Engagement With Digital Technologies_ (pp. 1-30). IGI Global. [https://doi.org/10.4018/979-8-3693-5633-3.ch001](https://doi.org/10.4018/979-8-3693-5633-3.ch001)\n24. Gikandi, J. W., Morrow, D., & Davis, N. E. (2011). Online Formative Assessment in Higher Education: A Review of the Literature. _Computers & Education_, 57(4), 2333-2351. [https://doi.org/10.1016/j.compedu.2011.06.004](https://doi.org/10.1016/j.compedu.2011.06.004)\n25. Gomez-del Rio, T., & Rodriguez, J. (2022). Design and Assessment of a Project-Based Learning in a Laboratory for Integrating Knowledge and Improving Engineering Design Skills. _Education for Chemical Engineers_, 40, 17-28. [https://doi.org/10.1016/j.ece.2022.04.002](https://doi.org/10.1016/j.ece.2022.04.002)\n26. Grapin, S. E. (2023). Assessment of English Learners and Their Peers in the Content Areas: Expanding What “Counts” as Evidence of Content Learning. _Language Assessment Quarterly_, 20(2), 215-234. [https://doi.org/10.1080/15434303.2022.2147072](https://doi.org/10.1080/15434303.2022.2147072)\n27. Gruenhagen, J. H., Sinclair, P. M., Carroll, J.-A., Baker, P. R. A., Wilson, A., & Demant, D. (2024). The Rapid Rise of Generative AI and Its Implications for Academic Integrity: Students’ Perceptions and Use of Chatbots for Assistance With Assessments. _Computers and Education: Artificial Intelligence_, 7, 1-10. [https://doi.org/10.1016/j.caeai.2024.100273](https://doi.org/10.1016/j.caeai.2024.100273)\n28. Hasanah, N. A., Aziza, M. R., Junikhah, A., Arif, Y. M., & Garcia, M. B. (2025). Navigating the Use of AI in Engineering Education Through a Systematic Review of Technology, Regulations, and Challenges. In _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_. IGI Global. [https://doi.org/10.4018/979-8-3373-0122-8.ch016](https://doi.org/10.4018/979-8-3373-0122-8.ch016)\n29. Heil, J., & Ifenthaler, D. (2023). Online Assessment in Higher Education: A Systematic Review. _Online Learning_, 27(1), 187-218. [https://doi.org/10.24059/olj.v27i1.3398](https://doi.org/10.24059/olj.v27i1.3398)\n30. Huang, K.-L., Liu, Y.-c., & Dong, M.-Q. (2024). Incorporating AIGC Into Design Ideation: A Study on Self-Efficacy and Learning Experience Acceptance Under Higher-Order Thinking. _Thinking Skills and Creativity_, 52, 1-16. [https://doi.org/10.1016/j.tsc.2024.101508](https://doi.org/10.1016/j.tsc.2024.101508)\n31. Hulus, A. (2025). A Systematic Review of Educators' Overreliance and Misuse of AI in Student Feedback: Introducing the ETHICAL-FEED Framework. In _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_. IGI Global. [https://doi.org/10.4018/979-8-3373-0122-8.ch015](https://doi.org/10.4018/979-8-3373-0122-8.ch015)\n32. Kim, S. C., Covington, B., Benavente, V., & Willson, P. (2019). Capstone Projects As Experiential Evidence-Based Practice Education. _The Journal for Nurse Practitioners_, 15(3), 51-56. [https://doi.org/10.1016/j.nurpra.2018.12.011](https://doi.org/10.1016/j.nurpra.2018.12.011)\n33. Kiritchenko, S., Nejadgholi, I., & Fraser, K. C. (2021). Confronting Abusive Language Online: A Survey from the Ethical and Human Rights Perspective. _Journal of Artificial Intelligence Research_, 71, 431–478. [https://doi.org/10.1613/jair.1.12590](https://doi.org/10.1613/jair.1.12590)\n34. Kong, Z. Y., Omar, A. A., Lau, S. L., & Sunarso, J. (2024). Introducing Process Simulation as an Alternative to Laboratory Session in Undergraduate Chemical Engineering Thermodynamics Course: A Case Study From Sunway University Malaysia. _Digital Chemical Engineering_, 12, 1-10. [https://doi.org/10.1016/j.dche.2024.100167](https://doi.org/10.1016/j.dche.2024.100167)\n35. Kovaleva, Y., Happonen, A., Garcia, M. B., & Kasurinen, J. (2024). Female-Inclusive Practices for Software Engineering and Computer Science Higher Education: A Literature Review. _Proceedings of the Annual Doctoral Symposium of Computer Science 2024_. [https://doi.org/https://ceur-ws.org/Vol-3776/paper08.pdf](https://doi.org/https://ceur-ws.org/Vol-3776/paper08.pdf)\n36. Landfried, M., Chen, E., Savelli, L. B., Cooper, M., Price, B. N., & Emmerling, D. (2023). MPH Capstone experiences: promising practices and lessons learned. _Frontiers in Public Health_, 11, 1-11. [https://doi.org/10.3389/fpubh.2023.1129330](https://doi.org/10.3389/fpubh.2023.1129330)\n37. Lee, V. R., Pope, D., Miles, S., & Zárate, R. C. (2024). Cheating in the Age of Generative AI: A High School Survey Study of Cheating Behaviors Before and After the Release of ChatGPT. _Computers and Education: Artificial Intelligence_, 7, 1-10. [https://doi.org/10.1016/j.caeai.2024.100253](https://doi.org/10.1016/j.caeai.2024.100253)\n38. Mangubat, J. C., Mangubat, M. R., Uy, T. B. L., Acut, D. P., & Garcia, M. B. (2025). Safeguarding Educational Innovations Amid AI Disruptions: A Reassessment of Patenting for Sustained Intellectual Property Protection. In _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_. IGI Global. [https://doi.org/10.4018/979-8-3373-0122-8.ch013](https://doi.org/10.4018/979-8-3373-0122-8.ch013)\n39. Martínez-Requejo, S., Redondo-Duarte, S., Jiménez-García, E., & Ruiz-Lázaro, J. (2025). Technoethics and the Use of Artificial Intelligence in Educational Contexts: Reflections on Integrity, Transparency, and Equity. In _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_. IGI Global. [https://doi.org/10.4018/979-8-3373-0122-8.ch010](https://doi.org/10.4018/979-8-3373-0122-8.ch010)\n40. Miller, J. C., Fernando, E. Q., Miranda, J. P. P., Bansil, J. A., Hernandez, H. E., & Regala, A. R. (2024). Extended Reality Technologies in Physical Fitness for Health Promotion: Insights from Bibliometric Research. In _Emerging Technologies for Health Literacy and Medical Practice_. IGI Global. [https://doi.org/10.4018/979-8-3693-1214-8.ch005](https://doi.org/10.4018/979-8-3693-1214-8.ch005)\n41. Miranda, J. P. P., Cruz, M. A. D., Fernandez, A. B., Balahadia, F. F., Aviles, J. S., Caro, C. A., Liwanag, I. G., & Gaña, E. P. (2025). Erosion of Critical Academic Skills Due to AI Dependency Among Tertiary Students: A Path Analysis. In _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_. IGI Global. [https://doi.org/10.4018/979-8-3373-0122-8.ch002](https://doi.org/10.4018/979-8-3373-0122-8.ch002)\n42. Montenegro-Rueda, M., Luque-de la Rosa, A., Sarasola Sánchez-Serrano, J. L., & Fernández-Cerero, J. (2021). Assessment in Higher Education during the COVID-19 Pandemic: A Systematic Review. _Sustainability_, 13(19), 1-13. [https://doi.org/10.3390/su131910509](https://doi.org/10.3390/su131910509)\n43. Ofosu-Ampong, K., Acheampong, B., Kevor, M., & Amankwah-Sarfo, F. (2023). Acceptance of Artificial Intelligence (ChatGPT) in Education: Trust, Innovativeness and Psychological Need of Students. _Information and Knowledge Management_, 13(4), 37-47. [https://doi.org/10.7176/IKM/13-4-03](https://doi.org/10.7176/IKM/13-4-03)\n44. Ofosu-Ampong, K., Agyekum, M. W., & Garcia, M. B. (2024). Long-Term Pandemic Management and the Need to Invest in Digital Transformation: A Resilience Theory Perspective. In _Transformative Approaches to Patient Literacy and Healthcare Innovation_ (pp. 242-260). IGI Global. [https://doi.org/10.4018/979-8-3693-3661-8.ch012](https://doi.org/10.4018/979-8-3693-3661-8.ch012)\n45. Olugbade, D. (2025). A Systematic Review of the Role of AI-Enabled Chatbots in Modern Education: Benefits, Risks, and Implementation Complexity. In _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_. IGI Global. [https://doi.org/10.4018/979-8-3373-0122-8.ch018](https://doi.org/10.4018/979-8-3373-0122-8.ch018)\n46. Petil, E. D., Florece, M. E. A., Gomez, M. G. A., Villaruel, K. B., Fernandez, H. G. C. Q., Dela Cruz, C. M. B., & Ferrer-Rafols, R. B. (2025). Virtual Reality in Physical Education: An Innovative Approach to Optimize Physical and Mental Health. In _Global Innovations in Physical Education and Health_. IGI Global. [https://doi.org/10.4018/979-8-3693-3952-7.ch005](https://doi.org/10.4018/979-8-3693-3952-7.ch005)\n47. Preiksaitis, C., & Rose, C. (2023). Opportunities, Challenges, and Future Directions of Generative Artificial Intelligence in Medical Education: Scoping Review. _JMIR Medical Education_, 9, 1-13. [https://doi.org/10.2196/48785](https://doi.org/10.2196/48785)\n48. Revano, T. F., & Garcia, M. B. (2020). Manufacturing Design Thinkers in Higher Education Institutions: The Use of Design Thinking Curriculum in the Education Landscape. _2020 IEEE 12th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management (HNICEM)_. [https://doi.org/10.1109/HNICEM51456.2020.9400034](https://doi.org/10.1109/HNICEM51456.2020.9400034)\n49. Riebe, L., Girardi, A., & Whitsed, C. (2016). A Systematic Literature Review of Teamwork Pedagogy in Higher Education. _Small Group Research_, 47(6), 619-664. [https://doi.org/10.1177/1046496416665221](https://doi.org/10.1177/1046496416665221)\n50. Ryan, M. (2011). Evaluating Portfolio Use as a Tool for Assessment and Professional Development in Graduate Nursing Education. _Journal of Professional Nursing_, 27(2), 84-91. [https://doi.org/10.1016/j.profnurs.2010.09.008](https://doi.org/10.1016/j.profnurs.2010.09.008)\n51. Salinas-Navarro, D. E., Vilalta-Perdomo, E., Michel-Villarreal, R., & Montesinos, L. (2024). Using Generative Artificial Intelligence Tools to Explain and Enhance Experiential Learning for Authentic Assessment. _Education Sciences_, 14(1), 1-24. [https://doi.org/10.3390/educsci14010083](https://doi.org/10.3390/educsci14010083)\n52. See, B. H., Gorard, S., Lu, B., Dong, L., & Siddiqui, N. (2022). Is Technology Always Helpful?: A Critical Review of the Impact on Learning Outcomes of Education Technology in Supporting Formative Assessment in Schools. _Research Papers in Education_, 37(6), 1064-1096. [https://doi.org/10.1080/02671522.2021.1907778](https://doi.org/10.1080/02671522.2021.1907778)\n53. Slack, H. R., & Priestley, M. (2023). Online Learning and Assessment During the COVID-19 Pandemic: Exploring the Impact on Undergraduate Student Well-Being. _Assessment & Evaluation in Higher Education_, 48(3), 333-349. [https://doi.org/10.1080/02602938.2022.2076804](https://doi.org/10.1080/02602938.2022.2076804)\n54. Slavinska, A., Palkova, K., Grigoroviča, E., Edelmers, E., & Pētersons, A. (2024). Narrative Review of Legal Aspects in the Integration of Simulation-Based Education into Medical and Healthcare Curricula. _Laws_, 13(2), 1-20. [https://doi.org/10.3390/laws13020015](https://doi.org/10.3390/laws13020015)\n55. Stephenson, S., Rogers, O., Ivy, C., Barron, R., & Burke, J. (2020). Designing Effective Capstone Experiences and Projects for Entry-Level Doctoral Students in Occupational Therapy: One Program’s Approaches and Lessons Learned. _The Open Journal of Occupational Therapy_, 8(3), 1-12. [https://doi.org/10.15453/2168-6408.1727](https://doi.org/10.15453/2168-6408.1727)\n56. Swiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J. M., Milligan, S., Selwyn, N., & Gašević, D. (2022). Assessment in the Age of Artificial Intelligence. _Computers and Education: Artificial Intelligence_, 3, 1-10. [https://doi.org/10.1016/j.caeai.2022.100075](https://doi.org/10.1016/j.caeai.2022.100075)\n57. Taneja, D., Prabagaren, H., & Thomas, M. R. (2025). AI in Academia: Balancing Integrity, Ethics, and Learning Amid Evolving Norms of Authorship and Scholarship. In _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_. IGI Global. [https://doi.org/10.4018/979-8-3373-0122-8.ch014](https://doi.org/10.4018/979-8-3373-0122-8.ch014)\n58. Tenhunen, S., Männistö, T., Luukkainen, M., & Ihantola, P. (2023). A Systematic Literature Review of Capstone Courses in Software Engineering. _Information and Software Technology_, 159, 1-21. [https://doi.org/10.1016/j.infsof.2023.107191](https://doi.org/10.1016/j.infsof.2023.107191)\n59. Topping, K. J., Gehringer, E., Khosravi, H., Gudipati, S., Jadhav, K., & Susarla, S. (2025). Enhancing Peer Assessment with Artificial Intelligence. _International Journal of Educational Technology in Higher Education_, 22(1), 1-33. [https://doi.org/10.1186/s41239-024-00501-1](https://doi.org/10.1186/s41239-024-00501-1)\n60. Valderama, A. M., Tuazon, J. B., & Garcia, M. B. (2022). Promoting Student Thinking and Engagement Through Question-Based and Gamified Learning. _2022 IEEE 14th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management (HNICEM)_. [https://doi.org/10.1109/HNICEM57413.2022.10109470](https://doi.org/10.1109/HNICEM57413.2022.10109470)\n61. Walter, Y. (2024). Embracing the Future of Artificial Intelligence in the Classroom: The Relevance of Ai Literacy, Prompt Engineering, and Critical Thinking in Modern Education. _International Journal of Educational Technology in Higher Education_, 21(1), 1-29. [https://doi.org/10.1186/s41239-024-00448-3](https://doi.org/10.1186/s41239-024-00448-3)\n62. Xiao, J., Bozkurt, A., Nichols, M., Pazurek, A., Stracke, C. M., Bai, J. Y. H., Farrow, R., Mulligan, D., Nerantzi, C., Sharma, R. C., Singh, L., Frumin, I., Swindell, A., Honeychurch, S., Bond, M., Dron, J., Moore, S., Leng, J., Slagter van Tryon, P. J., Garcia, M. B., Terentev, E., Tlili, A., Chiu, T. K. F., Hodges, C. B., Jandrić, P., Sidorkin, A. M., Crompton, H., Hrastinski, S., Koutropoulos, A., Cukurova, M., Shea, P., Watson, S., Zhang, K., Lee, K., Costello, E., Sharples, M., Vorochkov, A., Alexander, B., Bali, M., Moore, R., Zawacki-Richter, O., Asino, T. I., Huijser, H., Zheng, C., Sani-Bozkurt, S., Duart, J. M., & Themeli, C. (2025). Venturing into the Unknown: Critical Insights into Grey Areas and Pioneering Future Directions in Educational Generative AI Research. _TechTrends_, 1-16. [https://doi.org/10.1007/s11528-025-01060-6](https://doi.org/10.1007/s11528-025-01060-6)\n63. Yilmaz, R., & Karaoglan Yilmaz, F. G. (2023). The Effect of Generative Artificial Intelligence (AI)-Based Tool Use on Students' Computational Thinking Skills, Programming Self-Efficacy and Motivation. _Computers and Education: Artificial Intelligence_, 4, 1-14. [https://doi.org/10.1016/j.caeai.2023.100147](https://doi.org/10.1016/j.caeai.2023.100147)\n\n## Cite this paper\n\nGarcia, M. B., Rosak-Szyrocka, J., Yilmaz, R., Metwally, A. H. S., Acut, D. P., Ofosu-Ampong, K., Erdoğdu, F., Fung, C. Y., & Bozkurt, A. (2025). Rethinking Educational Assessment in the Age of Generative AI: Actionable Strategies to Mitigate Academic Dishonesty. _Pitfalls of AI Integration in Education: Skill Obsolescence, Misuse, and Bias_, 1-24. https://doi.org/10.4018/979-8-3373-0122-8.ch001.\n\n[Download Citation](javascript:void(0))\n\nSUBMITTED\n\nOct 06 2024\n\nREVISED\n\nJan 08 2025\n\nPUBLISHED\n\nMay 10 2025\n\nLINK\n\nhttps://doi.org/10.4018/979-8-3373-0122-8.ch001\n\n### Keywords\n\n- [Educational Assessment](https://manuelgarcia.info/search?keyword=educational+assessment)\n- [Artificial Intelligence](https://manuelgarcia.info/search?keyword=artificial+intelligence)\n- [Generative AI](https://manuelgarcia.info/search?keyword=generative+ai)\n- [Academic Dishonesty](https://manuelgarcia.info/search?keyword=academic+dishonesty)\n- [Technology-Enhanced Assessment](https://manuelgarcia.info/search?keyword=technology-enhanced+assessment)\n- [Academic Integrity](https://manuelgarcia.info/search?keyword=academic+integrity)\n- [ChatGPT](https://manuelgarcia.info/search?keyword=chatgpt)\n\n### Authors\n\n#### Garcia, Manuel B.\n\nEducational Innovation and Technology Hub\n\nFEU Institute of Technology, Philippines\n\n[iD 0000-0003-2615-422X](https://orcid.org/0000-0003-2615-422X)\n\n#### Rosak-Szyrocka, Joanna\n\nFaculty of Management\n\nCzestochowa University of Technology, Poland\n\n[iD 0000-0002-5548-6787](https://orcid.org/0000-0002-5548-6787)\n\n#### Yilmaz, Ramazan\n\nFaculty of Science\n\nBartin University, Turkey\n\n[iD 0000-0002-2041-1750](https://orcid.org/0000-0002-2041-1750)\n\n#### Metwally, Ahmed Hosny Saleh\n\nFaculty of Education\n\nHelwan University, Egypt\n\n[iD 0000-0002-9545-5870](https://orcid.org/0000-0002-9545-5870)\n\n#### Acut, Dharel P.\n\nCollege of Education\n\nCebu Technological University, Philippines\n\n[iD 0000-0002-9608-1292](https://orcid.org/0000-0002-9608-1292)\n\n#### Ofosu-Ampong, Kingsley\n\nBusiness School\n\nUniversity of Ghana, South Africa\n\n[iD 0000-0003-0561-6376](https://orcid.org/0000-0003-0561-6376)\n\n#### Erdoğdu, Fatih\n\nDepartment of Computer Technology\n\nZonguldak Bülent Ecevit University, Turkey\n\n[iD 0000-0003-1022-8570](https://orcid.org/0000-0003-1022-8570)\n\n#### Fung, Chorng Yuan\n\nFaculty of Business, Design and Arts\n\nSwinburne University of Technology, Malaysia\n\n[iD 0000-0002-2007-6286](https://orcid.org/0000-0002-2007-6286)\n\n#### Bozkurt, Aras\n\nDepartment of Distance Education\n\nAnadolu University, Turkey\n\n[iD 0000-0002-4520-642X](https://orcid.org/0000-0002-4520-642X)\n\nAdd Comment"}
{"title": "Perceived impact of generative AI on assessments", "content": "1. Introduction In a remarkable convergence of research and real-world impact, the sudden emergence of ChatGPT has sent shockwaves through the global landscape of education. As students, educators, and university administrators grapple with the practical implications of generative AI, it becomes abundantly clear that we stand at the precipice of a new era. Since the release of GPT-3, a groundbreaking large language model (LLM) released by OpenAI, and its offspring, the user-friendly ChatGPT conversational interface, researchers are both excited and filled with trepidation over its boundless possibilities and transformative potential ( Cotton et al., 2023; Farazouli et al., 2023; Nikolic et al., 2023). Generative AI, as defined by Weng (2023), refers to a technology that utilizes deep learning models to generate content that closely resembles human expression in response to complex and diverse prompts. These tools have the ability to produce conversational-style text that closely resembles human writing, as well as other visual and auditory media. They can be used to create systems that operate in ways that resemble human cognition and behavior ( Siemens et al., 2022; Markel et al., 2023; Park et al., 2023). For example, ChatGPT and its derivatives are increasingly utilized for language translation, human-like conversation with chatbots, writing articles, stories, computer code, and other forms of written content ( Cotton et al., 2023). Generative AI tools promise many benefits in education, such as increasing student engagement in learning tasks, providing timely feedback, aiding research and collaboration, and improving accessibility ( Kasneci et al., 2023). For example, AI technology can provide immediate feedback via automated grading ( Mate &amp; Weidenhofer, 2022) and facilitate the provision of meaningful feedback in large cohorts ( Bernius et al., 2022). At the same time, AI raises serious concerns about the validity of widely used assessment practices, especially concerns about academic integrity and bypassing important learning processes ( Swiecki et al., 2022). Because standard assessment practices focus on evaluating the final products like essays to measure learning, researchers have highlighted the potential for plagiarism as a key challenge with using ChatGPT for assessment in higher education ( Cotton et al., 2023). Students can potentially use generative AI tools like ChatGPT to cheat on online assessments by submitting essays that are not their own work. The problem might be more prevalent in online assessments where students tend to feel more distant from their instructors ( Papanastasiou &amp; Solomonidou, 2023). Educators can face challenges distinguishing between students' own work and responses generated by AI tools, making it difficult to assess students' level of understanding and their ability to apply the material ( Mao et al., 2024). Unless educators and academic institutions adapt to this new reality, generative AI can undermine academic integrity in online assessments and the purpose of higher education to educate students, which may reduce the signaling effects and inherent value in formal educational attainment ( Cotton et al., 2023). To address this major problem, scholars have called for applying AI in classrooms in such a way that promotes self-regulated and more productive learning, rather than treating it as a replacement for human effort in the learning process ( Hopfenbeck et al., 2023; Mao et al., 2024; Swiecki et al., 2022). AI has been framed as a transformative resource that educators and students can leverage in teaching and learning. Weng (2023) suggests ways to employ generative AI tools such as raising awareness of these tools, using them in class, in assessments, and engaging in discussions with students about their promises and challenges. They argue that this is more productive than either banning them or giving them a central role in the curriculum. Integrating generative AI with assessments can also transform assessment practices and experiences, for example, by immersing students in simulated learning environments where they can safely and repeatedly practice skills ( Markel et al., 2023). This paradigm shift may require the development of new assessment approaches and policies that achieve a balance between the advantages of AI and the imperative to maintain academic integrity ( Chan &amp; Chen, 2023). Bearman et al. (2023) argued that educational assessment practice has not kept up with the digital transformation. Students and educators require better guidance on how to engage in meaningful interactions with AI systems for the purpose of assessment ( Viberg et al., 2024). These interactions would directly assess students' learning process, critical thinking, and evaluative skills, not just their knowledge and comprehension. To this end, we expect to see revised guidelines and recommendations for educational assessment policies, incorporating input from stakeholders involved in assessment design to address the two major questions around AI integration in education: ‘what’ to assess ( Sabzalieva &amp; Valentini, 2023) and ‘how’ to assess it ( Chan &amp; Chen, 2023). There are many ongoing conversations around what types of assessments are needed given the capabilities of generative AI tools. Bearman and Luckin (2020) emphasize that machines lack the ability to define quality or establish standards, making it crucial to develop assessment designs that prioritize the distinctly human capacity for defining quality standards. This raises questions on assessment standards and a move towards more authentic, adaptive, and continuous assessment ( Gašević et al., 2023). Adapting current assessment practices in response to the ubiquitous availability of generative AI tools is timely but also effortful. As AI continues to play a pivotal role in society, assessments need to be adapted to ensure that they assess students authentically and ethically. Assessment approaches that foster human expertise and judgment are primed to gain greater significance through digital technologies ( Dann, 2014; Nieminen et al., 2023; Bearman &amp; Luckin, 2020). This moment presents a rare opportunity for real innovation in current assessment practices, because most commonly used assessments were not conceived with access to powerful generative AI tools in mind. To meet the moment, we need to understand educators' and students' perspectives on the issue to achieve sustainable advances in assessment practices. We are especially interested in how much the perspectives of these two stakeholders—educators and students—are in alignment to provide a common ground. This may vary across contexts shaped by the local pace of technological adoption, institutional characteristics, cultural differences, and linguistic variation in technological efficacy (i.e., generative AI tools may work better in English than in other languages such as Greek). Within this context, we pose the following three research questions: (1) Which types of assessments do educators and students consider to be most impacted by generative AI? (2) How do educators and students think that students will be using generative AI in completing assessments? (3) And what are their preferences and attitudes toward adapting assessments to incorporate generative AI? Answering these questions by building on an established framework for examining assessment quality for university online assessments is essential since such knowledge is needed to guide efforts to reform future assessment practices. 2. Background 2.1. Assessment in the era of generative AI Assessments are essential for measuring what students have learned ( Mislevy et al., 2003). Contemporary assessment approaches (e.g., assessment as learning; Torrance, 2007) require students to take an active role in their own learning, encouraging them to develop and apply capacities for self-regulation, critical thinking, and evaluative judgment ( Gašević et al., 2022). This brings assessments into closer alignment with high-level learning outcomes, for instance, as articulated in Bloom's Taxonomy ( Bloom et al., 1956). In his original taxonomy, Bloom placed the cognitive task of evaluation at the top of the pyramid (followed by synthesis, analysis, application, comprehension, and then knowledge): it is a complex and rich task that requires critical thinking and the integration of knowledge domains, but it is resource-intensive to assess and give effective feedback on using traditional methods ( Krathwohl, 2002). The advent of online or digital assessment in higher education predates the emergence of generative AI tools, yet it has continually evolved to incorporate technological advancements that promise to enhance the learning and assessment experience. The transition from traditional to digital assessment methods has been driven by the need for scalability, flexibility, and the potential to provide immediate feedback, among other benefits. In line with Vygotsky's emphasis on the learning journey over the destination ( Vygotsky &amp; Cole, 1978), there has been a shift towards assessing more of the process by which students arrive at a final product or solution ( Gašević et al., 2022). However, this transition has also raised concerns regarding academic integrity, the authenticity of student work, and the adequacy of these methods in evaluating higher-order thinking skills ( Sillat et al., 2021; Viberg et al., 2024; Gikandi et al., 2011). Recent developments in generative AI, particularly tools like ChatGPT, have introduced new dimensions to the ongoing discourse on digital assessment ( Swiecki et al., 2022). These tools possess the capability to generate human-like text, solve complex problems, produce code, and even simulate entire conversations, raising both opportunities and challenges for assessment practices in higher education. While generative AI tools can potentially support personalized learning and assist in creating more authentic, dynamic assessment tasks, they also pose significant risks related to academic dishonesty, educational equity, and the dilution of critical thinking and creativity in student work ( Perkins, 2023; Gipps &amp; Stobart, 2009; Kasneci et al., 2023; Yu, 2023). The literature on the integration of generative AI tools in educational assessment is emerging, with studies beginning to explore the implications of these technologies for teaching, learning, and assessment ( Swiecki et al., 2022). While there are an increasing number of studies demonstrating the possibilities of generative AI, few thus far provide any evidence of real-world impacts for students and educators. Any impacts are going to be strongly shaped by what educators and students think about generative AI for assessments. Prior work shows that student and educator perspectives are critical enablers or barriers for innovation in educational assessments ( Andrade &amp; Du, 2019; Bevitt, 2015; Bennett et al., 2017). Our study seeks to contribute to this burgeoning field by examining the perspectives of key stakeholders—educators and students—on the use of generative AI tools in assessment practices within higher education. By focusing on stakeholders' views, this research aims to shed light on the perceived benefits and drawbacks of generative AI in assessments, the types of assessments most impacted by these technologies, and the preferences and attitudes towards adapting assessment practices to incorporate generative AI. In doing so, we aim to better connect our findings to the existing body of research and to contribute valuable insights into the ongoing conversation about the future of assessment in an AI-augmented educational landscape. 2.2. Conceptual framework for online assessments In a national study of Australian educators in the business disciplines, researchers investigated the factors that influence the design and evaluation of online assessments, which are defined as any type of graded activity with an online component designed to measure students' mastery of knowledge and/or skills ( Huber et al., 2024). The authors identified six design dimensions and four contextual factors at play. The design dimensions include ensuring academic integrity, providing valuable feedback, creating a positive learning experience for students, delivering authentic assessment tasks, maintaining the integrity of student information, and ensuring equal opportunities for all students to complete the assessment successfully ( Table 1). The broader contextual factors that influence assessment design decisions and practices include scale of delivery, resource constraints, institutional policies, and accreditation requirements. Their study also identified constraints and trade-offs that need to be negotiated in designing, evaluating, and implementing online assessments; the most important one as identified by educators, was academic integrity (see definition in Table 1). Online assessment presents practical challenges for student authentication and academic integrity: identity verification is especially difficult in online essays, and remote invigilation is challenging for online examinations ( Mate &amp; Weidenhofer, 2022; Cram et al., 2022). Table 1. Assessment design dimensions with descriptions as provided in the survey instrument. Dimension Defined as the extent to which the assessment ... Academic integrity ensures security against cheating, impersonation, and other forms of inappropriate assistance Student experience enhances convenience and comfort for students, motivation, and concentration, minimizes stress and anxiety, and technical complication Authenticity has similar tasks to those performed in workplace or professional settings Information integrity reduces the likelihood of privacy breach (i.e., unauthorized access to student personal data, content students generated in their assessments) Quality feedback enables the provision of quality feedback (e.g., timely, multiple formats such as media, text, encourages the use of feedback towards later assessment) Equity of access enables flexible conditions to complete the assessment (e.g., ease of access for students with a disability/impairment, limited access to technology, geographically dispersed) Several of these challenges with designing and implementing new online assessments were highlighted in a recent study of business educators ( Cram et al., 2022). They surveyed 97 university faculty members in Australia about their views on assessments that are not conducted with pen and paper, but digitally through technology. Their focus was not on AI but they considered challenges that arise in online assessments that also apply to working with AI tools. These challenges include additional academic teacher time and effort, the logistics and timing of new kinds of assessments, technology access, consistency over time, functionality and usability, alignment with student preferences and expectations, effectively preparing students for new assessment formats, and institutional and departmental policies that might inhibit new assessment designs and implementations. Considering these challenges, it is important to understand educators' attitudes towards generative AI in the context of assessments. Yet, educators are not the only ones who will be quick to respond to assessment reform efforts. Students have been looking for guidance on how to approach assessments that were not designed with the capabilities and availability of modern AI tools in mind. Moreover, both educators and students look to school leadership to provide official guidance on academic integrity and effective uses of AI in teaching, learning, and assessment. In Australia, for example, the Tertiary Education Quality and Standards Agency (TEQSA) has compiled a set of resources to assist higher education providers in addressing the challenges and leveraging the opportunities brought by the advances in generative AI tools ( Tertiary Education Quality and Standards Agency, 2024). This has prompted universities to embed guiding statements about the use of AI tools in their policies. In this research study, we build on the ( Huber et al., 2024) framework, which has thus far been tested in the Australian higher education context with educators, by testing it as a heuristic to evaluate the impact of generative AI on assessments in new contexts. We collected data in two other continents, North America and Europe, to examine what similarities and differences might appear across the three international institutions, and thus acknowledge the value of understanding these dynamics in varied educational and cultural settings. We are also interested in students' perspectives on the design of online assessments and particularly the impact of generative AI tools. This study centers around both, the educator and student perspective to gain a holistic and comparative understanding of how these two groups make sense of how recent technological changes affect assessments. 3. Methods 3.1. Participants and contexts We collected survey data from students and educators at three institutions of higher education located in three countries across three continents (Australia, Cyprus, and the United States). The sample characteristics are shown in Table 2. Participants were recruited through email to complete a 15-minute survey through Qualtrics (Australia, USA) or SurveyMonkey (Cyprus). For the US sample, incentives to respond included a $5 charity donation and course credit for students; no incentives were offered for Australian or Cypriot respondents. Respondents who provided informed consent at the start of the survey and answered the first page of questions were retained for analysis. Given that each survey sample was collected in a specific institution of higher education, which is not representative of each country, we provide further information on the institutional context. The convenience samples are also not representative of the institutions where they were collected. Table 2. Survey sample characteristics for students and educators by country. Empty Cell Australian Sample Cypriot Sample US Sample Students Educators Students Educators Students Educators Sample Size 353 29 276 48 51 10 Age Mean (SD) 24.1 (7.9) – 30.7 (6.7) 45.5 (7.7) 21.1 (1.1) 48.2 (16.9) Undergraduates 48% – 14% – 100% – Graduates (Master/PhD) 52% – 86% – 0% – Yrs. Teaching Mean (SD) – 13 (9) – 15 (8) – 18 (19) Discipline  Agriculture, Life, Health 0% 0% 5% 6% 58% 25%  Arts and Science 14% 54% 7% 33% 11% 0%  Business 32% 38% 2% 11% 22% 0%  Education 0% 0% 78% 44% 0% 0%  Engineering 50% 8% 6% 6% 8% 50%  Law 3% 0% 1% 0% 0% 25%  Medicine 0% 1% 0% 0% 0% 0% In Australia, we collected responses at The University of Sydney, a large urban, public university classified as research-intensive, with around 70,000 students and 7,000 staff. The student survey was distributed by an announcement in the university Learning Management System and the faculty survey was advertised on internal social media channels and the various Faculty and School staff mailing lists. In Cyprus, we collected responses at the University of Nicosia, a private urban university in the Republic of Cyprus. In the distribution of European countries, Cyprus ranks below the average size and gross domestic product. The institution enrolls around 14,000 students and has about 1,100 full-time and part-time faculty and staff. The survey announcement was distributed to faculty members via e-mail, and to the students through the university's Learning Management System. In the US, we collected responses at Cornell University, a private land-grant university located in a rural region of the Northeastern part of the country. It enrolls around 15,000 undergraduate and 10,000 graduate students and has 2,000 full-time faculty. The student survey was distributed via course email lists, flyers, and social media postings. The faculty survey was sent to a large email list of faculty with an interest in technology and related fields. 3.2. Measures The survey included the same set of questions for students and educators. Our goal from the start was to understand how much overlap there is in the views of educators and students. To achieve a direct comparison, we hold the questions constant between the two stakeholders. This way we can reach internally valid claims about the similarities and differences of their attitudes at the same point in time, unaffected by variation in how each question was asked. 3.2.1. Awareness and use of generative AI We measured awareness with a single yes/no question: “Have you heard of ChatGPT before?” To ensure respondents understood the question consistently, we included a short definition above it: “Generative AI tools use artificial intelligence (AI) to generate new content such as text, imagery, audio and synthetic data. ChatGPT is an example of a generative AI tool that uses natural language processing to generate text. ChatGPT can be used to prompt graphics, create articles, write product descriptions, explain complex topics, and more.” We measured generative AI use using a Likert-style question: “How frequently do you use ChatGPT (or similar generative AI tools) in the following ways?” The following categories were provided: coursework; research; non-academic, professional purposes; and fun. Respondents rated their frequency of use for each category on the following scale: Never, A few times, Weekly, Daily. We aggregate the number of weekly and daily responses. 3.2.2. Perceived impact of generative AI on assessment types The perceived impact of generative AI on different types of assessments was measured using a Likert-style question: “How much do you expect each type of assessment to be impacted by the introduction of generative AI tools like ChatGPT?” For eight different types of assessments (see Fig. 1), respondents rated the perceived impact on the following scale: Not at all, Slightly, Moderately, Very, Extremely, Unsure. We excluded “Unsure” responses in the analysis. Download: Download high-res image (152KB) Download: Download full-size image Fig. 1. Mean ratings of how much different types of assessment are perceived to be impacted by the availability of generative AI tools like ChatGPT according to educators (left panel) and students (right) in each country (color). The scale points are labeled Not at all (1), Slightly (2), Moderately (3), Very (4), and Extremely (5). Standard error bars are shown. 3.2.3. Expected student use of generative AI We asked an open-ended question to understand how students and educators thought that students would use generative AI to complete two specific assessments. After viewing each of the original assessment prompts (see Table 3), and before seeing the adapted prompt, participants were asked: “How do you think students might use generative AI tools to complete this assessment?” We coded these open-ended responses and identified themes using the method explained in the analytic approach. Table 3. Original and adapted assessment prompt for each assessment type. Essay Assessment Prompt Original: Write a 5-page essay on [a given topic in your discipline; e.g., Greek mythology, human rights, sustainable energy, sorting algorithms]. You have 7 days to complete the essay. Adapted: You are given a 5-page essay produced by ChatGPT on [a given topic in your discipline; e.g., Greek mythology, human rights, sustainable energy, sorting algorithms]. You have 7 days to analyze the essay and edit it yourself to improve its quality, making clear references to the original text where applicable. Coding Assessment Prompt Original: 1. Write two different algorithms using Python code to sort a list of numbers. 2. Evaluate the correctness of each approach (1–2 paragraphs each). 3. Analyze the time complexities (i.e., how long they take depending on the length of the list) of each algorithm (1–2 paragraphs each). You have 7 days to submit your solution to the above questions. Adapted: Evaluate and compare two different algorithmic approaches to sort a list of numbers by following these three steps: 1. Ask ChatGPT to generate an algorithm using Python code to sort a list of numbers. Provide the output. In 1–2 paragraphs, explain whether you think the code is correct. Include examples of using the algorithm. 2. Ask ChatGPT to generate a more efficient algorithm using Python code to sort a list of numbers. Provide the output. In 1–2 paragraphs, explain whether you think the code is correct. Include examples of using the algorithm. 3. Ask ChatGPT to analyze the time complexity of the algorithms (i.e., how long they take depending on the length of the list). Provide the output. In 1–2 paragraphs, explain whether you agree with the output. You have 7 days to submit responses to the above questions. 3.2.4. Preference for assessment adaptation We used a scenario-based design to assess preferences with two different assessment scenarios (essay and coding). Table 3 shows the assessment prompts that were used. After seeing both the original and adapted assessment prompt for each context, participants were asked to choose between the original prompt, adapted prompt, or indicate no preference between the two: “Assuming ChatGPT is available, which assessment do you prefer?” We also asked educators to predict what students would prefer, and vice versa: “Assuming ChatGPT is available, which scenario do you think students (educators) prefer?” 3.2.5. Understanding assessment adaptation preferences After indicating their assessment preference for each assessment type (first essay and then coding), participants were asked: “Please explain why you chose the preference responses above.” We coded these open-ended responses and identified themes using the method explained in the analytic approach. Moreover, to unpack assessment adaptation preferences quantitatively, participants rated each assessment using the established dimensions in Table 1 ( Huber et al., 2024) to understand how generative AI and assessment adaptation were perceived to affect assessment quality. First, participants read the original prompt and answered: “Consider the assessment prompt prior to the availability of generative AI tools, such as ChatGPT. To what extent does this assessment ensure each design assessment dimension?” Participants rated the dimensions on a 5-point scale: None, Low, Medium, High, or Not Sure. We excluded “Not Sure” in the analysis. Then, participants were instructed, “Now consider the same assessment prompt again but in today's context when generative AI tools, such as ChatGPT, are widely available (i.e., students have equal access to the tool). To what extent does this assessment ensure each design assessment dimension?” They once again rated the dimensions in Table 1 on the same scale. Finally, participants were shown the adapted version of the assessment prompt and instructed to “consider an adapted version of the assessment prompt, given today when generative AI tools, such as ChatGPT, are widely available. To what extent does this assessment ensure each design assessment dimension?” For a third time, participants rated the dimensions on the same scale. 3.2.6. Perceived importance of assessment quality dimensions We measured the perceived importance of the assessment dimensions in Table 1 using a Likert-style question: “How important for the quality of an assessment do you consider each of these dimensions to be?” Respondents rated each dimension on a 5-point scale from ‘Not at all important’ to ‘Extremely important’. 3.3. Analytic approach We utilized a multi-stage, mixed-method analytic approach that combined quantitative and qualitative analyses. The quantitative data from this study were analyzed using common descriptive, correlational, and regression approaches in R. The focus of these analyses was to examine the differences between educators and students and, in some cases, to examine variations between respondents in different countries. For the qualitative analysis of open-ended responses, we used a thematic coding approach for each question. We developed codebooks with the help of GPT-4, carefully validated by the research team, and then manually coded responses. Recent work has tested the efficacy of GPT-4 for qualitative coding and found positive results ( Zambrano et al., 2023). We prompted ChatGPT with the Advanced Data Analysis Beta plugin to find themes in the responses that were uploaded. We also provided context about the research design and goals in the prompt. We requested that each theme be supplemented by examples from the responses. To check the reliability of themes across regions and repetitions, we had researchers in Australia, Cyprus, and the US conduct the thematic prompting three times each. 1 We aggregated the results, which differed only slightly, to obtain a summary of themes. Due to data use restrictions, we could only use GPT with responses from Cyprus and the US. For the Australian responses, two independent members of the research team who were unaware of the GPT-aided codebook manually created a thematic codebook from scratch. The manual coding process resulted in a codebook that was well-aligned with the machine-generated themes: for the two open-ended questions that were analyzed in this manner, the human raters identified 5 out of 6 and 6 out of 6 themes from the GPT-aided codebook. We used all six themes for each question for the final manual coding of the responses. 4. Results 4.1. Awareness and uses of generative AI To position and compare the three samples we collected in terms of their familiarity with generative AI, Table 4 shows how aware educators and students were of ChatGPT, and how they tended to use it. We found that educators and students in our sample were generally aware of ChatGPT (or similar generative AI tools), except for students in Cyprus, who reported lower levels of awareness (42%;). We also found that a remarkable number of educators in our sample were using ChatGPT or similar tools frequently for research, professional work, and fun. Many of the students in Australia and the US, but not Cyprus, were also regularly using ChatGPT for coursework, research, professional work, and fun. Table 4. Awareness and uses of ChatGPT among students and educators by country. Sample Awareness (%) Use Daily/Weekly for (%) Coursework Research Professional Work Fun Educators 100 7 20 28 22  Australia 100 7 17 31 28  Cyprus 100 9 20 30 15  USA 100 0 30 10 40 Students 74 19 18 20 16  Australia 97 29 28 33 25  Cyprus 42 6 5 5 6  USA 98 24 14 12 14 Students' awareness and aggregate use of ChatGPT were not associated with their age, degree type, or the year in their program (awareness:,; use:,). Likewise, educators' awareness and aggregate use of ChatGPT were not associated with how many years they had been teaching (awareness:,; use:,). 4.2. Expected impact of generative AI on assessments Students and educators across the three samples reported similar expectations about the impact that generative AI tools on different types of assessment ( Fig. 1). Educators generally rated coding assignments and essay prompts as the two most impacted assessments. These were also rated as strongly impacted by students along with short-answer and multiple-choice questions. The types of assessment expected to be most impacted were the ones that require written inputs and have a clear (set of) correct solution(s): for example, short answers to questions, mathematical proofs, computer code, and multiple-choice answers. In contrast, educators and students expected assignments that require real-time presentation (in-person or online) to be impacted the least. Students in the Cypriot sample appeared to be unsure how assessments would be impacted, rating all of them as “moderately impacted” (3 on the 1–5 scale) in Fig. 1. This result may be related to their lower level of awareness and engagement with ChatGPT. 4.3. Expected student use of generative AI in assessments Given that both educators and students in our sample believed that essay-style and coding-style assignments are most impacted by generative AI, we examined how they thought that students would use tools like ChatGPT to complete assessments. In particular, educators and students wrote about how they expected students might use generative AI to complete the original version of each prompt in Table 3. Thematic coding of all open-ended responses revealed a set of expected approaches that did not vary much based on the assessment (essay and coding) and respondent group (educators and students). Table 5 shows the identified themes and their relative frequency. Table 5. Expected uses of generative AI: thematic analysis results with relative frequency of occurrence among educators and students. Themes for Essay Educators Students Themes for Coding Educators Students Content Generation 57% 23% Code Generation and Automation 62% 50% Research and Idea Generation 17% 33% Guidance, Validation, Error-Checking 21% 22% Rewording and Revision 11% 19% Academic Integrity/Ethics 6% 6% Academic Integrity/Ethics 3% 4% Learning/Thinking Inhibitor 6% 2% Learning/Thinking Inhibitor – 5% Learning Enhancement 4% 12% Learning Enhancement 14% 13% Efficiency and Time-saving – 5% Efficiency and Time-saving – 6% The identified themes covered a range of expectations, but also opportunities and concerns. While many educators and students expected students to use tools like ChatGPT to write an entire essay or write all of the code, this inclination was weaker among students who were more likely to think that their peers would use it to get help in the process (e.g., research and idea generation; rewording and revision; guidance, validation, error-checking). For example, a student in Cyprus wrote: “Students in order to complete this assessment might use AI tools to help them check their knowledge, detect and solve errors and finally give them the right feedback.” Another student in the US wrote: “Ask it to write something, and then modify it. Ask it to teach the user about the topic. Maybe ask it to make an essay better.” Academic integrity concerns were brought up a few times by both educators and students, but only students mentioned expected efficiency gains from using generative AI. For example, a student in Australia wrote: “Finding obscure resources quicker, reducing manual searching time. This is huge as many students work and study.” Both groups noted an opportunity for enhancing learning and only a small number raised concerns about interfering with learning and critical thinking. The exception was educators commenting on the essay assessment, who raised more concerns about learning and mostly expected students to use ChatGPT to generate the essay content. 4.4. Preference for assessment adaptation After respondents reported how students might use generative AI to answer the original prompt, we showed them an adapted version of the same assessment that intentionally incorporated generative AI into the process (see Table 3). We asked for their preference between the original and the adapted prompt (including an option for expressing indifference) for each assessment (essay and coding). The preference rating results for the full sample are shown in Fig. 2. Educators strongly preferred the adapted prompt: 67% would select it, while only 16% would select the original prompt (), and 17% were undecided. Students also preferred the adapted prompt but not as strongly: 41% would select the adapted prompt, while 33% would select the original (), and 26% were undecided. We also found adaptation preferences to be remarkably similar between the two types of assessment (), even though the assessments and their adaptation were distinct. Download: Download high-res image (73KB) Download: Download full-size image Fig. 2. Percentage of respondents who preferred the adapted assessment prompt, which incorporates generative AI into the task, themselves versus what they think the other stakeholder prefers, by assessment domain (panels). Standard error bars are shown. In addition, we asked educators and students to predict what they thought the preference of the other group would be (i.e., what educators thought students would prefer, and vice versa). This yielded an almost identical response to what is shown in Fig. 2, with one exception: for the essay assessment, 37% of educators thought that students would prefer the original prompt, while only 15% of educators preferred it themselves. Their prediction here is relatively accurate as 34% of student respondents preferred the original prompt. This pattern was observed for the essay but not the coding assessment. 4.5. Understanding assessment adaptation preferences We used a mixed-methods approach to better understand the reasoning behind educators' and students' preferences for and against assessment adaptation. We examined ratings of the assessment prompts on each of the six dimensions of assessment quality ( Table 1) to see how educators and students thought that adaptation affected the assessment. In addition, we thematically coded open-ended responses in which educators and students explained their preference ratings for each assessment. Quantitative results: Fig. 3 shows educator and student ratings of the assessment prompts on each of the six dimensions of assessment quality. Ratings for the essay and coding assessments were combined in the visualization because they showed the same pattern of results. The results show a consistent and statistically significant () pattern for most dimensions of assessment quality: the introduction of generative AI negatively affected ratings of the original prompt, but the adapted prompt recovered this loss in quality. This pattern was generally stronger among educator responses than student responses. Educators thought that the adapted prompt would provide an even better student experience than the original prompt before generative AI, while students rated the student experience to be similar. Download: Download high-res image (144KB) Download: Download full-size image Fig. 3. Educator and student ratings of assessment prompts along six dimensions of assessment quality. Ratings show the perceived impact of generative AI (ChatGPT) on the quality of the original prompt (Before vs. With ChatGPT) and the impact of modifying the assessment prompt (With ChatGPT vs. Adapted). The scale points are labeled None (1), Low (2), Medium (3), and High (4). Standard error bars are shown (hidden under the dot for students). Before we asked educators and students in our sample to judge the specific assignments by rating them on the six dimensions of assessment quality, we checked if they considered the dimensions to be important. We found that all dimensions of assessment quality in the framework were considered to be, on average, “very important” (corresponding to 4 on a 1–5 scale) by educators and students. Fig. 4 shows the average ratings, which were consistently higher among educators than students (). Educators rated academic integrity as slightly more important than the other dimensions (). Students rated Quality Feedback slightly higher than both Information Integrity () and Student Experience (). There was a small amount of variation between countries: students' importance ratings were a little lower in the Cypriot sample (), while educators' importance ratings were a little lower in the US sample (). Download: Download high-res image (108KB) Download: Download full-size image Fig. 4. Importance ratings for each dimension of assessment quality among educators and students. Standard error bars are shown. Qualitative results: Our thematic analysis of open-ended explanations separated responses based on the stated preference to understand reasons for that specific preference (original or adapted). Among those who preferred the original assessment prompt, students were more inclined to explain what they disliked about the adapted prompt. For example, both students and educators expressed concerns about academic integrity as a reason for preferring the original prompt, with one student writing: “Improving an essay written by AI is by no means academic research” (Student, Cyprus). Both students and educators noted convenience and the amount of time it takes as reasons for their preference for the original prompt, but they prioritized different elements. Students were more concerned with ease of completion (noting that they could use ChatGPT to complete the original prompt), while educators were more focused on the quality: e.g., “The focus should be on enhancing the information and making quality improvements rather than generating content entirely” (Educator, USA). Furthermore, both groups agreed on the importance of critical thinking, creativity, and original contributions in essay assessments. One student in the US sample wrote: “The original prompt will still let me create something from scratch if I choose to not use ChatGPT. Thus, it is more authentic and I will have a learning experience.” Highlighting a student's original contribution is important either way, as an educator in the Cypriot sample remarks: “I believe that a presentation of the essay is critical as educators will understand their comprehension of the AI-created information and the student's contribution to the quality of the essay.” For those who preferred the adapted prompt, common themes among educators and students were that the adapted prompt provided more opportunities for cognitive skill development, as well as ease and efficiency. However, there were a few differences between educators' and students' comments. Educators noted that the adapted prompt may make learning more fun and motivating: e.g., “They get to engage with a fun tool” (Educator, Australia). Students cited a preference for improvement over creation as a reason for their adapted prompt preference: e.g., “I prefer the adapted prompt, as a student, as it involves identifying weaknesses of written work and utilising MY OWN skills to refine the work into a superior piece” (Student, Australia). Students also cited being interested in advances in education as a reason: e.g., “As AI tools become more advanced, it's interesting to think about how to adapt the education system to enhance learning” (Student, USA). 5. Discussion In this study, we used a theoretically grounded instrument to understand educator and student attitudes and preferences about the impact of generative AI on assessments. We examined variation in attitudes across contexts, backgrounds, and prior experiences. Instead of finding variation between educators and students and across countries in line with varying educational approaches and cultural norms, we observed a surprising level of agreement across stakeholders and geographically distant institutions. An important exception is that students were more hesitant to endorse the adapted prompt than educators for reasons including a perceived loss in creativity and critical thinking. This highlights an important need for carefully designing and framing new assessment prompts in ways that center the process of learning, higher-order thinking, and authentic tasks. Our research also speaks to the awareness of different groups to the opportunities of new technologies. Economics research on cross-country productivity suggests that differences in adoption and diffusion play an important role ( Foster &amp; Rosenzweig, 2010). Our results highlight how perceptions of generative AI—whether they are accurately informed or not—can play a role in the adoption of new technologies and practices. 5.1. Implications for theory The implications of integrating tools like ChatGPT into higher education assessment practices encourage a re-evaluation of existing theoretical frameworks, particularly with regard to fostering higher-order thinking skills. As our findings have indicated, evaluation skills, which were once seldom explicitly cultivated in students and were even more rarely assessed, are now essential when interacting with LLMs. This prompts us as educators to embed evaluative components directly into revised assessments to facilitate the development of these critical skills. Bloom's revised taxonomy ( Anderson et al., 2001) has long been sprucing this idea with its emphasis on higher-order cognitive skills and can serve as a foundational reference point for these developments. Alongside this, a focus on assisting students in developing skills in evaluative judgment ( Tai et al., 2018) will gain further relevance. The new landscape of AI-infused education calls for a nuanced theory that delineates when and how AI-based adaptation of pedagogical and assessment strategies is warranted. There is also an open question about how generative AI will affect productivity, and whether it may accelerate income inequality and polarization in the labor market ( Frank et al., 2019; Acemoglu &amp; Restrepo, 2018). Preliminary evidence from OpenAI indicates that 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of large language models (LLMs), and 19% of workers may see at least 50% of their tasks impacted ( Eloundou et al., 2023). However, they also find that access to an LLM could accelerate the time it takes to complete 15% of all worker tasks, and 47–56% of all tasks when incorporating software and tooling built on top of LLMs. Concretely, in a recent randomized experiment with 5,179 customer support agents, access to LLMs was found to increase their average productivity by 14% ( Brynjolfsson et al., 2023). Our study contributes to the emerging body of literature on the integration of generative AI tools in higher education assessment by providing empirical insights into the perspectives of educators and students. It underscores the need for further theoretical development to understand how generative AI can be aligned with educational objectives without compromising academic integrity and the assessment of higher-order thinking skills. In particular, generative AI could augment existing assessment frameworks but also calls for caution in ensuring that these technologies are used in ways that enhance, rather than diminish, educational outcomes. 5.2. Implications for practice Our results highlight a general tendency for faculty to perceive a bigger impact of how assessments will change following the emergence of ChatGPT and a stronger preference for adapted assessment prompts compared to students. To the extent that LLMs might encourage greater student participation, or reduce barriers to engaging in learning activities, our results suggest that LLMs could improve the rate of human capital accumulation and influence the entire curriculum for university programs. For instance, generative AI could function as a personalized learning assistant that works every hour, every day, tailoring content and communication styles to the individual learner. As a result, learning could become more effective per hour spent. LLMs might also serve as a catalyst for reforming university curricula and assessments. By embedding LLMs in the whole educational process, educators and students can strategically be steered away from lower-order cognitive skills, such as knowledge recall and comprehension, to focus more on higher-order skills, such as evaluation and critical thinking. This transition is not merely pedagogical but also pragmatic since helping students develop higher-order thinking skills, such as evaluating machine-produced content, is necessary for them to be able to navigate the complexities of professional and personal life in the 21st century. By embedding LLMs into the curriculum, educators can create learning environments that encourage active engagement, collaboration, critical thinking, problem-solving, and evaluation, which are all essential skills for the future of work. The shift created by embedding LLMs into assessments could however engender a measure of resistance or discomfort among some students who might be unaccustomed to assessments that demand these adapted types of assessment tasks. For example, tasks requiring the evaluation of machine-generated content could be met with skepticism, as has been evident from the student's qualitative comments. It is crucial to recognize that this discomfort is less a critique of the method than it is a reflection of an educational system that has traditionally prioritized other forms of assessments. So since these higher-order skills are increasingly indispensable in contemporary work settings, integrating LLMs into both curricula and assessments, and especially assessments that measure critical and evaluative thinking skills (not just comprehension), becomes not just innovative but necessary. By doing so, educational institutions can better align learning outcomes with the real-world challenges and complexities that await students post-graduation in the labor market. Our study offers insights into the current attitudes and preferences of educators and students regarding the use of generative AI in assessments. There is a general openness to adapting assessment practices to incorporate these technologies, albeit with concerns about academic integrity and the preservation of critical thinking. Based on our findings, we recommend that educational institutions consider pilot projects or experiments to explore the effective integration of generative AI in assessments, with a focus on transparency, student engagement, and the development of guidelines to maintain academic standards. However, we acknowledge that these recommendations are based on the perceptions and attitudes captured in our survey and that actual implementation should be approached with careful consideration of the specific institutional context, resources, and educational goals. 5.3. Limitations Despite the novelty and significance of the current study, due to the fact that it provides an important early contribution to the literature on the use of and attitudes about generative AI, we also recognize some of its limitations. The first limitation pertains to the nature of the sampling methodology. Although we attempted to distribute the current survey as widely as possible, our samples were not random, as we purposely administered the questionnaires within our own institutions. The participants who chose to participate in the study did so voluntarily. It is therefore likely that response bias has been introduced in the data and that the respondents are not a truly representative sample from their corresponding populations. The sample is likely to over-represent higher-performing students and faculty who have a greater interest in generative AI and its applications. As a result, their responses might be upward biased and might convey different perspectives related to generative AI than non-responding participants. The second limitation of the study lies in the time point at which the data were collected. This sample reflects attitudes from a cross-section of respondents during the spring semester of 2023, which reflects the early days of generative AI, whose uses and visibility are continuing to grow each day. The impact and applications of AI are continuing to grow rapidly each day and our results serve as a snapshot of AI attitudes in relation to assessment at a point in time. This can serve as a baseline that facilitates useful future comparisons. In light of this context, it would be interesting to replicate this study in several months, or at least another year, to gauge how attitudes have evolved. A third limitation of the study lies in the variability of the academic majors of the participating students. Since the nature of the various academic disciplines vary significantly in relation to their interaction with generative AI (e.g. based on the characteristics of their course assignments and assessments), there is a possibility that students from some majors might be predisposed to more frequent use and acceptance of AI compared to students from other majors. Such differences in majors could potentially explain some of the variation observed in the data as well. A fourth limitation of the study relates to the linguistic aspect of languages and ChatGPT. On the one hand, ChatGPT tends to be slower and less linguistically accurate in Greek compared to English. On the other hand, it was not widely known at the time that ChatGPT can be used in languages other than English. Therefore, it is likely that some of the Cypriot participants might have not been aware that ChatGPT is available in Greek, which could also explain its low rates of usage among the students in that sample. Due to these limitations, and since this was not an experimental study, our data does not allow us to infer any causal relationships. While we have endeavored to control for confounding factors like demographics as much as possible, there could still be unmeasured heterogeneity that generates upward or downward bias. Nonetheless, the survey provides an important starting point/baseline related to ChatGPT use in the current time period and provides results that can help guide future research, curricula, assessment practices, and education policy among administrators. Moreover, these considerations highlight the need for future studies to complement our work by utilizing a more diverse and randomly selected representative sample, which would further broaden our understanding of the attitudes towards and use of generative AI in academia. 6. Conclusion As we witness the widespread adoption of generative AI tools like ChatGPT in higher education, our study confirms the necessity for a fundamental shift in assessment practices. Our international survey across three universities reveals a shared recognition among educators and students of the profound impact AI has on traditional assessments, particularly in essay writing and coding. Educators are in favor of adapting assessments to leverage AI's capabilities to enhance critical thinking, while students express mixed feelings, highlighting concerns over potential losses in creativity. This underscores the dual challenge we face: to harness AI's power to improve learning outcomes while also preserving and fostering students' creative and evaluative capacities. By prioritizing educational strategies that emphasize cognitive flexibility, ethical reasoning, and the nuanced interplay between technology and human values, we can equip students to navigate and thrive in an AI-driven world. As Markauskaite et al. (2022) underscore, our efforts must extend beyond technological know-how and encompass a comprehensive understanding of the complex dynamics that shape our AI-driven world. 7. Statements on open data and ethics The study was reviewed by the institutional ethics committee at each institution (Cornell University: IRB0147447; The University of Australia: HREC 2021/800; The University of Nicosia: UREC/2023/5). Informed consent was obtained from all participants and their privacy was maintained by protecting their personal information during the research process. Respondents knew that participation was voluntary and that they could withdraw from the study at any time. One of the three ethics approvals prohibits sharing data even if de-identified, except with investigators added to the ethics protocol. Researchers interested in the data should email the corresponding author. CRediT authorship contribution statement René F. Kizilcec: Writing – review &amp; editing, Writing – original draft, Visualization, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. Elaine Huber: Writing – review &amp; editing, Writing – original draft, Project administration, Methodology, Investigation, Formal analysis, Data curation, Conceptualization. Elena C. Papanastasiou: Writing – review &amp; editing, Methodology, Investigation, Formal analysis, Data curation. Andrew Cram: Writing – review &amp; editing, Investigation, Conceptualization. Christos A. Makridis: Writing – review &amp; editing, Methodology, Investigation. Adele Smolansky: Writing – review &amp; editing, Validation, Investigation, Formal analysis, Data curation, Conceptualization. Sandris Zeivots: Writing – review &amp; editing, Methodology, Investigation, Conceptualization. Corina Raduescu: Writing – review &amp; editing, Methodology, Investigation, Conceptualization."}
{"title": "Generative AI and future education: a review, theoretical ...", "content": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#main-content)\n\n**Official websites use .gov**\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n**Secure .gov websites use HTTPS**\nA **lock** (\n\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC\n\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPeerJ Comput Sci\n\n. 2024 Dec 3;10:e2105. doi: [10.7717/peerj-cs.2105](https://doi.org/10.7717/peerj-cs.2105)\n\n# Generative AI and future education: a review, theoretical validation, and authors’ perspective on challenges and solutions\n\n[Wali Khan Monib](https://pubmed.ncbi.nlm.nih.gov/?term=%22Monib%20WK%22%5BAuthor%5D)\n\n### Wali Khan Monib\n\n1Centre for Lifelong Learning, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\nFind articles by [Wali Khan Monib](https://pubmed.ncbi.nlm.nih.gov/?term=%22Monib%20WK%22%5BAuthor%5D)\n\n1, [Atika Qazi](https://pubmed.ncbi.nlm.nih.gov/?term=%22Qazi%20A%22%5BAuthor%5D)\n\n### Atika Qazi\n\n1Centre for Lifelong Learning, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\nFind articles by [Atika Qazi](https://pubmed.ncbi.nlm.nih.gov/?term=%22Qazi%20A%22%5BAuthor%5D)\n\n1,✉, [Rosyzie Anna Apong](https://pubmed.ncbi.nlm.nih.gov/?term=%22Apong%20RA%22%5BAuthor%5D)\n\n### Rosyzie Anna Apong\n\n2School of Digital Science, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\nFind articles by [Rosyzie Anna Apong](https://pubmed.ncbi.nlm.nih.gov/?term=%22Apong%20RA%22%5BAuthor%5D)\n\n2, [Mohammad Tazli Azizan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Azizan%20MT%22%5BAuthor%5D)\n\n### Mohammad Tazli Azizan\n\n1Centre for Lifelong Learning, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\nFind articles by [Mohammad Tazli Azizan](https://pubmed.ncbi.nlm.nih.gov/?term=%22Azizan%20MT%22%5BAuthor%5D)\n\n1, [Liyanage De Silva](https://pubmed.ncbi.nlm.nih.gov/?term=%22De%20Silva%20L%22%5BAuthor%5D)\n\n### Liyanage De Silva\n\n2School of Digital Science, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\n3Faculty of Integrated Technologies, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\nFind articles by [Liyanage De Silva](https://pubmed.ncbi.nlm.nih.gov/?term=%22De%20Silva%20L%22%5BAuthor%5D)\n\n2,3, [Hayati Yassin](https://pubmed.ncbi.nlm.nih.gov/?term=%22Yassin%20H%22%5BAuthor%5D)\n\n### Hayati Yassin\n\n3Faculty of Integrated Technologies, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\nFind articles by [Hayati Yassin](https://pubmed.ncbi.nlm.nih.gov/?term=%22Yassin%20H%22%5BAuthor%5D)\n\n3\n\nEditor: Valentina Emilia Balas\n\n- Author information\n- Article notes\n- Copyright and License information\n\n1Centre for Lifelong Learning, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\n2School of Digital Science, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\n3Faculty of Integrated Technologies, Universiti Brunei Darussalam, Gadong, Brunei Darussalam\n\n✉\n\nCorresponding author.\n\nReceived 2024 Jan 24; Accepted 2024 May 15; Collection date 2024.\n\n© 2024 Monib et al.\n\nThis is an open access article distributed under the terms of the [Creative Commons Attribution License](https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ Computer Science) and either DOI or URL of the article must be cited.\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC11622955  PMID: [39650462](https://pubmed.ncbi.nlm.nih.gov/39650462/)\n\n## Abstract\n\nGenerative AI (Gen AI), exemplified by ChatGPT, has witnessed a remarkable surge in popularity recently. This cutting-edge technology demonstrates an exceptional ability to produce human-like responses and engage in natural language conversations guided by context-appropriate prompts. However, its integration into education has become a subject of ongoing debate. This review examines the challenges of using Gen AI like ChatGPT in education and offers effective strategies. To retrieve relevant literature, a search of reputable databases was conducted, resulting in the inclusion of twenty-two publications. Using Atlas.ti, the analysis reflected six primary challenges with plagiarism as the most prevalent issue, closely followed by responsibility and accountability challenges. Concerns were also raised about privacy, data protection, safety, and security risks, as well as discrimination and bias. Additionally, there were challenges about the loss of soft skills and the risks of the digital divide. To address these challenges, a number of strategies were identified and subjected to critical evaluation to assess their practicality. Most of them were practical and align with the ethical and pedagogical theories. Within the prevalent concepts, “ChatGPT” emerged as the most frequent one, followed by “AI,” “student,” “research,” and “education,” highlighting a growing trend in educational discourse. Moreover, close collaboration was evident among the leading countries, all forming a single cluster, led by the United States. This comprehensive review provides implications, recommendations, and future prospects concerning the use of generative AI in education.\n\n**Keywords:** Gen AI, ChatGPT, Education, Challenges, Solutions, Theory, Authors’ perspective, UNESCO\n\n## Introduction\n\nArtificial Intelligence (AI) refers to the field where machines or computer programs are designed to perform tasks that typically require human intellect, such as language processing, learning, problem-solving, and decision-making ( [Dalalah & Dalalah, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24)). Within AI, Gen AI constitutes a subset designed to produce new content, such as text, images, audio, or other data formats, often in a creative or human-like fashion. At the forefront of AI research and development stands OpenAI, a research company dedicated to advancing AI technology ( [Yilmaz & Yilmaz, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-74)). Among OpenAI notable achievements is ChatGPT ( [Yilmaz & Yilmaz, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-74)), a prominent member of the generative pre-training transformer (GPT) model family and the largest publicly accessible language model ( [Dave, Athaluri & Singh, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-25)) through various web browsers, including Safari, Firefox, and Chrome, on desktop computers and mobile devices ( [Barrot, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7)).\n\nSince its launch in November 2022, ChatGPT has quickly gained immense popularity and become a prominent chatbot on the Internet ( [Barrot, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7)). Both ChatGPT and GPT-3 are notable examples of natural language processing (NLP) applications ( [Howell & Potgieter, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-33)). [Barrot (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7) highlights the AI tool stays current and well-informed through ongoing updates and _corpus_ expansions, with the latest iteration, GPT-4, introduced in March 2023, capable of processing 32,000 tokens concurrently.\n\nChatGPT utilizes advanced computing techniques and extensive data to establish connections between words and ideas, enabling it to comprehend prompts within their context. Powered by a robust large language model (LLM), this tool generates “human-like” responses that closely resemble human language on diverse topics ( [Barrot, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7); [Bewersdorff et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-9); [Currie, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-23)). ChatGPT relies on an extensive collection of statistical patterns and associations, rather than a conventional database, to produce context-specific and logically relevant responses ( [Dalalah & Dalalah, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24)). It utilizes unsupervised pre-training and supervised fine-tuning techniques to generate human-like responses to queries on various topics ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). Additionally, sophisticated chatbots utilize algorithms and predictive text to generate new content in response to users’ prompts ( [Sweeney, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-64)). The algorithm used in ChatGPT is evolutionary, meaning that the training data consists of large volumes of data with high velocity, heterogeneity, and variability characteristics ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). They further state that the adoption of chatbots by humans initially aimed at automation, but it quickly evolved to the augmentation of human tasks and the formation of hybrid teams, where humans and machines closely collaborate to enhance the execution of relatively simple tasks that made a significant and historically transformative development. However, its emergence and transformative nature have caused intense debate on the implications for educational practices, raising questions about the role of AI in shaping the future of teaching and learning. Acknowledging the rapid evolution of technology in education, UNESCO has issued a call for the responsible utilization of technology, emphasizing the need for governance and regulation to adapt to the rapid pace of technological change and prioritize quality education for all ( [Azoulay, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-5)). In this comprehensive review, we explore Gen AI like ChatGPT in education, particularly the challenges posed by such tools, and how to turn these challenges into opportunities for learning enhancement.\n\n### Gen AI technologies\n\nIn this section, we provide a concise overview of state-of-the-art Gen AI technologies employed for various purposes.\n\n#### GPT\n\nGPT, the Generative Pre-Trained Transformer series, developed by OpenAI, consists of neural language models proficient in sequential text generation ( [Shaik Vadla, Suresh & Viswanathan, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-57)). GPT was designed at predicting and completing human-generated text, finding utility in diverse applications like machine learning and text prediction ( [Roumeliotis & Tselikas, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-53)). The GPT series consists of models pre-trained on a blend of five datasets, including Common Crawl, WebText2, Books1, Books2, and Wikipedia, boasting an impressive parameter count of 175 billion ( [Shaik Vadla, Suresh & Viswanathan, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-57)). The development of GPT laid the foundation for ChatGPT ( [Roumeliotis & Tselikas, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-53)). According to [Yilmaz & Yilmaz (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-74), five versions of ChatGPT have been introduced to date: GPT-1, released in 2018 with 117 million parameters, performed relatively poorly compared to later models; GPT-2, released in 2019, improved significantly with 1.5 billion parameters and better language generation; GPT-3, released in 2020, further enhanced language generation with 175 billion parameters and a larger dataset. GPT-3.5 served as an intermediate model before the introduction of GPT-4, which exhibits broad knowledge and improved problem-solving capabilities for accurate strategies. Earlier versions of GPT were less advanced and did not fully represent the current capabilities of the model ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)).\n\n#### BART\n\nBidirectional and Auto-Regressive Transformers (BART), developed by Facebook AI, is an NLP pre-trained model that combines bidirectional and auto-regressive Transformer ( [Lewis et al., 2019](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-38)). It is a modified BERT with an emphasis on natural text generation ( [Alokla et al., 2022](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-2)) and generation tasks, such as text summarization, text generation, and language translation ( [Radanliev, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-47)). It combines an encoder and decoder, trained with extensive unlabeled data, to achieve state-of-the-art results ( [Venkataramana, Srividya & Cristin, 2022](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-68)). The encoder role is to map the input sequence into an intermediate representation, while the decoder converts the intermediate representation back into the original input space ( [Liu, Ju & Wang, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-39)). This architecture facilitates the model ability to grasp intricate relationships within the inputs. Its performance on various generation tasks positions it as a valuable tool, particularly for tasks requiring both understanding and generation of natural language ( [Chen et al., 2020](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-16)).\n\n#### LLaMA\n\nLarge Language Model Meta AI (LLaMA), unveiled by Meta AI in February 2023, represents a significant milestone in large language model development. Built on the transformer architecture ( [Radanliev, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-47)), LLaMA promises enhanced capabilities in language understanding and generation. It is explicitly designed for research purposes, specifically to evaluate and compare existing language models across various natural language processing tasks ( [Shaik Vadla, Suresh & Viswanathan, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-57)). It helps researchers advance their work, having conversation, and summarizing written materials ( [Belagatti, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-8)). It is trained across a range of parameters from 7 billion to 65 billion that encompasses diverse evaluation metrics and tasks ( [Shaik Vadla, Suresh & Viswanathan, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-57)), offering a holistic approach to assess and compare language model performance in NLP ( [Oralbekova et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-46)).\n\n#### T5\n\nAnother tool is T5 (Text-To-Text Transfer Transformer), an encoder-decoder transformer ( [Raffel et al., 2020](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-48)) utilized for transfer learning to produce a unified framework for multiple NLP tasks ( [Al-Qaraghuli & Jaafar, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-1)). T5 was introduced by Google and functions on two fronts: the encoder comprehends input text, discerning its semantics and word relationships, while the decoder formulates responses, crafting new content such as summaries, translations, or dataset labels ( [Shaik Vadla, Suresh & Viswanathan, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-57)). It has been used for tasks such as translation, text generation ( [Chomphooyod et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-17)), and summarization ( [Venkataramana, Srividya & Cristin, 2022](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-68)). It offers varied sizes, from small to T5-11b, for adaptable pre-training suited to diverse NLP tasks, making it versatile for text-based applications ( [Oralbekova et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-46)).\n\n#### BARD\n\nBayesian Adaptive Representations for Dialogue (BARD) is a substantial language model primarily targeting computational efficiency within transformer-based NLP models ( [Shaik Vadla, Suresh & Viswanathan, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-57)). Google BARD, launched on March 21, 2023, emerges as a direct competitor to ChatGPT ( [Moons & Van Bulck, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-43)). Developed with similar training method ( [Bridgelall, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-13)), it has the same aims as ChatGPT ( [Moons & Van Bulck, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-43)). The main distinguishing feature lies in its foundation on the LaMDA family of large language models ( [Moons & Van Bulck, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-43)). BARD offers cost-effectiveness, adaptability, and unique features like internet access for real-time information, giving it a competitive edge over ChatGPT in dialogue-based language models ( [Shaik Vadla, Suresh & Viswanathan, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-57)). This study reviews the challenges posed by Generative AI, with an emphasis on ChatGPT, within the context of education.\n\n### Gen AI usage in education\n\nThe integration of Gen AI in education is remarkably swift, surpassing the lengthy processes for validating new textbooks ( [Giannini, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31)). Recent advancements in Gen AI, exemplified by ChatGPT, have demonstrated the ability to generate highly convincing output closely resembling human-authored content ( [Currie, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-23); [Howell & Potgieter, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-33); [Májovský et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-44)). For example, as part of the GPT series, ChatGPT-3, has demonstrated its ability to autonomously generate credible academic article with minimal human input and GPT-4 can handle visual queries and possesses an impressive 100 trillion parameters ( [Barrot, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7)). By leveraging extensive text data, ChatGPT captures the nuances of human language, facilitating contextually relevant responses across diverse prompts and streamlining research article writing by providing direct answers and eliminating manual article searches ( [Dave, Athaluri & Singh, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-25)). Such Gen AI tools excel at tasks like essay generation, intricate question answering, pronoun-noun agreement, sentiment analysis ( [Sezgin, Sirrianni & Linwood, 2022](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-56)), text summarization, code generation, and even story creation ( [Howell & Potgieter, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-33)). However, the pervasive use of such tools raises concerns regarding the potential for learners to become overly dependent on it, resulting in a decline in essential soft skills. Moreover, it is essential to acknowledge that Gen AI tools may generate fraudulent content, which can not only mislead learners but also foster incorrect learning. For example, a study by [Májovský et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-44) revealed that the AI language model can produce fraudulent articles that closely mimic genuine scientific articles, exhibiting convincing word usage, sentence structure, and overall composition. Additionally, tools like ChatGPT, with access to open-access data, can inadvertently introduce biases and discrimination in the output, potentially impacting the learning process. They analyze large corpora from diverse sources such as Wikipedia and Reddit to generate grammatically accurate content ( [Sweeney, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-64)).Therefore, it is important to acknowledge that, in the absence of human oversight, there is a risk of misleading or inaccurate content ( [Stokel-Walker & Van Noorden, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-61)). It is noteworthy that tools like ChatGPT recognize the dual impact of technology in education, akin to the controversy surrounding calculators in the 1970s ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). They further state that it would be illogical to prohibit the use of calculators for students. Therefore, it is crucial for education to be finely attuned to address AI risks, considering both known and emerging concerns ( [Giannini, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31)). This comprehensive review aims to answer the following research question:\n\n**RQ1:** What are the challenges of using Gen AI like ChatGPT in education?\n\n**RQ2:** How can the challenges posed by Gen AI like ChatGPT in education be addressed?\n\n### Rationale and intended audience\n\nThis review provides crucial contributions to academic discourse by comprehensively exploring Gen AI in education. First, the review aims to synthesize existing knowledge and research in this area, providing a cohesive overview of the current state of Gen AI with a focused on ChatGPT research. By consolidating information, it enables researchers and scholars to gain a holistic understanding of challenges, reflections, and solutions related to integrating Gen AI in education. Furthermore, the synthesized solutions or strategies are critically evaluated in light of relevant theories and frameworks, offering insights for future Gen AI usage in educational settings. This aspect of the review is particularly valuable for academics and researchers seeking to establish a solid theoretical foundation for their work in the intersection of AI and education. Theoretical validation contributes to the establishment of a robust framework that guides future research and development in this dynamic field. Additionally, the review provides authors’ perspective on the solutions or strategies pertaining to the implementation of Gen AI in education. This perspective can be especially beneficial for educators, educational technologists, and policymakers, offering them valuable insights into potential practicality of solutions or strategies for effectively incorporating Gen AI into educational practices. This includes an assessment of the feasibility of applying the derived strategies in educational settings.\n\nThe intended audience for this comprehensive review encompasses a wide spectrum. It caters to researchers in Gen AI and education who seek a nuanced understanding of current implications of Gen AI in education. Educators and educational technologists will find the review valuable as it addresses challenges, and provide practical solutions of integrating Gen AI in education. Furthermore, policymakers and administrators can leverage the insights from the review to make informed decisions regarding the adoption of AI technologies such as ChatGPT in educational institutions. Lastly, learners interested in AI-driven learning will find the review valuable, offering insights into effectively using emerging technologies like ChatGPT to mitigate negative consequences.\n\n## Methodology\n\n### Literature search\n\nIn this comprehensive review, the literature search covered multiple reputable databases, including Emerald, Scopus, Sage, Springer, Taylor & Francis, IEEE, and ERIC. The search was limited to the title, abstract, and keywords of the publications. A comprehensive set of keywords was employed. The Boolean operators included “ChatGPT” AND (“education” OR “educational” OR “learning” OR “teaching” OR “classroom” OR “school” OR “university” OR “student” OR “learner” OR “teacher” OR “instructor” OR “academic” OR “teaching” OR “instruction”) AND (“challenges” OR “limitations” OR “obstacles” OR “cons” OR “drawbacks” OR “ethical considerations” OR “privacy” OR “data security” OR “bias” OR “fairness” OR “ethical implications” OR “legal implications” OR “equity” OR “accessibility”). However, the exclusion of databases beyond those listed may result in overlooking relevant literature. The search of specific keywords and Boolean operators may inadvertently exclude related studies. Additionally, the focus on challenges have limited the scope of the study, excluding studies exploring other aspects other than challenges.\n\n### Inclusion and exclusion\n\nWe included relevant literature written in English and published between 2022 and 2023 that specifically mentioned challenges, limitations, threats, and/or concerns related to Gen AI, ChatGPT usage in educational settings. To ensure a comprehensive review and capture all relevant insights, the search was not restricted to a specific document type. In addition, the UNESCO website was explored because it provides reliable, global, and up-to-date educational content, policy resources, insights into current trends, and guidance on educational technology. We excluded literature that did not focus on the challenges of ChatGPT in education and literature published in languages other than English. As a result, the final selection comprised ( _n_ = 22) publications including one notes, and two editorials. The evident quality appraisal of the selected publications is indicated by their retrieval from reputable sources as outlined in the literature search section, aligning with the comprehensive review approach.\n\n### Analysis\n\nIn this review, we utilized ATLAS.ti, a robust qualitative data analysis software, to efficiently manage and analyze the selected publications. We initiated by importing the chosen documents into the software, facilitating efficient coding and categorization. Thematic analysis, a qualitative method for non-numerical data, was employed, involving the identification of codes from the data which serve as categories for analysis ( [Roberts, Dowell & Nie, 2019](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-52)). Coding approach include inductive, starting from data to identify meaning, and deductive, where pre-existing ideas or concepts are applied to the data ( [Braun et al., 2019](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-12)). We followed the deductive analysis, where pre-existing ideas or concepts were applied based on prior knowledge and literature. This approach involves predetermining (at least some of) the codes before commencing the analysis ( [Wæraas, 2022](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-72)). This allowed us to effectively analyze and interpret the selected literature.\n\n## Result and discussion\n\nThis section reports the results and discussion of the selected literature.\n\n### Concepts in the analyzed literature\n\nThe analysis in [Fig. 1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#fig-1) reveals core concepts within the reviewed literature. Notably, “ChatGPT” emerged 2,520 times, and “AI” 1,767 times, indicating a significant trend in education. “Student” appeared 1,705 times, while “research” and “education” were mentioned 920 and 873 times, respectively. These frequencies underscore the central concepts of “ChatGPT” and its emphasis on AI, students, research, education, among others. Education needs to be finely attuned to the risks of AI, both the known risks and those only just coming into view ( [Giannini, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31)).\n\n#### Figure 1. Concept in the analyzed literature.\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/figure/fig-1/)\n\n### Countries collaboration\n\n[Figure 2](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#fig-2) illustrates an overlay visualization of the collaborative network among countries in research related to Gen AI, such as ChatGPT. The analysis involved co-authorship, with the unit of analysis being countries with a minimum of two documents, utilizing a full counting method. Of the 30 countries, eight met the threshold in the selected publications sourced from Scopus. In the visualization, circle size corresponds to document frequency, lines depict collaborations, and the thickness of the lines indicates the frequency of collaboration. As observed, close collaboration is evident among countries such as the United States, Australia, Germany, and India, Hong Kong, Netherlands, Oman, and the United Kingdom. Notably, all are clustered together in cluster 1, highlighting a significant gap due to the absence of collaboration with other regions.\n\n#### Figure 2. Top collaborating countries.\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/figure/fig-2/)\n\n#### RQ1. What are the challenges of using Gen AI like ChatGPT in education context?\n\nDeductive thematic analysis was conducted, resulting in six overarching challenges regarding the usage of Gen AI in education, see [Fig. 3](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#fig-3). Foremost among these concerns is the category of plagiarism, followed by responsibility and accountability. Concerns were also raised about privacy, data protection, safety, and security risks, as well as discrimination and bias. Additionally, there were concerns about the loss of soft skills and the risks of the digital divide.\n\n##### Figure 3. Main challenges related to Gen AI in education.\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/figure/fig-3/)\n\nThese concerns were found in higher education, education, language teaching, research and writing, assessment practices, among others. Despite, these concerns largely overlap across different studies, some variations were evident. In higher education, challenges and concerns included plagiarism, digital divide, fairness, responsibility, lack of knowledge and resources, accuracy, privacy, reliability, biases, and the dissemination of falsified information and to name a few. For instance, [Cotton, Cotton & Shipway (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-22) examined the opportunities and challenges of using ChatGPT in higher education, raising concerns regarding plagiarism and academic dishonesty. Similarly, [Tlili et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65) study revealed worries regarding cheating, honesty, reliability of responses, privacy, dissemination of misleading information, and potential manipulation. While some studies such as [Dalalah & Dalalah (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24) emphasized on the challenge of false positive and false negative detection in generative AI, with a focus on ChatGPT in education and academic research. They revealed significant issues with false detection.\n\nIn the realm of medical education such as health professions education (HPE), concerns were related to data collection, anonymity, privacy, consent, data ownership, security, bias, transparency, responsibility, autonomy, and beneficence ( [Masters, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-40)), while in research domain, concerns revolve around fabricated content like citations. For instance, in a study by [McGowan et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-41), ChatGPT generated thirty-five citations, with only two being genuine. Of the rest, 12 resembled real manuscripts but had errors, while 21 were a mix of existing manuscripts. In addition, non-peer-reviewed journals and online sources can contain inaccurate or outdated information, which Gen AI tools may present as established knowledge ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)). It is further stated that this can pose a risk of producing low-quality research article and diminishing the quality of scientific publications, which could, in turn, affect future AI training data. Novice researchers may particularly encounter obstacles when they lack an understanding of how it generates outputs ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). In addition, Gen AI like ChatGPT poses a significant challenge for the academic community by questioning output veracity and authorship authentication, undermining the current publishing hierarchy reliant on journal quality and reputation ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)).\n\nIn second language writing, the concerns were related to writing pedagogy, academic integrity, and loss of uniqueness in writing style. For example, [Barrot (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7) investigated the utilization of ChatGPT for second language writing, noting concerns among academics regarding its potential impact on writing pedagogy and academic integrity, despite acknowledging its potential as an effective tutor and source of language input. Furthermore, assessment practices were also affected, with concerns evident in this area. For instance, [Farazouli et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-28) investigated how AI chatbots, particularly ChatGPT, influence university teachers’ assessment practices, focusing on home examinations in undergraduate contexts. Findings revealed varying passing rates for chatbot-generated texts and suspicions regarding their authenticity, with teachers exhibiting patterns of downgrading when grading student-written texts.\n\nSome studies had a broader focus. For example, [Stahl & Eke (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-60) focused on the ethical dimensions surrounding generative conversational AI systems. Key issues highlighted included responsibility, inclusion, social cohesion, autonomy, safety, bias, accountability, and environmental impacts. Next, we discuss the reflections on Gen AI in education and strategies for addressing the identified concerns in detail.\n\n#### RQ2. How to address the challenges posed by Gen AI like ChatGPT in education?\n\nTo address research question 2, an in-depth discussion of the identified challenges along with reflections and solutions or strategies, is presented below. The authors may or may not have reported one or multiple reflections and/or solutions in the given tables.\n\n### Plagiarism\n\nPlagiarism, the most prevalent concern, poses a significant challenge regarding the utilization of Gen AI in education, as noted in 16 publications (see [Table 1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#table-1)). For instance, ChatGPT ability to produce original content that may evade detection by anti-plagiarism checkers, particularly when rephrased using tools like Quilbolt is a concern ( [Barrot, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7)). While ChatGPT can assist students in text creation, it can also lead to fraud when a text is generated by ChatGPT and presented as a learner’s own work ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). They assert that controlling learners’ plagiarism and cheating in assignments, theses, and dissertations becomes more challenging due to ChatGPT advanced capabilities, making it difficult for teachers to detect assignments generated by the tool.\n\n#### Table 1. Plagiarism.\n\n| Concern | Reflections | Solutions | References |\n| --- | --- | --- | --- |\n| Plagiarism | Plagiarism prevalenceAcademic fraudLack of originalityImpact on reviewUnrefereed sourcesPlagiarism detection issuePlagiarism tool limitationsResearch quality issuesPublishing problemsLegal and institutional challenges | Domain-specific AI systemsPlagiarism detectorsAI-powered plagiarism detectionAwareness and consequencesDeclarations of originalityDraft submissionsGuidelines for Gen AIStudent work monitoringAnti-cheating measures enforcement | [Barrot (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7), [Bom (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-10), [Cardon et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14), [Chan & Hu (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-81), [Choudhary & Pandita (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-18), [Cotton, Cotton & Shipway (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-22), [Dalalah & Dalalah (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24), [Dwivedi et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26), [Eke (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-27), [Farazouli et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-28), [Farrokhnia et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29), [Kasneci et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35), [Kooli (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36), [McGrath et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-42), [Stahl & Eke (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-60), [Tlili et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65) |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/table-1/)\n\nIn addition, the lack of originality may lead to adverse outcomes. For example, ChatGPT potential to generate persuasive but often inaccurate article could distort scientific facts and encourage plagiarism, challenging traditional review processes and reshaping how research results are verified ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). Instructors were reported about the potential increase in plagiarism and the added complexity of evaluating work ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14)). Institutions encounter challenges in detecting and penalizing fraud, with current strategies lacking legal validity and internal regulations often failing to address AI-generated content fraud ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). This creates disparities between penalized students and undetected ones, democratizing plagiarism ( [Farrokhnia et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29)). However, this scenario is expected to evolve as ChatGPT and its counterparts are likely to advance in the months and years ahead ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). Ways for mitigating plagiarism can include raising awareness in students regarding the consequences of Gen AI ( [Cotton, Cotton & Shipway, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-22)), developing domain-specific AI systems ( [Farazouli et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-28)), advancing existing plagiarism detection software ( [Kooli, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36)), setting explicit Gen AI usage guidelines, requesting pre-submission drafts for review from students, and closely monitoring learners’ work ( [Cotton, Cotton & Shipway, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-22)), using anti-plagiarism tools ( [Barrot, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7); [Cotton, Cotton & Shipway, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-22); [Eke, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-27); [Kooli, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36)), and incorporating or supplementing integrated AI detector with current anti-plagiarism software ( [Dalalah & Dalalah, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24); [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)).\n\n### Responsibility and accountability\n\n[Table 2](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#table-2) highlights responsibility and accountability concerns raised in 15 publications, which are pertinent to developers, facilitators, and users. However, a significant challenge arises from Gen AI developers often disclaiming responsibility for output such as text, images, audio, video, recommendations, predictions, and other type of data or information, particularly when violating national or international laws on copyright or intellectual property rights. For instance, OpenAI disclaims responsibility for intellectual property infringements stemming from ChatGPT use, presenting researchers with challenges in preventing such infringements ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). They further state that the issue arises during the generation process when the model produces answers that contain full sentences or paragraphs that it has seen in the training set leading to copyright infringement and plagiarism. The terms of use for AI tools often protect the companies creating these tools from being held responsible for any inaccuracies or unreliability in the results generated by the AI ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)). It is further stated that achieving accountability in such cases is difficult, especially when there are no well-defined governance rules outlining accountability requirements. Legal complexities, like copyright lawsuits such as Stability AI and Getty Images, raise questions about responsibility—whether it lies with the developer, user, or AI itself ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)). In this case, the UNESCO Recommendations on AI state that AI systems should not be granted legal personality and that AI actors bear ethical responsibility and liability for their roles in AI systems ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)). Therefore, AI developers, users, and policymakers need to collaborate and adapt existing legal frameworks to ensure that ownership, copyright, and other intellectual property concerns are appropriately addressed in the context of AI-generated works. For copyright protection, legal professionals with expertise in intellectual property and AI law are valuable resources for navigating these evolving legal landscapes. Protocols have to be developed to ensure sustainable, ethical, and respectful use of these tools, especially regarding copyright and sources ( [Vázquez-Cano et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-70)). Furthermore, there is a need for suitable oversight and accountability measures ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)). For content usage, transparency in seeking permission from original document authors during model training, adhering to copyright terms for open-source content, specifying terms of use for content generated by the model, and informing users about these policies are crucial strategies ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)). For journals, it is important to establish clear guidelines. For example, these may include checklist and mechanism for authors’ and reviewers’ responsibility ( [Bom, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-10)).\n\n#### Table 2. Responsibility and accountability.\n\n| Concern | Reflections | Solutions | References |\n| --- | --- | --- | --- |\n| Responsibility and accountability | Open AI disclaims responsibilityTraining data quality and copyright infringementResponsibility and accountability challengesLegal complexity of AI-generated contentThe risk of false informationSusceptibility to errorsDissemination of inaccurate information and misinformationPotential harm to usersUnnoticed errors in academic articlesInaccurate responsesFabricated content | Protocols for sustainable, ethical, and respectful usagePermission from original document authorsTerms of use for model-generated contentPolicy communication to usersInstitutions guidelines and policiesTransparency and permissionsAuthor responsibility guidelinesAccountabilityHigher AI and information literacyHuman verification/validationEmpirical data training testTransparency, versatility, and variabilitySuitable oversight and measures | [Bom (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-10), [Cardon et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14), [Dalalah & Dalalah (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24), [Dwivedi et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26), [Eke (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-27), [Farrokhnia et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29), [Kasneci et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35), [Kooli (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36), [Masters (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-40), [McGowan et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-41), [McGrath et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-42), [Rasul et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-83), [Stahl & Eke (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-60), [Tlili et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65), [UNESCO (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67) |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/table-2/)\n\nIn addition, there are concerns regarding the risk of false information, fabricated content, and false positives and false negatives. The concerns encompass the spread of false information, including fake information, misleading information, misinformation, or disinformation ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14); [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26); [McGowan et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-41)), fabricated content ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26); [McGowan et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-41)) and false positive and false negative ( [Dalalah & Dalalah, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24); [Kooli, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36)). These arise when the model is exposed to false or misleading information during training, causing it to generate inaccurate or unreliable responses ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)) as the quality of Gen AI outputs hinges on the quality of its training data. Gen AI like ChatGPT is susceptible to errors, including the dissemination of inaccurate information ( [Tlili et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65)) as it generates content without true comprehension, presenting both accurate and false information with equal confidence ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). Harmful behaviors that may be exhibited by ChatGPT like dishonesty, manipulation, and misinformation could potentially harm users, especially those with limited information and communication technology (ICT) knowledge, rather than providing them with assistance ( [Tlili et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65)). This becomes highly misleading, when users lack expertise or background knowledge in the field. As professionals increasingly use AI for their communication, they will likely encounter reduced tolerance for inaccuracies, misinformation, and other forms of unreliable communication ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14)). They further maintain that professionals must prioritize advanced information literacy and improved discernment for distinguishing between accurate and inaccurate information always fully upheld. In addition, Gen AI like ChatGPT ability to produce persuasive but often inaccurate content, leading to distortions of scientific facts and the spread of misinformation ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). For instance, when requested to provide references or citations, they often fabricated sources to support their output ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)). The inaccurate or unreliable responses can have significant consequences, especially when ChatGPT information is relied upon, such as in decision-making and information dissemination contexts ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). Therefore, designing a responsible chatbot ( [Tlili et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65)) that focuses on transparency, explainability, and variability ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)) with empirical data training ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)), is imperative. Additionally, users must utilize Gen AI like ChatGPT with responsibility and accountability, as previously mentioned, by prioritizing information literacy ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14); [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)), ethical considerations ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)), and the necessity for human verification and validation ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14); [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)), to mitigate the risk of manipulation, misinformation, and disinformation.\n\nFurthermore, noted are concerns about false negatives and false positives ( [Dalalah & Dalalah, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24); [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). This can impact academic integrity in plagiarism detection. False negatives refer to undetected plagiarism instances, while false positives involve incorrectly flagging legitimate content as plagiarism. For example, a student’s original work with a writing style that resembles that of AI-generated text could be wrongly labeled as plagiarism (false positive), or text that lacks originality may be flagged as original (false negative). In order to mitigate the risk of false information and/or fabricated content, implementing strategies such as raising awareness ( [Dalalah & Dalalah, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24)), advancing information literacy ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14)), conducting human verification ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14); [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)), and incorporating ethical reflections and empirical data training tests ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)).\n\n### Privacy, data protection, safety, and security risks\n\nUsing large language models in education raises privacy, data protection, safety and/or security concerns as indicated in [Table 3](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#table-3) with 13 studies. Gen AI like ChatGPT use of ML algorithms involves processing vast amounts of data, making it susceptible to cyberattacks. The concerns extend to potential data breaches, unauthorized access, and misuse of student data ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)). For example, it generates extensive data on students’ academic performance, learning preferences, and personal information ( [Suen & Hung, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-63)). This sensitive information can be at risk of theft, potentially resulting in security threats ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)), and risk of privacy and data protection ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)). Researchers reported concerns about personal data exposure during interactions with ChatGPT, potentially revealing sensitive details ( [Tlili et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65)). Thus, digital technologies can affect individuals in terms of privacy, autonomy, identity, and security along with broader societal consequences ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). Furthermore, the use of foundation models like ChatGPT poses unforeseen security concerns, such as the dissemination of dangerous content like instructions for creating harmful devices such as dirty bombs, and the potential facilitation of cyber threats through the tool programming capabilities, enabling the creation of viruses, malware, ransomware, spyware, and phishing campaigns ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)).\n\n#### Table 3. Privacy, data protection, safety, and security.\n\n| Concern | Reflections | Solutions | References |\n| --- | --- | --- | --- |\n| Privacy, data protection, safety, and/or security | Vulnerability to cyberattacksRisks of data breaches Unauthorized accessSensitive and personal Information exposurePrivacy and security Dangerous contentCyber threatsAccuracy of content | Responsible and ethical data usageRobust data privacy and security policies compliant with ethics and relevant national and international lawMandatory consent for transparent data practicesModern technologies for data protectionRegular security auditsData breach incident response planStaff education and awareness on data privacy and securityAge appropriateness | [Barrot (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7), [Cardon et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14), [Chan & Hu (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-81), [Dalalah & Dalalah (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24), [Dwivedi et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26), [Giannini (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31), [Kasneci et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35), [Kooli (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36), [Masters (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-40), [Stahl & Eke (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-60), [Tlili et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65), [UNESCO (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67) |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/table-3/)\n\nA series of measures should be implemented to ensure privacy and security encompassing emphasis placed on upholding national and international legal standards in data collection, use, sharing, storage, and deletion, along with the adoption of robust data protection frameworks and governance mechanisms ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)). Furthermore, implementing robust data privacy and security policies, guidelines, principles, and/or strategies that align with established ethical standards and laws ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35); [Tlili et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65)) is crucial. In addition, educators should independently evaluate AI applications and build the capacity to approve them for formal school use, rather than relying on corporate creators ( [Giannini, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31)). Ensuring responsible data usage ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26); [Tlili et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65)) and prioritizing transparency with students and families for data collection, storage, and usage are other important measures. Utilize robust measures including anonymization, secure infrastructures, encryption, and regular audits to safeguard data effectively and proactively identify vulnerabilities ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)). It is also essential to ensure age appropriateness for AI usage. Presently, the ChatGPT terms of use mandate that users must be a minimum of 13 years old, with individuals under the age of 18 necessitating the consent of their parent or legal guardian to access the services ( [OpenAI, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-45)). Promoting education and awareness among staff, including educators and students, about data privacy and security policies, regulations, ethical considerations, and best practices can be another important solution to data protection ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)). Lastly, Gen AI should be subjected to rigorous scrutiny based on these and other relevant criteria.\n\n### The digital divide\n\nIntegrating Gen AI like ChatGPT into education raises concerns about unequal access, leading to disparities including inclusion, equity, access, and fairness as depicted in [Table 4](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#table-4). The aspect of whether it causes a digital divide or helps prevent it is highlighted in 12 studies. While AI and digital technologies offer diverse knowledge systems, but if a few dominant AI models and platforms control our access to knowledge, we risk moving in the opposite direction ( [Giannini, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31)), concentrating wealth and power ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)). In other words, instead of increasing diversity and openness in knowledge systems, it might lead to a concentration of power and control in the hands of a few, limiting the available variety and diversity. For example, despite ChatGPT being a multilingual model ( [Choudhary & Pandita, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-18)), the variations in accuracy and nuances in language can cause inequity and unequal access among learners. In this case, some students may not benefit fully from ChatGPT due to language limitations or reduced accuracy, creating disparities in their educational experience. Researchers noted language differences in queries, highlighting that even with accurate translation, responses often reflect U.S.-centric perspectives ( [Rettberg, 2022](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-51)). While efforts to address multilingual fairness are underway, there remains ample room for improvement in this respect ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)). When employing AI tools in education, UNESCO insists on prioritizing inclusion, equity, quality, and safety ( [Giannini, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31)). Blocking access to Gen AI like ChatGPT can also result in a digital divide and is not advisable.\n\n#### Table 4. The digital divide.\n\n| Concern | Reflections | Solutions | References |\n| --- | --- | --- | --- |\n| Digital divide: Inclusion, equity, access, and fairness | Risk of inequality in AI accessPotential concentration of powerLanguage-related inequityWorsening educational disparities | Dialectical pedagogy with Gen AIIndividualized dialogue support in ill-defined domainsContinues update and expansion,Increased access to information,Support for underserved learnersPolicies provision for Gen AI usageResource allocationAI models for the benefit of allMultilingual proficiency and multicultural representationLearners with communication disabilityOpenness and optimismRelevance of pedagogical methods | [Cardon et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14), [Cotton, Cotton & Shipway (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-22), [Dwivedi et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26), [Giannini (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31), [Kasneci et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35), [Kocoń et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-82), [McGrath et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-42), [Rasul et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-83), [Stahl & Eke (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-60), [Tlili et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65), [UNESCO (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67), [Yildirim-Erbasli & Bulut (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-73) |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/table-4/)\n\nHowever, some publications reported that ChatGPT holds significant potential for providing anytime and anywhere, individualized support, and educational opportunities. [Giannini (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31) states that we must embrace openness and optimism toward AI potential to enhance, supplement, and enrich formal education. In language learning, for instance, less prepared students, through no fault of their own, can benefit from ChatGPT to enhance their writing skills ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14)). The authors emphasize the utilization of Gen AI, particularly ChatGPT, in facilitating personalized learning, tailored instruction, and learning pathways ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14); [Cotton, Cotton & Shipway, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-22); [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26); [Farrokhnia et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29); [Tlili et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65); [Vázquez-Cano et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-70); [Yildirim-Erbasli & Bulut, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-73)). For instance, ChatGPT usage personalized to benefit students with communication disabilities ( [Chaudhry et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-15)) by comprehending poorly written text, contributing to their language improvement. In addition, opportunities include accessibility of large language models like ChatGPT ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)), multilingual support ( [Choudhary & Pandita, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-18)), and text-to-speech and speech-to-text capabilities ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)). These opportunities and/or advantages extend to other areas such as writing support ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)), increased information access ( [Farrokhnia et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29)), and aiding individuals without in-person tutors ( [Su & Yang, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-62)).\n\nHowever, policies and regulations should be in place to ensure equal access to GenAI, promote multilingualism, facilitate boundary-free access, and address the needs of learners with economic problems, disabilities and others. For instance, policies may include subsidies, public access programs, government procurement incentives, grants, and other initiatives aimed at fostering inclusion, and equity in AI access ( [Stahl & Eke, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-60)). Furthermore, the promise of AI for all ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)) and continuous updates and expansion ( [Barrot, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7)) are central to promoting universal access. Equitable education on a broad basis ( [McGrath et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-42)) and equity-oriented means for educational entities ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)) further contribute to learning for all. In addition, it is imperative that educational chatbots adhere to user-centered design principles. Finally, governmental regulation of AI training, as advocated by [Kasneci et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35), can reinforce its equitable inclusiveness, collectively creating a more accessible and fair AI education.\n\n### Discrimination and biases\n\nDiscrimination and bias was another most notable concern, highlighted in 12 publications, see [Table 5](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#table-5). One of the concern is that the Gen AI models like ChatGPT may perpetuate existing biases, stereotypes, and discrimination in society as it is trained on large corpora of textual data freely available on the internet ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). This risk arises from biases inherent in the training data, which may manifest in the model outputs ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26); [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35); [Kooli, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36)). There have been extensive examples of racist, sexist, ableist, and other discriminatory language making its way into the model and is then generated as output ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). Gender bias, particularly, has been highlighted in prior research, with GPT-3 narratives reinforcing stereotypes about females, depicting them as less powerful and defining them by physical appearance and family roles ( [Ary et al., 2018](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-4)). These inadvertent biases and discriminatory elements can profoundly impact students’ well-being, leading to stress and anxiety, diminished academic performance due to discouragement, erosion of self-esteem and self-confidence, and a weakened sense of belonging in the learning environment. In addition, the biased trained data might reflect societal value judgments by promoting certain beliefs or opinions over others, potentially impacting the objectivity of educational content. Similarly, if the training data lacks representation from underrepresented groups, the tools might present biased information about their experiences or contributions. In these cases, the educational quality and equity might be compromised.\n\n#### Table 5. Discrimination and biases.\n\n| Theme | Reflections | Solutions | References |\n| --- | --- | --- | --- |\n| Discrimination and biases | Biased perpetuations/reflectionsImpact on students’ well-beingImpact on educational contentAlgorithm biasPotential of exploiting Vulnerable populationsLack of representation | Representative and diverse training dataContinuous bias evaluationFairness measures and bias correctionTransparent mechanisms Ongoing model updatesGuarding against data and algorithm biasBias detection and mitigation method | [Cardon et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14), [Choudhary & Pandita (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-18), [Dalalah & Dalalah (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24), [Dwivedi et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26), [Farrokhnia et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29), [Giannini (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31), [Kasneci et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35), [Kooli (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36), [Masters (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-40), [Stahl & Eke (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-60), [Tlili et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65), [UNESCO (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67) |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/table-5/)\n\nStakeholders need to be aware of these biases and work towards ensuring that AI tools like ChatGPT provide unbiased information to support students' learning and promote a well-rounded education. Thus, for the model to provide accurate and unbiased responses, it is imperative to use a high-quality dataset that is representative of the question being posed to it because any biases or inaccuracies in the data can be reflected in the model output ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). Other vital strategies include ensuring model fairness and mitigating biases through transparency ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35); [Masters, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-40)), training with diverse data, ongoing performance monitoring, implementing fairness measures, human oversight, providing educator training, and conducting regular expert-supervised updates ( [Kasneci et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35)).\n\n### Loss of soft skills\n\n[Table 6](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#table-6) highlights concerns about the excessive reliance on Gen AI like ChatGPT, potentially impeding the development of soft skills such as critical thinking, creativity, problem-solving, decision-making, reasoning, and/or meaningful face-to-face interactions across 11 studies. For example, relying too much on ChatGPT may undermine higher cognitive abilities such as creativity and problem-solving, diminishing motivation for independent work ( [Farrokhnia et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29)). This concern is heightened when students lack guidance on appropriate ChatGPT usage ( [Barrot, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7)) or engage in what [Dwivedi et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26) referred to as “blind usage.” While initial utilization of Gen AI models may enhance individual performance, prolonged reliance on AI has been associated with lower performance attributed to the loss of complementary skills ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14)). It can potentially undermine various cognitive abilities linked to literacy, including writing, understanding, and critical thinking ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)), critical thinking ( [Tlili et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65)) and creativity ( [Kooli, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36); [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)) and problem solving abilities ( [Kooli, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36)). Moreover, its excessive use can result in reduced opportunities for human learning ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)), and degradation of social interactions ( [UNESCO, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67)), such as teacher-student relationship ( [Farrokhnia et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29)).\n\n#### Table 6. Loss of soft skills.\n\n| Concern | Reflections | Solutions | References |\n| --- | --- | --- | --- |\n| Loss of Soft skills: Communication, problem-solving, creativity, decision-making, critical thinking, reasoning, and/or research skills | Reduced motivation for independent workRisk to cognitive abilitiesReduced opportunities for human learningImpact on (social) interactions | Monitoring language model usageEfficient human resource allocationInstructor roleRethinking instruction design and assessmentDigital technology-supported cognitive skills activitiesPerformance-based evaluation systemCreative and independent projectsCreative use of large language modelsNew ways of teachingVarying information resourcesHuman oversightAI literacy/awarenessInvesting in and promoting digital, media, and information literacy skills | [Barrot (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7), [Cardon et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14), [Chan & Hu (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-81), [Choudhary & Pandita (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-18), [Dwivedi et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26), [Farrokhnia et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-29), [Kasneci et al. (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-35), [Kooli (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-36), [Stahl & Eke (2024)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-60), [UNESCO (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-67), [Yildirim-Erbasli & Bulut (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-73) |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/table-6/)\n\nSimilar to that of digital divide, while some studies highlight concerns about excessive dependence on ChatGPT potentially hindering the development of cognitive skills, others reported positive effects. Therefore, we should maintain an open and positive outlook on how AI can enhance and complement the essential learning that occurs through interactions in the physical and social environments of formal education ( [Giannini, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31)). In other words, we should be hopeful and receptive to the idea that AI can contribute positively to education, provided that it is used safely and responsibly. For example, Gen AI, including ChatGPT, has been reported to stimulate critical thinking in students by presenting tailored sets of questions corresponding to their proficiency levels ( [Cotton, Cotton & Shipway, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-22)), decision making, and problem-solving and communication ( [Dalalah & Dalalah, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-24)). Through the development of customized interactive learning materials, Gen AI such as ChatGPT can foster critical thinking and problem-solving abilities ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). For example, instructors can leverage Gen AI to create personalized assignments that require critical thinking, problem-solving, and communication skills, such as group discussions, presentations, and interactive activities ( [Cotton, Cotton & Shipway, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-22)). Similarly, students could be encouraged to evaluate Gen AI responses and compare them to original content, thereby fostering critical thinking ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26); [Su & Yang, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-62)) as they need to think critically to ensure the accuracy of their writing ( [Su & Yang, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-62)).\n\nIn the context of written communication and language improvement, students can leverage Gen AI tools like ChatGPT to refine initial outlines, content, organization, and structural feedback, thereby enhancing language style, vocabulary, and grammar ( [Barrot, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-7)). In communication, the role of Gen AI can encompass various functions, serving as a tool, assistant, monitor, coach, or teammate ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14)). However, the concerns are that learners will be spoon-fed, and communication will be depersonalized ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14)). In addition, there can be resistance to change in teaching ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14)). Moreover, as AI advances in language abilities, it challenges our conceptions of what it means to be human and how we coexist with increasingly intelligent machines ( [Giannini, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-31)). However, at the same time, this indicates an inconsistency, underscoring the need for further empirical research to better understand the overall impact of Gen AI on cognitive skills and to identify effective strategies for its integration into education.\n\nIt is worth highlighting that while some Gen AI like ChatGPT does not demand extensive technical ICT proficiency, it heavily relies on critical thinking and question-asking skills for optimal performance ( [Tlili et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-65)). Without appropriate prompts, the results it generates can be misleading. In addition, it has ushered in fresh opportunities for interdisciplinary collaboration in academic research. Through its automation of language-related tasks, researchers from diverse fields can now collaborate with greater efficiency, potentially resulting in the emergence of novel research concepts, and methodologies, and a surge in innovation and breakthroughs within academic research ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)).\n\nThe strategies involve future professionals cultivating AI literacy in authenticity, accountability, and agency, with a focus on information literacy and communication reliability ( [Cardon et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-14)). They further state that instructors must consistently assess the effectiveness of Gen AI for diverse professional objectives, continually enhance their expertise in every aspect of AI literacy, and refrain from isolated Gen AI endeavors. Other recommendations that can be implemented include raising awareness of AI impact ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)), particularly about the limitations and vulnerabilities. Encouraging students to assess and provide feedback on ChatGPT responses to questions can also contribute to critical thinking ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)), and diversifying information sources, such as books and articles, can contribute to critical thinking. Furthermore, integrating critical thinking and problem-solving activities into the curriculum can help students develop these crucial skills. Educators should actively promote critical thinking when students engage with technology ( [Dwivedi et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-26)). Lastly, human expertise and teacher involvement should play a central role in reviewing, validating, and explaining AI-generated information to ensure accuracy, authenticity, and responsible use. These recommendations collectively foster a balanced and responsible usage of Gen AI in education while nurturing critical thinking and ethical practices.\n\n### Critical evaluation of the solutions: theories and authors’ perspective\n\nIn this section, we critically evaluated the synthesized strategies to the challenges posed by Gen AI (ChatGPT) in education. The synthesis (see, [Fig. 4](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#fig-4).) encompasses various concerns, including plagiarism followed by responsibility, accountability. Other concerns included the risk of false information, the digital divide; and privacy, data protection, safety, and security, discrimination and bias, and loss of soft skills. The extracted solutions were then assessed as displayed in [Table 7](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#table-7). The table consists of columns for challenges, solutions, practicality rating, theoretical validation, and authors’ perspective. The practicality rating indicates the feasibility or applicability of derived solutions in educational settings. The theoretical validation column shows assessment of the solutions against the established theories from the authors’ perspective. Three experts, two from the Center for Lifelong Learning and one from the School of Digital Science, assessed and validated the solutions. The category concerning plagiarism is evaluated through deontology, a theory associated with Kant, which prioritizes moral rules and duty over consequences ( [Anshari et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-3)). Deontology holds the normative ethical notion that actions are inherently right or wrong, significantly influencing decision-making approaches ( [Sheedy, 2024](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-58)). It focuses on duty and defines the morality of actions based on strict principles, categorizing them as obligatory, prohibited, or permissible ( [Banks, 2015](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-6); [Sandberg, 2013](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-54)). In deontological ideology, judgment relies on implicit obligations, rules, and responsibilities ( [Cohen, Pant & Sharp, 2001](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-20); [Turk & Avcilar, 2018](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-66)). A student who adheres to deontology could perform better academically by fulfilling his or her essential responsibility as a student ( [Jung, 2009](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-34)). The integration of justice and deontology ideologies enhances moral meaningfulness, which, in turn, fosters student citizenship behaviors and in-role performance, ultimately positively influencing academic achievement ( [Soto-Pérez, Ávila-Palet & Núñez-Ríos, 2022](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-59)). Ethical issues in AI are analyzed within this framework to provide insights for policy recommendations ( [Anshari et al., 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-3)).\n\n#### Figure 4. Synthesis of solutions for addressing emerged challenges.\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/figure/fig-4/)\n\n#### Table 7. Synthesis and critical evaluation.\n\n| No. | Challenges | Solutions | Practicality rating(H, P & M) | Theoretical validation | Authors’perspective |\n| --- | --- | --- | --- | --- | --- |\n| 1. | Plagiarism | 1 & 2 | P | Deontology | Supported |\n| 3 | H | Deontology | Supported |\n| 4 & 5 | P | Deontology | Supported |\n| 2. | Responsibility and accountability | 1, 3–5 | H | Deontology | Supported |\n| 2 | P | Deontology | Supported |\n| 3. | Privacy, data protection, safety and security | 1–6 | H | GDPR | Supported |\n| 4. | Discrimination and biases | 1 | P | Intersectionality theory | Supported depends on the availability of diverse and quality data and its effective use |\n| 2 | H | Intersectionality theory | Supported |\n| 3 & 4 | P | Intersectionality theory | Supported |\n| 5. | Loss of soft skills | 1 | H | Deontology | Supported |\n| 2 | P | Social constructivism | Supported with the need for certain modifications to the curriculum |\n| 3 | H | Social constructivism | Supported with the requirement for an investment in technology infrastructure |\n| 4 & 5 | H | Connectivism | Support |\n| 6. | Digital divide | 1 & 6 | H | UDL | Support |\n| 2 | P | UDL | Supported |\n| 3 | P | UDL | Supported though careful consideration and adaptation for diverse user needs are required |\n| 4 | M | UDL | Supported with appropriate efforts and right resources |\n| 5 | M | UDL | Supported depends on government and organizational capabilities and coordination levels |\n\n[Open in a new tab](https://pmc.ncbi.nlm.nih.gov/table/table-7/)\n\n**Note:**\n\nH, Highly Practical; P, Practical; M, Moderately Practical.\n\nIn the category of plagiarism, solutions 3 was rated as highly practical, while solutions 1, 2, 4, and 5 were deemed practical. The strategies, developing domain-specific Gen AI and advancing existing plagiarism detection software to address plagiarism in various fields reflects the duty to maintain truthfulness and respect for intellectual property. Setting explicit guidelines for Gen AI usage is another strategy for the responsible use of AI, which underscores the importance of providing ethical guidance and ensuring adherence to academic integrity principles. The strategy, closely monitoring learners work align with the duty to verify the originality of work and promote honesty among learners. While monitoring is practical for ensuring academic integrity, it must be conducted with respect for privacy and individual rights, balancing the duty of monitoring with ethical considerations. Incorporating automated AI detectors with current anti-plagiarism software, reinforces the commitment to uphold ethical standards within educational contexts. These strategies prioritize the duty to support academic honesty and ethical conduct while addressing the issue of plagiarism.\n\nRegarding responsibility and accountability, solutions 1, 3, 4, and 5 were considered highly practical, and solution 2 was rated practical. The strategy, developing protocols to ensure sustainable, responsible, and respectful use of AI tools underlines the obligation to act ethically and responsibly. Collaborating with AI and intellectual property (IP) law experts to navigate legal landscapes demonstrates a commitment to following the rules and laws, aligning with deontological principles. Additionally, seeking permission from original document authors for content usage and adhering to copyright terms for open-source content strategies reflect the ethical duty to respect the rights of content creators. Specifying terms of use for AI-generated content and informing users about these terms illustrate a commitment to transparency and accountability, which are essential elements of ethical responsibility. These strategies uphold deontological principles by prioritizing honesty, respect, and ethical duty in the context of Gen AI tools development and usage.\n\nThe category pertains to privacy, data protection, safety, and security, with the solutions evaluated in alignment with the European Union General Data Protection Regulation (GDPR) ( [Bowen, 2021](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-11); [Gautam & Jahankhani, 2021](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-30)). All strategies (1–6) were rated as highly practical. The solution emphasizes the importance of upholding national and international legal standards in data collection, use, sharing, and storage, ensuring compliance with GDPR requirements for lawful data processing ( [Gautam & Jahankhani, 2021](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-30)). The adoption of robust data protection frameworks and governance mechanisms that align with ethical standards and laws reflects the GDPR emphasis on the need for safeguards in the processing of data. Moreover, ensuring responsible data usage and prioritizing transparency with users align with GDPR principles, highlighting the importance of transparency in data processing, as stated by [Schneider & Xhafa (2022)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-55). Furthermore, conducting regular audits of data privacy and security measures is essential, along with promoting education among users about data privacy and security to guide the utilization of Gen AI reflects GDPR emphasis on ensuring the security and integrity of personal data and transparency and accountability. Ensuring age appropriateness for AI usage can be an effective strategy. Implementing age-appropriate restrictions is essential for AI developers to uphold legal compliance, prevent access to their personal data, promote responsible use of AI systems, and build trust with users and stakeholders.\n\nThe category of discrimination and biases is evaluated with Intersectionality theory. This theory, introduced by Kimberlé Crenshaw, acknowledges individuals’ multiple intersecting social identities ( _e.g_., race, gender, class, disability, religion, age) that influence their experiences ( [Chowdhury & Okazaki, 2020](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-19)). Solution 2 is rated as highly practical, while the remaining solutions 1, 3, and 4 are considered practical. To ensure that Gen AI systems produce accurate and unbiased output, training the models with high-quality, diverse, and representative data is an essential solution. This strategy aligns with Intersectionality theory, recognizing that individuals with intersecting identities may have unique experiences that should be reflected in the data. This solution addresses biases associated with social identities, making it less likely for Gen AI systems trained on such datasets to perpetuate biases. Additionally, providing transparent mechanisms are crucial for ensuring openness and clarity in how Gen AI makes decisions, operates, and generates outputs. This makes the processes and decision-making mechanisms understandable and interpretable to humans. Ongoing performance monitoring is also necessary to ensure that Gen AI remains aligned with its intended objectives and helps to detect and correct any emerging biases. Furthermore, regular expert-supervised updates are crucial to keeping the Gen AI up-to-date. These updates ensure its continued relevance and accuracy, enabling it to adapt to changing circumstances and evolving user needs effectively.\n\nIn the loss of soft skills category, the solutions were evaluated considering Deontology, Social Constructivism and Connectivism theories, with solutions 1, 3–5 rated as highly practical while solution 2 received a practical rating. Social constructivism, a subset of constructivism, emphasizes learning through social interaction, distinguishing itself by placing greater emphasis on this aspect ( [Kukla, 2000](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-37)). This theory asserts that learners actively construct knowledge through interactions with others ( [Rannikmäe, Holbrook & Soobard, 2020](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-49); [Vygotsky, 1962](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-69)). In addition, Connectivism was employed, a learning theory emphasizing the significance of diverse information sources and networking in the learning process. The theory is built upon four foundational principles: autonomy (learner’s choice and control), connectedness (learning through connections with others and resources), diversity (exposure to a wide range of perspectives and ideas), and openness (access to information and knowledge sharing) ( [Corbett & Spinello, 2020](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-21)).\n\nAwareness regarding the risks of overreliance on Gen AI among users can be raised by experts, educators, and teachers through various communication channels, including digital platforms like websites and blogs, social media, podcasts, webinars, as well as face-to-face methods like workshops and seminars. This aligns with deontological principles emphasizing moral duties and obligations. The strategy, embracing new teaching methods and enhancing soft skills activities ( _e.g_., assigning analytical tasks), aligns with the constructivist principles of prioritizing a student-centered approach. While it may require adjustments to the curriculum, enhancing soft skills activities such as assigning analytical tasks, presenting complex decisions or dilemmas, and creating conflict scenarios is relatively straightforward to apply. Encouraging students to foster meaningful interaction with AI models, such as active engagement, asking insightful questions, receiving instant feedback, critically evaluating its responses, and to name a few can be another promising strategy. It adheres to the principles of social constructivism, which stress the importance of social interaction and the external environment, especially in the context of Gen AI, for knowledge formation ( [Vîșcu & Watkins, 2021](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-71)). It is highly valuable, as it enables users to interact and receive instant feedback around the clock, eliminating the constraints of traditional methods that require adherence to formal schedules, or contend with different time zones. Another reason is Gen AI can efficiently provide feedback and engage a large number of learners simultaneously, making education more accessible and cost-effective. For instance, consider a scenario where learners in a webinar pose questions to a teacher. In this traditional setup, the teacher can only address one question at a time, even if receiving multiple inquiries from participants. In contrast, Gen AI can handle a multitude of questions from numerous learners and respond to them at the same time. However, it depends on the availability of AI tools and platforms suitable for educational use and may require investment in technology infrastructure. Another strategy involves promoting AI literacy, emphasizing informed application, authenticity, accountability, and individual agency, particularly in writing. This is essential to educate users about how to use AI effectively and efficiently. We feel that Gen AI literacy plays a pivotal role in harnessing the potential of Gen AI, particularly, to elevate learners’ writing while preserving their unique writing styles and creativeness. Apart from this, Gen AI can help save valuable time by automating certain facets of the writing process, like grammar and spelling checks, thereby enabling learners and writers to concentrate on more creative and critical aspects. Diversify information sources ( _e.g_., use books and articles) can be another useful strategy. Connectivism theory emphasizes diverse information sources and networking reinforces this strategy. By leveraging a range of sources and connections, learners can access a wealth of perspectives and stay updated with the latest information, enriching their understanding in a rapidly changing world where knowledge can quickly become outdated.\n\nActivities involves assigning projects, exploring content in different formats, engaging in group discussions, and encouraging learners to present topics of interest.\n\nThe category of challenges pertains to the digital divide, encompassing exclusion, inequity, unequal access, and unfairness. To address these challenges, six strategies have been derived, evaluated in light of the Universal Design for Learning (UDL), with strategies 1 and 6 rated as highly practical, 2 and 3 as practical, and 4 and 5 as moderately practical. The UDL model is based on three main principles: providing multiple means of representation, action and expression, and engagement ( [Rao, 2023](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-50)). Essentially, UDL encourages educators to design accessible curricula and learning environments that minimize barriers to learning from the outset ( [Griful-Freixenet et al., 2020](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-32)). The strategies such as embracing Gen AI potential to enhance, supplement, and personalize learning resonates with UDL core principles of providing multiple means of representation and engagement. Customizing educational content with Gen AI accommodates diverse learners by enabling individualized, adaptive learning experiences. For instance, it generates interactive visual explanations for visual learners and detailed written instructions for those who prefer text-based guidance. Ensuring the benefit of all learners is imperative for promoting inclusivity, equity, and equal access to education, transcending barriers related to race, gender, socioeconomic status, or other characteristics. It is crucial for creating a more inclusive and effective learning environment. Additionally, the strategy which emphasis on user-centered design of Gen AI tools considering (social, emotional, cognitive, and pedagogical aspects), supports the UDL goal of fostering inclusive education. User-centered design can better cater to students with varying abilities, backgrounds, and learning preferences, making education more accessible and effective for all. Such enhancements can significantly improve the learning experience, rendering it more engaging, satisfying, and effective for learners, consequently leading to improved learning outcomes. For instance, chatbots equipped with natural language processing and sentiment analysis can discern when a student is struggling or frustrated and provide emotional support, encouragement, or resources tailored to the student’s emotional state.\n\nFurthermore, the strategy that focuses on improving multilingual and multicultural representation in models echoes UDL emphasis on providing multiple means of expression to meet the diverse needs of students. This promotes an equitable learning environment where all students can access content in their preferred language and see their cultural heritage acknowledged. It is essential to acknowledge that students may have diverse linguistic preferences and cultural backgrounds. An example of this is when learners see their own language, culture, and experiences reflected in the Gen AI content, they are more likely to connect with the material, leading to increased motivation, involvement, and learning.\n\nThe strategy establishing comprehensive policies and regulations can ensure equitable access to and responsible usage of Gen AI. The implementation of inclusive initiatives such as subsidies, public access programs, and government incentives can facilitate a multitude of representation methods. These initiatives aim to accommodate diverse learner needs, ensure equitable access to resources, and promote a more inclusive and supportive learning environment. For example, offering financial support for assistive technologies such as screen readers, speech-to-text software, and specialized devices for students with disabilities, coupled with the provision of affordable high-speed internet connections, empowers learners to access and engage with educational content more effectively. Moreover, controlling and regulating AI training data can help in achieving inclusiveness. While control and regulation are important, the practicality can vary depending on the governments’ and other organizations’ capabilities and the level of coordination with Gen AI developers. Overall, these strategies align with the Universal Design for Learning (UDL) framework, which aims to promote inclusivity and accessibility in education for all learners. In summary, while most of the strategies are consistent with existing theories, some adjustments may be necessary, and their applicability depends on specific contextual factors.\n\n## Implication, recommendations, and future research\n\nGen AI like ChatGPT is foreseen to have a lasting presence. While there are concerns and challenges associated with Gen AI usage in education, outright banning may not be the most effective strategy. Instead, a more balanced approach involving policies, regulations and guidance for its optimization should be considered, as it offers educational value by enabling personalized and interactive learning. Similarly, [Howell & Potgieter (2023)](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#ref-33) state that educators should embrace them as indispensable tools in teaching and learning, akin to modern workplace tools.\n\nThe integration of Gen AI in education has the potential to significantly impact cognitive skills such as communication, problem-solving, creativity, decision-making, critical thinking, reasoning, and research skills when appropriately employed. Educators and institutions should carefully consider how to leverage ChatGPT to enhance these skills in students, enriching students’ learning experiences, and offering guidance and essential resources. Moreover, there is a need for further empirical research to examine the effects of Gen AI usage, such as ChatGPT, on cognitive skills, as inconsistencies in reported findings were evident. Moreover, prioritizing inclusion, equity, and access is essential, providing equal opportunities for all students, including equitable access to large language models, especially for disadvantaged and marginalized students, and implementing mitigation strategies to ensure justice. Addressing discrimination and biases in ChatGPT use in education is vital to ensure fair learning opportunities for students. Privacy and security measures must be strengthened to safeguard sensitive student information and maintain the integrity of educational environments. Additionally, educators and institutions should implement effective strategies to detect and prevent plagiarism and copyright infringement when using ChatGPT in educational settings, promoting academic integrity and respecting intellectual property rights.\n\nFuture research in the integration of Gen AI in education should prioritize conducting longitudinal studies to assess its long-term impact on students’ learning. Additionally, there is a need for the development and implementation of ethical frameworks and guidelines specific to ChatGPT in educational settings, addressing concerns related to discrimination, privacy, plagiarism, and copyright infringement. Research should also focus on how to achieve accessibility and inclusivity for all students, particularly those with disabilities, and explore the role of teacher training programs in effectively leveraging AI tools. it is recommended that future research focus on empirical studies to test the strategies. Conducting empirical studies will validate and refine the solutions, providing valuable insights into their practical applicability. Understanding the implications of ChatGPT on student engagement and satisfaction will be crucial for its successful integration into education.\n\n## Limitations\n\nThis study has several limitations. Firstly, its reliance on a relatively small number of publications may restrict the breadth of perspectives considered. It is possible that our search strategy may have inadvertently excluded relevant literature. Additionally, our focus on literature published in English may have limited the diversity of perspectives represented in the findings and the reliance on sources like the UNESCO website may introduce biases. The focus solely on challenges associated with ChatGPT in education neglects broader applications of Gen AI that could offer valuable insights. Deductive analysis with specific themes from literature may have caused overlooking other important challenges and relevant solutions. In addition, the study focused mainly on challenges without thoroughly considering the potential benefits and positive impacts of integrating Gen AI into educational settings, indicating a need for further exploration in this regard. Hence, it is crucial to interpret the findings carefully. Future research is recommended to address these gaps and provide a more comprehensive understanding of the topic.\n\n## Conclusion\n\nThe integration of Gen AI into education has undoubtedly raised a number of concerns and challenges including plagiarism as the most prevalent concern, closely followed by responsibility and accountability. Other major concerns included discrimination and bias, and the loss of soft skills, the digital divide and privacy, data protection, safety, and security risks. Various strategies have been put forward to tackle these concerns, and each set of strategies has undergone rigorous evaluation using diverse theories and frameworks, including deontology, social constructivism, connectivism, intersectionality theory, UDL, and GDPR. Most of these strategies are practical and align with the ethical and pedagogical theories, addressing the challenges. However, the success of these strategies rely on their conscientious implementation.\n\n## Funding Statement\n\nThis work was supported by Universiti Brunei Darussalam. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\n\n## Additional Information and Declarations\n\n### Competing Interests\n\nThe authors declare that they have no competing interests.\n\n### Author Contributions\n\nWali Khan Monib conceived and designed the experiments, performed the experiments, analyzed the data, performed the computation work, prepared figures and/or tables, authored or reviewed drafts of the article, and approved the final draft.\n\nAtika Qazi conceived and designed the experiments, performed the experiments, analyzed the data, performed the computation work, prepared figures and/or tables, authored or reviewed drafts of the article, and approved the final draft.\n\nRosyzie Anna Apong performed the computation work, prepared figures and/or tables, authored or reviewed drafts of the article, and approved the final draft.\n\nMohammad Tazli Azizan performed the computation work, prepared figures and/or tables, authored or reviewed drafts of the article, and approved the final draft.\n\nLiyanage De Silva performed the computation work, prepared figures and/or tables, authored or reviewed drafts of the article, and approved the final draft.\n\nHayati Yassin performed the computation work, prepared figures and/or tables, authored or reviewed drafts of the article, and approved the final draft.\n\n### Data Availability\n\nThe following information was supplied regarding data availability:\n\nThis is a literature review and no new data were created or analyzed.\n\n## References\n\n- Al-Qaraghuli & Jaafar (2024).Al-Qaraghuli M, Jaafar OA. Arabic soft spelling correction with T5. Jordanian Journal of Computers and Information Technology (JJCIT) 2024;10(1):46–56. doi: 10.5455/jjcit.71-1699768515. \\[ [DOI](https://doi.org/10.5455/jjcit.71-1699768515)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Jordanian%20Journal%20of%20Computers%20and%20Information%20Technology%20(JJCIT)&title=Arabic%20soft%20spelling%20correction%20with%20T5&author=M%20Al-Qaraghuli&author=OA%20Jaafar&volume=10&issue=1&publication_year=2024&pages=46-56&doi=10.5455/jjcit.71-1699768515&)\\]\n- Alokla et al. (2022).Alokla A, Gad W, Nazih W, Aref M, Salem AB. Pseudocode generation from source code using the BART model. Mathematics. 2022;10(21):Article 3967. doi: 10.3390/math10213967. \\[ [DOI](https://doi.org/10.3390/math10213967)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Mathematics&title=Pseudocode%20generation%20from%20source%20code%20using%20the%20BART%20model&author=A%20Alokla&author=W%20Gad&author=W%20Nazih&author=M%20Aref&author=AB%20Salem&volume=10&issue=21&publication_year=2022&pages=Article%203967&doi=10.3390/math10213967&)\\]\n- Anshari et al. (2023).Anshari M, Hamdan M, Ahmad N, Ali E, Haidi H. COVID-19, artificial intelligence, ethical challenges and policy implications. AI & SOCIETY. 2023;38(2):707–720. doi: 10.1007/s00146-022-01471-6. \\[ [DOI](https://doi.org/10.1007/s00146-022-01471-6)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC9117835/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/35607368/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=AI%20&%20SOCIETY&title=COVID-19,%20artificial%20intelligence,%20ethical%20challenges%20and%20policy%20implications&author=M%20Anshari&author=M%20Hamdan&author=N%20Ahmad&author=E%20Ali&author=H%20Haidi&volume=38&issue=2&publication_year=2023&pages=707-720&pmid=35607368&doi=10.1007/s00146-022-01471-6&)\\]\n- Ary et al. (2018).Ary D, Jacobs LC, Irvine CKS, Walker D. Introduction to research in education. Boston, MA: Cengage Learning; 2018. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Introduction%20to%20research%20in%20education&author=D%20Ary&author=LC%20Jacobs&author=CKS%20Irvine&author=D%20Walker&publication_year=2018&)\\]\n- Azoulay (2023).Azoulay A. UNESCO issues urgent call for appropriate use of technology in education. 2023. [https://www.unesco.org/gem-report/en/articles/unesco-issues-urgent-call-appropriate-use-technology-education](https://www.unesco.org/gem-report/en/articles/unesco-issues-urgent-call-appropriate-use-technology-education) [https://www.unesco.org/gem-report/en/articles/unesco-issues-urgent-call-appropriate-use-technology-education](https://www.unesco.org/gem-report/en/articles/unesco-issues-urgent-call-appropriate-use-technology-education)\n- Banks (2015).Banks S. International Encyclopedia of the Social & Behavioral Sciences. Second Edition. Vol. 22. Netherlands: Elsevier; 2015. Social work ethics. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=International%20Encyclopedia%20of%20the%20Social%20&%20Behavioral%20Sciences&author=S%20Banks&publication_year=2015&)\\]\n- Barrot (2023).Barrot JS. Using ChatGPT for second language writing: pitfalls and potentials. Assessing Writing. 2023;57:Article 100745. doi: 10.1016/j.asw.2023.100745. \\[ [DOI](https://doi.org/10.1016/j.asw.2023.100745)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Assessing%20Writing&title=Using%20ChatGPT%20for%20second%20language%20writing:%20pitfalls%20and%20potentials&author=JS%20Barrot&volume=57&publication_year=2023&pages=Article%20100745&doi=10.1016/j.asw.2023.100745&)\\]\n- Belagatti (2023).Belagatti P. Unpacking Meta’s Llama 2: the next leap in generative AI. 2023. [https://www.singlestore.com/blog/a-complete-beginners-guide-to-llama2/](https://www.singlestore.com/blog/a-complete-beginners-guide-to-llama2/) [https://www.singlestore.com/blog/a-complete-beginners-guide-to-llama2/](https://www.singlestore.com/blog/a-complete-beginners-guide-to-llama2/) SingleStore.\n- Bewersdorff et al. (2023).Bewersdorff A, Zhai X, Roberts J, Nerdel C. Myths, mis-and preconceptions of artificial intelligence: a review of the literature. Computers and Education: Artificial Intelligence. 2023;4:100143. doi: 10.1016/j.caeai.2023.100143. \\[ [DOI](https://doi.org/10.1016/j.caeai.2023.100143)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Computers%20and%20Education:%20Artificial%20Intelligence&title=Myths,%20mis-and%20preconceptions%20of%20artificial%20intelligence:%20a%20review%20of%20the%20literature&author=A%20Bewersdorff&author=X%20Zhai&author=J%20Roberts&author=C%20Nerdel&volume=4&publication_year=2023&pages=100143&doi=10.1016/j.caeai.2023.100143&)\\]\n- Bom (2023).Bom HSH. Exploring the opportunities and challenges of ChatGPT in academic writing: a roundtable discussion. Nuclear Medicine and Molecular Imaging. 2023;57(4):165–167. doi: 10.1007/s13139-023-00809-2. \\[ [DOI](https://doi.org/10.1007/s13139-023-00809-2)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10359226/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37483875/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Nuclear%20Medicine%20and%20Molecular%20Imaging&title=Exploring%20the%20opportunities%20and%20challenges%20of%20ChatGPT%20in%20academic%20writing:%20a%20roundtable%20discussion&author=HSH%20Bom&volume=57&issue=4&publication_year=2023&pages=165-167&pmid=37483875&doi=10.1007/s13139-023-00809-2&)\\]\n- Bowen (2021).Bowen G. Strategy, Leadership, and AI in the Cyber Ecosystem. Netherlands: Elsevier; 2021. Digital leadership, ethics, and challenges; pp. 23–39. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Strategy,%20Leadership,%20and%20AI%20in%20the%20Cyber%20Ecosystem&author=G%20Bowen&publication_year=2021&)\\]\n- Braun et al. (2019).Braun V, Clarke V, Hayfield N, Terry G. Thematic analysis. In: Liamputtong P, editor. Handbook of Research Methods in Health Social Sciences. Singapore: Springer Singapore; 2019. pp. 843–860. \\[ [DOI](https://doi.org/10.1007/978-981-10-5251-4_103)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Handbook%20of%20Research%20Methods%20in%20Health%20Social%20Sciences&author=V%20Braun&author=V%20Clarke&author=N%20Hayfield&author=G%20Terry&publication_year=2019&)\\]\n- Bridgelall (2024).Bridgelall R. Unraveling the mysteries of AI chatbots. Artificial Intelligence Review. 2024;57(4):Article 89. doi: 10.1007/s10462-024-10720-7. \\[ [DOI](https://doi.org/10.1007/s10462-024-10720-7)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Artificial%20Intelligence%20Review&title=Unraveling%20the%20mysteries%20of%20AI%20chatbots&author=R%20Bridgelall&volume=57&issue=4&publication_year=2024&pages=Article%2089&doi=10.1007/s10462-024-10720-7&)\\]\n- Cardon et al. (2023).Cardon P, Fleischmann C, Aritz J, Logemann M, Heidewald J. The challenges and opportunities of AI-assisted writing: developing AI literacy for the AI age. Business and Professional Communication Quarterly. 2023;86(3):257–295. doi: 10.1177/23294906231176517. \\[ [DOI](https://doi.org/10.1177/23294906231176517)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Business%20and%20Professional%20Communication%20Quarterly&title=The%20challenges%20and%20opportunities%20of%20AI-assisted%20writing:%20developing%20AI%20literacy%20for%20the%20AI%20age&author=P%20Cardon&author=C%20Fleischmann&author=J%20Aritz&author=M%20Logemann&author=J%20Heidewald&volume=86&issue=3&publication_year=2023&pages=257-295&doi=10.1177/23294906231176517&)\\]\n- Chan & Hu (2023).Chan CKY, Hu W. Students’ voices on generative AI: perceptions, benefits, and challenges in higher education. International Journal of Educational Technology in Higher Education. 2023;20(1):43. doi: 10.1186/s41239-023-00411-8. \\[ [DOI](https://doi.org/10.1186/s41239-023-00411-8)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Educational%20Technology%20in%20Higher%20Education&title=Students%E2%80%99%20voices%20on%20generative%20AI:%20perceptions,%20benefits,%20and%20challenges%20in%20higher%20education&author=CKY%20Chan&author=W%20Hu&volume=20&issue=1&publication_year=2023&pages=43&doi=10.1186/s41239-023-00411-8&)\\]\n- Chaudhry et al. (2023).Chaudhry IS, Sarwary SAM, El Refae GA, Chabchoub H. Time to revisit existing student’s performance evaluation approach in higher education sector in a new era of ChatGPT—a case study. Cogent Education. 2023;10(1):Article 2210461. doi: 10.1080/2331186X.2023.2210461. \\[ [DOI](https://doi.org/10.1080/2331186X.2023.2210461)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Cogent%20Education&title=Time%20to%20revisit%20existing%20student%E2%80%99s%20performance%20evaluation%20approach%20in%20higher%20education%20sector%20in%20a%20new%20era%20of%20ChatGPT%E2%80%94a%20case%20study&author=IS%20Chaudhry&author=SAM%20Sarwary&author=GA%20El%20Refae&author=H%20Chabchoub&volume=10&issue=1&publication_year=2023&pages=Article%202210461&doi=10.1080/2331186X.2023.2210461&)\\]\n- Chen et al. (2020).Chen YC, Gan Z, Cheng Y, Liu J, Liu J. Distilling knowledge learned in BERT for text generation. Proceedings of the Annual Meeting of the Association for Computational Linguistics.2020. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Chen%20YC,%20Gan%20Z,%20Cheng%20Y,%20Liu%20J,%20Liu%20J.%20Distilling%20knowledge%20learned%20in%20BERT%20for%20text%20generation.%20Proceedings%20of%20the%20Annual%20Meeting%20of%20the%20Association%20for%20Computational%20Linguistics.2020.)\\]\n- Chomphooyod et al. (2023).Chomphooyod P, Suchato A, Tuaycharoen N, Punyabukkana P. English grammar multiple-choice question generation using Text-to-Text Transfer Transformer. Computers and Education: Artificial Intelligence. 2023;5:Article 100158. doi: 10.1016/j.caeai.2023.100158. \\[ [DOI](https://doi.org/10.1016/j.caeai.2023.100158)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Computers%20and%20Education:%20Artificial%20Intelligence&title=English%20grammar%20multiple-choice%20question%20generation%20using%20Text-to-Text%20Transfer%20Transformer&author=P%20Chomphooyod&author=A%20Suchato&author=N%20Tuaycharoen&author=P%20Punyabukkana&volume=5&publication_year=2023&pages=Article%20100158&doi=10.1016/j.caeai.2023.100158&)\\]\n- Choudhary & Pandita (2023).Choudhary H, Pandita D. Maximizing learning outcomes in the digital age: the role of microlearning for Gen Z. Development and Learning in Organizations: An International Journal. 2023;38(3):15. doi: 10.1108/DLO-02-2023-0038. \\[ [DOI](https://doi.org/10.1108/DLO-02-2023-0038)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Development%20and%20Learning%20in%20Organizations:%20An%20International%20Journal&title=Maximizing%20learning%20outcomes%20in%20the%20digital%20age:%20the%20role%20of%20microlearning%20for%20Gen%20Z&author=H%20Choudhary&author=D%20Pandita&volume=38&issue=3&publication_year=2023&pages=15&doi=10.1108/DLO-02-2023-0038&)\\]\n- Chowdhury & Okazaki (2020).Chowdhury T, Okazaki S. Mental and Behavioral Health of Immigrants in the United States. Netherlands: Elsevier; 2020. Intersectional complexities of South Asian Muslim Americans: implications for identity and mental health; pp. 179–200. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Mental%20and%20Behavioral%20Health%20of%20Immigrants%20in%20the%20United%20States&author=T%20Chowdhury&author=S%20Okazaki&publication_year=2020&)\\]\n- Cohen, Pant & Sharp (2001).Cohen JR, Pant LW, Sharp DJ. An examination of differences in ethical decision-making between Canadian business students and accounting professionals. Journal of Business Ethics. 2001;30(4):319–336. doi: 10.1023/A:1010745425675. \\[ [DOI](https://doi.org/10.1023/A:1010745425675)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Business%20Ethics&title=An%20examination%20of%20differences%20in%20ethical%20decision-making%20between%20Canadian%20business%20students%20and%20accounting%20professionals&author=JR%20Cohen&author=LW%20Pant&author=DJ%20Sharp&volume=30&issue=4&publication_year=2001&pages=319-336&doi=10.1023/A:1010745425675&)\\]\n- Corbett & Spinello (2020).Corbett F, Spinello E. Connectivism and leadership: harnessing a learning theory for the digital age to redefine leadership in the twenty-first century. Heliyon. 2020;6(1):e03250. doi: 10.1016/j.heliyon.2020.e03250. \\[ [DOI](https://doi.org/10.1016/j.heliyon.2020.e03250)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC6971348/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/31993523/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Heliyon&title=Connectivism%20and%20leadership:%20harnessing%20a%20learning%20theory%20for%20the%20digital%20age%20to%20redefine%20leadership%20in%20the%20twenty-first%20century&author=F%20Corbett&author=E%20Spinello&volume=6&issue=1&publication_year=2020&pages=e03250&pmid=31993523&doi=10.1016/j.heliyon.2020.e03250&)\\]\n- Cotton, Cotton & Shipway (2024).Cotton DR, Cotton PA, Shipway JR. Chatting and cheating: ensuring academic integrity in the era of ChatGPT. Innovations in Education and Teaching International. 2024;61(2):228–239. doi: 10.1080/14703297.2023.2190148. \\[ [DOI](https://doi.org/10.1080/14703297.2023.2190148)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Innovations%20in%20Education%20and%20Teaching%20International&title=Chatting%20and%20cheating:%20ensuring%20academic%20integrity%20in%20the%20era%20of%20ChatGPT&author=DR%20Cotton&author=PA%20Cotton&author=JR%20Shipway&volume=61&issue=2&publication_year=2024&pages=228-239&doi=10.1080/14703297.2023.2190148&)\\]\n- Currie (2023).Currie GM. Academic integrity and artificial intelligence: is ChatGPT hype, hero or heresy? Seminars in Nuclear Medicine. 2023;53(5):719–730. doi: 10.1053/j.semnuclmed.2023.04.008. \\[ [DOI](https://doi.org/10.1053/j.semnuclmed.2023.04.008)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37225599/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Seminars%20in%20Nuclear%20Medicine&title=Academic%20integrity%20and%20artificial%20intelligence:%20is%20ChatGPT%20hype,%20hero%20or%20heresy?&author=GM%20Currie&volume=53&issue=5&publication_year=2023&pages=719-730&pmid=37225599&doi=10.1053/j.semnuclmed.2023.04.008&)\\]\n- Dalalah & Dalalah (2023).Dalalah D, Dalalah OMA. The false positives and false negatives of generative AI detection tools in education and academic research: the case of ChatGPT. International Journal of Management Education. 2023;21(2):Article 100822. doi: 10.1016/j.ijme.2023.100822. \\[ [DOI](https://doi.org/10.1016/j.ijme.2023.100822)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Management%20Education&title=The%20false%20positives%20and%20false%20negatives%20of%20generative%20AI%20detection%20tools%20in%20education%20and%20academic%20research:%20the%20case%20of%20ChatGPT&author=D%20Dalalah&author=OMA%20Dalalah&volume=21&issue=2&publication_year=2023&pages=Article%20100822&doi=10.1016/j.ijme.2023.100822&)\\]\n- Dave, Athaluri & Singh (2023).Dave T, Athaluri SA, Singh S. ChatGPT in medicine: an overview of its applications, advantages, limitations, future prospects, and ethical considerations. Frontiers in Artificial Intelligence. 2023;6:1169595. doi: 10.3389/frai.2023.1169595. \\[ [DOI](https://doi.org/10.3389/frai.2023.1169595)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10192861/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37215063/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Frontiers%20in%20Artificial%20Intelligence&title=ChatGPT%20in%20medicine:%20an%20overview%20of%20its%20applications,%20advantages,%20limitations,%20future%20prospects,%20and%20ethical%20considerations&author=T%20Dave&author=SA%20Athaluri&author=S%20Singh&volume=6&publication_year=2023&pages=1169595&pmid=37215063&doi=10.3389/frai.2023.1169595&)\\]\n- Dwivedi et al. (2023).Dwivedi YK, Kshetri N, Hughes L, Slade EL, Jeyaraj A, Kar AK, Baabdullah AM, Koohang A, Raghavan V, Ahuja M. “So what if ChatGPT wrote it?” Multidisciplinary perspectives on opportunities, challenges and implications of generative conversational AI for research, practice and policy. International Journal of Information Management. 2023;71(2):102642. doi: 10.1016/j.ijinfomgt.2023.102642. \\[ [DOI](https://doi.org/10.1016/j.ijinfomgt.2023.102642)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Information%20Management&title=%E2%80%9CSo%20what%20if%20ChatGPT%20wrote%20it?%E2%80%9D%20Multidisciplinary%20perspectives%20on%20opportunities,%20challenges%20and%20implications%20of%20generative%20conversational%20AI%20for%20research,%20practice%20and%20policy&author=YK%20Dwivedi&author=N%20Kshetri&author=L%20Hughes&author=EL%20Slade&author=A%20Jeyaraj&volume=71&issue=2&publication_year=2023&pages=102642&doi=10.1016/j.ijinfomgt.2023.102642&)\\]\n- Eke (2023).Eke DO. ChatGPT and the rise of generative AI: threat to academic integrity? Journal of Responsible Technology. 2023;13:Article 100060. doi: 10.1016/j.jrt.2023.100060. \\[ [DOI](https://doi.org/10.1016/j.jrt.2023.100060)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Responsible%20Technology&title=ChatGPT%20and%20the%20rise%20of%20generative%20AI:%20threat%20to%20academic%20integrity?&author=DO%20Eke&volume=13&publication_year=2023&pages=Article%20100060&doi=10.1016/j.jrt.2023.100060&)\\]\n- Farazouli et al. (2023).Farazouli A, Cerratto-Pargman T, Bolander-Laksov K, McGrath C. Hello GPT! Goodbye home examination? An exploratory study of AI chatbots impact on university teachers’ assessment practices. Assessment and Evaluation in Higher Education. 2023;49:363–375. doi: 10.1080/02602938.2023.2241676. \\[ [DOI](https://doi.org/10.1080/02602938.2023.2241676)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Assessment%20and%20Evaluation%20in%20Higher%20Education&title=Hello%20GPT!%20Goodbye%20home%20examination?%20An%20exploratory%20study%20of%20AI%20chatbots%20impact%20on%20university%20teachers%E2%80%99%20assessment%20practices&author=A%20Farazouli&author=T%20Cerratto-Pargman&author=K%20Bolander-Laksov&author=C%20McGrath&volume=49&publication_year=2023&pages=363-375&doi=10.1080/02602938.2023.2241676&)\\]\n- Farrokhnia et al. (2023).Farrokhnia M, Banihashem SK, Noroozi O, Wals A. A SWOT analysis of ChatGPT: implications for educational practice and research. Innovations in Education and Teaching International. 2023;61(3):460–474. doi: 10.1080/14703297.2023.2195846. \\[ [DOI](https://doi.org/10.1080/14703297.2023.2195846)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Innovations%20in%20Education%20and%20Teaching%20International&title=A%20SWOT%20analysis%20of%20ChatGPT:%20implications%20for%20educational%20practice%20and%20research&author=M%20Farrokhnia&author=SK%20Banihashem&author=O%20Noroozi&author=A%20Wals&volume=61&issue=3&publication_year=2023&pages=460-474&doi=10.1080/14703297.2023.2195846&)\\]\n- Gautam & Jahankhani (2021).Gautam S, Jahankhani H. Strategy, Leadership, and AI in the Cyber Ecosystem. Netherlands: Elsevier; 2021. Balancing privacy and public benefit to detect and prevent fraud; pp. 137–157. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Strategy,%20Leadership,%20and%20AI%20in%20the%20Cyber%20Ecosystem&author=S%20Gautam&author=H%20Jahankhani&publication_year=2021&)\\]\n- Giannini (2023).Giannini S. Generative AI and the future of education. 2023. [https://teachertaskforce.org/sites/default/files/2023-07/2023\\_Giannini-UNESCO\\_Generative-AI-and-the-future-of-education\\_EN.pdf](https://teachertaskforce.org/sites/default/files/2023-07/2023_Giannini-UNESCO_Generative-AI-and-the-future-of-education_EN.pdf) [https://teachertaskforce.org/sites/default/files/2023-07/2023\\_Giannini-UNESCO\\_Generative-AI-and-the-future-of-education\\_EN.pdf](https://teachertaskforce.org/sites/default/files/2023-07/2023_Giannini-UNESCO_Generative-AI-and-the-future-of-education_EN.pdf)\n- Griful-Freixenet et al. (2020).Griful-Freixenet J, Struyven K, Vantieghem W, Gheyssens E. Exploring the interrelationship between Universal Design for Learning (UDL) and Differentiated Instruction (DI): a systematic review. Educational research review. 2020;29(2):100306. doi: 10.1016/j.edurev.2019.100306. \\[ [DOI](https://doi.org/10.1016/j.edurev.2019.100306)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Educational%20research%20review&title=Exploring%20the%20interrelationship%20between%20Universal%20Design%20for%20Learning%20(UDL)%20and%20Differentiated%20Instruction%20(DI):%20a%20systematic%20review&author=J%20Griful-Freixenet&author=K%20Struyven&author=W%20Vantieghem&author=E%20Gheyssens&volume=29&issue=2&publication_year=2020&pages=100306&doi=10.1016/j.edurev.2019.100306&)\\]\n- Howell & Potgieter (2023).Howell BE, Potgieter PH. What do telecommunications policy academics have to fear from GPT-3? Telecommunications Policy. 2023;47(7):102576. doi: 10.1016/j.telpol.2023.102576. \\[ [DOI](https://doi.org/10.1016/j.telpol.2023.102576)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Telecommunications%20Policy&title=What%20do%20telecommunications%20policy%20academics%20have%20to%20fear%20from%20GPT-3?&author=BE%20Howell&author=PH%20Potgieter&volume=47&issue=7&publication_year=2023&pages=102576&doi=10.1016/j.telpol.2023.102576&)\\]\n- Jung (2009).Jung I. Ethical judgments and behaviors: applying a multidimensional ethics scale to measuring ICT ethics of college students. Computers & Education. 2009;53(3):940–949. doi: 10.1016/j.compedu.2009.05.011. \\[ [DOI](https://doi.org/10.1016/j.compedu.2009.05.011)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Computers%20&%20Education&title=Ethical%20judgments%20and%20behaviors:%20applying%20a%20multidimensional%20ethics%20scale%20to%20measuring%20ICT%20ethics%20of%20college%20students&author=I%20Jung&volume=53&issue=3&publication_year=2009&pages=940-949&doi=10.1016/j.compedu.2009.05.011&)\\]\n- Kasneci et al. (2023).Kasneci E, Sessler K, Küchemann S, Bannert M, Dementieva D, Fischer F, Gasser U, Groh G, Günnemann S, Hüllermeier E, Krusche S, Kutyniok G, Michaeli T, Nerdel C, Pfeffer J, Poquet O, Sailer M, Schmidt A, Seidel T, Stadler M, Weller J, Kuhn J, Kasneci G. ChatGPT for good? On opportunities and challenges of large language models for education. Learning and Individual Differences. 2023;103:Article 102274. doi: 10.1016/j.lindif.2023.102274. \\[ [DOI](https://doi.org/10.1016/j.lindif.2023.102274)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Learning%20and%20Individual%20Differences&title=ChatGPT%20for%20good?%20On%20opportunities%20and%20challenges%20of%20large%20language%20models%20for%20education&author=E%20Kasneci&author=K%20Sessler&author=S%20K%C3%BCchemann&author=M%20Bannert&author=D%20Dementieva&volume=103&publication_year=2023&pages=Article%20102274&doi=10.1016/j.lindif.2023.102274&)\\]\n- Kocoń et al. (2023).Kocoń J, Cichecki I, Kaszyca O, Kochanek M, Szydło D, Baran J, Bielaniewicz J, Gruza M, Janz A, Kanclerz K. ChatGPT: jack of all trades, master of none. Information Fusion. 2023;99:101861. doi: 10.1016/j.inffus.2023.101861. \\[ [DOI](https://doi.org/10.1016/j.inffus.2023.101861)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Information%20Fusion&title=ChatGPT:%20jack%20of%20all%20trades,%20master%20of%20none&author=J%20Koco%C5%84&author=I%20Cichecki&author=O%20Kaszyca&author=M%20Kochanek&author=D%20Szyd%C5%82o&volume=99&publication_year=2023&pages=101861&doi=10.1016/j.inffus.2023.101861&)\\]\n- Kooli (2023).Kooli C. Chatbots in education and research: a critical examination of ethical implications and solutions. Sustainability (Switzerland) 2023;15(7):Article 5614. doi: 10.3390/su15075614. \\[ [DOI](https://doi.org/10.3390/su15075614)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Sustainability%20(Switzerland)&title=Chatbots%20in%20education%20and%20research:%20a%20critical%20examination%20of%20ethical%20implications%20and%20solutions&author=C%20Kooli&volume=15&issue=7&publication_year=2023&pages=Article%205614&doi=10.3390/su15075614&)\\]\n- Kukla (2000).Kukla A. Social constructivism and the philosophy of science. England, UK: Routledge; 2000. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Social%20constructivism%20and%20the%20philosophy%20of%20science&author=A%20Kukla&publication_year=2000&)\\]\n- Lewis et al. (2019).Lewis M, Liu Y, Goyal N, Ghazvininejad M, Mohamed A, Levy O, Stoyanov V, Zettlemoyer L. Bart: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. 2019. ArXiv preprint. \\[ [DOI](https://doi.org/10.48550/arXiv.1910.13461)\\]\n- Liu, Ju & Wang (2024).Liu Y, Ju S, Wang J. Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences. BMC Medical Informatics and Decision Making. 2024;24(1):75. doi: 10.1186/s12911-024-02481-8. \\[ [DOI](https://doi.org/10.1186/s12911-024-02481-8)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10938713/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/38486198/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=BMC%20Medical%20Informatics%20and%20Decision%20Making&title=Exploring%20the%20potential%20of%20ChatGPT%20in%20medical%20dialogue%20summarization:%20a%20study%20on%20consistency%20with%20human%20preferences&author=Y%20Liu&author=S%20Ju&author=J%20Wang&volume=24&issue=1&publication_year=2024&pages=75&pmid=38486198&doi=10.1186/s12911-024-02481-8&)\\]\n- Májovský et al. (2023).Májovský M, Černý M, Kasal M, Komarc M, Netuka D. Artificial intelligence can generate fraudulent but authentic-looking scientific medical articles: pandora’s box has been opened. Journal of Medical Internet Research. 2023;25:e46924. doi: 10.2196/46924. \\[ [DOI](https://doi.org/10.2196/46924)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10267787/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37256685/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Medical%20Internet%20Research&title=Artificial%20intelligence%20can%20generate%20fraudulent%20but%20authentic-looking%20scientific%20medical%20articles:%20pandora%E2%80%99s%20box%20has%20been%20opened&author=M%20M%C3%A1jovsk%C3%BD&author=M%20%C4%8Cern%C3%BD&author=M%20Kasal&author=M%20Komarc&author=D%20Netuka&volume=25&publication_year=2023&pages=e46924&pmid=37256685&doi=10.2196/46924&)\\]\n- Masters (2023).Masters K. Ethical use of artificial intelligence in health professions education: AMEE Guide No. 158. Medical Teacher. 2023;45(158):574–584. doi: 10.1080/0142159X.2023.2186203. \\[ [DOI](https://doi.org/10.1080/0142159X.2023.2186203)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/36912253/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Medical%20Teacher&title=Ethical%20use%20of%20artificial%20intelligence%20in%20health%20professions%20education:%20AMEE%20Guide%20No.%20158&author=K%20Masters&volume=45&issue=158&publication_year=2023&pages=574-584&pmid=36912253&doi=10.1080/0142159X.2023.2186203&)\\]\n- McGowan et al. (2023).McGowan A, Gui Y, Dobbs M, Shuster S, Cotter M, Selloni A, Goodman M, Srivastava A, Cecchi GA, Corcoran CM. ChatGPT and Bard exhibit spontaneous citation fabrication during psychiatry literature search. Psychiatry Research. 2023;326(2):115334. doi: 10.1016/j.psychres.2023.115334. \\[ [DOI](https://doi.org/10.1016/j.psychres.2023.115334)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10424704/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37499282/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Psychiatry%20Research&title=ChatGPT%20and%20Bard%20exhibit%20spontaneous%20citation%20fabrication%20during%20psychiatry%20literature%20search&author=A%20McGowan&author=Y%20Gui&author=M%20Dobbs&author=S%20Shuster&author=M%20Cotter&volume=326&issue=2&publication_year=2023&pages=115334&pmid=37499282&doi=10.1016/j.psychres.2023.115334&)\\]\n- McGrath et al. (2023).McGrath C, Cerratto Pargman T, Juth N, Palmgren PJ. University teachers’ perceptions of responsibility and artificial intelligence in higher education-an experimental philosophical study. Computers and Education: Artificial Intelligence. 2023;4(2):Article 100139. doi: 10.1016/j.caeai.2023.100139. \\[ [DOI](https://doi.org/10.1016/j.caeai.2023.100139)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Computers%20and%20Education:%20Artificial%20Intelligence&title=University%20teachers%E2%80%99%20perceptions%20of%20responsibility%20and%20artificial%20intelligence%20in%20higher%20education-an%20experimental%20philosophical%20study&author=C%20McGrath&author=T%20Cerratto%20Pargman&author=N%20Juth&author=PJ%20Palmgren&volume=4&issue=2&publication_year=2023&pages=Article%20100139&doi=10.1016/j.caeai.2023.100139&)\\]\n- Moons & Van Bulck (2023).Moons P, Van Bulck L. Using ChatGPT and Google Bard to improve the readability of written patient information: a proof of concept. European Journal of Cardiovascular Nursing. 2023;23(2):122–126. doi: 10.1093/eurjcn/zvad087. \\[ [DOI](https://doi.org/10.1093/eurjcn/zvad087)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37603843/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=European%20Journal%20of%20Cardiovascular%20Nursing&title=Using%20ChatGPT%20and%20Google%20Bard%20to%20improve%20the%20readability%20of%20written%20patient%20information:%20a%20proof%20of%20concept&author=P%20Moons&author=L%20Van%20Bulck&volume=23&issue=2&publication_year=2023&pages=122-126&pmid=37603843&doi=10.1093/eurjcn/zvad087&)\\]\n- OpenAI (2023).OpenAI Terms of use. 2023. [https://openai.com/policies/terms-of-use](https://openai.com/policies/terms-of-use) [https://openai.com/policies/terms-of-use](https://openai.com/policies/terms-of-use)\n- Oralbekova et al. (2023).Oralbekova D, Mamyrbayev O, Othman M, Kassymova D, Mukhsina K. Contemporary approaches in evolving language models. Applied Sciences. 2023;13(23):12901. doi: 10.3390/app132312901. \\[ [DOI](https://doi.org/10.3390/app132312901)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Applied%20Sciences&title=Contemporary%20approaches%20in%20evolving%20language%20models&author=D%20Oralbekova&author=O%20Mamyrbayev&author=M%20Othman&author=D%20Kassymova&author=K%20Mukhsina&volume=13&issue=23&publication_year=2023&pages=12901&doi=10.3390/app132312901&)\\]\n- Radanliev (2024).Radanliev P. Artificial intelligence: reflecting on the past and looking towards the next paradigm shift. Journal of Experimental and Theoretical Artificial Intelligence. 2024;13(5):1–18. doi: 10.1080/0952813X.2024.2323042. \\[ [DOI](https://doi.org/10.1080/0952813X.2024.2323042)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Experimental%20and%20Theoretical%20Artificial%20Intelligence&title=Artificial%20intelligence:%20reflecting%20on%20the%20past%20and%20looking%20towards%20the%20next%20paradigm%20shift&author=P%20Radanliev&volume=13&issue=5&publication_year=2024&pages=1-18&doi=10.1080/0952813X.2024.2323042&)\\]\n- Raffel et al. (2020).Raffel C, Shazeer N, Roberts A, Lee K, Narang S, Matena M, Zhou Y, Li W, Liu PJ. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research. 2020;21(140):1–67. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Machine%20Learning%20Research&title=Exploring%20the%20limits%20of%20transfer%20learning%20with%20a%20unified%20text-to-text%20transformer&author=C%20Raffel&author=N%20Shazeer&author=A%20Roberts&author=K%20Lee&author=S%20Narang&volume=21&issue=140&publication_year=2020&pages=1-67&)\\]\n- Rannikmäe, Holbrook & Soobard (2020).Rannikmäe M, Holbrook J, Soobard R. Science Education in Theory and Practice: An Introductory Guide to Learning Theory. Cham: Springer International Publishing; 2020. Social constructivism—Jerome Bruner; pp. 259–275. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Science%20Education%20in%20Theory%20and%20Practice:%20An%20Introductory%20Guide%20to%20Learning%20Theory&author=M%20Rannikm%C3%A4e&author=J%20Holbrook&author=R%20Soobard&publication_year=2020&)\\]\n- Rao (2023).Rao D. The urgent need for healthcare workforce upskilling and ethical considerations in the era of AI-assisted medicine. Indian Journal of Otolaryngology and Head & Neck Surgery. 2023;75(3):2638–2639. doi: 10.1007/s12070-023-03755-9. \\[ [DOI](https://doi.org/10.1007/s12070-023-03755-9)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC10132410/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/37362116/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Indian%20Journal%20of%20Otolaryngology%20and%20Head%20&%20Neck%20Surgery&title=The%20urgent%20need%20for%20healthcare%20workforce%20upskilling%20and%20ethical%20considerations%20in%20the%20era%20of%20AI-assisted%20medicine&author=D%20Rao&volume=75&issue=3&publication_year=2023&pages=2638-2639&pmid=37362116&doi=10.1007/s12070-023-03755-9&)\\]\n- Rasul et al. (2023).Rasul T, Nair S, Kalendra D, Robin M, Santini FO, Ladeira WJ, Sun M, Day I, Rather RA, Heathcote L. The role of ChatGPT in higher education: benefits, challenges, and future research directions. Journal of Applied Learning and Teaching. 2023;6(1):41–56. doi: 10.37074/jalt.2023.6.1.29. \\[ [DOI](https://doi.org/10.37074/jalt.2023.6.1.29)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Applied%20Learning%20and%20Teaching&title=The%20role%20of%20ChatGPT%20in%20higher%20education:%20benefits,%20challenges,%20and%20future%20research%20directions&author=T%20Rasul&author=S%20Nair&author=D%20Kalendra&author=M%20Robin&author=FO%20Santini&volume=6&issue=1&publication_year=2023&pages=41-56&doi=10.37074/jalt.2023.6.1.29&)\\]\n- Rettberg (2022).Rettberg JW. ChatGPT is multilingual but monocultural, and it’s learning your values. 2022. [https://jilltxt.net/right-now-chatgpt-is-multilingual-but-monocultural-but-its-learning-your-values/](https://jilltxt.net/right-now-chatgpt-is-multilingual-but-monocultural-but-its-learning-your-values/) [https://jilltxt.net/right-now-chatgpt-is-multilingual-but-monocultural-but-its-learning-your-values/](https://jilltxt.net/right-now-chatgpt-is-multilingual-but-monocultural-but-its-learning-your-values/)\n- Roberts, Dowell & Nie (2019).Roberts K, Dowell A, Nie J-B. Attempting rigour and replicability in thematic analysis of qualitative research data; a case study of codebook development. BMC Medical Research Methodology. 2019;19(1):66. doi: 10.1186/s12874-019-0707-y. \\[ [DOI](https://doi.org/10.1186/s12874-019-0707-y)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC6437927/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/30922220/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=BMC%20Medical%20Research%20Methodology&title=Attempting%20rigour%20and%20replicability%20in%20thematic%20analysis%20of%20qualitative%20research%20data;%20a%20case%20study%20of%20codebook%20development&author=K%20Roberts&author=A%20Dowell&author=J-B%20Nie&volume=19&issue=1&publication_year=2019&pages=66&pmid=30922220&doi=10.1186/s12874-019-0707-y&)\\]\n- Roumeliotis & Tselikas (2023).Roumeliotis KI, Tselikas ND. ChatGPT and open-AI models: a preliminary review. Future Internet. 2023;15(6):192. doi: 10.3390/fi15060192. \\[ [DOI](https://doi.org/10.3390/fi15060192)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Future%20Internet&title=ChatGPT%20and%20open-AI%20models:%20a%20preliminary%20review&author=KI%20Roumeliotis&author=ND%20Tselikas&volume=15&issue=6&publication_year=2023&pages=192&doi=10.3390/fi15060192&)\\]\n- Sandberg (2013).Sandberg J. Deontology. In: Runehov ALC, Oviedo L, editors. Encyclopedia of Sciences and Religions. Netherlands: Springer Netherlands; 2013. pp. 603–608. \\[ [DOI](https://doi.org/10.1007/978-1-4020-8265-8_703)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Encyclopedia%20of%20Sciences%20and%20Religions&author=J%20Sandberg&publication_year=2013&)\\]\n- Schneider & Xhafa (2022).Schneider P, Xhafa F. Chapter 13-ethics, emerging research trends, issues and challenges: protecting patient data. In: Schneider P, Xhafa F, editors. Anomaly Detection and Complex Event Processing Over IoT Data Streams. Cambridge, MA: Academic Press; 2022. pp. 317–368. \\[ [DOI](https://doi.org/10.1016/B978-0-12-823818-9.00025-0)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Anomaly%20Detection%20and%20Complex%20Event%20Processing%20Over%20IoT%20Data%20Streams&author=P%20Schneider&author=F%20Xhafa&publication_year=2022&)\\]\n- Sezgin, Sirrianni & Linwood (2022).Sezgin E, Sirrianni J, Linwood SL. Operationalizing and implementing pretrained, large artificial intelligence linguistic models in the US health care system: outlook of generative pretrained transformer 3 (GPT-3) as a service model. JMIR Medical Informatics. 2022;10(2):e32875. doi: 10.2196/32875. \\[ [DOI](https://doi.org/10.2196/32875)\\] \\[ [PMC free article](https://pmc.ncbi.nlm.nih.gov/articles/PMC8874824/)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/35142635/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=JMIR%20Medical%20Informatics&title=Operationalizing%20and%20implementing%20pretrained,%20large%20artificial%20intelligence%20linguistic%20models%20in%20the%20US%20health%20care%20system:%20outlook%20of%20generative%20pretrained%20transformer%203%20(GPT-3)%20as%20a%20service%20model&author=E%20Sezgin&author=J%20Sirrianni&author=SL%20Linwood&volume=10&issue=2&publication_year=2022&pages=e32875&pmid=35142635&doi=10.2196/32875&)\\]\n- Shaik Vadla, Suresh & Viswanathan (2024).Shaik Vadla MK, Suresh MA, Viswanathan VK. Enhancing product design through AI-driven sentiment analysis of amazon reviews using BERT. Algorithms. 2024;17(2):Article 59. doi: 10.3390/a17020059. \\[ [DOI](https://doi.org/10.3390/a17020059)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Algorithms&title=Enhancing%20product%20design%20through%20AI-driven%20sentiment%20analysis%20of%20amazon%20reviews%20using%20BERT&author=MK%20Shaik%20Vadla&author=MA%20Suresh&author=VK%20Viswanathan&volume=17&issue=2&publication_year=2024&pages=Article%2059&doi=10.3390/a17020059&)\\]\n- Sheedy (2024).Sheedy AD. Exploration of multicultural student education on ethical issues in an Australian undergraduate nursing curriculum. Open Nursing Journal. 2024;18(1):Article e18744346277389. doi: 10.2174/0118744346277389231126185215. \\[ [DOI](https://doi.org/10.2174/0118744346277389231126185215)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Open%20Nursing%20Journal&title=Exploration%20of%20multicultural%20student%20education%20on%20ethical%20issues%20in%20an%20Australian%20undergraduate%20nursing%20curriculum&author=AD%20Sheedy&volume=18&issue=1&publication_year=2024&pages=Article%20e18744346277389&doi=10.2174/0118744346277389231126185215&)\\]\n- Soto-Pérez, Ávila-Palet & Núñez-Ríos (2022).Soto-Pérez M, Ávila-Palet J-E, Núñez-Ríos JE. Justice, deontology and moral meaningfulness as factors to improve student performance and academic achievement. Journal of Academic Ethics. 2022;20(3):375–397. doi: 10.1007/s10805-021-09423-3. \\[ [DOI](https://doi.org/10.1007/s10805-021-09423-3)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Journal%20of%20Academic%20Ethics&title=Justice,%20deontology%20and%20moral%20meaningfulness%20as%20factors%20to%20improve%20student%20performance%20and%20academic%20achievement&author=M%20Soto-P%C3%A9rez&author=J-E%20%C3%81vila-Palet&author=JE%20N%C3%BA%C3%B1ez-R%C3%ADos&volume=20&issue=3&publication_year=2022&pages=375-397&doi=10.1007/s10805-021-09423-3&)\\]\n- Stahl & Eke (2024).Stahl BC, Eke D. The ethics of ChatGPT–exploring the ethical issues of an emerging technology. International Journal of Information Management. 2024;74:Article 102700. doi: 10.1016/j.ijinfomgt.2023.102700. \\[ [DOI](https://doi.org/10.1016/j.ijinfomgt.2023.102700)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=International%20Journal%20of%20Information%20Management&title=The%20ethics%20of%20ChatGPT%E2%80%93exploring%20the%20ethical%20issues%20of%20an%20emerging%20technology&author=BC%20Stahl&author=D%20Eke&volume=74&publication_year=2024&pages=Article%20102700&doi=10.1016/j.ijinfomgt.2023.102700&)\\]\n- Stokel-Walker & Van Noorden (2023).Stokel-Walker C, Van Noorden R. What ChatGPT and generative AI mean for science. Nature. 2023;614(7947):214–216. doi: 10.1038/d41586-023-00340-6. \\[ [DOI](https://doi.org/10.1038/d41586-023-00340-6)\\] \\[ [PubMed](https://pubmed.ncbi.nlm.nih.gov/36747115/)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Nature&title=What%20ChatGPT%20and%20generative%20AI%20mean%20for%20science&author=C%20Stokel-Walker&author=R%20Van%20Noorden&volume=614&issue=7947&publication_year=2023&pages=214-216&pmid=36747115&doi=10.1038/d41586-023-00340-6&)\\]\n- Su & Yang (2023).Su J, Yang W. Unlocking the power of ChatGPT: a framework for applying generative AI in education. ECNU Review of Education. 2023;6(3):355–366. doi: 10.1177/20965311231168423. \\[ [DOI](https://doi.org/10.1177/20965311231168423)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=ECNU%20Review%20of%20Education&title=Unlocking%20the%20power%20of%20ChatGPT:%20a%20framework%20for%20applying%20generative%20AI%20in%20education&author=J%20Su&author=W%20Yang&volume=6&issue=3&publication_year=2023&pages=355-366&doi=10.1177/20965311231168423&)\\]\n- Suen & Hung (2023).Suen H-Y, Hung K-E. Building trust in automatic video interviews using various AI interfaces: tangibility, immediacy, and transparency. Computers in Human Behavior. 2023;143(4):107713. doi: 10.1016/j.chb.2023.107713. \\[ [DOI](https://doi.org/10.1016/j.chb.2023.107713)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Computers%20in%20Human%20Behavior&title=Building%20trust%20in%20automatic%20video%20interviews%20using%20various%20AI%20interfaces:%20tangibility,%20immediacy,%20and%20transparency&author=H-Y%20Suen&author=K-E%20Hung&volume=143&issue=4&publication_year=2023&pages=107713&doi=10.1016/j.chb.2023.107713&)\\]\n- Sweeney (2023).Sweeney S. Who wrote this? Essay mills and assessment-considerations regarding contract cheating and AI in higher education. The International Journal of Management Education. 2023;21(2):100818. doi: 10.1016/j.ijme.2023.100818. \\[ [DOI](https://doi.org/10.1016/j.ijme.2023.100818)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=The%20International%20Journal%20of%20Management%20Education&title=Who%20wrote%20this?%20Essay%20mills%20and%20assessment-considerations%20regarding%20contract%20cheating%20and%20AI%20in%20higher%20education&author=S%20Sweeney&volume=21&issue=2&publication_year=2023&pages=100818&doi=10.1016/j.ijme.2023.100818&)\\]\n- Tlili et al. (2023).Tlili A, Shehata B, Adarkwah MA, Bozkurt A, Hickey DT, Huang R, Agyemang B. What if the devil is my guardian angel: ChatGPT as a case study of using chatbots in education. Smart Learning Environments. 2023;10(1):15. doi: 10.1186/s40561-023-00237-x. \\[ [DOI](https://doi.org/10.1186/s40561-023-00237-x)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Smart%20Learning%20Environments&title=What%20if%20the%20devil%20is%20my%20guardian%20angel:%20ChatGPT%20as%20a%20case%20study%20of%20using%20chatbots%20in%20education&author=A%20Tlili&author=B%20Shehata&author=MA%20Adarkwah&author=A%20Bozkurt&author=DT%20Hickey&volume=10&issue=1&publication_year=2023&pages=15&doi=10.1186/s40561-023-00237-x&)\\]\n- Turk & Avcilar (2018).Turk Z, Avcilar MY. An investigation of the effect of personal values on the students’ ethical decision-making process. Eurasian Business Perspectives: Proceedings of the 20th Eurasia Business and Economics Society Conference-Vol 1.2018. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Turk%20Z,%20Avcilar%20MY.%20An%20investigation%20of%20the%20effect%20of%20personal%20values%20on%20the%20students%E2%80%99%20ethical%20decision-making%20process.%20Eurasian%20Business%20Perspectives:%20Proceedings%20of%20the%2020th%20Eurasia%20Business%20and%20Economics%20Society%20Conference-Vol%201.2018.)\\]\n- UNESCO (2023).UNESCO . Foundation models such as ChatGPT through the prism of the UNESCO recommendation on the ethics of artificial intelligence. Paris, France: UNESCO; 2023. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Foundation%20models%20such%20as%20ChatGPT%20through%20the%20prism%20of%20the%20UNESCO%20recommendation%20on%20the%20ethics%20of%20artificial%20intelligence&publication_year=2023&)\\]\n- Vázquez-Cano et al. (2023).Vázquez-Cano E, Ramírez-Hurtado JM, Sáez-López JM, López-Meneses E. ChatGPT: the brightest student in the class. Thinking Skills and Creativity. 2023;49:Article 101380. doi: 10.1016/j.tsc.2023.101380. \\[ [DOI](https://doi.org/10.1016/j.tsc.2023.101380)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Thinking%20Skills%20and%20Creativity&title=ChatGPT:%20the%20brightest%20student%20in%20the%20class&author=E%20V%C3%A1zquez-Cano&author=JM%20Ram%C3%ADrez-Hurtado&author=JM%20S%C3%A1ez-L%C3%B3pez&author=E%20L%C3%B3pez-Meneses&volume=49&publication_year=2023&pages=Article%20101380&doi=10.1016/j.tsc.2023.101380&)\\]\n- Venkataramana, Srividya & Cristin (2022).Venkataramana A, Srividya K, Cristin R. Abstractive text summarization using BART. MysuruCon 2022-2022 IEEE 2nd Mysore Sub Section International Conference.2022. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?Venkataramana%20A,%20Srividya%20K,%20Cristin%20R.%20Abstractive%20text%20summarization%20using%20BART.%20MysuruCon%202022-2022%20IEEE%202nd%20Mysore%20Sub%20Section%20International%20Conference.2022.)\\]\n- Vîșcu & Watkins (2021).Vîșcu L, Watkins C., Jr . A Guide to Clinical Supervision. Cambridge, USA: Academic Press; 2021. Chapter 5—Constructivism in clinical supervision. The supervision pyramid and the constructivist paradigm of learning; pp. 39–49. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=A%20Guide%20to%20Clinical%20Supervision&author=L%20V%C3%AE%C8%99cu&author=C%20Watkins&publication_year=2021&)\\]\n- Vygotsky (1962).Vygotsky LS. Thought and language. Cambridge, MA: MIT Press; 1962. \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Thought%20and%20language&author=LS%20Vygotsky&publication_year=1962&)\\]\n- Wæraas (2022).Wæraas A. Thematic analysis: making values emerge from texts. In: Espedal G, Løvaas BJ, Sirris S, Wæraas A, editors. Researching Values: Methodological Approaches for Understanding Values Work in Organisations and Leadership. New York City: Springer International Publishing; 2022. pp. 153–170. \\[ [DOI](https://doi.org/10.1007/978-3-030-90769-3_9)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?title=Researching%20Values:%20Methodological%20Approaches%20for%20Understanding%20Values%20Work%20in%20Organisations%20and%20Leadership&author=A%20W%C3%A6raas&publication_year=2022&)\\]\n- Yildirim-Erbasli & Bulut (2023).Yildirim-Erbasli SN, Bulut O. Conversation-based assessment: a novel approach to boosting test-taking effort in digital formative assessment. Computers and Education: Artificial Intelligence. 2023;4:Article 100135. doi: 10.1016/j.caeai.2023.100135. \\[ [DOI](https://doi.org/10.1016/j.caeai.2023.100135)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Computers%20and%20Education:%20Artificial%20Intelligence&title=Conversation-based%20assessment:%20a%20novel%20approach%20to%20boosting%20test-taking%20effort%20in%20digital%20formative%20assessment&author=SN%20Yildirim-Erbasli&author=O%20Bulut&volume=4&publication_year=2023&pages=Article%20100135&doi=10.1016/j.caeai.2023.100135&)\\]\n- Yilmaz & Yilmaz (2023).Yilmaz R, Yilmaz FGK. The effect of generative artificial intelligence (AI)-based tool use on students’ computational thinking skills, programming self-efficacy and motivation. Computers and Education: Artificial Intelligence. 2023;4(2):100147. doi: 10.1016/j.caeai.2023.100147. \\[ [DOI](https://doi.org/10.1016/j.caeai.2023.100147)\\] \\[ [Google Scholar](https://scholar.google.com/scholar_lookup?journal=Computers%20and%20Education:%20Artificial%20Intelligence&title=The%20effect%20of%20generative%20artificial%20intelligence%20(AI)-based%20tool%20use%20on%20students%E2%80%99%20computational%20thinking%20skills,%20programming%20self-efficacy%20and%20motivation&author=R%20Yilmaz&author=FGK%20Yilmaz&volume=4&issue=2&publication_year=2023&pages=100147&doi=10.1016/j.caeai.2023.100147&)\\]\n\n## Associated Data\n\n_This section collects any data citations, data availability statements, or supplementary materials included in this article._\n\n### Data Availability Statement\n\nThe following information was supplied regarding data availability:\n\nThis is a literature review and no new data were created or analyzed.\n\n## ACTIONS\n\n- [View on publisher site](https://doi.org/10.7717/peerj-cs.2105)\n- [PDF (8.0 MB)](https://pmc.ncbi.nlm.nih.gov/pdf/peerj-cs-10-2105.pdf)\n- Cite\n- Collections\n- Permalink\n\n\n## PERMALINK\n\n\n\nCopy\n\n\n## RESOURCES\n\n### Similar articles\n\n### Cited by other articles\n\n### Links to NCBI Databases\n\nBack to Top"}
