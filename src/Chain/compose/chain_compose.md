# ChainML Documentation

**ChainML (Chain Markup Language)** is a JSON-based domain-specific language for defining LLM workflows as Directed Acyclic Graphs (DAGs). ChainML workflows can be generated by LLMs and seamlessly converted to executable Chain framework code. This is inspired by BAML, Prompt Flow, and my own PromptFlow project.

## Table of Contents

- [Overview](#overview)
- [Basic Syntax](#basic-syntax)
- [Workflow Structure](#workflow-structure)
- [Steps](#steps)
- [Data Flow & Variables](#data-flow--variables)
- [Parser Types](#parser-types)
- [Conditional Logic](#conditional-logic)
- [Examples](#examples)
- [Best Practices](#best-practices)

## Overview

ChainML is designed for:
- **LLM Generation**: JSON syntax that LLMs can reliably generate without syntax errors
- **Human Readability**: Self-documenting with clear descriptions 
- **DAG Validation**: Built-in dependency tracking prevents cycles
- **Chain Integration**: Direct mapping to Chain framework components

### Core Principles

1. **Explicit Dependencies**: Every step declares its dependencies
2. **Self-Documenting**: Required descriptions for all components
3. **Type Safety**: Structured data schemas with validation
4. **Variable Flow**: Clear data passing between steps

## Basic Syntax

Every ChainML file defines a single workflow:

```json
{
  "workflow": {
    "name": "Workflow Name",
    "description": "What this workflow does",
    "inputs": {
      // Define workflow inputs
    },
    "outputs": {
      // Define workflow outputs
    },
    "steps": {
      // Define processing steps
    }
  }
}
```

## Workflow Structure

### Metadata

```json
{
  "workflow": {
    "name": "Content Analysis Pipeline",
    "description": "Analyzes web content for sentiment and topics"
  }
}
```

- **name**: Human-readable workflow name
- **description**: What the workflow accomplishes

### Inputs

Define data that flows into the workflow:

```json
{
  "inputs": {
    "url": {
      "type": "string",
      "description": "URL of content to analyze"
    },
    "analysis_depth": {
      "type": "string",
      "default": "standard",
      "description": "Analysis depth: quick, standard, or detailed"
    },
    "max_topics": {
      "type": "int",
      "default": 5,
      "description": "Maximum number of topics to extract"
    }
  }
}
```

**Input Fields:**
- **type**: Data type (`string`, `int`, `float`, `bool`)
- **description**: Required explanation of the input's purpose
- **default**: Optional default value

### Outputs

Define what the workflow returns:

```json
{
  "outputs": {
    "summary": {
      "from": "generate_summary.output",
      "description": "Generated content summary"
    },
    "sentiment_score": {
      "from": "analyze_sentiment.output.confidence",
      "description": "Sentiment confidence score"
    },
    "report": {
      "from": "compile_report.output",
      "description": "Complete analysis report"
    }
  }
}
```

**Output Fields:**
- **from**: Reference to step output (see [Variable References](#variable-references))
- **description**: Required explanation of the output

## Steps

Steps are the core processing units of ChainML workflows. Each step corresponds to a Chain function call.

### Basic Step Structure

```json
{
  "steps": {
    "extract_content": {
      "model": "gpt-4o-mini",
      "description": "Extract main content from webpage",
      "prompt": "Extract the main text content from this URL: {{inputs.url}}\n\nFocus on the primary article content, ignore navigation and ads.",
      "depends_on": []
    }
  }
}
```

### Required Step Fields

- **model**: LLM model to use (maps to Chain's `Model()`)
- **description**: Required explanation of what this step does
- **prompt**: Jinja2 template for the LLM prompt (maps to Chain's `Prompt()`)
- **depends_on**: Array of step names this step depends on

### Optional Step Fields

- **parser**: Structured output configuration (maps to Chain's `Parser()`)
- **condition**: Conditional execution logic

### Step Dependencies

Dependencies create the DAG structure:

```json
{
  "steps": {
    "extract_content": {
      "model": "gpt-4o-mini",
      "description": "Extract content",
      "prompt": "Extract content from {{inputs.url}}",
      "depends_on": []
    },
    "generate_summary": {
      "model": "gpt-4o-mini", 
      "description": "Generate summary",
      "prompt": "Summarize: {{extract_content.output}}",
      "depends_on": ["extract_content"]
    },
    "analyze_sentiment": {
      "model": "claude-3-5-haiku",
      "description": "Analyze sentiment",
      "prompt": "Sentiment of: {{generate_summary.output}}",
      "depends_on": ["generate_summary"]
    },
    "final_report": {
      "model": "gpt-4o-mini",
      "description": "Compile final report", 
      "prompt": "Create report from summary: {{generate_summary.output}} and sentiment: {{analyze_sentiment.output}}",
      "depends_on": ["generate_summary", "analyze_sentiment"]
    }
  }
}
```

**Parallel Execution**: Steps with no interdependencies can run in parallel:

```json
{
  "steps": {
    "sentiment_analysis": {
      "depends_on": ["extract_content"]
    },
    "topic_extraction": {
      "depends_on": ["extract_content"]
    },
    "entity_recognition": {
      "depends_on": ["extract_content"]
    }
  }
}
```

## Data Flow & Variables

ChainML uses Jinja2 templating for variable substitution in prompts.

### Variable References

**Workflow Inputs:**
```json
{
  "prompt": "Analyze this URL: {{inputs.url}} with depth {{inputs.analysis_depth}}"
}
```

**Step Outputs (String):**
```json
{
  "prompt": "Sentiment of this summary: {{generate_summary.output}}"
}
```

**Step Outputs (Structured Data):**
```json
{
  "prompt": "Title: {{extract_content.output.title}}\nWord Count: {{extract_content.output.word_count}}\nMain Content: {{extract_content.output.text}}"
}
```

**Jinja2 Filters:**
```json
{
  "prompt": "Topics found: {{topic_extraction.output|join(\", \")}}\nEmotions detected: {{sentiment_analysis.output.emotions|join(\"; \")}}"
}
```

### Jinja2 Conditionals in Prompts

```json
{
  "prompt": "{% if inputs.analysis_depth == \"quick\" %}\nProvide a brief 1-sentence summary.\n{% elif inputs.analysis_depth == \"standard\" %}\nProvide a paragraph summary.\n{% else %}\nProvide a detailed multi-paragraph analysis.\n{% endif %}\n\nContent: {{extract_content.output.text}}"
}
```

## Parser Types

Parsers define how to structure LLM outputs (maps to Chain's `Parser()` with Pydantic models).

### String Output (Default)

```json
{
  "generate_summary": {
    "model": "gpt-4o-mini",
    "prompt": "Summarize: {{inputs.text}}"
  }
}
```

### JSON Array Output

```json
{
  "extract_topics": {
    "model": "gpt-4o-mini",
    "prompt": "Extract 5 topics as JSON array: {{inputs.text}}",
    "parser": {
      "type": "json",
      "schema": "list[string]"
    }
  }
}
```

### Structured Output

```json
{
  "analyze_sentiment": {
    "model": "claude-3-5-haiku",
    "prompt": "Analyze sentiment and return structured data:\n{{inputs.text}}",
    "parser": {
      "type": "structured",
      "title": "SentimentAnalysis",
      "schema": {
        "sentiment": "string",
        "confidence": "float", 
        "emotions": "list[string]",
        "reasoning": "string"
      }
    }
  }
}
```

### Complex Structured Output

```json
{
  "extract_entities": {
    "model": "gpt-4o-mini",
    "prompt": "Find people, places, organizations: {{inputs.text}}",
    "parser": {
      "type": "structured",
      "title": "EntityExtraction",
      "schema": {
        "people": "list[string]",
        "places": "list[string]",
        "organizations": "list[string]",
        "relationships": "dict",
        "confidence_scores": "dict"
      }
    }
  }
}
```

**Supported Parser Fields:**
- **type**: Parser type (`string`, `json`, `structured`)
- **title**: Optional name for the generated data model (used with `structured` type)
- **schema**: Data structure definition (required for `json` and `structured` types)

**Supported Schema Types:**
- `string`, `int`, `float`, `bool`
- `list[type]` (e.g., `list[string]`, `list[int]`)
- `dict` (for key-value data)
- Nested objects with multiple fields

### Parser Title Benefits

The optional `title` field provides several advantages:

- **Better Debugging**: Named Pydantic models are easier to identify in error messages
- **Code Generation**: More readable generated client code
- **Documentation**: Self-documenting data structures
- **Type Safety**: Clear type names in generated bindings

## Conditional Logic

### Step-Level Conditions

Execute steps only when conditions are met:

```json
{
  "steps": {
    "process_code": {
      "model": "claude-3-5-haiku",
      "prompt": "Analyze this code: {{inputs.content}}",
      "depends_on": ["detect_content_type"],
      "condition": {
        "when": "{{detect_content_type.output}} == 'code'"
      }
    },
    "process_article": {
      "model": "gpt-4o-mini",
      "prompt": "Summarize this article: {{inputs.content}}",
      "depends_on": ["detect_content_type"],
      "condition": {
        "when": "{{detect_content_type.output}} == 'article'"
      }
    }
  }
}
```

### Prompt-Level Conditionals

Use Jinja2 conditionals within prompts:

```json
{
  "adaptive_analysis": {
    "model": "gpt-4o-mini",
    "prompt": "{% if previous_step.output.confidence > 0.8 %}\nHigh confidence detected. Provide detailed analysis of: {{inputs.content}}\n{% else %}\nLow confidence. Provide basic analysis of: {{inputs.content}}\n{% endif %}",
    "depends_on": ["previous_step"]
  }
}
```

## Examples

### Linear Pipeline

```json
{
  "workflow": {
    "name": "Text Analysis Pipeline",
    "description": "Analyzes text through sequential processing steps",
    "inputs": {
      "text": {
        "type": "string",
        "description": "Text to analyze"
      }
    },
    "outputs": {
      "final_report": {
        "from": "compile_report.output",
        "description": "Complete analysis report"
      }
    },
    "steps": {
      "clean_text": {
        "model": "gpt-4o-mini",
        "description": "Clean and normalize input text",
        "prompt": "Clean this text, fix typos, normalize formatting: {{inputs.text}}",
        "depends_on": []
      },
      "extract_topics": {
        "model": "gpt-4o-mini",
        "description": "Extract main topics",
        "prompt": "Extract 5 main topics from: {{clean_text.output}}",
        "parser": {
          "type": "json",
          "schema": "list[string]"
        },
        "depends_on": ["clean_text"]
      },
      "analyze_sentiment": {
        "model": "claude-3-5-haiku",
        "description": "Analyze emotional sentiment",
        "prompt": "Analyze sentiment: {{clean_text.output}}",
        "parser": {
          "type": "structured",
          "title": "SentimentResult",
          "schema": {
            "sentiment": "string",
            "confidence": "float"
          }
        },
        "depends_on": ["clean_text"]
      },
      "compile_report": {
        "model": "gpt-4o-mini",
        "description": "Compile comprehensive analysis",
        "prompt": "Create analysis report:\n\nText: {{clean_text.output}}\nTopics: {{extract_topics.output|join(\", \")}}\nSentiment: {{analyze_sentiment.output.sentiment}} ({{analyze_sentiment.output.confidence}})",
        "depends_on": ["extract_topics", "analyze_sentiment"]
      }
    }
  }
}
```

### Conditional Branching

```json
{
  "workflow": {
    "name": "Content Router",
    "description": "Routes content to specialized processors based on type",
    "inputs": {
      "content": {
        "type": "string",
        "description": "Content to process"
      }
    },
    "outputs": {
      "result": {
        "from": "merge_results.output",
        "description": "Processed content result"
      }
    },
    "steps": {
      "detect_type": {
        "model": "gpt-4o-mini",
        "description": "Detect content type",
        "prompt": "What type of content is this? Choose one: email, article, code, resume\n\nContent: {{inputs.content}}",
        "depends_on": []
      },
      "process_email": {
        "model": "gpt-4o-mini",
        "description": "Extract email metadata",
        "prompt": "Extract sender, subject, key points: {{inputs.content}}",
        "parser": {
          "type": "structured",
          "title": "EmailData",
          "schema": {
            "sender": "string",
            "subject": "string",
            "key_points": "list[string]"
          }
        },
        "depends_on": ["detect_type"],
        "condition": {
          "when": "{{detect_type.output}} == 'email'"
        }
      },
      "process_article": {
        "model": "claude-3-5-haiku",
        "description": "Summarize article",
        "prompt": "Summarize in 3 key points: {{inputs.content}}",
        "parser": {
          "type": "json",
          "schema": "list[string]"
        },
        "depends_on": ["detect_type"],
        "condition": {
          "when": "{{detect_type.output}} == 'article'"
        }
      },
      "merge_results": {
        "model": "gpt-4o-mini",
        "description": "Merge results from conditional branches",
        "prompt": "Content type: {{detect_type.output}}\n\n{% if process_email.output %}\nEmail from {{process_email.output.sender}}: {{process_email.output.subject}}\nKey points: {{process_email.output.key_points|join(\"; \")}}\n{% elif process_article.output %}\nArticle summary: {{process_article.output|join(\"; \")}}\n{% endif %}",
        "depends_on": ["process_email", "process_article"]
      }
    }
  }
}
```

### Parallel Processing

```json
{
  "workflow": {
    "name": "Multi-Analysis Pipeline",
    "description": "Runs multiple analyses in parallel then combines results",
    "inputs": {
      "document": {
        "type": "string",
        "description": "Document to analyze"
      }
    },
    "outputs": {
      "combined_analysis": {
        "from": "combine_results.output",
        "description": "All analyses combined"
      }
    },
    "steps": {
      "sentiment_analysis": {
        "model": "claude-3-5-haiku",
        "description": "Analyze emotional sentiment",
        "prompt": "Sentiment analysis: {{inputs.document}}",
        "depends_on": []
      },
      "topic_extraction": {
        "model": "gpt-4o-mini",
        "description": "Extract main topics",
        "prompt": "Extract 5 topics: {{inputs.document}}",
        "parser": {
          "type": "json",
          "schema": "list[string]"
        },
        "depends_on": []
      },
      "entity_recognition": {
        "model": "gpt-4o-mini",
        "description": "Identify named entities",
        "prompt": "Find people, places, organizations: {{inputs.document}}",
        "parser": {
          "type": "structured",
          "title": "EntityData",
          "schema": {
            "people": "list[string]",
            "places": "list[string]",
            "organizations": "list[string]"
          }
        },
        "depends_on": []
      },
      "combine_results": {
        "model": "gpt-4o-mini",
        "description": "Synthesize all analysis results",
        "prompt": "Combine these analyses into a comprehensive report:\n\nSentiment: {{sentiment_analysis.output}}\nTopics: {{topic_extraction.output|join(\", \")}}\nPeople: {{entity_recognition.output.people|join(\", \")}}\nPlaces: {{entity_recognition.output.places|join(\", \")}}\nOrganizations: {{entity_recognition.output.organizations|join(\", \")}}",
        "parser": {
          "type": "structured",
          "title": "CombinedAnalysis",
          "schema": {
            "sentiment": "string",
            "main_topics": "list[string]",
            "key_entities": "dict",
            "summary": "string"
          }
        },
        "depends_on": ["sentiment_analysis", "topic_extraction", "entity_recognition"]
      }
    }
  }
}
```

## Best Practices

### For LLM Generation

1. **Use descriptive names**: `extract_content` not `step1`
2. **Include detailed descriptions**: Help LLMs understand purpose
3. **Be explicit about dependencies**: Don't rely on implicit ordering
4. **Use clear variable names**: `{{inputs.url}}` not `{{data}}`
5. **Escape quotes properly**: Use `\"` for quotes within JSON strings
6. **Use consistent formatting**: Proper JSON structure helps LLMs

### For Human Readability

1. **Group related steps**: Organize logically in the file
2. **Use consistent naming**: `analyze_sentiment` not `sentimentAnalysis`
3. **Document complex logic**: Explain non-obvious conditions
4. **Keep prompts focused**: One clear task per step
5. **Format JSON clearly**: Use proper indentation and spacing

### For Performance

1. **Minimize dependencies**: Enable parallel execution where possible
2. **Use appropriate models**: Fast models for simple tasks, powerful models for complex analysis
3. **Structure outputs properly**: Use parsers for data that feeds other steps
4. **Avoid unnecessary steps**: Combine simple operations when logical

### DAG Design

1. **Keep it acyclic**: No step should depend on its own output
2. **Minimize bottlenecks**: Avoid single steps that block many others
3. **Plan data flow**: Consider what each step needs from previous steps
4. **Test edge cases**: Ensure conditionals handle all possible inputs

### JSON-Specific Tips

1. **Validate JSON**: Use tools to ensure proper syntax before execution
2. **Handle multiline strings**: Use `\n` for line breaks in prompts
3. **Escape special characters**: Properly escape quotes, backslashes, etc.
4. **Use arrays for dependencies**: Always use `["step1", "step2"]` format
5. **Consistent quoting**: All keys and string values must be quoted
